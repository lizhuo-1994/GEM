eval_ep_rewmean,eval_time_elapsed,eval_eplenmean,total timesteps,eval mean 100 episode reward,eval_qs_difference,eval_discount_q,eval_qs,eval_abs_qs_difference,time_elapsed,train_time,env_time,act_time,episodes,qs_difference,n_updates,current_lr,fps,update_time,eplenmean,ep_rewmean,qs_abs_difference,discount_q,mean 100 episode reward,qs_mean
24.031300545454542,30,1000.0,1,24.3,-2.187175455932245,7.8329211456838514,-0.5595046,2.4517791,,,,,,,,,,,,,,,,
,,,4000,,,,,,43,0,6,0,4,1.3262776903976923,0,0.0003,90,3,1000.0,3.40275425,3.213881429641758,-5.1417699019457015e-14,3.4,0.62404174
,,,8000,,,,,,62,0,12,1,8,0.8419756177903714,0,0.0003,128,13,1000.0,-1.58857025,4.175871915844928,-1.3169590610796015e-13,-1.6,0.570135
25.261906999999997,31,1000.0,10001,24.6,-2.095299369297198,10.015424554308726,-0.5606357,2.2971044,,,,,,,,,,,,,,,,
,,,12000,,,,,,117,0,19,1,12,0.5575399619147504,0,0.0003,101,30,1000.0,-0.12107458333333347,3.406082255083448,2.8785166652536114e-13,-0.1,0.6061605
,,,16000,,,,,,148,0,25,2,16,-3.1439156547011664,0,0.0003,107,53,1000.0,3.347022875,5.881823399991671,-3.1059282678079683e-13,3.3,0.6008581
,,,20000,,,,,,186,0,31,3,20,2.506480411304487,0,0.0003,107,82,1000.0,1.3424410500000001,4.575307866762336,4.569292440339096e-15,1.3,0.5314182
24.550171545454546,31,1000.0,20001,24.6,-2.1334129291213775,8.896374769530704,-0.55913687,2.3576918,,,,,,,,,,,,,,,,
,,,24000,,,,,,260,0,37,3,24,0.9377906450740834,0,0.0003,92,117,1000.0,0.8767193750000001,2.8419872311747048,-5.0604900299414184e-14,0.9,0.5496645
