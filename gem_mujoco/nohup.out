Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 4, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'hopper_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_0
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'hopper_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_1
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'hopper_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_2
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'hopper_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_3
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'hopper_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_0
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'hopper_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_4
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'hopper_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_1
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'walker_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_0
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'hopper_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_2
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'walker_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_1
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'hopper_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_3
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'walker_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_2
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'hopper_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_0
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

max_step:  1000
Box(-inf, inf, (11,), float64) Box(-1.0, 1.0, (3,), float32)
max_step:  1000
seed=0, logdir=./log_gem/mujoco/gem+tbp/hopper_gem+tbp_0
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/run/train.py:30: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-05-04 14:53:44.461159: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-05-04 14:53:44.468692: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz
2022-05-04 14:53:44.469042: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562815a4ade0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-05-04 14:53:44.469070: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:98: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/policies.py:283: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'hopper_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_4
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:138: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:203: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:226: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'walker_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_3
WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:251: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:261: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'walker_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_0
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:264: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
GEM Agent Here
TD3 Update Memory Many Agent here
here (?, 1)
model building finished
-----------------------------------------
| eval mean 100 episod... | 23.4        |
| eval_abs_qs_difference  | 10.0202875  |
| eval_discount_q         | 21.1        |
| eval_ep_rewmean         | 23.5        |
| eval_eplenmean          | 27.3        |
| eval_qs                 | -0.39565918 |
| eval_qs_difference      | -10         |
| eval_time_elapsed       | 0           |
| total timesteps         | 1           |
-----------------------------------------
{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'walker_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_4
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 10.4       |
| env_time                | 0          |
| ep_rewmean              | 17.1       |
| episodes                | 4          |
| eplenmean               | 18         |
| fps                     | 49         |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 8.55       |
| qs_difference           | -8.55      |
| qs_mean                 | 0.67865396 |
| time_elapsed            | 1          |
| total timesteps         | 72         |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 2.24      |
| env_time                | 0         |
| ep_rewmean              | 25.1      |
| episodes                | 8         |
| eplenmean               | 24        |
| fps                     | 93        |
| mean 100 episode reward | 25.1      |
| n_updates               | 0         |
| qs_abs_difference       | 2.49      |
| qs_difference           | -2.44     |
| qs_mean                 | 0.7891239 |
| time_elapsed            | 2         |
| total timesteps         | 192       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 2.23       |
| env_time                | 0          |
| ep_rewmean              | 32.2       |
| episodes                | 12         |
| eplenmean               | 28.5       |
| fps                     | 139        |
| mean 100 episode reward | 32.2       |
| n_updates               | 0          |
| qs_abs_difference       | 3.57       |
| qs_difference           | -3.54      |
| qs_mean                 | 0.72496027 |
| time_elapsed            | 2          |
| total timesteps         | 342        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 8.35      |
| env_time                | 0         |
| ep_rewmean              | 27.2      |
| episodes                | 16        |
| eplenmean               | 26.1      |
| fps                     | 153       |
| mean 100 episode reward | 27.2      |
| n_updates               | 0         |
| qs_abs_difference       | 7.28      |
| qs_difference           | -7.28     |
| qs_mean                 | 0.7073544 |
| time_elapsed            | 2         |
| total timesteps         | 418       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.16       |
| env_time                | 1          |
| ep_rewmean              | 25.2       |
| episodes                | 20         |
| eplenmean               | 26.2       |
| fps                     | 171        |
| mean 100 episode reward | 25.2       |
| n_updates               | 0          |
| qs_abs_difference       | 3.61       |
| qs_difference           | -3.45      |
| qs_mean                 | 0.64365005 |
| time_elapsed            | 3          |
| total timesteps         | 524        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 10.2      |
| env_time                | 1         |
| ep_rewmean              | 23        |
| episodes                | 24        |
| eplenmean               | 24.9      |
| fps                     | 186       |
| mean 100 episode reward | 23        |
| n_updates               | 0         |
| qs_abs_difference       | 9.41      |
| qs_difference           | -9.41     |
| qs_mean                 | 0.7212225 |
| time_elapsed            | 3         |
| total timesteps         | 597       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.53      |
| env_time                | 1         |
| ep_rewmean              | 23.4      |
| episodes                | 28        |
| eplenmean               | 25.2      |
| fps                     | 193       |
| mean 100 episode reward | 23.4      |
| n_updates               | 0         |
| qs_abs_difference       | 6.91      |
| qs_difference           | -6.91     |
| qs_mean                 | 0.6211666 |
| time_elapsed            | 3         |
| total timesteps         | 705       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 15.9      |
| env_time                | 1         |
| ep_rewmean              | 22.9      |
| episodes                | 32        |
| eplenmean               | 24.5      |
| fps                     | 203       |
| mean 100 episode reward | 22.9      |
| n_updates               | 0         |
| qs_abs_difference       | 14.8      |
| qs_difference           | -14.8     |
| qs_mean                 | 0.5774101 |
| time_elapsed            | 3         |
| total timesteps         | 785       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'walker_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_1
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 3.13      |
| env_time                | 1         |
| ep_rewmean              | 21.7      |
| episodes                | 36        |
| eplenmean               | 23.5      |
| fps                     | 207       |
| mean 100 episode reward | 21.7      |
| n_updates               | 0         |
| qs_abs_difference       | 2.01      |
| qs_difference           | -2        |
| qs_mean                 | 0.7445673 |
| time_elapsed            | 4         |
| total timesteps         | 847       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 3.36      |
| env_time                | 1         |
| ep_rewmean              | 21.1      |
| episodes                | 40        |
| eplenmean               | 23.2      |
| fps                     | 210       |
| mean 100 episode reward | 21.1      |
| n_updates               | 0         |
| qs_abs_difference       | 2.12      |
| qs_difference           | -1.77     |
| qs_mean                 | 0.7186053 |
| time_elapsed            | 4         |
| total timesteps         | 930       |
| train_time              | 0         |
| update_time             | 1         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 1.97      |
| env_time                | 1         |
| ep_rewmean              | 21.8      |
| episodes                | 44        |
| eplenmean               | 24.1      |
| fps                     | 220       |
| mean 100 episode reward | 21.8      |
| n_updates               | 0         |
| qs_abs_difference       | 1.86      |
| qs_difference           | -1.47     |
| qs_mean                 | 0.6516195 |
| time_elapsed            | 4         |
| total timesteps         | 1060      |
| train_time              | 0         |
| update_time             | 1         |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.8        |
| env_time                | 2          |
| ep_rewmean              | 21.7       |
| episodes                | 48         |
| eplenmean               | 24.3       |
| fps                     | 225        |
| mean 100 episode reward | 21.7       |
| n_updates               | 0          |
| qs_abs_difference       | 8.61       |
| qs_difference           | -8.61      |
| qs_mean                 | 0.68955374 |
| time_elapsed            | 5          |
| total timesteps         | 1168       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.66      |
| env_time                | 2         |
| ep_rewmean              | 21        |
| episodes                | 52        |
| eplenmean               | 23.7      |
| fps                     | 223       |
| mean 100 episode reward | 21        |
| n_updates               | 0         |
| qs_abs_difference       | 4.61      |
| qs_difference           | -4.59     |
| qs_mean                 | 0.6561754 |
| time_elapsed            | 5         |
| total timesteps         | 1234      |
| train_time              | 0         |
| update_time             | 1         |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'swimmer_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_0
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 7.94      |
| env_time                | 2         |
| ep_rewmean              | 21.2      |
| episodes                | 56        |
| eplenmean               | 24.1      |
| fps                     | 227       |
| mean 100 episode reward | 21.2      |
| n_updates               | 0         |
| qs_abs_difference       | 9.88      |
| qs_difference           | -9.88     |
| qs_mean                 | 0.6524194 |
| time_elapsed            | 5         |
| total timesteps         | 1347      |
| train_time              | 0         |
| update_time             | 1         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.89       |
| env_time                | 2          |
| ep_rewmean              | 21.1       |
| episodes                | 60         |
| eplenmean               | 24.1       |
| fps                     | 226        |
| mean 100 episode reward | 21.1       |
| n_updates               | 0          |
| qs_abs_difference       | 8.82       |
| qs_difference           | -8.82      |
| qs_mean                 | 0.60799325 |
| time_elapsed            | 6          |
| total timesteps         | 1443       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.21       |
| env_time                | 2          |
| ep_rewmean              | 20.6       |
| episodes                | 64         |
| eplenmean               | 23.9       |
| fps                     | 226        |
| mean 100 episode reward | 20.6       |
| n_updates               | 0          |
| qs_abs_difference       | 2.07       |
| qs_difference           | -1.99      |
| qs_mean                 | 0.77897125 |
| time_elapsed            | 6          |
| total timesteps         | 1532       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 2.93      |
| env_time                | 2         |
| ep_rewmean              | 20.9      |
| episodes                | 68        |
| eplenmean               | 24.5      |
| fps                     | 230       |
| mean 100 episode reward | 20.9      |
| n_updates               | 0         |
| qs_abs_difference       | 4.59      |
| qs_difference           | -4.59     |
| qs_mean                 | 0.7360182 |
| time_elapsed            | 7         |
| total timesteps         | 1668      |
| train_time              | 0         |
| update_time             | 2         |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.54      |
| env_time                | 2         |
| ep_rewmean              | 20.5      |
| episodes                | 72        |
| eplenmean               | 24.1      |
| fps                     | 228       |
| mean 100 episode reward | 20.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.9       |
| qs_difference           | -3.61     |
| qs_mean                 | 0.7120118 |
| time_elapsed            | 7         |
| total timesteps         | 1736      |
| train_time              | 0         |
| update_time             | 2         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.28       |
| env_time                | 2          |
| ep_rewmean              | 20         |
| episodes                | 76         |
| eplenmean               | 24         |
| fps                     | 228        |
| mean 100 episode reward | 20         |
| n_updates               | 0          |
| qs_abs_difference       | 2.37       |
| qs_difference           | -2.25      |
| qs_mean                 | 0.74630755 |
| time_elapsed            | 7          |
| total timesteps         | 1823       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'walker_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_2
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 7.19      |
| env_time                | 3         |
| ep_rewmean              | 19.9      |
| episodes                | 80        |
| eplenmean               | 23.8      |
| fps                     | 226       |
| mean 100 episode reward | 19.9      |
| n_updates               | 0         |
| qs_abs_difference       | 5.04      |
| qs_difference           | -5.02     |
| qs_mean                 | 0.6387382 |
| time_elapsed            | 8         |
| total timesteps         | 1903      |
| train_time              | 0         |
| update_time             | 3         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.9       |
| env_time                | 3         |
| ep_rewmean              | 19.4      |
| episodes                | 84        |
| eplenmean               | 23.3      |
| fps                     | 230       |
| mean 100 episode reward | 19.4      |
| n_updates               | 0         |
| qs_abs_difference       | 3.24      |
| qs_difference           | -2.96     |
| qs_mean                 | 0.6980223 |
| time_elapsed            | 8         |
| total timesteps         | 1959      |
| train_time              | 0         |
| update_time             | 3         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.92       |
| env_time                | 3          |
| ep_rewmean              | 18.9       |
| episodes                | 88         |
| eplenmean               | 23         |
| fps                     | 226        |
| mean 100 episode reward | 18.9       |
| n_updates               | 0          |
| qs_abs_difference       | 2.56       |
| qs_difference           | -2.56      |
| qs_mean                 | 0.74212253 |
| time_elapsed            | 8          |
| total timesteps         | 2020       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.37       |
| env_time                | 3          |
| ep_rewmean              | 18.7       |
| episodes                | 92         |
| eplenmean               | 22.9       |
| fps                     | 223        |
| mean 100 episode reward | 18.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.07       |
| qs_difference           | -2.44      |
| qs_mean                 | 0.63358974 |
| time_elapsed            | 9          |
| total timesteps         | 2104       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 14         |
| env_time                | 3          |
| ep_rewmean              | 18.5       |
| episodes                | 96         |
| eplenmean               | 22.8       |
| fps                     | 227        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 11.6       |
| qs_difference           | -11.6      |
| qs_mean                 | 0.63798386 |
| time_elapsed            | 9          |
| total timesteps         | 2187       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'swimmer_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_1
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.31       |
| env_time                | 3          |
| ep_rewmean              | 18.3       |
| episodes                | 100        |
| eplenmean               | 22.7       |
| fps                     | 225        |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 6.74       |
| qs_difference           | -6.73      |
| qs_mean                 | 0.64926946 |
| time_elapsed            | 10         |
| total timesteps         | 2267       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.82       |
| env_time                | 3          |
| ep_rewmean              | 18.1       |
| episodes                | 104        |
| eplenmean               | 22.5       |
| fps                     | 220        |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.57       |
| qs_difference           | -5.57      |
| qs_mean                 | 0.81764036 |
| time_elapsed            | 10         |
| total timesteps         | 2323       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 11         |
| env_time                | 3          |
| ep_rewmean              | 17.2       |
| episodes                | 108        |
| eplenmean               | 22         |
| fps                     | 224        |
| mean 100 episode reward | 17.2       |
| n_updates               | 0          |
| qs_abs_difference       | 8.29       |
| qs_difference           | -8.28      |
| qs_mean                 | 0.56664115 |
| time_elapsed            | 10         |
| total timesteps         | 2390       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.97       |
| env_time                | 3          |
| ep_rewmean              | 15.7       |
| episodes                | 112        |
| eplenmean               | 21.1       |
| fps                     | 218        |
| mean 100 episode reward | 15.7       |
| n_updates               | 0          |
| qs_abs_difference       | 5.05       |
| qs_difference           | -5.02      |
| qs_mean                 | 0.72809476 |
| time_elapsed            | 11         |
| total timesteps         | 2450       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.68      |
| env_time                | 3         |
| ep_rewmean              | 16        |
| episodes                | 116       |
| eplenmean               | 21.4      |
| fps                     | 217       |
| mean 100 episode reward | 16        |
| n_updates               | 0         |
| qs_abs_difference       | 5.81      |
| qs_difference           | -5.74     |
| qs_mean                 | 0.6306311 |
| time_elapsed            | 11        |
| total timesteps         | 2562      |
| train_time              | 0         |
| update_time             | 5         |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'walker_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_3
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.63       |
| env_time                | 4          |
| ep_rewmean              | 15.8       |
| episodes                | 120        |
| eplenmean               | 21.2       |
| fps                     | 213        |
| mean 100 episode reward | 15.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.66       |
| qs_difference           | -4.63      |
| qs_mean                 | 0.75683063 |
| time_elapsed            | 12         |
| total timesteps         | 2640       |
| train_time              | 0          |
| update_time             | 5          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 9.06      |
| env_time                | 4         |
| ep_rewmean              | 16.1      |
| episodes                | 124       |
| eplenmean               | 21.2      |
| fps                     | 209       |
| mean 100 episode reward | 16.1      |
| n_updates               | 0         |
| qs_abs_difference       | 6.17      |
| qs_difference           | -6.12     |
| qs_mean                 | 0.6074324 |
| time_elapsed            | 12        |
| total timesteps         | 2715      |
| train_time              | 0         |
| update_time             | 6         |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.16       |
| env_time                | 4          |
| ep_rewmean              | 15.5       |
| episodes                | 128        |
| eplenmean               | 20.9       |
| fps                     | 206        |
| mean 100 episode reward | 15.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.46       |
| qs_difference           | -4.46      |
| qs_mean                 | 0.64939153 |
| time_elapsed            | 13         |
| total timesteps         | 2800       |
| train_time              | 0          |
| update_time             | 6          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.44       |
| env_time                | 4          |
| ep_rewmean              | 15.3       |
| episodes                | 132        |
| eplenmean               | 20.9       |
| fps                     | 209        |
| mean 100 episode reward | 15.3       |
| n_updates               | 0          |
| qs_abs_difference       | 6.75       |
| qs_difference           | -6.75      |
| qs_mean                 | 0.65874374 |
| time_elapsed            | 13         |
| total timesteps         | 2876       |
| train_time              | 0          |
| update_time             | 6          |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'swimmer_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_2
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.82       |
| env_time                | 4          |
| ep_rewmean              | 15.3       |
| episodes                | 136        |
| eplenmean               | 21         |
| fps                     | 205        |
| mean 100 episode reward | 15.3       |
| n_updates               | 0          |
| qs_abs_difference       | 8.01       |
| qs_difference           | -8.01      |
| qs_mean                 | 0.60283136 |
| time_elapsed            | 14         |
| total timesteps         | 2945       |
| train_time              | 0          |
| update_time             | 7          |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 2.91       |
| env_time                | 4          |
| ep_rewmean              | 15.7       |
| episodes                | 140        |
| eplenmean               | 21.2       |
| fps                     | 204        |
| mean 100 episode reward | 15.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.15       |
| qs_difference           | -3.14      |
| qs_mean                 | 0.78309965 |
| time_elapsed            | 14         |
| total timesteps         | 3054       |
| train_time              | 0          |
| update_time             | 7          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.68       |
| env_time                | 4          |
| ep_rewmean              | 15.3       |
| episodes                | 144        |
| eplenmean               | 21.1       |
| fps                     | 203        |
| mean 100 episode reward | 15.3       |
| n_updates               | 0          |
| qs_abs_difference       | 10.4       |
| qs_difference           | -10.4      |
| qs_mean                 | 0.61666465 |
| time_elapsed            | 15         |
| total timesteps         | 3170       |
| train_time              | 0          |
| update_time             | 7          |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 7.56      |
| env_time                | 4         |
| ep_rewmean              | 15        |
| episodes                | 148       |
| eplenmean               | 20.8      |
| fps                     | 199       |
| mean 100 episode reward | 15        |
| n_updates               | 0         |
| qs_abs_difference       | 6.8       |
| qs_difference           | -6.8      |
| qs_mean                 | 0.7224445 |
| time_elapsed            | 16        |
| total timesteps         | 3245      |
| train_time              | 0         |
| update_time             | 8         |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'Walker2d-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'walker_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/walker_gem+tbp_4
--------------------------------------
| act_time                | 0        |
| current_lr              | 0.0003   |
| discount_q              | 9.49     |
| env_time                | 4        |
| ep_rewmean              | 15.1     |
| episodes                | 152      |
| eplenmean               | 20.9     |
| fps                     | 195      |
| mean 100 episode reward | 15.1     |
| n_updates               | 0        |
| qs_abs_difference       | 8.96     |
| qs_difference           | -8.96    |
| qs_mean                 | 0.61806  |
| time_elapsed            | 16       |
| total timesteps         | 3327     |
| train_time              | 0        |
| update_time             | 9        |
--------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 7.71      |
| env_time                | 5         |
| ep_rewmean              | 14.9      |
| episodes                | 156       |
| eplenmean               | 20.8      |
| fps                     | 193       |
| mean 100 episode reward | 14.9      |
| n_updates               | 0         |
| qs_abs_difference       | 7.11      |
| qs_difference           | -7.1      |
| qs_mean                 | 0.6479356 |
| time_elapsed            | 17        |
| total timesteps         | 3429      |
| train_time              | 0         |
| update_time             | 9         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.53      |
| env_time                | 5         |
| ep_rewmean              | 14.7      |
| episodes                | 160       |
| eplenmean               | 20.5      |
| fps                     | 195       |
| mean 100 episode reward | 14.7      |
| n_updates               | 0         |
| qs_abs_difference       | 4.89      |
| qs_difference           | -4.88     |
| qs_mean                 | 0.7506675 |
| time_elapsed            | 17        |
| total timesteps         | 3490      |
| train_time              | 0         |
| update_time             | 9         |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'swimmer_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_3
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.01      |
| env_time                | 5         |
| ep_rewmean              | 14.5      |
| episodes                | 164       |
| eplenmean               | 20.2      |
| fps                     | 192       |
| mean 100 episode reward | 14.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.7       |
| qs_difference           | -3.7      |
| qs_mean                 | 0.7261399 |
| time_elapsed            | 18        |
| total timesteps         | 3549      |
| train_time              | 0         |
| update_time             | 10        |
---------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 4.25      |
| env_time                | 5         |
| ep_rewmean              | 14.5      |
| episodes                | 168       |
| eplenmean               | 20        |
| fps                     | 190       |
| mean 100 episode reward | 14.5      |
| n_updates               | 0         |
| qs_abs_difference       | 2.36      |
| qs_difference           | -2.24     |
| qs_mean                 | 0.6313388 |
| time_elapsed            | 19        |
| total timesteps         | 3665      |
| train_time              | 0         |
| update_time             | 10        |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.2        |
| env_time                | 5          |
| ep_rewmean              | 14.5       |
| episodes                | 172        |
| eplenmean               | 19.9       |
| fps                     | 186        |
| mean 100 episode reward | 14.5       |
| n_updates               | 0          |
| qs_abs_difference       | 5.61       |
| qs_difference           | -5.61      |
| qs_mean                 | 0.56140393 |
| time_elapsed            | 20         |
| total timesteps         | 3731       |
| train_time              | 0          |
| update_time             | 11         |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'swimmer_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_0
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 9.45       |
| env_time                | 5          |
| ep_rewmean              | 14.8       |
| episodes                | 176        |
| eplenmean               | 20.1       |
| fps                     | 183        |
| mean 100 episode reward | 14.8       |
| n_updates               | 0          |
| qs_abs_difference       | 7.4        |
| qs_difference           | -7.37      |
| qs_mean                 | 0.62320507 |
| time_elapsed            | 20         |
| total timesteps         | 3831       |
| train_time              | 0          |
| update_time             | 11         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.63      |
| env_time                | 5         |
| ep_rewmean              | 14.7      |
| episodes                | 180       |
| eplenmean               | 20.2      |
| fps                     | 181       |
| mean 100 episode reward | 14.7      |
| n_updates               | 0         |
| qs_abs_difference       | 3.44      |
| qs_difference           | -2.4      |
| qs_mean                 | 0.6477624 |
| time_elapsed            | 21        |
| total timesteps         | 3923      |
| train_time              | 0         |
| update_time             | 12        |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'swimmer_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_4
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 12.9      |
| env_time                | 5         |
| ep_rewmean              | 14.9      |
| episodes                | 184       |
| eplenmean               | 20.4      |
| fps                     | 178       |
| mean 100 episode reward | 14.9      |
| n_updates               | 0         |
| qs_abs_difference       | 9.14      |
| qs_difference           | -9.14     |
| qs_mean                 | 0.6113868 |
| time_elapsed            | 22        |
| total timesteps         | 4003      |
| train_time              | 0         |
| update_time             | 13        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.65       |
| env_time                | 5          |
| ep_rewmean              | 15.1       |
| episodes                | 188        |
| eplenmean               | 20.6       |
| fps                     | 180        |
| mean 100 episode reward | 15.1       |
| n_updates               | 0          |
| qs_abs_difference       | 3.27       |
| qs_difference           | -3.15      |
| qs_mean                 | 0.66708034 |
| time_elapsed            | 22         |
| total timesteps         | 4084       |
| train_time              | 0          |
| update_time             | 13         |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.06      |
| env_time                | 6         |
| ep_rewmean              | 15.5      |
| episodes                | 192       |
| eplenmean               | 20.8      |
| fps                     | 178       |
| mean 100 episode reward | 15.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.92      |
| qs_difference           | -3.89     |
| qs_mean                 | 0.7389455 |
| time_elapsed            | 23        |
| total timesteps         | 4184      |
| train_time              | 0         |
| update_time             | 13        |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 3.97      |
| env_time                | 6         |
| ep_rewmean              | 15.4      |
| episodes                | 196       |
| eplenmean               | 20.6      |
| fps                     | 174       |
| mean 100 episode reward | 15.4      |
| n_updates               | 0         |
| qs_abs_difference       | 3.01      |
| qs_difference           | -3.01     |
| qs_mean                 | 0.6971009 |
| time_elapsed            | 24        |
| total timesteps         | 4250      |
| train_time              | 0         |
| update_time             | 14        |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'swimmer_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_1
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 3.41      |
| env_time                | 6         |
| ep_rewmean              | 15.4      |
| episodes                | 200       |
| eplenmean               | 20.7      |
| fps                     | 172       |
| mean 100 episode reward | 15.4      |
| n_updates               | 0         |
| qs_abs_difference       | 2.04      |
| qs_difference           | -1.31     |
| qs_mean                 | 0.6791726 |
| time_elapsed            | 25        |
| total timesteps         | 4334      |
| train_time              | 0         |
| update_time             | 15        |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.33       |
| env_time                | 6          |
| ep_rewmean              | 15.4       |
| episodes                | 204        |
| eplenmean               | 20.9       |
| fps                     | 169        |
| mean 100 episode reward | 15.4       |
| n_updates               | 0          |
| qs_abs_difference       | 2.66       |
| qs_difference           | -1.33      |
| qs_mean                 | 0.65832555 |
| time_elapsed            | 25         |
| total timesteps         | 4412       |
| train_time              | 0          |
| update_time             | 15         |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'doublependulum_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_0
--------------------------------------
| act_time                | 0        |
| current_lr              | 0.0003   |
| discount_q              | 7.81     |
| env_time                | 6        |
| ep_rewmean              | 15.4     |
| episodes                | 208      |
| eplenmean               | 20.9     |
| fps                     | 171      |
| mean 100 episode reward | 15.4     |
| n_updates               | 0        |
| qs_abs_difference       | 6.34     |
| qs_difference           | -6.34    |
| qs_mean                 | 0.776439 |
| time_elapsed            | 26       |
| total timesteps         | 4475     |
| train_time              | 0        |
| update_time             | 15       |
--------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.76      |
| env_time                | 6         |
| ep_rewmean              | 15.5      |
| episodes                | 212       |
| eplenmean               | 21        |
| fps                     | 169       |
| mean 100 episode reward | 15.5      |
| n_updates               | 0         |
| qs_abs_difference       | 4.73      |
| qs_difference           | -4.73     |
| qs_mean                 | 0.7166332 |
| time_elapsed            | 26        |
| total timesteps         | 4552      |
| train_time              | 0         |
| update_time             | 16        |
---------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.18       |
| env_time                | 6          |
| ep_rewmean              | 15.8       |
| episodes                | 216        |
| eplenmean               | 21         |
| fps                     | 168        |
| mean 100 episode reward | 15.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.09       |
| qs_difference           | -2.99      |
| qs_mean                 | 0.62954557 |
| time_elapsed            | 27         |
| total timesteps         | 4660       |
| train_time              | 0          |
| update_time             | 17         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.69       |
| env_time                | 6          |
| ep_rewmean              | 16         |
| episodes                | 220        |
| eplenmean               | 21         |
| fps                     | 166        |
| mean 100 episode reward | 16         |
| n_updates               | 0          |
| qs_abs_difference       | 5.85       |
| qs_difference           | -5.84      |
| qs_mean                 | 0.66401315 |
| time_elapsed            | 28         |
| total timesteps         | 4742       |
| train_time              | 0          |
| update_time             | 17         |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'swimmer_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_2
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.3        |
| env_time                | 6          |
| ep_rewmean              | 15.7       |
| episodes                | 224        |
| eplenmean               | 20.9       |
| fps                     | 163        |
| mean 100 episode reward | 15.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.75       |
| qs_difference           | -3.72      |
| qs_mean                 | 0.66544425 |
| time_elapsed            | 29         |
| total timesteps         | 4808       |
| train_time              | 0          |
| update_time             | 18         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.14       |
| env_time                | 6          |
| ep_rewmean              | 15.6       |
| episodes                | 228        |
| eplenmean               | 20.7       |
| fps                     | 164        |
| mean 100 episode reward | 15.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.09       |
| qs_difference           | -4.09      |
| qs_mean                 | 0.66373116 |
| time_elapsed            | 29         |
| total timesteps         | 4873       |
| train_time              | 0          |
| update_time             | 18         |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'doublependulum_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_1
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.08       |
| env_time                | 7          |
| ep_rewmean              | 15.5       |
| episodes                | 232        |
| eplenmean               | 20.7       |
| fps                     | 161        |
| mean 100 episode reward | 15.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.94       |
| qs_difference           | -2.3       |
| qs_mean                 | 0.58893114 |
| time_elapsed            | 30         |
| total timesteps         | 4944       |
| train_time              | 0          |
| update_time             | 19         |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.09       |
| env_time                | 7          |
| ep_rewmean              | 15.6       |
| episodes                | 236        |
| eplenmean               | 20.9       |
| fps                     | 159        |
| mean 100 episode reward | 15.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.33       |
| qs_difference           | -4.32      |
| qs_mean                 | 0.75029606 |
| time_elapsed            | 31         |
| total timesteps         | 5033       |
| train_time              | 0          |
| update_time             | 20         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 32.7       |
| env_time                | 7          |
| ep_rewmean              | 16.1       |
| episodes                | 240        |
| eplenmean               | 21.1       |
| fps                     | 158        |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 38.3       |
| qs_difference           | -38.3      |
| qs_mean                 | 0.54044944 |
| time_elapsed            | 32         |
| total timesteps         | 5166       |
| train_time              | 0          |
| update_time             | 21         |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'swimmer_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_3
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

--------------------------------------
| act_time                | 0        |
| current_lr              | 0.0003   |
| discount_q              | 4.99     |
| env_time                | 7        |
| ep_rewmean              | 15.8     |
| episodes                | 244      |
| eplenmean               | 20.7     |
| fps                     | 155      |
| mean 100 episode reward | 15.8     |
| n_updates               | 0        |
| qs_abs_difference       | 3.82     |
| qs_difference           | -3.8     |
| qs_mean                 | 0.65518  |
| time_elapsed            | 33       |
| total timesteps         | 5240     |
| train_time              | 0        |
| update_time             | 21       |
--------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 9.58      |
| env_time                | 7         |
| ep_rewmean              | 15.6      |
| episodes                | 248       |
| eplenmean               | 20.5      |
| fps                     | 157       |
| mean 100 episode reward | 15.6      |
| n_updates               | 0         |
| qs_abs_difference       | 6.41      |
| qs_difference           | -6.41     |
| qs_mean                 | 0.6685301 |
| time_elapsed            | 33        |
| total timesteps         | 5296      |
| train_time              | 0         |
| update_time             | 21        |
---------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'doublependulum_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_2
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.29       |
| env_time                | 7          |
| ep_rewmean              | 15.9       |
| episodes                | 252        |
| eplenmean               | 20.6       |
| fps                     | 154        |
| mean 100 episode reward | 15.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.58       |
| qs_difference           | -5.58      |
| qs_mean                 | 0.62430847 |
| time_elapsed            | 34         |
| total timesteps         | 5392       |
| train_time              | 0          |
| update_time             | 22         |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.48       |
| env_time                | 7          |
| ep_rewmean              | 15.9       |
| episodes                | 256        |
| eplenmean               | 20.6       |
| fps                     | 152        |
| mean 100 episode reward | 15.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.77       |
| qs_difference           | -5.77      |
| qs_mean                 | 0.73109853 |
| time_elapsed            | 35         |
| total timesteps         | 5485       |
| train_time              | 0          |
| update_time             | 23         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 4.07      |
| env_time                | 7         |
| ep_rewmean              | 16.1      |
| episodes                | 260       |
| eplenmean               | 20.9      |
| fps                     | 151       |
| mean 100 episode reward | 16.1      |
| n_updates               | 0         |
| qs_abs_difference       | 4.17      |
| qs_difference           | -4.16     |
| qs_mean                 | 0.7410345 |
| time_elapsed            | 36        |
| total timesteps         | 5582      |
| train_time              | 0         |
| update_time             | 24        |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'Swimmer-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'swimmer_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/swimmer_gem+tbp_4
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.74       |
| env_time                | 8          |
| ep_rewmean              | 16.6       |
| episodes                | 264        |
| eplenmean               | 21.3       |
| fps                     | 149        |
| mean 100 episode reward | 16.6       |
| n_updates               | 0          |
| qs_abs_difference       | 2.2        |
| qs_difference           | -1.39      |
| qs_mean                 | 0.65664387 |
| time_elapsed            | 38         |
| total timesteps         | 5677       |
| train_time              | 0          |
| update_time             | 25         |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'doublependulum_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_3
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 9.73      |
| env_time                | 8         |
| ep_rewmean              | 16.6      |
| episodes                | 268       |
| eplenmean               | 21.4      |
| fps                     | 144       |
| mean 100 episode reward | 16.6      |
| n_updates               | 0         |
| qs_abs_difference       | 12.6      |
| qs_difference           | -12.6     |
| qs_mean                 | 0.5865139 |
| time_elapsed            | 40        |
| total timesteps         | 5803      |
| train_time              | 0         |
| update_time             | 27        |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 3.23      |
| env_time                | 8         |
| ep_rewmean              | 16.5      |
| episodes                | 272       |
| eplenmean               | 21.3      |
| fps                     | 145       |
| mean 100 episode reward | 16.5      |
| n_updates               | 0         |
| qs_abs_difference       | 1.85      |
| qs_difference           | -1.83     |
| qs_mean                 | 0.8077996 |
| time_elapsed            | 40        |
| total timesteps         | 5857      |
| train_time              | 0         |
| update_time             | 27        |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 7.74      |
| env_time                | 8         |
| ep_rewmean              | 16.6      |
| episodes                | 276       |
| eplenmean               | 21.4      |
| fps                     | 144       |
| mean 100 episode reward | 16.6      |
| n_updates               | 0         |
| qs_abs_difference       | 7.59      |
| qs_difference           | -7.59     |
| qs_mean                 | 0.6074436 |
| time_elapsed            | 41        |
| total timesteps         | 5974      |
| train_time              | 0         |
| update_time             | 28        |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'doublependulum_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_0
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'doublependulum_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_4
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 4.91      |
| env_time                | 8         |
| ep_rewmean              | 16.3      |
| episodes                | 280       |
| eplenmean               | 21.3      |
| fps                     | 142       |
| mean 100 episode reward | 16.3      |
| n_updates               | 0         |
| qs_abs_difference       | 3.6       |
| qs_difference           | 1.54      |
| qs_mean                 | 0.6347328 |
| time_elapsed            | 42        |
| total timesteps         | 6056      |
| train_time              | 0         |
| update_time             | 29        |
---------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.61      |
| env_time                | 8         |
| ep_rewmean              | 16.8      |
| episodes                | 284       |
| eplenmean               | 21.7      |
| fps                     | 141       |
| mean 100 episode reward | 16.8      |
| n_updates               | 0         |
| qs_abs_difference       | 7.87      |
| qs_difference           | -7.86     |
| qs_mean                 | 0.6521612 |
| time_elapsed            | 43        |
| total timesteps         | 6169      |
| train_time              | 0         |
| update_time             | 30        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.28       |
| env_time                | 8          |
| ep_rewmean              | 17.6       |
| episodes                | 288        |
| eplenmean               | 21.9       |
| fps                     | 140        |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.49       |
| qs_difference           | -4.47      |
| qs_mean                 | 0.67126524 |
| time_elapsed            | 44         |
| total timesteps         | 6279       |
| train_time              | 0          |
| update_time             | 31         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'doublependulum_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_1
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 7.79      |
| env_time                | 8         |
| ep_rewmean              | 17.5      |
| episodes                | 292       |
| eplenmean               | 21.9      |
| fps                     | 138       |
| mean 100 episode reward | 17.5      |
| n_updates               | 0         |
| qs_abs_difference       | 8.93      |
| qs_difference           | -8.93     |
| qs_mean                 | 0.6398501 |
| time_elapsed            | 45        |
| total timesteps         | 6378      |
| train_time              | 0         |
| update_time             | 32        |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'pendulum_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_0
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 11.8      |
| env_time                | 9         |
| ep_rewmean              | 18.3      |
| episodes                | 296       |
| eplenmean               | 22.4      |
| fps                     | 137       |
| mean 100 episode reward | 18.3      |
| n_updates               | 0         |
| qs_abs_difference       | 15.2      |
| qs_difference           | -15.2     |
| qs_mean                 | 0.5811826 |
| time_elapsed            | 47        |
| total timesteps         | 6489      |
| train_time              | 0         |
| update_time             | 33        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.98       |
| env_time                | 9          |
| ep_rewmean              | 18.3       |
| episodes                | 300        |
| eplenmean               | 22.5       |
| fps                     | 135        |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.41       |
| qs_difference           | -4.41      |
| qs_mean                 | 0.58396935 |
| time_elapsed            | 48         |
| total timesteps         | 6582       |
| train_time              | 0          |
| update_time             | 34         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.19      |
| env_time                | 9         |
| ep_rewmean              | 18.5      |
| episodes                | 304       |
| eplenmean               | 22.5      |
| fps                     | 134       |
| mean 100 episode reward | 18.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.58      |
| qs_difference           | -3.31     |
| qs_mean                 | 0.7055761 |
| time_elapsed            | 49        |
| total timesteps         | 6659      |
| train_time              | 0         |
| update_time             | 35        |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'doublependulum_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_2
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'pendulum_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_1
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.77       |
| env_time                | 9          |
| ep_rewmean              | 18.7       |
| episodes                | 308        |
| eplenmean               | 22.8       |
| fps                     | 132        |
| mean 100 episode reward | 18.7       |
| n_updates               | 0          |
| qs_abs_difference       | 6.17       |
| qs_difference           | -6.12      |
| qs_mean                 | 0.67289484 |
| time_elapsed            | 50         |
| total timesteps         | 6759       |
| train_time              | 0          |
| update_time             | 36         |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
--------------------------------------
| act_time                | 0        |
| current_lr              | 0.0003   |
| discount_q              | 4.28     |
| env_time                | 9        |
| ep_rewmean              | 19       |
| episodes                | 312      |
| eplenmean               | 22.9     |
| fps                     | 131      |
| mean 100 episode reward | 19       |
| n_updates               | 0        |
| qs_abs_difference       | 3.28     |
| qs_difference           | -3.26    |
| qs_mean                 | 0.683386 |
| time_elapsed            | 52       |
| total timesteps         | 6845     |
| train_time              | 0        |
| update_time             | 37       |
--------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 4.32      |
| env_time                | 9         |
| ep_rewmean              | 19.1      |
| episodes                | 316       |
| eplenmean               | 23.1      |
| fps                     | 130       |
| mean 100 episode reward | 19.1      |
| n_updates               | 0         |
| qs_abs_difference       | 5.45      |
| qs_difference           | -5.42     |
| qs_mean                 | 0.5949375 |
| time_elapsed            | 53        |
| total timesteps         | 6974      |
| train_time              | 0         |
| update_time             | 38        |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'doublependulum_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_3
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'pendulum_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_2
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.85       |
| env_time                | 9          |
| ep_rewmean              | 18.9       |
| episodes                | 320        |
| eplenmean               | 23.1       |
| fps                     | 128        |
| mean 100 episode reward | 18.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.18       |
| qs_difference           | -5.14      |
| qs_mean                 | 0.65794325 |
| time_elapsed            | 54         |
| total timesteps         | 7048       |
| train_time              | 0          |
| update_time             | 39         |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.99       |
| env_time                | 10         |
| ep_rewmean              | 19.4       |
| episodes                | 324        |
| eplenmean               | 23.5       |
| fps                     | 127        |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 7.57       |
| qs_difference           | -7.57      |
| qs_mean                 | 0.60975283 |
| time_elapsed            | 56         |
| total timesteps         | 7158       |
| train_time              | 0          |
| update_time             | 40         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 4.94      |
| env_time                | 10        |
| ep_rewmean              | 19.6      |
| episodes                | 328       |
| eplenmean               | 23.5      |
| fps                     | 126       |
| mean 100 episode reward | 19.6      |
| n_updates               | 0         |
| qs_abs_difference       | 2.49      |
| qs_difference           | -2.38     |
| qs_mean                 | 0.7397484 |
| time_elapsed            | 57        |
| total timesteps         | 7225      |
| train_time              | 0         |
| update_time             | 41        |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'InvertedDoublePendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'doublependulum_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/doublependulum_gem+tbp_4
{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'pendulum_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_3
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.13       |
| env_time                | 10         |
| ep_rewmean              | 20.2       |
| episodes                | 332        |
| eplenmean               | 24.1       |
| fps                     | 125        |
| mean 100 episode reward | 20.2       |
| n_updates               | 0          |
| qs_abs_difference       | 10.6       |
| qs_difference           | -10.6      |
| qs_mean                 | 0.58983624 |
| time_elapsed            | 58         |
| total timesteps         | 7354       |
| train_time              | 0          |
| update_time             | 43         |
----------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.66      |
| env_time                | 10        |
| ep_rewmean              | 20        |
| episodes                | 336       |
| eplenmean               | 23.8      |
| fps                     | 123       |
| mean 100 episode reward | 20        |
| n_updates               | 0         |
| qs_abs_difference       | 4.65      |
| qs_difference           | -4.65     |
| qs_mean                 | 0.7211463 |
| time_elapsed            | 60        |
| total timesteps         | 7412      |
| train_time              | 0         |
| update_time             | 44        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.35       |
| env_time                | 10         |
| ep_rewmean              | 19         |
| episodes                | 340        |
| eplenmean               | 23.2       |
| fps                     | 124        |
| mean 100 episode reward | 19         |
| n_updates               | 0          |
| qs_abs_difference       | 5.34       |
| qs_difference           | -5.32      |
| qs_mean                 | 0.59512794 |
| time_elapsed            | 60         |
| total timesteps         | 7486       |
| train_time              | 0          |
| update_time             | 44         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 0, 'comment': 'pendulum_gem+tbp_0', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_0
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.14      |
| env_time                | 10        |
| ep_rewmean              | 20.5      |
| episodes                | 344       |
| eplenmean               | 23.6      |
| fps                     | 121       |
| mean 100 episode reward | 20.5      |
| n_updates               | 0         |
| qs_abs_difference       | 7.32      |
| qs_difference           | -7.32     |
| qs_mean                 | 0.5535345 |
| time_elapsed            | 62        |
| total timesteps         | 7603      |
| train_time              | 0         |
| update_time             | 46        |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.43      |
| env_time                | 10        |
| ep_rewmean              | 20.5      |
| episodes                | 348       |
| eplenmean               | 23.8      |
| fps                     | 122       |
| mean 100 episode reward | 20.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.04      |
| qs_difference           | -0.23     |
| qs_mean                 | 0.5779533 |
| time_elapsed            | 62        |
| total timesteps         | 7671      |
| train_time              | 0         |
| update_time             | 46        |
---------------------------------------
{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'pendulum_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_4
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 74, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", lib_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/lizhuo/.mujoco/mujoco210/bin
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 3.78      |
| env_time                | 10        |
| ep_rewmean              | 19.9      |
| episodes                | 352       |
| eplenmean               | 23.5      |
| fps                     | 120       |
| mean 100 episode reward | 19.9      |
| n_updates               | 0         |
| qs_abs_difference       | 2.61      |
| qs_difference           | -2.56     |
| qs_mean                 | 0.7087805 |
| time_elapsed            | 64        |
| total timesteps         | 7741      |
| train_time              | 0         |
| update_time             | 47        |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 15.1      |
| env_time                | 10        |
| ep_rewmean              | 19.8      |
| episodes                | 356       |
| eplenmean               | 23.3      |
| fps                     | 119       |
| mean 100 episode reward | 19.8      |
| n_updates               | 0         |
| qs_abs_difference       | 11        |
| qs_difference           | -11       |
| qs_mean                 | 0.6314837 |
| time_elapsed            | 65        |
| total timesteps         | 7815      |
| train_time              | 0         |
| update_time             | 49        |
---------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'pendulum_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_1
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 10.3      |
| env_time                | 11        |
| ep_rewmean              | 19.6      |
| episodes                | 360       |
| eplenmean               | 23.2      |
| fps                     | 117       |
| mean 100 episode reward | 19.6      |
| n_updates               | 0         |
| qs_abs_difference       | 10.9      |
| qs_difference           | -10.9     |
| qs_mean                 | 0.5991267 |
| time_elapsed            | 67        |
| total timesteps         | 7904      |
| train_time              | 0         |
| update_time             | 50        |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.32      |
| env_time                | 11        |
| ep_rewmean              | 19.6      |
| episodes                | 364       |
| eplenmean               | 23.1      |
| fps                     | 118       |
| mean 100 episode reward | 19.6      |
| n_updates               | 0         |
| qs_abs_difference       | 6.3       |
| qs_difference           | -6.3      |
| qs_mean                 | 0.6085659 |
| time_elapsed            | 67        |
| total timesteps         | 7987      |
| train_time              | 0         |
| update_time             | 50        |
---------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.72       |
| env_time                | 11         |
| ep_rewmean              | 19         |
| episodes                | 368        |
| eplenmean               | 22.7       |
| fps                     | 117        |
| mean 100 episode reward | 19         |
| n_updates               | 0          |
| qs_abs_difference       | 4.93       |
| qs_difference           | -4.92      |
| qs_mean                 | 0.53271616 |
| time_elapsed            | 68         |
| total timesteps         | 8072       |
| train_time              | 0          |
| update_time             | 51         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.96       |
| env_time                | 11         |
| ep_rewmean              | 19.3       |
| episodes                | 372        |
| eplenmean               | 23         |
| fps                     | 116        |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 6.32       |
| qs_difference           | -6.3       |
| qs_mean                 | 0.63617456 |
| time_elapsed            | 70         |
| total timesteps         | 8155       |
| train_time              | 0          |
| update_time             | 52         |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'pendulum_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_2
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 8.31      |
| env_time                | 11        |
| ep_rewmean              | 19.4      |
| episodes                | 376       |
| eplenmean               | 22.7      |
| fps                     | 115       |
| mean 100 episode reward | 19.4      |
| n_updates               | 0         |
| qs_abs_difference       | 8.06      |
| qs_difference           | -8.06     |
| qs_mean                 | 0.5771311 |
| time_elapsed            | 71        |
| total timesteps         | 8247      |
| train_time              | 0         |
| update_time             | 54        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.58      |
| env_time                | 11        |
| ep_rewmean              | 19.7      |
| episodes                | 380       |
| eplenmean               | 22.7      |
| fps                     | 113       |
| mean 100 episode reward | 19.7      |
| n_updates               | 0         |
| qs_abs_difference       | 4.02      |
| qs_difference           | -4.02     |
| qs_mean                 | 0.7966608 |
| time_elapsed            | 73        |
| total timesteps         | 8330      |
| train_time              | 0         |
| update_time             | 55        |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.67       |
| env_time                | 11         |
| ep_rewmean              | 19.1       |
| episodes                | 384        |
| eplenmean               | 22.2       |
| fps                     | 114        |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 2.7        |
| qs_difference           | -2.63      |
| qs_mean                 | 0.77062887 |
| time_elapsed            | 73         |
| total timesteps         | 8388       |
| train_time              | 0          |
| update_time             | 55         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'pendulum_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_3
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 3.36      |
| env_time                | 11        |
| ep_rewmean              | 18.5      |
| episodes                | 388       |
| eplenmean               | 22.1      |
| fps                     | 113       |
| mean 100 episode reward | 18.5      |
| n_updates               | 0         |
| qs_abs_difference       | 2.49      |
| qs_difference           | -2.14     |
| qs_mean                 | 0.6348278 |
| time_elapsed            | 74        |
| total timesteps         | 8489      |
| train_time              | 0         |
| update_time             | 56        |
---------------------------------------
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.89       |
| env_time                | 12         |
| ep_rewmean              | 18         |
| episodes                | 392        |
| eplenmean               | 21.9       |
| fps                     | 112        |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 4.46       |
| qs_difference           | -4.46      |
| qs_mean                 | 0.65170676 |
| time_elapsed            | 76         |
| total timesteps         | 8569       |
| train_time              | 0          |
| update_time             | 58         |
----------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.88       |
| env_time                | 12         |
| ep_rewmean              | 17.2       |
| episodes                | 396        |
| eplenmean               | 21.4       |
| fps                     | 110        |
| mean 100 episode reward | 17.2       |
| n_updates               | 0          |
| qs_abs_difference       | 3.33       |
| qs_difference           | -3.31      |
| qs_mean                 | 0.72223103 |
| time_elapsed            | 77         |
| total timesteps         | 8630       |
| train_time              | 0          |
| update_time             | 59         |
----------------------------------------
{'env_type': 'mujoco', 'env_id': 'InvertedPendulum-v2', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'pendulum_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 100001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/pendulum_gem+tbp_4
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
Traceback (most recent call last):
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 103, in <module>
    run(**args)
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/train.py", line 21, in run
    env = create_env(env_id, delay_step, str(0))
  File "/home/lizhuo/workspace/GEM/gem_mujoco/run/run_util.py", line 17, in create_env
    env = gym.make(env_id)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 145, in make
    return registry.make(id, **kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 90, in make
    env = spec.make(**kwargs)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 59, in make
    cls = load(self.entry_point)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/registration.py", line 18, in load
    mod = importlib.import_module(mod_name)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/__init__.py", line 1, in <module>
    from gym.envs.mujoco.mujoco_env import MujocoEnv
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/gym/envs/mujoco/mujoco_env.py", line 12, in <module>
    import mujoco_py
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/__init__.py", line 2, in <module>
    from mujoco_py.builder import cymj, ignore_mujoco_warnings, functions, MujocoException
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 504, in <module>
    cymj = load_cython_ext(mujoco_path)
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 76, in load_cython_ext
    _ensure_set_env_var("LD_LIBRARY_PATH", get_nvidia_lib_dir())
  File "/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/mujoco_py/builder.py", line 124, in _ensure_set_env_var
    var_name, var_name, lib_path))
Exception: 
Missing path to your environment variable. 
Current values LD_LIBRARY_PATH=:/home/lizhuo/.mujoco/mujoco210/bin
Please add following line to .bashrc:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 28.8       |
| env_time                | 12         |
| ep_rewmean              | 17.9       |
| episodes                | 400        |
| eplenmean               | 21.5       |
| fps                     | 109        |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 35         |
| qs_difference           | -35        |
| qs_mean                 | 0.48281738 |
| time_elapsed            | 79         |
| total timesteps         | 8735       |
| train_time              | 0          |
| update_time             | 61         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.7        |
| env_time                | 12         |
| ep_rewmean              | 17.9       |
| episodes                | 404        |
| eplenmean               | 21.6       |
| fps                     | 108        |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 2.88       |
| qs_difference           | -1.03      |
| qs_mean                 | 0.61142975 |
| time_elapsed            | 81         |
| total timesteps         | 8821       |
| train_time              | 0          |
| update_time             | 62         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 10.1      |
| env_time                | 12        |
| ep_rewmean              | 17.7      |
| episodes                | 408       |
| eplenmean               | 21.4      |
| fps                     | 107       |
| mean 100 episode reward | 17.7      |
| n_updates               | 0         |
| qs_abs_difference       | 10        |
| qs_difference           | -10       |
| qs_mean                 | 0.7012302 |
| time_elapsed            | 82        |
| total timesteps         | 8903      |
| train_time              | 0         |
| update_time             | 64        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 17.4      |
| env_time                | 12        |
| ep_rewmean              | 17.7      |
| episodes                | 412       |
| eplenmean               | 21.5      |
| fps                     | 108       |
| mean 100 episode reward | 17.7      |
| n_updates               | 0         |
| qs_abs_difference       | 14        |
| qs_difference           | -14       |
| qs_mean                 | 0.5788619 |
| time_elapsed            | 83        |
| total timesteps         | 8992      |
| train_time              | 0         |
| update_time             | 64        |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 23.2       |
| env_time                | 12         |
| ep_rewmean              | 17.8       |
| episodes                | 416        |
| eplenmean               | 21.5       |
| fps                     | 105        |
| mean 100 episode reward | 17.8       |
| n_updates               | 0          |
| qs_abs_difference       | 26.3       |
| qs_difference           | -26.3      |
| qs_mean                 | 0.60041887 |
| time_elapsed            | 86         |
| total timesteps         | 9120       |
| train_time              | 0          |
| update_time             | 67         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 5.8       |
| env_time                | 13        |
| ep_rewmean              | 17.6      |
| episodes                | 420       |
| eplenmean               | 21.6      |
| fps                     | 104       |
| mean 100 episode reward | 17.6      |
| n_updates               | 0         |
| qs_abs_difference       | 4.16      |
| qs_difference           | -3.96     |
| qs_mean                 | 0.6580399 |
| time_elapsed            | 88        |
| total timesteps         | 9205      |
| train_time              | 0         |
| update_time             | 68        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 5.83      |
| env_time                | 13        |
| ep_rewmean              | 17.3      |
| episodes                | 424       |
| eplenmean               | 21.3      |
| fps                     | 105       |
| mean 100 episode reward | 17.3      |
| n_updates               | 0         |
| qs_abs_difference       | 5.24      |
| qs_difference           | -5.21     |
| qs_mean                 | 0.5764781 |
| time_elapsed            | 88        |
| total timesteps         | 9289      |
| train_time              | 0         |
| update_time             | 68        |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 22.9       |
| env_time                | 13         |
| ep_rewmean              | 18.1       |
| episodes                | 428        |
| eplenmean               | 21.9       |
| fps                     | 102        |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 32.7       |
| qs_difference           | -32.7      |
| qs_mean                 | 0.50445706 |
| time_elapsed            | 91         |
| total timesteps         | 9419       |
| train_time              | 0          |
| update_time             | 71         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.02       |
| env_time                | 13         |
| ep_rewmean              | 17.5       |
| episodes                | 432        |
| eplenmean               | 21.4       |
| fps                     | 103        |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 2.76       |
| qs_difference           | -0.396     |
| qs_mean                 | 0.62265617 |
| time_elapsed            | 91         |
| total timesteps         | 9497       |
| train_time              | 0          |
| update_time             | 71         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 2.73       |
| env_time                | 13         |
| ep_rewmean              | 17.7       |
| episodes                | 436        |
| eplenmean               | 21.7       |
| fps                     | 102        |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 1.52       |
| qs_difference           | -1.14      |
| qs_mean                 | 0.69627863 |
| time_elapsed            | 93         |
| total timesteps         | 9585       |
| train_time              | 0          |
| update_time             | 73         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 7.31      |
| env_time                | 13        |
| ep_rewmean              | 17.8      |
| episodes                | 440       |
| eplenmean               | 21.7      |
| fps                     | 101       |
| mean 100 episode reward | 17.8      |
| n_updates               | 0         |
| qs_abs_difference       | 3.93      |
| qs_difference           | -3.01     |
| qs_mean                 | 0.5546325 |
| time_elapsed            | 95        |
| total timesteps         | 9660      |
| train_time              | 0         |
| update_time             | 74        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.94      |
| env_time                | 13        |
| ep_rewmean              | 16.3      |
| episodes                | 444       |
| eplenmean               | 21.2      |
| fps                     | 100       |
| mean 100 episode reward | 16.3      |
| n_updates               | 0         |
| qs_abs_difference       | 2.19      |
| qs_difference           | -2.06     |
| qs_mean                 | 0.6651852 |
| time_elapsed            | 97        |
| total timesteps         | 9725      |
| train_time              | 0         |
| update_time             | 76        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.09      |
| env_time                | 13        |
| ep_rewmean              | 16.5      |
| episodes                | 448       |
| eplenmean               | 21.4      |
| fps                     | 99        |
| mean 100 episode reward | 16.5      |
| n_updates               | 0         |
| qs_abs_difference       | 2.21      |
| qs_difference           | -1.8      |
| qs_mean                 | 0.6560167 |
| time_elapsed            | 98        |
| total timesteps         | 9808      |
| train_time              | 0         |
| update_time             | 77        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 6.04      |
| env_time                | 13        |
| ep_rewmean              | 16.6      |
| episodes                | 452       |
| eplenmean               | 21.2      |
| fps                     | 99        |
| mean 100 episode reward | 16.6      |
| n_updates               | 0         |
| qs_abs_difference       | 4.06      |
| qs_difference           | -4.06     |
| qs_mean                 | 0.7009954 |
| time_elapsed            | 98        |
| total timesteps         | 9863      |
| train_time              | 0         |
| update_time             | 77        |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.41       |
| env_time                | 14         |
| ep_rewmean              | 16.7       |
| episodes                | 456        |
| eplenmean               | 21.4       |
| fps                     | 98         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 6.34       |
| qs_difference           | -6.32      |
| qs_mean                 | 0.63179964 |
| time_elapsed            | 100        |
| total timesteps         | 9950       |
| train_time              | 0          |
| update_time             | 79         |
----------------------------------------
----------------------------------------
| eval mean 100 episod... | 24         |
| eval_abs_qs_difference  | 10.608311  |
| eval_discount_q         | 21.7       |
| eval_ep_rewmean         | 24.3       |
| eval_eplenmean          | 27.1       |
| eval_qs                 | -0.3942563 |
| eval_qs_difference      | -10.6      |
| eval_time_elapsed       | 0          |
| total timesteps         | 10001      |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 11.3       |
| env_time                | 14         |
| ep_rewmean              | 16.7       |
| episodes                | 460        |
| eplenmean               | 21.2       |
| fps                     | 97         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 8.37       |
| qs_difference           | -8.37      |
| qs_mean                 | 0.75678843 |
| time_elapsed            | 103        |
| total timesteps         | 10022      |
| train_time              | 0          |
| update_time             | 81         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 15.1       |
| env_time                | 14         |
| ep_rewmean              | 16.8       |
| episodes                | 464        |
| eplenmean               | 21.6       |
| fps                     | 96         |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 16.5       |
| qs_difference           | -16.5      |
| qs_mean                 | 0.62477714 |
| time_elapsed            | 105        |
| total timesteps         | 10144      |
| train_time              | 0          |
| update_time             | 82         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 6.81      |
| env_time                | 14        |
| ep_rewmean              | 17.6      |
| episodes                | 468       |
| eplenmean               | 21.9      |
| fps                     | 95        |
| mean 100 episode reward | 17.6      |
| n_updates               | 0         |
| qs_abs_difference       | 8.11      |
| qs_difference           | -8.07     |
| qs_mean                 | 0.6432023 |
| time_elapsed            | 107       |
| total timesteps         | 10260     |
| train_time              | 0         |
| update_time             | 84        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 13.9      |
| env_time                | 14        |
| ep_rewmean              | 17.4      |
| episodes                | 472       |
| eplenmean               | 21.8      |
| fps                     | 94        |
| mean 100 episode reward | 17.4      |
| n_updates               | 0         |
| qs_abs_difference       | 11        |
| qs_difference           | -11       |
| qs_mean                 | 0.6394128 |
| time_elapsed            | 109       |
| total timesteps         | 10333     |
| train_time              | 0         |
| update_time             | 86        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 13.9      |
| env_time                | 14        |
| ep_rewmean              | 17        |
| episodes                | 476       |
| eplenmean               | 21.4      |
| fps                     | 95        |
| mean 100 episode reward | 17        |
| n_updates               | 0         |
| qs_abs_difference       | 9.9       |
| qs_difference           | -9.9      |
| qs_mean                 | 0.5795696 |
| time_elapsed            | 109       |
| total timesteps         | 10391     |
| train_time              | 0         |
| update_time             | 86        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 14.9      |
| env_time                | 15        |
| ep_rewmean              | 17        |
| episodes                | 480       |
| eplenmean               | 21.4      |
| fps                     | 94        |
| mean 100 episode reward | 17        |
| n_updates               | 0         |
| qs_abs_difference       | 13.1      |
| qs_difference           | -13.1     |
| qs_mean                 | 0.5987029 |
| time_elapsed            | 111       |
| total timesteps         | 10475     |
| train_time              | 0         |
| update_time             | 88        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.84      |
| env_time                | 15        |
| ep_rewmean              | 16.9      |
| episodes                | 484       |
| eplenmean               | 21.5      |
| fps                     | 93        |
| mean 100 episode reward | 16.9      |
| n_updates               | 0         |
| qs_abs_difference       | 3.46      |
| qs_difference           | -3.45     |
| qs_mean                 | 0.7824938 |
| time_elapsed            | 112       |
| total timesteps         | 10537     |
| train_time              | 0         |
| update_time             | 89        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 8.5       |
| env_time                | 15        |
| ep_rewmean              | 17.1      |
| episodes                | 488       |
| eplenmean               | 21.4      |
| fps                     | 92        |
| mean 100 episode reward | 17.1      |
| n_updates               | 0         |
| qs_abs_difference       | 8.05      |
| qs_difference           | -8.04     |
| qs_mean                 | 0.6031945 |
| time_elapsed            | 114       |
| total timesteps         | 10626     |
| train_time              | 0         |
| update_time             | 91        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 5.18      |
| env_time                | 15        |
| ep_rewmean              | 17.5      |
| episodes                | 492       |
| eplenmean               | 21.9      |
| fps                     | 91        |
| mean 100 episode reward | 17.5      |
| n_updates               | 0         |
| qs_abs_difference       | 7.13      |
| qs_difference           | -7.1      |
| qs_mean                 | 0.6278764 |
| time_elapsed            | 117       |
| total timesteps         | 10758     |
| train_time              | 0         |
| update_time             | 93        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 5.2       |
| env_time                | 15        |
| ep_rewmean              | 17.8      |
| episodes                | 496       |
| eplenmean               | 22.1      |
| fps                     | 91        |
| mean 100 episode reward | 17.8      |
| n_updates               | 0         |
| qs_abs_difference       | 4.38      |
| qs_difference           | -4.35     |
| qs_mean                 | 0.7148512 |
| time_elapsed            | 119       |
| total timesteps         | 10843     |
| train_time              | 0         |
| update_time             | 95        |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 9.49       |
| env_time                | 15         |
| ep_rewmean              | 17.3       |
| episodes                | 500        |
| eplenmean               | 21.9       |
| fps                     | 90         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 8.71       |
| qs_difference           | -8.71      |
| qs_mean                 | 0.63561124 |
| time_elapsed            | 120        |
| total timesteps         | 10927      |
| train_time              | 0          |
| update_time             | 96         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.23       |
| env_time                | 15         |
| ep_rewmean              | 17.1       |
| episodes                | 504        |
| eplenmean               | 21.7       |
| fps                     | 90         |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 4.5        |
| qs_difference           | -4.5       |
| qs_mean                 | 0.73325455 |
| time_elapsed            | 121        |
| total timesteps         | 10991      |
| train_time              | 0          |
| update_time             | 96         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.1       |
| env_time                | 15        |
| ep_rewmean              | 17.4      |
| episodes                | 508       |
| eplenmean               | 21.9      |
| fps                     | 90        |
| mean 100 episode reward | 17.4      |
| n_updates               | 0         |
| qs_abs_difference       | 4.32      |
| qs_difference           | -4.28     |
| qs_mean                 | 0.6073721 |
| time_elapsed            | 123       |
| total timesteps         | 11098     |
| train_time              | 0         |
| update_time             | 98        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 3.33      |
| env_time                | 16        |
| ep_rewmean              | 17.1      |
| episodes                | 512       |
| eplenmean               | 21.7      |
| fps                     | 89        |
| mean 100 episode reward | 17.1      |
| n_updates               | 0         |
| qs_abs_difference       | 1.97      |
| qs_difference           | -1.92     |
| qs_mean                 | 0.7607452 |
| time_elapsed            | 125       |
| total timesteps         | 11159     |
| train_time              | 0         |
| update_time             | 100       |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.61      |
| env_time                | 16        |
| ep_rewmean              | 16.7      |
| episodes                | 516       |
| eplenmean               | 21.1      |
| fps                     | 88        |
| mean 100 episode reward | 16.7      |
| n_updates               | 0         |
| qs_abs_difference       | 2.65      |
| qs_difference           | -2.24     |
| qs_mean                 | 0.7400481 |
| time_elapsed            | 127       |
| total timesteps         | 11235     |
| train_time              | 0         |
| update_time             | 102       |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.31      |
| env_time                | 16        |
| ep_rewmean              | 16.6      |
| episodes                | 520       |
| eplenmean               | 21        |
| fps                     | 87        |
| mean 100 episode reward | 16.6      |
| n_updates               | 0         |
| qs_abs_difference       | 2.52      |
| qs_difference           | -2.17     |
| qs_mean                 | 0.7606192 |
| time_elapsed            | 129       |
| total timesteps         | 11303     |
| train_time              | 0         |
| update_time             | 104       |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 6.43      |
| env_time                | 16        |
| ep_rewmean              | 16.5      |
| episodes                | 524       |
| eplenmean               | 20.8      |
| fps                     | 87        |
| mean 100 episode reward | 16.5      |
| n_updates               | 0         |
| qs_abs_difference       | 4.88      |
| qs_difference           | -4.88     |
| qs_mean                 | 0.6829805 |
| time_elapsed            | 129       |
| total timesteps         | 11368     |
| train_time              | 0         |
| update_time             | 104       |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.39      |
| env_time                | 16        |
| ep_rewmean              | 15.5      |
| episodes                | 528       |
| eplenmean               | 20.1      |
| fps                     | 87        |
| mean 100 episode reward | 15.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.25      |
| qs_difference           | -3.23     |
| qs_mean                 | 0.6954606 |
| time_elapsed            | 131       |
| total timesteps         | 11434     |
| train_time              | 0         |
| update_time             | 106       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.94       |
| env_time                | 16         |
| ep_rewmean              | 15.5       |
| episodes                | 532        |
| eplenmean               | 20.2       |
| fps                     | 86         |
| mean 100 episode reward | 15.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.64       |
| qs_difference           | -4.62      |
| qs_mean                 | 0.72771126 |
| time_elapsed            | 133        |
| total timesteps         | 11517      |
| train_time              | 0          |
| update_time             | 108        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.71      |
| env_time                | 16        |
| ep_rewmean              | 15.4      |
| episodes                | 536       |
| eplenmean               | 20.1      |
| fps                     | 86        |
| mean 100 episode reward | 15.4      |
| n_updates               | 0         |
| qs_abs_difference       | 2.63      |
| qs_difference           | -1.64     |
| qs_mean                 | 0.7239048 |
| time_elapsed            | 133       |
| total timesteps         | 11599     |
| train_time              | 0         |
| update_time             | 108       |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 3.38      |
| env_time                | 16        |
| ep_rewmean              | 16.2      |
| episodes                | 540       |
| eplenmean               | 20.5      |
| fps                     | 84        |
| mean 100 episode reward | 16.2      |
| n_updates               | 0         |
| qs_abs_difference       | 3.67      |
| qs_difference           | -3.64     |
| qs_mean                 | 0.7250089 |
| time_elapsed            | 137       |
| total timesteps         | 11707     |
| train_time              | 0         |
| update_time             | 111       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 11.1       |
| env_time                | 17         |
| ep_rewmean              | 16.2       |
| episodes                | 544        |
| eplenmean               | 20.5       |
| fps                     | 85         |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 8.48       |
| qs_difference           | -8.48      |
| qs_mean                 | 0.58947766 |
| time_elapsed            | 137        |
| total timesteps         | 11778      |
| train_time              | 0          |
| update_time             | 111        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 11.1       |
| env_time                | 17         |
| ep_rewmean              | 16.2       |
| episodes                | 548        |
| eplenmean               | 20.6       |
| fps                     | 84         |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 9.79       |
| qs_difference           | -9.75      |
| qs_mean                 | 0.64256215 |
| time_elapsed            | 140        |
| total timesteps         | 11867      |
| train_time              | 0          |
| update_time             | 113        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 11.3       |
| env_time                | 17         |
| ep_rewmean              | 16.5       |
| episodes                | 552        |
| eplenmean               | 21         |
| fps                     | 84         |
| mean 100 episode reward | 16.5       |
| n_updates               | 0          |
| qs_abs_difference       | 9.98       |
| qs_difference           | -9.98      |
| qs_mean                 | 0.61976475 |
| time_elapsed            | 142        |
| total timesteps         | 11960      |
| train_time              | 0          |
| update_time             | 115        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.26       |
| env_time                | 17         |
| ep_rewmean              | 16.2       |
| episodes                | 556        |
| eplenmean               | 20.8       |
| fps                     | 83         |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 3.33       |
| qs_difference           | -3.21      |
| qs_mean                 | 0.70228356 |
| time_elapsed            | 144        |
| total timesteps         | 12026      |
| train_time              | 0          |
| update_time             | 117        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.9        |
| env_time                | 17         |
| ep_rewmean              | 16.7       |
| episodes                | 560        |
| eplenmean               | 21.1       |
| fps                     | 82         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 6.52       |
| qs_difference           | -6.52      |
| qs_mean                 | 0.67063236 |
| time_elapsed            | 146        |
| total timesteps         | 12128      |
| train_time              | 0          |
| update_time             | 119        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 20.4       |
| env_time                | 17         |
| ep_rewmean              | 16.7       |
| episodes                | 564        |
| eplenmean               | 21         |
| fps                     | 82         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 20.8       |
| qs_difference           | -20.8      |
| qs_mean                 | 0.66797525 |
| time_elapsed            | 148        |
| total timesteps         | 12240      |
| train_time              | 0          |
| update_time             | 121        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 9.04      |
| env_time                | 17        |
| ep_rewmean              | 15.8      |
| episodes                | 568       |
| eplenmean               | 20.3      |
| fps                     | 82        |
| mean 100 episode reward | 15.8      |
| n_updates               | 0         |
| qs_abs_difference       | 6.82      |
| qs_difference           | -6.82     |
| qs_mean                 | 0.6612721 |
| time_elapsed            | 148       |
| total timesteps         | 12292     |
| train_time              | 0         |
| update_time             | 121       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 9.44       |
| env_time                | 18         |
| ep_rewmean              | 15.9       |
| episodes                | 572        |
| eplenmean               | 20.4       |
| fps                     | 81         |
| mean 100 episode reward | 15.9       |
| n_updates               | 0          |
| qs_abs_difference       | 9.62       |
| qs_difference           | -9.62      |
| qs_mean                 | 0.64475465 |
| time_elapsed            | 151        |
| total timesteps         | 12376      |
| train_time              | 0          |
| update_time             | 123        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.95       |
| env_time                | 18         |
| ep_rewmean              | 16.2       |
| episodes                | 576        |
| eplenmean               | 20.7       |
| fps                     | 81         |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 3.26       |
| qs_difference           | -3.06      |
| qs_mean                 | 0.68778276 |
| time_elapsed            | 153        |
| total timesteps         | 12460      |
| train_time              | 0          |
| update_time             | 125        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 2.9       |
| env_time                | 18        |
| ep_rewmean              | 16.1      |
| episodes                | 580       |
| eplenmean               | 20.6      |
| fps                     | 80        |
| mean 100 episode reward | 16.1      |
| n_updates               | 0         |
| qs_abs_difference       | 2.1       |
| qs_difference           | -2.06     |
| qs_mean                 | 0.7607766 |
| time_elapsed            | 155       |
| total timesteps         | 12540     |
| train_time              | 0         |
| update_time             | 127       |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.45      |
| env_time                | 18        |
| ep_rewmean              | 16.1      |
| episodes                | 584       |
| eplenmean               | 20.9      |
| fps                     | 79        |
| mean 100 episode reward | 16.1      |
| n_updates               | 0         |
| qs_abs_difference       | 2.77      |
| qs_difference           | -2.56     |
| qs_mean                 | 0.6976447 |
| time_elapsed            | 157       |
| total timesteps         | 12623     |
| train_time              | 0         |
| update_time             | 129       |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 15.4      |
| env_time                | 18        |
| ep_rewmean              | 16.1      |
| episodes                | 588       |
| eplenmean               | 20.8      |
| fps                     | 79        |
| mean 100 episode reward | 16.1      |
| n_updates               | 0         |
| qs_abs_difference       | 11.2      |
| qs_difference           | -11.2     |
| qs_mean                 | 0.5359582 |
| time_elapsed            | 160       |
| total timesteps         | 12710     |
| train_time              | 0         |
| update_time             | 132       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 2.83       |
| env_time                | 18         |
| ep_rewmean              | 16.5       |
| episodes                | 592        |
| eplenmean               | 20.7       |
| fps                     | 78         |
| mean 100 episode reward | 16.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.15       |
| qs_difference           | -3.14      |
| qs_mean                 | 0.74501413 |
| time_elapsed            | 162        |
| total timesteps         | 12825      |
| train_time              | 0          |
| update_time             | 134        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 6.33      |
| env_time                | 18        |
| ep_rewmean              | 16.5      |
| episodes                | 596       |
| eplenmean               | 20.8      |
| fps                     | 78        |
| mean 100 episode reward | 16.5      |
| n_updates               | 0         |
| qs_abs_difference       | 7.36      |
| qs_difference           | -7.36     |
| qs_mean                 | 0.6926761 |
| time_elapsed            | 164       |
| total timesteps         | 12924     |
| train_time              | 0         |
| update_time             | 136       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.75       |
| env_time                | 19         |
| ep_rewmean              | 16.5       |
| episodes                | 600        |
| eplenmean               | 21         |
| fps                     | 77         |
| mean 100 episode reward | 16.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.54       |
| qs_difference           | -3.23      |
| qs_mean                 | 0.73367596 |
| time_elapsed            | 167        |
| total timesteps         | 13023      |
| train_time              | 0          |
| update_time             | 138        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.46      |
| env_time                | 19        |
| ep_rewmean              | 16.6      |
| episodes                | 604       |
| eplenmean               | 21.1      |
| fps                     | 78        |
| mean 100 episode reward | 16.6      |
| n_updates               | 0         |
| qs_abs_difference       | 2.7       |
| qs_difference           | -2.15     |
| qs_mean                 | 0.6407241 |
| time_elapsed            | 167       |
| total timesteps         | 13098     |
| train_time              | 0         |
| update_time             | 138       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 39.1       |
| env_time                | 19         |
| ep_rewmean              | 17         |
| episodes                | 608        |
| eplenmean               | 21         |
| fps                     | 77         |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 41         |
| qs_difference           | -41        |
| qs_mean                 | 0.41392398 |
| time_elapsed            | 169        |
| total timesteps         | 13196      |
| train_time              | 0          |
| update_time             | 140        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 16        |
| env_time                | 19        |
| ep_rewmean              | 17.1      |
| episodes                | 612       |
| eplenmean               | 21.3      |
| fps                     | 77        |
| mean 100 episode reward | 17.1      |
| n_updates               | 0         |
| qs_abs_difference       | 15.1      |
| qs_difference           | -15.1     |
| qs_mean                 | 0.5323604 |
| time_elapsed            | 172       |
| total timesteps         | 13293     |
| train_time              | 0         |
| update_time             | 142       |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 5.01      |
| env_time                | 19        |
| ep_rewmean              | 17.7      |
| episodes                | 616       |
| eplenmean               | 22        |
| fps                     | 75        |
| mean 100 episode reward | 17.7      |
| n_updates               | 0         |
| qs_abs_difference       | 8.04      |
| qs_difference           | -8.04     |
| qs_mean                 | 0.5917009 |
| time_elapsed            | 177       |
| total timesteps         | 13434     |
| train_time              | 0         |
| update_time             | 147       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 8.31       |
| env_time                | 19         |
| ep_rewmean              | 19.2       |
| episodes                | 620        |
| eplenmean               | 22.7       |
| fps                     | 75         |
| mean 100 episode reward | 19.2       |
| n_updates               | 0          |
| qs_abs_difference       | 15.2       |
| qs_difference           | -15.2      |
| qs_mean                 | 0.57256734 |
| time_elapsed            | 179        |
| total timesteps         | 13574      |
| train_time              | 0          |
| update_time             | 149        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 6.26      |
| env_time                | 20        |
| ep_rewmean              | 19.6      |
| episodes                | 624       |
| eplenmean               | 22.9      |
| fps                     | 75        |
| mean 100 episode reward | 19.6      |
| n_updates               | 0         |
| qs_abs_difference       | 4.72      |
| qs_difference           | -4.66     |
| qs_mean                 | 0.6954064 |
| time_elapsed            | 181       |
| total timesteps         | 13660     |
| train_time              | 0         |
| update_time             | 151       |
---------------------------------------
--------------------------------------
| act_time                | 1        |
| current_lr              | 0.0003   |
| discount_q              | 3.99     |
| env_time                | 20       |
| ep_rewmean              | 20       |
| episodes                | 628      |
| eplenmean               | 23.3     |
| fps                     | 74       |
| mean 100 episode reward | 20       |
| n_updates               | 0        |
| qs_abs_difference       | 2.97     |
| qs_difference           | -0.718   |
| qs_mean                 | 0.676194 |
| time_elapsed            | 184      |
| total timesteps         | 13765    |
| train_time              | 0        |
| update_time             | 153      |
--------------------------------------
--------------------------------------
| act_time                | 1        |
| current_lr              | 0.0003   |
| discount_q              | 4.3      |
| env_time                | 20       |
| ep_rewmean              | 20.7     |
| episodes                | 632      |
| eplenmean               | 23.6     |
| fps                     | 74       |
| mean 100 episode reward | 20.7     |
| n_updates               | 0        |
| qs_abs_difference       | 4.34     |
| qs_difference           | -4.12    |
| qs_mean                 | 0.61569  |
| time_elapsed            | 187      |
| total timesteps         | 13878    |
| train_time              | 0        |
| update_time             | 156      |
--------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 3.39      |
| env_time                | 20        |
| ep_rewmean              | 20.6      |
| episodes                | 636       |
| eplenmean               | 23.6      |
| fps                     | 73        |
| mean 100 episode reward | 20.6      |
| n_updates               | 0         |
| qs_abs_difference       | 2.35      |
| qs_difference           | -2.17     |
| qs_mean                 | 0.7566092 |
| time_elapsed            | 189       |
| total timesteps         | 13958     |
| train_time              | 0         |
| update_time             | 158       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.36       |
| env_time                | 20         |
| ep_rewmean              | 19.9       |
| episodes                | 640        |
| eplenmean               | 23.2       |
| fps                     | 73         |
| mean 100 episode reward | 19.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.78       |
| qs_difference           | -5.77      |
| qs_mean                 | 0.74530375 |
| time_elapsed            | 191        |
| total timesteps         | 14032      |
| train_time              | 0          |
| update_time             | 160        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 3.17      |
| env_time                | 20        |
| ep_rewmean              | 20.2      |
| episodes                | 644       |
| eplenmean               | 23.5      |
| fps                     | 72        |
| mean 100 episode reward | 20.2      |
| n_updates               | 0         |
| qs_abs_difference       | 3.28      |
| qs_difference           | -3.28     |
| qs_mean                 | 0.7432895 |
| time_elapsed            | 194       |
| total timesteps         | 14127     |
| train_time              | 0         |
| update_time             | 163       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.87       |
| env_time                | 20         |
| ep_rewmean              | 19.8       |
| episodes                | 648        |
| eplenmean               | 23.1       |
| fps                     | 72         |
| mean 100 episode reward | 19.8       |
| n_updates               | 0          |
| qs_abs_difference       | 3.78       |
| qs_difference           | -3.74      |
| qs_mean                 | 0.66181326 |
| time_elapsed            | 194        |
| total timesteps         | 14181      |
| train_time              | 0          |
| update_time             | 163        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 5.16      |
| env_time                | 21        |
| ep_rewmean              | 20.1      |
| episodes                | 652       |
| eplenmean               | 23.2      |
| fps                     | 72        |
| mean 100 episode reward | 20.1      |
| n_updates               | 0         |
| qs_abs_difference       | 4.53      |
| qs_difference           | -4.46     |
| qs_mean                 | 0.6325371 |
| time_elapsed            | 197       |
| total timesteps         | 14277     |
| train_time              | 0         |
| update_time             | 165       |
---------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.47       |
| env_time                | 21         |
| ep_rewmean              | 21.1       |
| episodes                | 656        |
| eplenmean               | 24.1       |
| fps                     | 71         |
| mean 100 episode reward | 21.1       |
| n_updates               | 0          |
| qs_abs_difference       | 11.5       |
| qs_difference           | -11.5      |
| qs_mean                 | 0.56845725 |
| time_elapsed            | 202        |
| total timesteps         | 14435      |
| train_time              | 0          |
| update_time             | 170        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.18       |
| env_time                | 21         |
| ep_rewmean              | 20.7       |
| episodes                | 660        |
| eplenmean               | 23.8       |
| fps                     | 70         |
| mean 100 episode reward | 20.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.92       |
| qs_difference           | -3.9       |
| qs_mean                 | 0.76679987 |
| time_elapsed            | 204        |
| total timesteps         | 14510      |
| train_time              | 0          |
| update_time             | 172        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 13.6       |
| env_time                | 21         |
| ep_rewmean              | 20.4       |
| episodes                | 664        |
| eplenmean               | 23.5       |
| fps                     | 71         |
| mean 100 episode reward | 20.4       |
| n_updates               | 0          |
| qs_abs_difference       | 13.2       |
| qs_difference           | -13.2      |
| qs_mean                 | 0.58089644 |
| time_elapsed            | 204        |
| total timesteps         | 14591      |
| train_time              | 0          |
| update_time             | 172        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 3.38       |
| env_time                | 21         |
| ep_rewmean              | 20.9       |
| episodes                | 668        |
| eplenmean               | 24         |
| fps                     | 70         |
| mean 100 episode reward | 20.9       |
| n_updates               | 0          |
| qs_abs_difference       | 1.58       |
| qs_difference           | -1.25      |
| qs_mean                 | 0.67749166 |
| time_elapsed            | 207        |
| total timesteps         | 14688      |
| train_time              | 0          |
| update_time             | 174        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 15.7       |
| env_time                | 21         |
| ep_rewmean              | 21.2       |
| episodes                | 672        |
| eplenmean               | 24.1       |
| fps                     | 70         |
| mean 100 episode reward | 21.2       |
| n_updates               | 0          |
| qs_abs_difference       | 18.9       |
| qs_difference           | -18.9      |
| qs_mean                 | 0.54038334 |
| time_elapsed            | 210        |
| total timesteps         | 14791      |
| train_time              | 0          |
| update_time             | 177        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 25.7      |
| env_time                | 22        |
| ep_rewmean              | 21.7      |
| episodes                | 676       |
| eplenmean               | 24.8      |
| fps                     | 69        |
| mean 100 episode reward | 21.7      |
| n_updates               | 0         |
| qs_abs_difference       | 34.3      |
| qs_difference           | -34.3     |
| qs_mean                 | 0.5651175 |
| time_elapsed            | 215       |
| total timesteps         | 14935     |
| train_time              | 0         |
| update_time             | 182       |
---------------------------------------
--------------------------------------
| act_time                | 2        |
| current_lr              | 0.0003   |
| discount_q              | 8.38     |
| env_time                | 22       |
| ep_rewmean              | 22.2     |
| episodes                | 680      |
| eplenmean               | 25.1     |
| fps                     | 68       |
| mean 100 episode reward | 22.2     |
| n_updates               | 0        |
| qs_abs_difference       | 11.3     |
| qs_difference           | -11.3    |
| qs_mean                 | 0.582468 |
| time_elapsed            | 218      |
| total timesteps         | 15051    |
| train_time              | 0        |
| update_time             | 184      |
--------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 11.5       |
| env_time                | 22         |
| ep_rewmean              | 22.2       |
| episodes                | 684        |
| eplenmean               | 25.2       |
| fps                     | 68         |
| mean 100 episode reward | 22.2       |
| n_updates               | 0          |
| qs_abs_difference       | 6.52       |
| qs_difference           | -6.18      |
| qs_mean                 | 0.66140944 |
| time_elapsed            | 220        |
| total timesteps         | 15142      |
| train_time              | 0          |
| update_time             | 187        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.36       |
| env_time                | 22         |
| ep_rewmean              | 22.5       |
| episodes                | 688        |
| eplenmean               | 25.3       |
| fps                     | 68         |
| mean 100 episode reward | 22.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.38       |
| qs_difference           | -3.38      |
| qs_mean                 | 0.82984066 |
| time_elapsed            | 223        |
| total timesteps         | 15243      |
| train_time              | 0          |
| update_time             | 189        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 5.77      |
| env_time                | 22        |
| ep_rewmean              | 21.7      |
| episodes                | 692       |
| eplenmean               | 25.1      |
| fps                     | 67        |
| mean 100 episode reward | 21.7      |
| n_updates               | 0         |
| qs_abs_difference       | 2.62      |
| qs_difference           | -2.1      |
| qs_mean                 | 0.6279291 |
| time_elapsed            | 226       |
| total timesteps         | 15333     |
| train_time              | 0         |
| update_time             | 192       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 3.43      |
| env_time                | 22        |
| ep_rewmean              | 21.7      |
| episodes                | 696       |
| eplenmean               | 25        |
| fps                     | 67        |
| mean 100 episode reward | 21.7      |
| n_updates               | 0         |
| qs_abs_difference       | 2.27      |
| qs_difference           | -2.03     |
| qs_mean                 | 0.6908081 |
| time_elapsed            | 228       |
| total timesteps         | 15428     |
| train_time              | 0         |
| update_time             | 194       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 6.23      |
| env_time                | 22        |
| ep_rewmean              | 21.5      |
| episodes                | 700       |
| eplenmean               | 24.9      |
| fps                     | 66        |
| mean 100 episode reward | 21.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.71      |
| qs_difference           | -0.771    |
| qs_mean                 | 0.5528517 |
| time_elapsed            | 231       |
| total timesteps         | 15518     |
| train_time              | 0         |
| update_time             | 197       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 8.12       |
| env_time                | 23         |
| ep_rewmean              | 21.3       |
| episodes                | 704        |
| eplenmean               | 24.8       |
| fps                     | 67         |
| mean 100 episode reward | 21.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.88       |
| qs_difference           | -4.85      |
| qs_mean                 | 0.64374435 |
| time_elapsed            | 231        |
| total timesteps         | 15578      |
| train_time              | 0          |
| update_time             | 197        |
----------------------------------------
--------------------------------------
| act_time                | 2        |
| current_lr              | 0.0003   |
| discount_q              | 3.83     |
| env_time                | 23       |
| ep_rewmean              | 20.7     |
| episodes                | 708      |
| eplenmean               | 24.6     |
| fps                     | 66       |
| mean 100 episode reward | 20.7     |
| n_updates               | 0        |
| qs_abs_difference       | 3.17     |
| qs_difference           | -3.17    |
| qs_mean                 | 0.614484 |
| time_elapsed            | 234      |
| total timesteps         | 15658    |
| train_time              | 0        |
| update_time             | 199      |
--------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.36       |
| env_time                | 23         |
| ep_rewmean              | 20.8       |
| episodes                | 712        |
| eplenmean               | 24.5       |
| fps                     | 66         |
| mean 100 episode reward | 20.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.16       |
| qs_difference           | -4.13      |
| qs_mean                 | 0.73810166 |
| time_elapsed            | 237        |
| total timesteps         | 15746      |
| train_time              | 0          |
| update_time             | 202        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 66.2      |
| env_time                | 23        |
| ep_rewmean              | 22.4      |
| episodes                | 716       |
| eplenmean               | 25        |
| fps                     | 65        |
| mean 100 episode reward | 22.4      |
| n_updates               | 0         |
| qs_abs_difference       | 97.3      |
| qs_difference           | -97.3     |
| qs_mean                 | 0.4011257 |
| time_elapsed            | 242       |
| total timesteps         | 15937     |
| train_time              | 0         |
| update_time             | 207       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.88       |
| env_time                | 23         |
| ep_rewmean              | 21.2       |
| episodes                | 720        |
| eplenmean               | 24.7       |
| fps                     | 65         |
| mean 100 episode reward | 21.2       |
| n_updates               | 0          |
| qs_abs_difference       | 4.5        |
| qs_difference           | -4.48      |
| qs_mean                 | 0.69510937 |
| time_elapsed            | 245        |
| total timesteps         | 16043      |
| train_time              | 0          |
| update_time             | 210        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.55       |
| env_time                | 23         |
| ep_rewmean              | 20.7       |
| episodes                | 724        |
| eplenmean               | 24.6       |
| fps                     | 64         |
| mean 100 episode reward | 20.7       |
| n_updates               | 0          |
| qs_abs_difference       | 2.44       |
| qs_difference           | -2.28      |
| qs_mean                 | 0.68629205 |
| time_elapsed            | 248        |
| total timesteps         | 16115      |
| train_time              | 0          |
| update_time             | 212        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 5.41      |
| env_time                | 23        |
| ep_rewmean              | 20.7      |
| episodes                | 728       |
| eplenmean               | 24.6      |
| fps                     | 64        |
| mean 100 episode reward | 20.7      |
| n_updates               | 0         |
| qs_abs_difference       | 5.95      |
| qs_difference           | -5.91     |
| qs_mean                 | 0.5754483 |
| time_elapsed            | 251       |
| total timesteps         | 16226     |
| train_time              | 0         |
| update_time             | 215       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 9.34       |
| env_time                | 24         |
| ep_rewmean              | 20         |
| episodes                | 732        |
| eplenmean               | 24.2       |
| fps                     | 64         |
| mean 100 episode reward | 20         |
| n_updates               | 0          |
| qs_abs_difference       | 6.24       |
| qs_difference           | -6.24      |
| qs_mean                 | 0.61516565 |
| time_elapsed            | 251        |
| total timesteps         | 16298      |
| train_time              | 0          |
| update_time             | 215        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 4.63      |
| env_time                | 24        |
| ep_rewmean              | 20.5      |
| episodes                | 736       |
| eplenmean               | 24.3      |
| fps                     | 64        |
| mean 100 episode reward | 20.5      |
| n_updates               | 0         |
| qs_abs_difference       | 2.84      |
| qs_difference           | -2.55     |
| qs_mean                 | 0.6737921 |
| time_elapsed            | 254       |
| total timesteps         | 16388     |
| train_time              | 0         |
| update_time             | 218       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 6.14      |
| env_time                | 24        |
| ep_rewmean              | 20.8      |
| episodes                | 740       |
| eplenmean               | 24.5      |
| fps                     | 64        |
| mean 100 episode reward | 20.8      |
| n_updates               | 0         |
| qs_abs_difference       | 5.88      |
| qs_difference           | -5.84     |
| qs_mean                 | 0.6214196 |
| time_elapsed            | 257       |
| total timesteps         | 16485     |
| train_time              | 0         |
| update_time             | 220       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 26.1      |
| env_time                | 24        |
| ep_rewmean              | 20.7      |
| episodes                | 744       |
| eplenmean               | 24.4      |
| fps                     | 63        |
| mean 100 episode reward | 20.7      |
| n_updates               | 0         |
| qs_abs_difference       | 17.5      |
| qs_difference           | -17.5     |
| qs_mean                 | 0.5931597 |
| time_elapsed            | 260       |
| total timesteps         | 16563     |
| train_time              | 0         |
| update_time             | 223       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 8.32       |
| env_time                | 24         |
| ep_rewmean              | 20.8       |
| episodes                | 748        |
| eplenmean               | 24.5       |
| fps                     | 63         |
| mean 100 episode reward | 20.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.19       |
| qs_difference           | -3.72      |
| qs_mean                 | 0.63640606 |
| time_elapsed            | 262        |
| total timesteps         | 16630      |
| train_time              | 0          |
| update_time             | 226        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 3.69      |
| env_time                | 24        |
| ep_rewmean              | 20.6      |
| episodes                | 752       |
| eplenmean               | 24.4      |
| fps                     | 62        |
| mean 100 episode reward | 20.6      |
| n_updates               | 0         |
| qs_abs_difference       | 2.84      |
| qs_difference           | -2.79     |
| qs_mean                 | 0.7412974 |
| time_elapsed            | 265       |
| total timesteps         | 16713     |
| train_time              | 0         |
| update_time             | 228       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.8        |
| env_time                | 24         |
| ep_rewmean              | 19.9       |
| episodes                | 756        |
| eplenmean               | 23.5       |
| fps                     | 63         |
| mean 100 episode reward | 19.9       |
| n_updates               | 0          |
| qs_abs_difference       | 6.21       |
| qs_difference           | -6.21      |
| qs_mean                 | 0.66303974 |
| time_elapsed            | 266        |
| total timesteps         | 16783      |
| train_time              | 0          |
| update_time             | 228        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 2.76      |
| env_time                | 25        |
| ep_rewmean              | 21        |
| episodes                | 760       |
| eplenmean               | 24        |
| fps                     | 62        |
| mean 100 episode reward | 21        |
| n_updates               | 0         |
| qs_abs_difference       | 3.45      |
| qs_difference           | -3.39     |
| qs_mean                 | 0.7040045 |
| time_elapsed            | 271       |
| total timesteps         | 16914     |
| train_time              | 0         |
| update_time             | 234       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 12.4      |
| env_time                | 25        |
| ep_rewmean              | 21        |
| episodes                | 764       |
| eplenmean               | 24        |
| fps                     | 62        |
| mean 100 episode reward | 21        |
| n_updates               | 0         |
| qs_abs_difference       | 11.2      |
| qs_difference           | -11.2     |
| qs_mean                 | 0.6271356 |
| time_elapsed            | 271       |
| total timesteps         | 16993     |
| train_time              | 0         |
| update_time             | 234       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 14.2      |
| env_time                | 25        |
| ep_rewmean              | 21        |
| episodes                | 768       |
| eplenmean               | 24.3      |
| fps                     | 61        |
| mean 100 episode reward | 21        |
| n_updates               | 0         |
| qs_abs_difference       | 15.7      |
| qs_difference           | -15.7     |
| qs_mean                 | 0.6473714 |
| time_elapsed            | 277       |
| total timesteps         | 17114     |
| train_time              | 0         |
| update_time             | 239       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 1.99       |
| env_time                | 25         |
| ep_rewmean              | 20.9       |
| episodes                | 772        |
| eplenmean               | 24.3       |
| fps                     | 61         |
| mean 100 episode reward | 20.9       |
| n_updates               | 0          |
| qs_abs_difference       | 1.66       |
| qs_difference           | -0.957     |
| qs_mean                 | 0.66338414 |
| time_elapsed            | 280        |
| total timesteps         | 17225      |
| train_time              | 0          |
| update_time             | 242        |
----------------------------------------
--------------------------------------
| act_time                | 2        |
| current_lr              | 0.0003   |
| discount_q              | 9.4      |
| env_time                | 25       |
| ep_rewmean              | 20.1     |
| episodes                | 776      |
| eplenmean               | 23.7     |
| fps                     | 60       |
| mean 100 episode reward | 20.1     |
| n_updates               | 0        |
| qs_abs_difference       | 4.21     |
| qs_difference           | -3.99    |
| qs_mean                 | 0.629615 |
| time_elapsed            | 283      |
| total timesteps         | 17302    |
| train_time              | 0        |
| update_time             | 245      |
--------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 2.62       |
| env_time                | 25         |
| ep_rewmean              | 20         |
| episodes                | 780        |
| eplenmean               | 23.4       |
| fps                     | 61         |
| mean 100 episode reward | 20         |
| n_updates               | 0          |
| qs_abs_difference       | 2.02       |
| qs_difference           | -1.98      |
| qs_mean                 | 0.70941406 |
| time_elapsed            | 284        |
| total timesteps         | 17395      |
| train_time              | 0          |
| update_time             | 245        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 12.2      |
| env_time                | 25        |
| ep_rewmean              | 20        |
| episodes                | 784       |
| eplenmean               | 23.2      |
| fps                     | 60        |
| mean 100 episode reward | 20        |
| n_updates               | 0         |
| qs_abs_difference       | 9.05      |
| qs_difference           | -9.05     |
| qs_mean                 | 0.6020488 |
| time_elapsed            | 287       |
| total timesteps         | 17467     |
| train_time              | 0         |
| update_time             | 248       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 9.11      |
| env_time                | 26        |
| ep_rewmean              | 19.8      |
| episodes                | 788       |
| eplenmean               | 23.1      |
| fps                     | 60        |
| mean 100 episode reward | 19.8      |
| n_updates               | 0         |
| qs_abs_difference       | 6.71      |
| qs_difference           | -6.7      |
| qs_mean                 | 0.6085644 |
| time_elapsed            | 290       |
| total timesteps         | 17554     |
| train_time              | 0         |
| update_time             | 251       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 6.43      |
| env_time                | 26        |
| ep_rewmean              | 19.9      |
| episodes                | 792       |
| eplenmean               | 22.9      |
| fps                     | 60        |
| mean 100 episode reward | 19.9      |
| n_updates               | 0         |
| qs_abs_difference       | 3.69      |
| qs_difference           | -3.67     |
| qs_mean                 | 0.6095905 |
| time_elapsed            | 293       |
| total timesteps         | 17624     |
| train_time              | 0         |
| update_time             | 253       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.56       |
| env_time                | 26         |
| ep_rewmean              | 19.7       |
| episodes                | 796        |
| eplenmean               | 22.6       |
| fps                     | 60         |
| mean 100 episode reward | 19.7       |
| n_updates               | 0          |
| qs_abs_difference       | 5.48       |
| qs_difference           | -5.48      |
| qs_mean                 | 0.69425493 |
| time_elapsed            | 293        |
| total timesteps         | 17685      |
| train_time              | 0          |
| update_time             | 253        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 11        |
| env_time                | 26        |
| ep_rewmean              | 19.7      |
| episodes                | 800       |
| eplenmean               | 22.5      |
| fps                     | 59        |
| mean 100 episode reward | 19.7      |
| n_updates               | 0         |
| qs_abs_difference       | 9.64      |
| qs_difference           | -9.63     |
| qs_mean                 | 0.7002992 |
| time_elapsed            | 296       |
| total timesteps         | 17766     |
| train_time              | 0         |
| update_time             | 256       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 26.4       |
| env_time                | 26         |
| ep_rewmean              | 20.3       |
| episodes                | 804        |
| eplenmean               | 22.9       |
| fps                     | 59         |
| mean 100 episode reward | 20.3       |
| n_updates               | 0          |
| qs_abs_difference       | 29.5       |
| qs_difference           | -29.5      |
| qs_mean                 | 0.61588824 |
| time_elapsed            | 299        |
| total timesteps         | 17868      |
| train_time              | 0          |
| update_time             | 259        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 24.2      |
| env_time                | 26        |
| ep_rewmean              | 20.6      |
| episodes                | 808       |
| eplenmean               | 22.9      |
| fps                     | 59        |
| mean 100 episode reward | 20.6      |
| n_updates               | 0         |
| qs_abs_difference       | 22.7      |
| qs_difference           | -22.7     |
| qs_mean                 | 0.6011275 |
| time_elapsed            | 302       |
| total timesteps         | 17950     |
| train_time              | 0         |
| update_time             | 262       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 9.32       |
| env_time                | 26         |
| ep_rewmean              | 20.6       |
| episodes                | 812        |
| eplenmean               | 23.1       |
| fps                     | 59         |
| mean 100 episode reward | 20.6       |
| n_updates               | 0          |
| qs_abs_difference       | 12.5       |
| qs_difference           | -12.5      |
| qs_mean                 | 0.55130905 |
| time_elapsed            | 305        |
| total timesteps         | 18059      |
| train_time              | 0          |
| update_time             | 265        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 73.8      |
| env_time                | 27        |
| ep_rewmean              | 20.1      |
| episodes                | 816       |
| eplenmean               | 22.8      |
| fps                     | 58        |
| mean 100 episode reward | 20.1      |
| n_updates               | 0         |
| qs_abs_difference       | 82.8      |
| qs_difference           | -82.8     |
| qs_mean                 | 0.4259467 |
| time_elapsed            | 312       |
| total timesteps         | 18217     |
| train_time              | 0         |
| update_time             | 271       |
---------------------------------------
--------------------------------------
| act_time                | 2        |
| current_lr              | 0.0003   |
| discount_q              | 4.31     |
| env_time                | 27       |
| ep_rewmean              | 20.4     |
| episodes                | 820      |
| eplenmean               | 23.1     |
| fps                     | 58       |
| mean 100 episode reward | 20.4     |
| n_updates               | 0        |
| qs_abs_difference       | 4.41     |
| qs_difference           | 0.22     |
| qs_mean                 | 0.602926 |
| time_elapsed            | 315      |
| total timesteps         | 18355    |
| train_time              | 0        |
| update_time             | 274      |
--------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.5        |
| env_time                | 27         |
| ep_rewmean              | 20.5       |
| episodes                | 824        |
| eplenmean               | 23.3       |
| fps                     | 57         |
| mean 100 episode reward | 20.5       |
| n_updates               | 0          |
| qs_abs_difference       | 5.48       |
| qs_difference           | -5.45      |
| qs_mean                 | 0.61527383 |
| time_elapsed            | 318        |
| total timesteps         | 18448      |
| train_time              | 0          |
| update_time             | 277        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 9.9        |
| env_time                | 27         |
| ep_rewmean              | 20.4       |
| episodes                | 828        |
| eplenmean               | 22.9       |
| fps                     | 57         |
| mean 100 episode reward | 20.4       |
| n_updates               | 0          |
| qs_abs_difference       | 6.81       |
| qs_difference           | -6.8       |
| qs_mean                 | 0.61306846 |
| time_elapsed            | 321        |
| total timesteps         | 18516      |
| train_time              | 0          |
| update_time             | 280        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 9.41      |
| env_time                | 27        |
| ep_rewmean              | 20.5      |
| episodes                | 832       |
| eplenmean               | 23.1      |
| fps                     | 57        |
| mean 100 episode reward | 20.5      |
| n_updates               | 0         |
| qs_abs_difference       | 7.64      |
| qs_difference           | -7.59     |
| qs_mean                 | 0.5996119 |
| time_elapsed            | 324       |
| total timesteps         | 18604     |
| train_time              | 0         |
| update_time             | 283       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 2.67      |
| env_time                | 27        |
| ep_rewmean              | 21.3      |
| episodes                | 836       |
| eplenmean               | 23.5      |
| fps                     | 57        |
| mean 100 episode reward | 21.3      |
| n_updates               | 0         |
| qs_abs_difference       | 2.66      |
| qs_difference           | -1.1      |
| qs_mean                 | 0.6308715 |
| time_elapsed            | 328       |
| total timesteps         | 18734     |
| train_time              | 0         |
| update_time             | 286       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.42       |
| env_time                | 28         |
| ep_rewmean              | 20.8       |
| episodes                | 840        |
| eplenmean               | 23.2       |
| fps                     | 56         |
| mean 100 episode reward | 20.8       |
| n_updates               | 0          |
| qs_abs_difference       | 3.85       |
| qs_difference           | -3.81      |
| qs_mean                 | 0.58535886 |
| time_elapsed            | 331        |
| total timesteps         | 18805      |
| train_time              | 0          |
| update_time             | 289        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 6.17      |
| env_time                | 28        |
| ep_rewmean              | 20.6      |
| episodes                | 844       |
| eplenmean               | 23        |
| fps                     | 56        |
| mean 100 episode reward | 20.6      |
| n_updates               | 0         |
| qs_abs_difference       | 3.08      |
| qs_difference           | -2.8      |
| qs_mean                 | 0.6856984 |
| time_elapsed            | 331       |
| total timesteps         | 18864     |
| train_time              | 0         |
| update_time             | 289       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 9.9       |
| env_time                | 28        |
| ep_rewmean              | 20.7      |
| episodes                | 848       |
| eplenmean               | 23.4      |
| fps                     | 56        |
| mean 100 episode reward | 20.7      |
| n_updates               | 0         |
| qs_abs_difference       | 7.03      |
| qs_difference           | -6.84     |
| qs_mean                 | 0.6341028 |
| time_elapsed            | 334       |
| total timesteps         | 18965     |
| train_time              | 0         |
| update_time             | 292       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 10.4      |
| env_time                | 28        |
| ep_rewmean              | 20.7      |
| episodes                | 852       |
| eplenmean               | 23.6      |
| fps                     | 56        |
| mean 100 episode reward | 20.7      |
| n_updates               | 0         |
| qs_abs_difference       | 10.8      |
| qs_difference           | -10.8     |
| qs_mean                 | 0.6358948 |
| time_elapsed            | 338       |
| total timesteps         | 19078     |
| train_time              | 0         |
| update_time             | 295       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 11.1       |
| env_time                | 28         |
| ep_rewmean              | 20.7       |
| episodes                | 856        |
| eplenmean               | 23.8       |
| fps                     | 56         |
| mean 100 episode reward | 20.7       |
| n_updates               | 0          |
| qs_abs_difference       | 10         |
| qs_difference           | -10        |
| qs_mean                 | 0.63521546 |
| time_elapsed            | 341        |
| total timesteps         | 19162      |
| train_time              | 0          |
| update_time             | 298        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 25.5       |
| env_time                | 28         |
| ep_rewmean              | 19.8       |
| episodes                | 860        |
| eplenmean               | 23.4       |
| fps                     | 55         |
| mean 100 episode reward | 19.8       |
| n_updates               | 0          |
| qs_abs_difference       | 24.1       |
| qs_difference           | -24.1      |
| qs_mean                 | 0.59304446 |
| time_elapsed            | 344        |
| total timesteps         | 19249      |
| train_time              | 0          |
| update_time             | 302        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 4.9       |
| env_time                | 28        |
| ep_rewmean              | 19.6      |
| episodes                | 864       |
| eplenmean               | 23.2      |
| fps                     | 55        |
| mean 100 episode reward | 19.6      |
| n_updates               | 0         |
| qs_abs_difference       | 4.03      |
| qs_difference           | -4.02     |
| qs_mean                 | 0.6936689 |
| time_elapsed            | 347       |
| total timesteps         | 19318     |
| train_time              | 0         |
| update_time             | 305       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.3        |
| env_time                | 28         |
| ep_rewmean              | 19.3       |
| episodes                | 868        |
| eplenmean               | 22.7       |
| fps                     | 55         |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 3.82       |
| qs_difference           | -3.79      |
| qs_mean                 | 0.73612505 |
| time_elapsed            | 348        |
| total timesteps         | 19387      |
| train_time              | 0          |
| update_time             | 305        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.63       |
| env_time                | 29         |
| ep_rewmean              | 19.6       |
| episodes                | 872        |
| eplenmean               | 22.6       |
| fps                     | 55         |
| mean 100 episode reward | 19.6       |
| n_updates               | 0          |
| qs_abs_difference       | 2.49       |
| qs_difference           | -1.66      |
| qs_mean                 | 0.63624114 |
| time_elapsed            | 351        |
| total timesteps         | 19489      |
| train_time              | 0          |
| update_time             | 308        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 14.7      |
| env_time                | 29        |
| ep_rewmean              | 19.7      |
| episodes                | 876       |
| eplenmean               | 22.5      |
| fps                     | 55        |
| mean 100 episode reward | 19.7      |
| n_updates               | 0         |
| qs_abs_difference       | 11.8      |
| qs_difference           | -11.8     |
| qs_mean                 | 0.6566192 |
| time_elapsed            | 354       |
| total timesteps         | 19556     |
| train_time              | 0         |
| update_time             | 311       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 12        |
| env_time                | 29        |
| ep_rewmean              | 19.5      |
| episodes                | 880       |
| eplenmean               | 22.5      |
| fps                     | 54        |
| mean 100 episode reward | 19.5      |
| n_updates               | 0         |
| qs_abs_difference       | 11.9      |
| qs_difference           | -11.9     |
| qs_mean                 | 0.6547032 |
| time_elapsed            | 358       |
| total timesteps         | 19642     |
| train_time              | 0         |
| update_time             | 314       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 12.1       |
| env_time                | 29         |
| ep_rewmean              | 19.4       |
| episodes                | 884        |
| eplenmean               | 22.4       |
| fps                     | 54         |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 8.91       |
| qs_difference           | -8.91      |
| qs_mean                 | 0.63606465 |
| time_elapsed            | 361        |
| total timesteps         | 19702      |
| train_time              | 0          |
| update_time             | 317        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 5.45      |
| env_time                | 29        |
| ep_rewmean              | 19.2      |
| episodes                | 888       |
| eplenmean               | 22.1      |
| fps                     | 54        |
| mean 100 episode reward | 19.2      |
| n_updates               | 0         |
| qs_abs_difference       | 3.97      |
| qs_difference           | -3.94     |
| qs_mean                 | 0.7575939 |
| time_elapsed            | 361       |
| total timesteps         | 19766     |
| train_time              | 0         |
| update_time             | 317       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 11.7      |
| env_time                | 29        |
| ep_rewmean              | 19.2      |
| episodes                | 892       |
| eplenmean               | 22.5      |
| fps                     | 54        |
| mean 100 episode reward | 19.2      |
| n_updates               | 0         |
| qs_abs_difference       | 9.51      |
| qs_difference           | -9.5      |
| qs_mean                 | 0.5638265 |
| time_elapsed            | 365       |
| total timesteps         | 19873     |
| train_time              | 0         |
| update_time             | 321       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 5.46      |
| env_time                | 29        |
| ep_rewmean              | 19.2      |
| episodes                | 896       |
| eplenmean               | 22.7      |
| fps                     | 54        |
| mean 100 episode reward | 19.2      |
| n_updates               | 0         |
| qs_abs_difference       | 4.38      |
| qs_difference           | -4.36     |
| qs_mean                 | 0.7462578 |
| time_elapsed            | 368       |
| total timesteps         | 19953     |
| train_time              | 0         |
| update_time             | 324       |
---------------------------------------
-----------------------------------------
| eval mean 100 episod... | 23.8        |
| eval_abs_qs_difference  | 10.113447   |
| eval_discount_q         | 21.2        |
| eval_ep_rewmean         | 23.7        |
| eval_eplenmean          | 27.4        |
| eval_qs                 | -0.39193535 |
| eval_qs_difference      | -10.1       |
| eval_time_elapsed       | 0           |
| total timesteps         | 20001       |
-----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 3.48      |
| env_time                | 29        |
| ep_rewmean              | 19.4      |
| episodes                | 900       |
| eplenmean               | 22.9      |
| fps                     | 53        |
| mean 100 episode reward | 19.4      |
| n_updates               | 0         |
| qs_abs_difference       | 4.08      |
| qs_difference           | -4.08     |
| qs_mean                 | 0.6755361 |
| time_elapsed            | 372       |
| total timesteps         | 20056     |
| train_time              | 0         |
| update_time             | 327       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 6.57      |
| env_time                | 30        |
| ep_rewmean              | 18.9      |
| episodes                | 904       |
| eplenmean               | 22.7      |
| fps                     | 53        |
| mean 100 episode reward | 18.9      |
| n_updates               | 0         |
| qs_abs_difference       | 3.46      |
| qs_difference           | -1.87     |
| qs_mean                 | 0.6254186 |
| time_elapsed            | 376       |
| total timesteps         | 20134     |
| train_time              | 0         |
| update_time             | 330       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.48       |
| env_time                | 30         |
| ep_rewmean              | 18.7       |
| episodes                | 908        |
| eplenmean               | 22.7       |
| fps                     | 53         |
| mean 100 episode reward | 18.7       |
| n_updates               | 0          |
| qs_abs_difference       | 4.12       |
| qs_difference           | -4.09      |
| qs_mean                 | 0.69171584 |
| time_elapsed            | 379        |
| total timesteps         | 20217      |
| train_time              | 0          |
| update_time             | 334        |
----------------------------------------
--------------------------------------
| act_time                | 2        |
| current_lr              | 0.0003   |
| discount_q              | 6.19     |
| env_time                | 30       |
| ep_rewmean              | 18.5     |
| episodes                | 912      |
| eplenmean               | 22.3     |
| fps                     | 53       |
| mean 100 episode reward | 18.5     |
| n_updates               | 0        |
| qs_abs_difference       | 4.94     |
| qs_difference           | -4.94    |
| qs_mean                 | 0.643946 |
| time_elapsed            | 379      |
| total timesteps         | 20286    |
| train_time              | 0        |
| update_time             | 334      |
--------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.93       |
| env_time                | 30         |
| ep_rewmean              | 16.7       |
| episodes                | 916        |
| eplenmean               | 21.6       |
| fps                     | 53         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 2.53       |
| qs_difference           | -2.19      |
| qs_mean                 | 0.71551704 |
| time_elapsed            | 383        |
| total timesteps         | 20379      |
| train_time              | 0          |
| update_time             | 337        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 9.26      |
| env_time                | 30        |
| ep_rewmean              | 16.2      |
| episodes                | 920       |
| eplenmean               | 20.9      |
| fps                     | 52        |
| mean 100 episode reward | 16.2      |
| n_updates               | 0         |
| qs_abs_difference       | 4.89      |
| qs_difference           | -4.79     |
| qs_mean                 | 0.6553073 |
| time_elapsed            | 386       |
| total timesteps         | 20449     |
| train_time              | 0         |
| update_time             | 340       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 7.99      |
| env_time                | 30        |
| ep_rewmean              | 16.2      |
| episodes                | 924       |
| eplenmean               | 21        |
| fps                     | 52        |
| mean 100 episode reward | 16.2      |
| n_updates               | 0         |
| qs_abs_difference       | 5.39      |
| qs_difference           | -5.3      |
| qs_mean                 | 0.5925464 |
| time_elapsed            | 390       |
| total timesteps         | 20545     |
| train_time              | 0         |
| update_time             | 344       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 7.79      |
| env_time                | 30        |
| ep_rewmean              | 16        |
| episodes                | 928       |
| eplenmean               | 20.9      |
| fps                     | 52        |
| mean 100 episode reward | 16        |
| n_updates               | 0         |
| qs_abs_difference       | 4.39      |
| qs_difference           | -4.22     |
| qs_mean                 | 0.6437919 |
| time_elapsed            | 393       |
| total timesteps         | 20607     |
| train_time              | 0         |
| update_time             | 347       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 3.69      |
| env_time                | 30        |
| ep_rewmean              | 15.8      |
| episodes                | 932       |
| eplenmean               | 20.8      |
| fps                     | 52        |
| mean 100 episode reward | 15.8      |
| n_updates               | 0         |
| qs_abs_difference       | 2.43      |
| qs_difference           | 1.19      |
| qs_mean                 | 0.6539513 |
| time_elapsed            | 393       |
| total timesteps         | 20683     |
| train_time              | 0         |
| update_time             | 347       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 5.92      |
| env_time                | 31        |
| ep_rewmean              | 14.6      |
| episodes                | 936       |
| eplenmean               | 20.3      |
| fps                     | 52        |
| mean 100 episode reward | 14.6      |
| n_updates               | 0         |
| qs_abs_difference       | 2.89      |
| qs_difference           | -1.53     |
| qs_mean                 | 0.6689792 |
| time_elapsed            | 397       |
| total timesteps         | 20760     |
| train_time              | 0         |
| update_time             | 350       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 4.68      |
| env_time                | 31        |
| ep_rewmean              | 14.8      |
| episodes                | 940       |
| eplenmean               | 20.3      |
| fps                     | 51        |
| mean 100 episode reward | 14.8      |
| n_updates               | 0         |
| qs_abs_difference       | 4.09      |
| qs_difference           | -4.09     |
| qs_mean                 | 0.7243094 |
| time_elapsed            | 401       |
| total timesteps         | 20837     |
| train_time              | 0         |
| update_time             | 354       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.86       |
| env_time                | 31         |
| ep_rewmean              | 15.1       |
| episodes                | 944        |
| eplenmean               | 20.7       |
| fps                     | 51         |
| mean 100 episode reward | 15.1       |
| n_updates               | 0          |
| qs_abs_difference       | 4.2        |
| qs_difference           | -4.03      |
| qs_mean                 | 0.71433103 |
| time_elapsed            | 404        |
| total timesteps         | 20932      |
| train_time              | 0          |
| update_time             | 357        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 3.62      |
| env_time                | 31        |
| ep_rewmean              | 16.3      |
| episodes                | 948       |
| eplenmean               | 21.1      |
| fps                     | 51        |
| mean 100 episode reward | 16.3      |
| n_updates               | 0         |
| qs_abs_difference       | 6.54      |
| qs_difference           | -6.54     |
| qs_mean                 | 0.6737446 |
| time_elapsed            | 408       |
| total timesteps         | 21076     |
| train_time              | 0         |
| update_time             | 361       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 11.7       |
| env_time                | 31         |
| ep_rewmean              | 16.3       |
| episodes                | 952        |
| eplenmean               | 20.9       |
| fps                     | 51         |
| mean 100 episode reward | 16.3       |
| n_updates               | 0          |
| qs_abs_difference       | 11.1       |
| qs_difference           | -11.1      |
| qs_mean                 | 0.60279006 |
| time_elapsed            | 412        |
| total timesteps         | 21164      |
| train_time              | 0          |
| update_time             | 364        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.44       |
| env_time                | 31         |
| ep_rewmean              | 16.4       |
| episodes                | 956        |
| eplenmean               | 20.8       |
| fps                     | 51         |
| mean 100 episode reward | 16.4       |
| n_updates               | 0          |
| qs_abs_difference       | 3.85       |
| qs_difference           | -3.29      |
| qs_mean                 | 0.55955625 |
| time_elapsed            | 415        |
| total timesteps         | 21241      |
| train_time              | 0          |
| update_time             | 367        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 5.6       |
| env_time                | 31        |
| ep_rewmean              | 16.1      |
| episodes                | 960       |
| eplenmean               | 20.6      |
| fps                     | 50        |
| mean 100 episode reward | 16.1      |
| n_updates               | 0         |
| qs_abs_difference       | 2.99      |
| qs_difference           | -2.7      |
| qs_mean                 | 0.7520263 |
| time_elapsed            | 419       |
| total timesteps         | 21311     |
| train_time              | 0         |
| update_time             | 371       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 11.2      |
| env_time                | 31        |
| ep_rewmean              | 16        |
| episodes                | 964       |
| eplenmean               | 20.6      |
| fps                     | 50        |
| mean 100 episode reward | 16        |
| n_updates               | 0         |
| qs_abs_difference       | 7.55      |
| qs_difference           | -7.55     |
| qs_mean                 | 0.5674649 |
| time_elapsed            | 419       |
| total timesteps         | 21377     |
| train_time              | 0         |
| update_time             | 371       |
---------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 15.6      |
| env_time                | 32        |
| ep_rewmean              | 16.4      |
| episodes                | 968       |
| eplenmean               | 20.7      |
| fps                     | 50        |
| mean 100 episode reward | 16.4      |
| n_updates               | 0         |
| qs_abs_difference       | 15.9      |
| qs_difference           | -15.9     |
| qs_mean                 | 0.5159985 |
| time_elapsed            | 423       |
| total timesteps         | 21460     |
| train_time              | 0         |
| update_time             | 374       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.96       |
| env_time                | 32         |
| ep_rewmean              | 15.9       |
| episodes                | 972        |
| eplenmean               | 20.7       |
| fps                     | 50         |
| mean 100 episode reward | 15.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.7        |
| qs_difference           | -5.67      |
| qs_mean                 | 0.74843776 |
| time_elapsed            | 426        |
| total timesteps         | 21560      |
| train_time              | 0          |
| update_time             | 378        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.33       |
| env_time                | 32         |
| ep_rewmean              | 15.6       |
| episodes                | 976        |
| eplenmean               | 20.4       |
| fps                     | 50         |
| mean 100 episode reward | 15.6       |
| n_updates               | 0          |
| qs_abs_difference       | 2.44       |
| qs_difference           | -2.44      |
| qs_mean                 | 0.72850096 |
| time_elapsed            | 430        |
| total timesteps         | 21601      |
| train_time              | 0          |
| update_time             | 381        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 10.8      |
| env_time                | 32        |
| ep_rewmean              | 15.6      |
| episodes                | 980       |
| eplenmean               | 20.4      |
| fps                     | 50        |
| mean 100 episode reward | 15.6      |
| n_updates               | 0         |
| qs_abs_difference       | 9.5       |
| qs_difference           | -9.49     |
| qs_mean                 | 0.6660137 |
| time_elapsed            | 430       |
| total timesteps         | 21686     |
| train_time              | 0         |
| update_time             | 381       |
---------------------------------------
--------------------------------------
| act_time                | 2        |
| current_lr              | 0.0003   |
| discount_q              | 9.18     |
| env_time                | 32       |
| ep_rewmean              | 15.6     |
| episodes                | 984      |
| eplenmean               | 20.5     |
| fps                     | 50       |
| mean 100 episode reward | 15.6     |
| n_updates               | 0        |
| qs_abs_difference       | 7.21     |
| qs_difference           | -7.21    |
| qs_mean                 | 0.74357  |
| time_elapsed            | 434      |
| total timesteps         | 21749    |
| train_time              | 0        |
| update_time             | 385      |
--------------------------------------
--------------------------------------
| act_time                | 2        |
| current_lr              | 0.0003   |
| discount_q              | 13.2     |
| env_time                | 32       |
| ep_rewmean              | 15.9     |
| episodes                | 988      |
| eplenmean               | 20.9     |
| fps                     | 49       |
| mean 100 episode reward | 15.9     |
| n_updates               | 0        |
| qs_abs_difference       | 14.6     |
| qs_difference           | -14.6    |
| qs_mean                 | 0.594597 |
| time_elapsed            | 438      |
| total timesteps         | 21854    |
| train_time              | 0        |
| update_time             | 388      |
--------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.47       |
| env_time                | 32         |
| ep_rewmean              | 16         |
| episodes                | 992        |
| eplenmean               | 20.7       |
| fps                     | 49         |
| mean 100 episode reward | 16         |
| n_updates               | 0          |
| qs_abs_difference       | 3.06       |
| qs_difference           | -1.74      |
| qs_mean                 | 0.62229913 |
| time_elapsed            | 441        |
| total timesteps         | 21942      |
| train_time              | 0          |
| update_time             | 392        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 2.43       |
| env_time                | 32         |
| ep_rewmean              | 15.8       |
| episodes                | 996        |
| eplenmean               | 20.6       |
| fps                     | 49         |
| mean 100 episode reward | 15.8       |
| n_updates               | 0          |
| qs_abs_difference       | 1.64       |
| qs_difference           | 0.589      |
| qs_mean                 | 0.73544914 |
| time_elapsed            | 445        |
| total timesteps         | 22008      |
| train_time              | 0          |
| update_time             | 396        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 3.68      |
| env_time                | 33        |
| ep_rewmean              | 15.7      |
| episodes                | 1000      |
| eplenmean               | 20.3      |
| fps                     | 49        |
| mean 100 episode reward | 15.7      |
| n_updates               | 0         |
| qs_abs_difference       | 3.11      |
| qs_difference           | -3.11     |
| qs_mean                 | 0.7248832 |
| time_elapsed            | 445       |
| total timesteps         | 22089     |
| train_time              | 0         |
| update_time             | 396       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 10.1      |
| env_time                | 33        |
| ep_rewmean              | 15.8      |
| episodes                | 1004      |
| eplenmean               | 20.3      |
| fps                     | 49        |
| mean 100 episode reward | 15.8      |
| n_updates               | 0         |
| qs_abs_difference       | 7.85      |
| qs_difference           | -7.85     |
| qs_mean                 | 0.6313725 |
| time_elapsed            | 449       |
| total timesteps         | 22165     |
| train_time              | 0         |
| update_time             | 399       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 16.2      |
| env_time                | 33        |
| ep_rewmean              | 15.8      |
| episodes                | 1008      |
| eplenmean               | 20.3      |
| fps                     | 49        |
| mean 100 episode reward | 15.8      |
| n_updates               | 0         |
| qs_abs_difference       | 15.9      |
| qs_difference           | -15.9     |
| qs_mean                 | 0.5468825 |
| time_elapsed            | 453       |
| total timesteps         | 22244     |
| train_time              | 0         |
| update_time             | 403       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 11        |
| env_time                | 33        |
| ep_rewmean              | 16.4      |
| episodes                | 1012      |
| eplenmean               | 20.8      |
| fps                     | 48        |
| mean 100 episode reward | 16.4      |
| n_updates               | 0         |
| qs_abs_difference       | 14.6      |
| qs_difference           | -14.6     |
| qs_mean                 | 0.6391435 |
| time_elapsed            | 457       |
| total timesteps         | 22369     |
| train_time              | 0         |
| update_time             | 407       |
---------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 4.49       |
| env_time                | 33         |
| ep_rewmean              | 17         |
| episodes                | 1016       |
| eplenmean               | 21.3       |
| fps                     | 48         |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 4.04       |
| qs_difference           | -3.83      |
| qs_mean                 | 0.63840395 |
| time_elapsed            | 465        |
| total timesteps         | 22507      |
| train_time              | 0          |
| update_time             | 414        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 26.4      |
| env_time                | 33        |
| ep_rewmean              | 17.3      |
| episodes                | 1020      |
| eplenmean               | 21.6      |
| fps                     | 48        |
| mean 100 episode reward | 17.3      |
| n_updates               | 0         |
| qs_abs_difference       | 22.4      |
| qs_difference           | -22.4     |
| qs_mean                 | 0.6835899 |
| time_elapsed            | 468       |
| total timesteps         | 22605     |
| train_time              | 0         |
| update_time             | 418       |
---------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 8.14       |
| env_time                | 34         |
| ep_rewmean              | 17.4       |
| episodes                | 1024       |
| eplenmean               | 21.3       |
| fps                     | 48         |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 7.03       |
| qs_difference           | -7.03      |
| qs_mean                 | 0.72241557 |
| time_elapsed            | 469        |
| total timesteps         | 22679      |
| train_time              | 0          |
| update_time             | 418        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 5.89       |
| env_time                | 34         |
| ep_rewmean              | 17.6       |
| episodes                | 1028       |
| eplenmean               | 21.6       |
| fps                     | 48         |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.5        |
| qs_difference           | -5.5       |
| qs_mean                 | 0.69329065 |
| time_elapsed            | 473        |
| total timesteps         | 22762      |
| train_time              | 0          |
| update_time             | 421        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 17.6      |
| env_time                | 34        |
| ep_rewmean              | 18.2      |
| episodes                | 1032      |
| eplenmean               | 21.8      |
| fps                     | 47        |
| mean 100 episode reward | 18.2      |
| n_updates               | 0         |
| qs_abs_difference       | 19.8      |
| qs_difference           | -19.8     |
| qs_mean                 | 0.5719189 |
| time_elapsed            | 477       |
| total timesteps         | 22863     |
| train_time              | 0         |
| update_time             | 425       |
---------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 7.9        |
| env_time                | 34         |
| ep_rewmean              | 18.3       |
| episodes                | 1036       |
| eplenmean               | 21.7       |
| fps                     | 47         |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 6.28       |
| qs_difference           | -6.28      |
| qs_mean                 | 0.47590804 |
| time_elapsed            | 480        |
| total timesteps         | 22932      |
| train_time              | 0          |
| update_time             | 429        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 23        |
| env_time                | 34        |
| ep_rewmean              | 18.6      |
| episodes                | 1040      |
| eplenmean               | 21.9      |
| fps                     | 47        |
| mean 100 episode reward | 18.6      |
| n_updates               | 0         |
| qs_abs_difference       | 22.7      |
| qs_difference           | -22.7     |
| qs_mean                 | 0.6063781 |
| time_elapsed            | 484       |
| total timesteps         | 23029     |
| train_time              | 0         |
| update_time             | 433       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 0.745     |
| env_time                | 35        |
| ep_rewmean              | 21.1      |
| episodes                | 1044      |
| eplenmean               | 23.5      |
| fps                     | 47        |
| mean 100 episode reward | 21.1      |
| n_updates               | 0         |
| qs_abs_difference       | 3.28      |
| qs_difference           | -3.22     |
| qs_mean                 | 0.7367083 |
| time_elapsed            | 493       |
| total timesteps         | 23279     |
| train_time              | 0         |
| update_time             | 440       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 15.3      |
| env_time                | 35        |
| ep_rewmean              | 20.1      |
| episodes                | 1048      |
| eplenmean               | 22.9      |
| fps                     | 47        |
| mean 100 episode reward | 20.1      |
| n_updates               | 0         |
| qs_abs_difference       | 13.6      |
| qs_difference           | -13.6     |
| qs_mean                 | 0.6640681 |
| time_elapsed            | 497       |
| total timesteps         | 23365     |
| train_time              | 0         |
| update_time             | 444       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 8.62      |
| env_time                | 35        |
| ep_rewmean              | 19.8      |
| episodes                | 1052      |
| eplenmean               | 22.7      |
| fps                     | 46        |
| mean 100 episode reward | 19.8      |
| n_updates               | 0         |
| qs_abs_difference       | 4.06      |
| qs_difference           | -3.41     |
| qs_mean                 | 0.6374401 |
| time_elapsed            | 501       |
| total timesteps         | 23433     |
| train_time              | 0         |
| update_time             | 448       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 17.2      |
| env_time                | 35        |
| ep_rewmean              | 20        |
| episodes                | 1056      |
| eplenmean               | 23.1      |
| fps                     | 46        |
| mean 100 episode reward | 20        |
| n_updates               | 0         |
| qs_abs_difference       | 20.6      |
| qs_difference           | -20.6     |
| qs_mean                 | 0.5602925 |
| time_elapsed            | 505       |
| total timesteps         | 23555     |
| train_time              | 0         |
| update_time             | 452       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 3.92      |
| env_time                | 35        |
| ep_rewmean              | 20.5      |
| episodes                | 1060      |
| eplenmean               | 23.6      |
| fps                     | 46        |
| mean 100 episode reward | 20.5      |
| n_updates               | 0         |
| qs_abs_difference       | 5.18      |
| qs_difference           | -5.18     |
| qs_mean                 | 0.6904574 |
| time_elapsed            | 509       |
| total timesteps         | 23671     |
| train_time              | 0         |
| update_time             | 455       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 5.36      |
| env_time                | 35        |
| ep_rewmean              | 21.1      |
| episodes                | 1064      |
| eplenmean               | 23.9      |
| fps                     | 46        |
| mean 100 episode reward | 21.1      |
| n_updates               | 0         |
| qs_abs_difference       | 4.01      |
| qs_difference           | -3.94     |
| qs_mean                 | 0.6928765 |
| time_elapsed            | 513       |
| total timesteps         | 23766     |
| train_time              | 0         |
| update_time             | 459       |
---------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 6.52       |
| env_time                | 35         |
| ep_rewmean              | 20.9       |
| episodes                | 1068       |
| eplenmean               | 24.2       |
| fps                     | 46         |
| mean 100 episode reward | 20.9       |
| n_updates               | 0          |
| qs_abs_difference       | 7.03       |
| qs_difference           | -7.01      |
| qs_mean                 | 0.62276024 |
| time_elapsed            | 517        |
| total timesteps         | 23881      |
| train_time              | 0          |
| update_time             | 463        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 7.32      |
| env_time                | 36        |
| ep_rewmean              | 20.9      |
| episodes                | 1072      |
| eplenmean               | 24        |
| fps                     | 45        |
| mean 100 episode reward | 20.9      |
| n_updates               | 0         |
| qs_abs_difference       | 6         |
| qs_difference           | -5.98     |
| qs_mean                 | 0.6720745 |
| time_elapsed            | 521       |
| total timesteps         | 23956     |
| train_time              | 0         |
| update_time             | 467       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 11.1      |
| env_time                | 36        |
| ep_rewmean              | 21.6      |
| episodes                | 1076      |
| eplenmean               | 24.7      |
| fps                     | 45        |
| mean 100 episode reward | 21.6      |
| n_updates               | 0         |
| qs_abs_difference       | 14.3      |
| qs_difference           | -14.3     |
| qs_mean                 | 0.5671246 |
| time_elapsed            | 525       |
| total timesteps         | 24068     |
| train_time              | 0         |
| update_time             | 471       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 6.05      |
| env_time                | 36        |
| ep_rewmean              | 22.4      |
| episodes                | 1080      |
| eplenmean               | 25        |
| fps                     | 45        |
| mean 100 episode reward | 22.4      |
| n_updates               | 0         |
| qs_abs_difference       | 8.49      |
| qs_difference           | -8.49     |
| qs_mean                 | 0.6372695 |
| time_elapsed            | 529       |
| total timesteps         | 24190     |
| train_time              | 0         |
| update_time             | 475       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 6.42      |
| env_time                | 36        |
| ep_rewmean              | 22.5      |
| episodes                | 1084      |
| eplenmean               | 25.1      |
| fps                     | 45        |
| mean 100 episode reward | 22.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.97      |
| qs_difference           | -3.82     |
| qs_mean                 | 0.7104944 |
| time_elapsed            | 533       |
| total timesteps         | 24257     |
| train_time              | 0         |
| update_time             | 479       |
---------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 2.78       |
| env_time                | 36         |
| ep_rewmean              | 22.6       |
| episodes                | 1088       |
| eplenmean               | 25         |
| fps                     | 45         |
| mean 100 episode reward | 22.6       |
| n_updates               | 0          |
| qs_abs_difference       | 2.47       |
| qs_difference           | -2.41      |
| qs_mean                 | 0.76003563 |
| time_elapsed            | 537        |
| total timesteps         | 24354      |
| train_time              | 0          |
| update_time             | 483        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 4.76       |
| env_time                | 36         |
| ep_rewmean              | 22.4       |
| episodes                | 1092       |
| eplenmean               | 24.7       |
| fps                     | 45         |
| mean 100 episode reward | 22.4       |
| n_updates               | 0          |
| qs_abs_difference       | 2.35       |
| qs_difference           | -2.01      |
| qs_mean                 | 0.72421753 |
| time_elapsed            | 542        |
| total timesteps         | 24416      |
| train_time              | 0          |
| update_time             | 487        |
----------------------------------------
--------------------------------------
| act_time                | 3        |
| current_lr              | 0.0003   |
| discount_q              | 6.47     |
| env_time                | 36       |
| ep_rewmean              | 22.6     |
| episodes                | 1096     |
| eplenmean               | 24.8     |
| fps                     | 45       |
| mean 100 episode reward | 22.6     |
| n_updates               | 0        |
| qs_abs_difference       | 4.39     |
| qs_difference           | -4.28    |
| qs_mean                 | 0.717571 |
| time_elapsed            | 542      |
| total timesteps         | 24483    |
| train_time              | 0        |
| update_time             | 487      |
--------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 3.48      |
| env_time                | 37        |
| ep_rewmean              | 22.8      |
| episodes                | 1100      |
| eplenmean               | 24.9      |
| fps                     | 44        |
| mean 100 episode reward | 22.8      |
| n_updates               | 0         |
| qs_abs_difference       | 3.17      |
| qs_difference           | -3.1      |
| qs_mean                 | 0.8210222 |
| time_elapsed            | 546       |
| total timesteps         | 24582     |
| train_time              | 0         |
| update_time             | 491       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 9.45      |
| env_time                | 37        |
| ep_rewmean              | 23        |
| episodes                | 1104      |
| eplenmean               | 25.1      |
| fps                     | 44        |
| mean 100 episode reward | 23        |
| n_updates               | 0         |
| qs_abs_difference       | 9.93      |
| qs_difference           | -9.93     |
| qs_mean                 | 0.6001177 |
| time_elapsed            | 550       |
| total timesteps         | 24675     |
| train_time              | 0         |
| update_time             | 495       |
---------------------------------------
--------------------------------------
| act_time                | 3        |
| current_lr              | 0.0003   |
| discount_q              | 2.99     |
| env_time                | 37       |
| ep_rewmean              | 23.8     |
| episodes                | 1108     |
| eplenmean               | 25.5     |
| fps                     | 44       |
| mean 100 episode reward | 23.8     |
| n_updates               | 0        |
| qs_abs_difference       | 3.17     |
| qs_difference           | -3.15    |
| qs_mean                 | 0.707159 |
| time_elapsed            | 554      |
| total timesteps         | 24791    |
| train_time              | 0        |
| update_time             | 499      |
--------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 4.72       |
| env_time                | 37         |
| ep_rewmean              | 23.5       |
| episodes                | 1112       |
| eplenmean               | 25.3       |
| fps                     | 44         |
| mean 100 episode reward | 23.5       |
| n_updates               | 0          |
| qs_abs_difference       | 5.19       |
| qs_difference           | -5.17      |
| qs_mean                 | 0.61362374 |
| time_elapsed            | 563        |
| total timesteps         | 24902      |
| train_time              | 0          |
| update_time             | 507        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 5.31       |
| env_time                | 37         |
| ep_rewmean              | 22.9       |
| episodes                | 1116       |
| eplenmean               | 24.8       |
| fps                     | 44         |
| mean 100 episode reward | 22.9       |
| n_updates               | 0          |
| qs_abs_difference       | 4.5        |
| qs_difference           | -4.46      |
| qs_mean                 | 0.71587604 |
| time_elapsed            | 563        |
| total timesteps         | 24988      |
| train_time              | 0          |
| update_time             | 507        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 17.4       |
| env_time                | 37         |
| ep_rewmean              | 23.6       |
| episodes                | 1120       |
| eplenmean               | 24.7       |
| fps                     | 43         |
| mean 100 episode reward | 23.6       |
| n_updates               | 200        |
| q_grad_norm             | 32.53397   |
| qfs_loss                | 143.78381  |
| qs_abs_difference       | 20.9       |
| qs_difference           | -20.9      |
| qs_mean                 | 0.29305613 |
| time_elapsed            | 572        |
| total timesteps         | 25078      |
| train_time              | 5          |
| update_time             | 511        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 18.6      |
| env_time                | 37        |
| ep_rewmean              | 24.9      |
| episodes                | 1124      |
| eplenmean               | 25.1      |
| fps                     | 43        |
| mean 100 episode reward | 24.9      |
| n_updates               | 400       |
| q_grad_norm             | 40.099472 |
| qfs_loss                | 135.2818  |
| qs_abs_difference       | 14.6      |
| qs_difference           | -11.2     |
| qs_mean                 | 14.276521 |
| time_elapsed            | 579       |
| total timesteps         | 25189     |
| train_time              | 7         |
| update_time             | 515       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 17.7      |
| env_time                | 38        |
| ep_rewmean              | 26.1      |
| episodes                | 1128      |
| eplenmean               | 25.2      |
| fps                     | 43        |
| mean 100 episode reward | 26.1      |
| n_updates               | 600       |
| q_grad_norm             | 52.472477 |
| qfs_loss                | 122.19562 |
| qs_abs_difference       | 10.2      |
| qs_difference           | 0.0542    |
| qs_mean                 | 22.637583 |
| time_elapsed            | 586       |
| total timesteps         | 25287     |
| train_time              | 10        |
| update_time             | 519       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 18.4      |
| env_time                | 38        |
| ep_rewmean              | 26.8      |
| episodes                | 1132      |
| eplenmean               | 25.2      |
| fps                     | 42        |
| mean 100 episode reward | 26.8      |
| n_updates               | 800       |
| q_grad_norm             | 71.491936 |
| qfs_loss                | 120.41034 |
| qs_abs_difference       | 11.3      |
| qs_difference           | 7.42      |
| qs_mean                 | 30.52832  |
| time_elapsed            | 594       |
| total timesteps         | 25385     |
| train_time              | 13        |
| update_time             | 523       |
---------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 17.6       |
| env_time                | 38         |
| ep_rewmean              | 27.8       |
| episodes                | 1136       |
| eplenmean               | 25.4       |
| fps                     | 42         |
| mean 100 episode reward | 27.8       |
| n_updates               | 1000       |
| q_grad_norm             | 104.440186 |
| qfs_loss                | 120.54004  |
| qs_abs_difference       | 16.8       |
| qs_difference           | 16.6       |
| qs_mean                 | 37.870377  |
| time_elapsed            | 601        |
| total timesteps         | 25477      |
| train_time              | 15         |
| update_time             | 527        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 17.4      |
| env_time                | 38        |
| ep_rewmean              | 28.5      |
| episodes                | 1140      |
| eplenmean               | 25.4      |
| fps                     | 42        |
| mean 100 episode reward | 28.5      |
| n_updates               | 1200      |
| q_grad_norm             | 158.10788 |
| qfs_loss                | 109.94809 |
| qs_abs_difference       | 24.4      |
| qs_difference           | 24.4      |
| qs_mean                 | 45.191433 |
| time_elapsed            | 608       |
| total timesteps         | 25566     |
| train_time              | 18        |
| update_time             | 531       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 17.3      |
| env_time                | 38        |
| ep_rewmean              | 26.7      |
| episodes                | 1144      |
| eplenmean               | 23.8      |
| fps                     | 41        |
| mean 100 episode reward | 26.7      |
| n_updates               | 1400      |
| q_grad_norm             | 189.34416 |
| qfs_loss                | 107.05308 |
| qs_abs_difference       | 30.7      |
| qs_difference           | 30.7      |
| qs_mean                 | 51.368717 |
| time_elapsed            | 615       |
| total timesteps         | 25655     |
| train_time              | 21        |
| update_time             | 535       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 18.4      |
| env_time                | 38        |
| ep_rewmean              | 27.6      |
| episodes                | 1148      |
| eplenmean               | 23.8      |
| fps                     | 41        |
| mean 100 episode reward | 27.6      |
| n_updates               | 1600      |
| q_grad_norm             | 246.72337 |
| qfs_loss                | 95.15623  |
| qs_abs_difference       | 33.7      |
| qs_difference           | 33.7      |
| qs_mean                 | 55.379578 |
| time_elapsed            | 622       |
| total timesteps         | 25746     |
| train_time              | 23        |
| update_time             | 539       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 26.7      |
| env_time                | 39        |
| ep_rewmean              | 29.9      |
| episodes                | 1152      |
| eplenmean               | 24.7      |
| fps                     | 40        |
| mean 100 episode reward | 29.9      |
| n_updates               | 2000      |
| q_grad_norm             | 386.1023  |
| qfs_loss                | 93.12314  |
| qs_abs_difference       | 22.1      |
| qs_difference           | 18.7      |
| qs_mean                 | 62.634636 |
| time_elapsed            | 636       |
| total timesteps         | 25900     |
| train_time              | 29        |
| update_time             | 548       |
---------------------------------------
--------------------------------------
| act_time                | 4        |
| current_lr              | 0.0003   |
| discount_q              | 18       |
| env_time                | 39       |
| ep_rewmean              | 35.1     |
| episodes                | 1156     |
| eplenmean               | 26.5     |
| fps                     | 39       |
| mean 100 episode reward | 35.1     |
| n_updates               | 2600     |
| q_grad_norm             | 539.4511 |
| qfs_loss                | 92.13876 |
| qs_abs_difference       | 35.3     |
| qs_difference           | -13.2    |
| qs_mean                 | 79.53383 |
| time_elapsed            | 657      |
| total timesteps         | 26206    |
| train_time              | 37       |
| update_time             | 561      |
--------------------------------------
----------------------------------------
| act_time                | 4          |
| current_lr              | 0.0003     |
| discount_q              | 20         |
| env_time                | 40         |
| ep_rewmean              | 42.3       |
| episodes                | 1160       |
| eplenmean               | 28.8       |
| fps                     | 39         |
| mean 100 episode reward | 42.3       |
| n_updates               | 3200       |
| q_grad_norm             | 841.99097  |
| qfs_loss                | 114.031746 |
| qs_abs_difference       | 54.5       |
| qs_difference           | -23.6      |
| qs_mean                 | 104.29584  |
| time_elapsed            | 679        |
| total timesteps         | 26555      |
| train_time              | 45         |
| update_time             | 573        |
----------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 0.438     |
| env_time                | 41        |
| ep_rewmean              | 62        |
| episodes                | 1164      |
| eplenmean               | 35.7      |
| fps                     | 37        |
| mean 100 episode reward | 62        |
| n_updates               | 4800      |
| q_grad_norm             | 1722.7926 |
| qfs_loss                | 171.48347 |
| qs_abs_difference       | 44        |
| qs_difference           | 11.5      |
| qs_mean                 | 164.4649  |
| time_elapsed            | 737       |
| total timesteps         | 27333     |
| train_time              | 66        |
| update_time             | 608       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 1.02      |
| env_time                | 42        |
| ep_rewmean              | 79.6      |
| episodes                | 1168      |
| eplenmean               | 41.6      |
| fps                     | 35        |
| mean 100 episode reward | 79.6      |
| n_updates               | 6200      |
| q_grad_norm             | 3033.0576 |
| qfs_loss                | 148.38715 |
| qs_abs_difference       | 56.7      |
| qs_difference           | 56.5      |
| qs_mean                 | 221.62903 |
| time_elapsed            | 788       |
| total timesteps         | 28041     |
| train_time              | 84        |
| update_time             | 638       |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 1.33      |
| env_time                | 43        |
| ep_rewmean              | 95.5      |
| episodes                | 1172      |
| eplenmean               | 47.2      |
| fps                     | 34        |
| mean 100 episode reward | 95.5      |
| n_updates               | 7400      |
| q_grad_norm             | 4369.045  |
| qfs_loss                | 149.66719 |
| qs_abs_difference       | 93.1      |
| qs_difference           | 93.1      |
| qs_mean                 | 230.89374 |
| time_elapsed            | 832       |
| total timesteps         | 28674     |
| train_time              | 100       |
| update_time             | 664       |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 2.86      |
| env_time                | 44        |
| ep_rewmean              | 107       |
| episodes                | 1176      |
| eplenmean               | 51.3      |
| fps                     | 33        |
| mean 100 episode reward | 107       |
| n_updates               | 8400      |
| q_grad_norm             | 4800.5376 |
| qfs_loss                | 139.33823 |
| qs_abs_difference       | 105       |
| qs_difference           | 105       |
| qs_mean                 | 221.91148 |
| time_elapsed            | 868       |
| total timesteps         | 29198     |
| train_time              | 114       |
| update_time             | 686       |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 2.13      |
| env_time                | 45        |
| ep_rewmean              | 118       |
| episodes                | 1180      |
| eplenmean               | 55.5      |
| fps                     | 32        |
| mean 100 episode reward | 118       |
| n_updates               | 9600      |
| q_grad_norm             | 6392.049  |
| qfs_loss                | 170.68576 |
| qs_abs_difference       | 166       |
| qs_difference           | 166       |
| qs_mean                 | 263.1321  |
| time_elapsed            | 912       |
| total timesteps         | 29735     |
| train_time              | 130       |
| update_time             | 713       |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 83        |
| eval_abs_qs_difference  | 159.06921 |
| eval_discount_q         | 147       |
| eval_ep_rewmean         | 278       |
| eval_eplenmean          | 128       |
| eval_qs                 | 263.3485  |
| eval_qs_difference      | 159       |
| eval_time_elapsed       | 3         |
| total timesteps         | 30001     |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 2.09      |
| env_time                | 46        |
| ep_rewmean              | 130       |
| episodes                | 1184      |
| eplenmean               | 60.3      |
| fps                     | 31        |
| mean 100 episode reward | 130       |
| n_updates               | 10600     |
| q_grad_norm             | 6161.87   |
| qfs_loss                | 155.56111 |
| qs_abs_difference       | 169       |
| qs_difference           | 169       |
| qs_mean                 | 268.7616  |
| time_elapsed            | 953       |
| total timesteps         | 30284     |
| train_time              | 143       |
| update_time             | 735       |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 3.37      |
| env_time                | 46        |
| ep_rewmean              | 140       |
| episodes                | 1188      |
| eplenmean               | 63.8      |
| fps                     | 31        |
| mean 100 episode reward | 140       |
| n_updates               | 11600     |
| q_grad_norm             | 7197.967  |
| qfs_loss                | 173.73026 |
| qs_abs_difference       | 177       |
| qs_difference           | 177       |
| qs_mean                 | 258.0443  |
| time_elapsed            | 990       |
| total timesteps         | 30736     |
| train_time              | 156       |
| update_time             | 758       |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 3.76      |
| env_time                | 47        |
| ep_rewmean              | 152       |
| episodes                | 1192      |
| eplenmean               | 68.3      |
| fps                     | 30        |
| mean 100 episode reward | 152       |
| n_updates               | 12600     |
| q_grad_norm             | 5384.7407 |
| qfs_loss                | 127.16529 |
| qs_abs_difference       | 118       |
| qs_difference           | 118       |
| qs_mean                 | 245.57355 |
| time_elapsed            | 1027      |
| total timesteps         | 31242     |
| train_time              | 169       |
| update_time             | 780       |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 0.807     |
| env_time                | 48        |
| ep_rewmean              | 161       |
| episodes                | 1196      |
| eplenmean               | 71.6      |
| fps                     | 29        |
| mean 100 episode reward | 161       |
| n_updates               | 13400     |
| q_grad_norm             | 6567.273  |
| qfs_loss                | 132.38922 |
| qs_abs_difference       | 241       |
| qs_difference           | 241       |
| qs_mean                 | 262.81787 |
| time_elapsed            | 1057      |
| total timesteps         | 31642     |
| train_time              | 180       |
| update_time             | 798       |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 41        |
| env_time                | 48        |
| ep_rewmean              | 165       |
| episodes                | 1200      |
| eplenmean               | 72.7      |
| fps                     | 29        |
| mean 100 episode reward | 165       |
| n_updates               | 13800     |
| q_grad_norm             | 7392.774  |
| qfs_loss                | 202.4846  |
| qs_abs_difference       | 182       |
| qs_difference           | 182       |
| qs_mean                 | 268.13098 |
| time_elapsed            | 1072      |
| total timesteps         | 31847     |
| train_time              | 185       |
| update_time             | 808       |
---------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 14.8      |
| env_time                | 49        |
| ep_rewmean              | 173       |
| episodes                | 1204      |
| eplenmean               | 75.5      |
| fps                     | 29        |
| mean 100 episode reward | 173       |
| n_updates               | 14600     |
| q_grad_norm             | 6381.643  |
| qfs_loss                | 162.30084 |
| qs_abs_difference       | 125       |
| qs_difference           | 125       |
| qs_mean                 | 247.90337 |
| time_elapsed            | 1103      |
| total timesteps         | 32225     |
| train_time              | 196       |
| update_time             | 826       |
---------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 5.38      |
| env_time                | 50        |
| ep_rewmean              | 185       |
| episodes                | 1208      |
| eplenmean               | 79.4      |
| fps                     | 28        |
| mean 100 episode reward | 185       |
| n_updates               | 15600     |
| q_grad_norm             | 7362.0425 |
| qfs_loss                | 163.1028  |
| qs_abs_difference       | 58.3      |
| qs_difference           | 56.2      |
| qs_mean                 | 232.04909 |
| time_elapsed            | 1141      |
| total timesteps         | 32734     |
| train_time              | 209       |
| update_time             | 850       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 2.89      |
| env_time                | 50        |
| ep_rewmean              | 195       |
| episodes                | 1212      |
| eplenmean               | 82.7      |
| fps                     | 28        |
| mean 100 episode reward | 195       |
| n_updates               | 16400     |
| q_grad_norm             | 6680.667  |
| qfs_loss                | 147.96748 |
| qs_abs_difference       | 190       |
| qs_difference           | 190       |
| qs_mean                 | 262.72958 |
| time_elapsed            | 1171      |
| total timesteps         | 33169     |
| train_time              | 220       |
| update_time             | 868       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 8.88      |
| env_time                | 51        |
| ep_rewmean              | 201       |
| episodes                | 1216      |
| eplenmean               | 85.2      |
| fps                     | 27        |
| mean 100 episode reward | 201       |
| n_updates               | 17200     |
| q_grad_norm             | 6823.672  |
| qfs_loss                | 158.59067 |
| qs_abs_difference       | 188       |
| qs_difference           | 188       |
| qs_mean                 | 265.82037 |
| time_elapsed            | 1202      |
| total timesteps         | 33503     |
| train_time              | 231       |
| update_time             | 887       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 1.47      |
| env_time                | 52        |
| ep_rewmean              | 211       |
| episodes                | 1220      |
| eplenmean               | 89.7      |
| fps                     | 27        |
| mean 100 episode reward | 210       |
| n_updates               | 18200     |
| q_grad_norm             | 6029.4194 |
| qfs_loss                | 138.85426 |
| qs_abs_difference       | 164       |
| qs_difference           | 164       |
| qs_mean                 | 252.42227 |
| time_elapsed            | 1240      |
| total timesteps         | 34052     |
| train_time              | 244       |
| update_time             | 911       |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 2.37      |
| env_time                | 53        |
| ep_rewmean              | 221       |
| episodes                | 1224      |
| eplenmean               | 94.1      |
| fps                     | 27        |
| mean 100 episode reward | 221       |
| n_updates               | 19200     |
| q_grad_norm             | 7594.516  |
| qfs_loss                | 175.31738 |
| qs_abs_difference       | 97.1      |
| qs_difference           | 97        |
| qs_mean                 | 209.8558  |
| time_elapsed            | 1279      |
| total timesteps         | 34595     |
| train_time              | 257       |
| update_time             | 935       |
---------------------------------------
--------------------------------------
| act_time                | 11       |
| current_lr              | 0.0003   |
| discount_q              | 3.16     |
| env_time                | 53       |
| ep_rewmean              | 232      |
| episodes                | 1228     |
| eplenmean               | 98.6     |
| fps                     | 26       |
| mean 100 episode reward | 232      |
| n_updates               | 20400    |
| q_grad_norm             | 6749.572 |
| qfs_loss                | 138.0169 |
| qs_abs_difference       | 104      |
| qs_difference           | 104      |
| qs_mean                 | 228.379  |
| time_elapsed            | 1325     |
| total timesteps         | 35150    |
| train_time              | 273      |
| update_time             | 964      |
--------------------------------------
--------------------------------------
| act_time                | 11       |
| current_lr              | 0.0003   |
| discount_q              | 8.3      |
| env_time                | 54       |
| ep_rewmean              | 240      |
| episodes                | 1232     |
| eplenmean               | 102      |
| fps                     | 26       |
| mean 100 episode reward | 240      |
| n_updates               | 21200    |
| q_grad_norm             | 7131.35  |
| qfs_loss                | 166.2433 |
| qs_abs_difference       | 86.1     |
| qs_difference           | 86.1     |
| qs_mean                 | 202.989  |
| time_elapsed            | 1357     |
| total timesteps         | 35578    |
| train_time              | 284      |
| update_time             | 983      |
--------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 3.94      |
| env_time                | 55        |
| ep_rewmean              | 253       |
| episodes                | 1236      |
| eplenmean               | 106       |
| fps                     | 25        |
| mean 100 episode reward | 253       |
| n_updates               | 22200     |
| q_grad_norm             | 6841.4736 |
| qfs_loss                | 161.73396 |
| qs_abs_difference       | 63.2      |
| qs_difference           | 59.1      |
| qs_mean                 | 200.76917 |
| time_elapsed            | 1396      |
| total timesteps         | 36080     |
| train_time              | 297       |
| update_time             | 1008      |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 4.56      |
| env_time                | 56        |
| ep_rewmean              | 266       |
| episodes                | 1240      |
| eplenmean               | 110       |
| fps                     | 25        |
| mean 100 episode reward | 266       |
| n_updates               | 23400     |
| q_grad_norm             | 6770.268  |
| qfs_loss                | 141.3203  |
| qs_abs_difference       | 50.4      |
| qs_difference           | 44.1      |
| qs_mean                 | 214.18597 |
| time_elapsed            | 1442      |
| total timesteps         | 36610     |
| train_time              | 313       |
| update_time             | 1037      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 2.33      |
| env_time                | 57        |
| ep_rewmean              | 280       |
| episodes                | 1244      |
| eplenmean               | 115       |
| fps                     | 25        |
| mean 100 episode reward | 280       |
| n_updates               | 24400     |
| q_grad_norm             | 6845.9644 |
| qfs_loss                | 146.46265 |
| qs_abs_difference       | 79.4      |
| qs_difference           | 79        |
| qs_mean                 | 225.09808 |
| time_elapsed            | 1482      |
| total timesteps         | 37183     |
| train_time              | 326       |
| update_time             | 1062      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 2.7       |
| env_time                | 58        |
| ep_rewmean              | 295       |
| episodes                | 1248      |
| eplenmean               | 120       |
| fps                     | 24        |
| mean 100 episode reward | 295       |
| n_updates               | 25600     |
| q_grad_norm             | 6213.7188 |
| qfs_loss                | 121.23116 |
| qs_abs_difference       | 53.7      |
| qs_difference           | 53        |
| qs_mean                 | 219.33324 |
| time_elapsed            | 1530      |
| total timesteps         | 37759     |
| train_time              | 342       |
| update_time             | 1092      |
---------------------------------------
---------------------------------------
| act_time                | 14        |
| current_lr              | 0.0003    |
| discount_q              | 2.49      |
| env_time                | 59        |
| ep_rewmean              | 308       |
| episodes                | 1252      |
| eplenmean               | 124       |
| fps                     | 24        |
| mean 100 episode reward | 308       |
| n_updates               | 26800     |
| q_grad_norm             | 6111.002  |
| qfs_loss                | 126.17044 |
| qs_abs_difference       | 83.9      |
| qs_difference           | 83.3      |
| qs_mean                 | 223.36037 |
| time_elapsed            | 1577      |
| total timesteps         | 38324     |
| train_time              | 358       |
| update_time             | 1122      |
---------------------------------------
----------------------------------------
| act_time                | 14         |
| current_lr              | 0.0003     |
| discount_q              | 2.97       |
| env_time                | 60         |
| ep_rewmean              | 318        |
| episodes                | 1256       |
| eplenmean               | 127        |
| fps                     | 23         |
| mean 100 episode reward | 318        |
| n_updates               | 28000      |
| q_grad_norm             | 5333.8013  |
| qfs_loss                | 122.621376 |
| qs_abs_difference       | 43         |
| qs_difference           | 38         |
| qs_mean                 | 205.62599  |
| time_elapsed            | 1625       |
| total timesteps         | 38907      |
| train_time              | 374        |
| update_time             | 1152       |
----------------------------------------
---------------------------------------
| act_time                | 15        |
| current_lr              | 0.0003    |
| discount_q              | 2.33      |
| env_time                | 60        |
| ep_rewmean              | 326       |
| episodes                | 1260      |
| eplenmean               | 130       |
| fps                     | 23        |
| mean 100 episode reward | 326       |
| n_updates               | 29200     |
| q_grad_norm             | 7164.5444 |
| qfs_loss                | 146.04164 |
| qs_abs_difference       | 46.6      |
| qs_difference           | 43.5      |
| qs_mean                 | 212.53925 |
| time_elapsed            | 1673      |
| total timesteps         | 39523     |
| train_time              | 390       |
| update_time             | 1183      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 141       |
| eval_abs_qs_difference  | 91.417206 |
| eval_discount_q         | 158       |
| eval_ep_rewmean         | 377       |
| eval_eplenmean          | 177       |
| eval_qs                 | 216.01958 |
| eval_qs_difference      | 91.2      |
| eval_time_elapsed       | 4         |
| total timesteps         | 40001     |
---------------------------------------
----------------------------------------
| act_time                | 15         |
| current_lr              | 0.0003     |
| discount_q              | 2.3        |
| env_time                | 61         |
| ep_rewmean              | 318        |
| episodes                | 1264       |
| eplenmean               | 128        |
| fps                     | 23         |
| mean 100 episode reward | 318        |
| n_updates               | 30200      |
| q_grad_norm             | 5885.4883  |
| qfs_loss                | 122.113625 |
| qs_abs_difference       | 114        |
| qs_difference           | 113        |
| qs_mean                 | 226.06427  |
| time_elapsed            | 1717       |
| total timesteps         | 40096      |
| train_time              | 403        |
| update_time             | 1208       |
----------------------------------------
----------------------------------------
| act_time                | 15         |
| current_lr              | 0.0003     |
| discount_q              | 1.92       |
| env_time                | 62         |
| ep_rewmean              | 314        |
| episodes                | 1268       |
| eplenmean               | 127        |
| fps                     | 22         |
| mean 100 episode reward | 314        |
| n_updates               | 31600      |
| q_grad_norm             | 5492.8623  |
| qfs_loss                | 104.368614 |
| qs_abs_difference       | 66.4       |
| qs_difference           | 65.6       |
| qs_mean                 | 216.53342  |
| time_elapsed            | 1773       |
| total timesteps         | 40706      |
| train_time              | 421        |
| update_time             | 1244       |
----------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 1.65      |
| env_time                | 63        |
| ep_rewmean              | 312       |
| episodes                | 1272      |
| eplenmean               | 127       |
| fps                     | 22        |
| mean 100 episode reward | 312       |
| n_updates               | 32800     |
| q_grad_norm             | 7047.4033 |
| qfs_loss                | 148.31352 |
| qs_abs_difference       | 80.5      |
| qs_difference           | 80        |
| qs_mean                 | 212.27802 |
| time_elapsed            | 1822      |
| total timesteps         | 41326     |
| train_time              | 437       |
| update_time             | 1275      |
---------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 3.87      |
| env_time                | 64        |
| ep_rewmean              | 306       |
| episodes                | 1276      |
| eplenmean               | 125       |
| fps                     | 22        |
| mean 100 episode reward | 306       |
| n_updates               | 33600     |
| q_grad_norm             | 5308.072  |
| qfs_loss                | 114.88211 |
| qs_abs_difference       | 186       |
| qs_difference           | 186       |
| qs_mean                 | 246.64337 |
| time_elapsed            | 1855      |
| total timesteps         | 41746     |
| train_time              | 448       |
| update_time             | 1296      |
---------------------------------------
---------------------------------------
| act_time                | 17        |
| current_lr              | 0.0003    |
| discount_q              | 4.52      |
| env_time                | 65        |
| ep_rewmean              | 300       |
| episodes                | 1280      |
| eplenmean               | 124       |
| fps                     | 22        |
| mean 100 episode reward | 300       |
| n_updates               | 34400     |
| q_grad_norm             | 5921.331  |
| qfs_loss                | 129.33833 |
| qs_abs_difference       | 174       |
| qs_difference           | 174       |
| qs_mean                 | 228.00066 |
| time_elapsed            | 1888      |
| total timesteps         | 42124     |
| train_time              | 459       |
| update_time             | 1318      |
---------------------------------------
---------------------------------------
| act_time                | 17        |
| current_lr              | 0.0003    |
| discount_q              | 6.85      |
| env_time                | 65        |
| ep_rewmean              | 300       |
| episodes                | 1284      |
| eplenmean               | 124       |
| fps                     | 22        |
| mean 100 episode reward | 300       |
| n_updates               | 35400     |
| q_grad_norm             | 6302.131  |
| qfs_loss                | 133.06125 |
| qs_abs_difference       | 41.1      |
| qs_difference           | 36.8      |
| qs_mean                 | 208.56447 |
| time_elapsed            | 1929      |
| total timesteps         | 42640     |
| train_time              | 472       |
| update_time             | 1344      |
---------------------------------------
---------------------------------------
| act_time                | 18        |
| current_lr              | 0.0003    |
| discount_q              | 4.37      |
| env_time                | 66        |
| ep_rewmean              | 304       |
| episodes                | 1288      |
| eplenmean               | 125       |
| fps                     | 21        |
| mean 100 episode reward | 304       |
| n_updates               | 36600     |
| q_grad_norm             | 4980.8706 |
| qfs_loss                | 92.51447  |
| qs_abs_difference       | 51.6      |
| qs_difference           | 50.4      |
| qs_mean                 | 231.34137 |
| time_elapsed            | 1979      |
| total timesteps         | 43241     |
| train_time              | 488       |
| update_time             | 1376      |
---------------------------------------
---------------------------------------
| act_time                | 18        |
| current_lr              | 0.0003    |
| discount_q              | 0.102     |
| env_time                | 68        |
| ep_rewmean              | 318       |
| episodes                | 1292      |
| eplenmean               | 129       |
| fps                     | 21        |
| mean 100 episode reward | 318       |
| n_updates               | 38400     |
| q_grad_norm             | 5646.483  |
| qfs_loss                | 116.97232 |
| qs_abs_difference       | 44.9      |
| qs_difference           | 44.3      |
| qs_mean                 | 219.53328 |
| time_elapsed            | 2053      |
| total timesteps         | 44164     |
| train_time              | 511       |
| update_time             | 1425      |
---------------------------------------
---------------------------------------
| act_time                | 19        |
| current_lr              | 0.0003    |
| discount_q              | 19.4      |
| env_time                | 68        |
| ep_rewmean              | 318       |
| episodes                | 1296      |
| eplenmean               | 129       |
| fps                     | 21        |
| mean 100 episode reward | 318       |
| n_updates               | 39200     |
| q_grad_norm             | 5417.6113 |
| qfs_loss                | 127.79369 |
| qs_abs_difference       | 94.2      |
| qs_difference           | 93.9      |
| qs_mean                 | 257.34003 |
| time_elapsed            | 2086      |
| total timesteps         | 44564     |
| train_time              | 521       |
| update_time             | 1447      |
---------------------------------------
---------------------------------------
| act_time                | 19        |
| current_lr              | 0.0003    |
| discount_q              | 0.104     |
| env_time                | 70        |
| ep_rewmean              | 329       |
| episodes                | 1300      |
| eplenmean               | 135       |
| fps                     | 21        |
| mean 100 episode reward | 329       |
| n_updates               | 40800     |
| q_grad_norm             | 6013.0986 |
| qfs_loss                | 139.68642 |
| qs_abs_difference       | 171       |
| qs_difference           | 171       |
| qs_mean                 | 265.61755 |
| time_elapsed            | 2153      |
| total timesteps         | 45386     |
| train_time              | 543       |
| update_time             | 1490      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 0.421     |
| env_time                | 71        |
| ep_rewmean              | 334       |
| episodes                | 1304      |
| eplenmean               | 137       |
| fps                     | 20        |
| mean 100 episode reward | 334       |
| n_updates               | 42000     |
| q_grad_norm             | 6210.0264 |
| qfs_loss                | 120.9305  |
| qs_abs_difference       | 223       |
| qs_difference           | 223       |
| qs_mean                 | 258.36594 |
| time_elapsed            | 2204      |
| total timesteps         | 45921     |
| train_time              | 558       |
| update_time             | 1523      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 5.48      |
| env_time                | 71        |
| ep_rewmean              | 327       |
| episodes                | 1308      |
| eplenmean               | 135       |
| fps                     | 20        |
| mean 100 episode reward | 327       |
| n_updates               | 42600     |
| q_grad_norm             | 5402.629  |
| qfs_loss                | 133.1542  |
| qs_abs_difference       | 224       |
| qs_difference           | 224       |
| qs_mean                 | 259.42834 |
| time_elapsed            | 2230      |
| total timesteps         | 46202     |
| train_time              | 566       |
| update_time             | 1540      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 8.59      |
| env_time                | 72        |
| ep_rewmean              | 326       |
| episodes                | 1312      |
| eplenmean               | 134       |
| fps                     | 20        |
| mean 100 episode reward | 326       |
| n_updates               | 43200     |
| q_grad_norm             | 5852.5024 |
| qfs_loss                | 152.94359 |
| qs_abs_difference       | 179       |
| qs_difference           | 179       |
| qs_mean                 | 271.70776 |
| time_elapsed            | 2255      |
| total timesteps         | 46590     |
| train_time              | 574       |
| update_time             | 1557      |
---------------------------------------
---------------------------------------
| act_time                | 21        |
| current_lr              | 0.0003    |
| discount_q              | 0.472     |
| env_time                | 73        |
| ep_rewmean              | 341       |
| episodes                | 1316      |
| eplenmean               | 138       |
| fps                     | 20        |
| mean 100 episode reward | 341       |
| n_updates               | 44800     |
| q_grad_norm             | 6003.0254 |
| qfs_loss                | 145.87381 |
| qs_abs_difference       | 57.8      |
| qs_difference           | 57.6      |
| qs_mean                 | 229.7598  |
| time_elapsed            | 2324      |
| total timesteps         | 47352     |
| train_time              | 596       |
| update_time             | 1602      |
---------------------------------------
---------------------------------------
| act_time                | 21        |
| current_lr              | 0.0003    |
| discount_q              | 0.112     |
| env_time                | 74        |
| ep_rewmean              | 354       |
| episodes                | 1320      |
| eplenmean               | 142       |
| fps                     | 20        |
| mean 100 episode reward | 354       |
| n_updates               | 46600     |
| q_grad_norm             | 5349.4434 |
| qfs_loss                | 144.74863 |
| qs_abs_difference       | 181       |
| qs_difference           | 181       |
| qs_mean                 | 254.37761 |
| time_elapsed            | 2401      |
| total timesteps         | 48251     |
| train_time              | 619       |
| update_time             | 1653      |
---------------------------------------
---------------------------------------
| act_time                | 22        |
| current_lr              | 0.0003    |
| discount_q              | 0.062     |
| env_time                | 76        |
| ep_rewmean              | 369       |
| episodes                | 1324      |
| eplenmean               | 148       |
| fps                     | 19        |
| mean 100 episode reward | 369       |
| n_updates               | 48800     |
| q_grad_norm             | 5690.0273 |
| qfs_loss                | 138.29497 |
| qs_abs_difference       | 63.8      |
| qs_difference           | 63.6      |
| qs_mean                 | 255.85654 |
| time_elapsed            | 2495      |
| total timesteps         | 49375     |
| train_time              | 648       |
| update_time             | 1715      |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 208      |
| eval_abs_qs_difference  | 84.07696 |
| eval_discount_q         | 205      |
| eval_ep_rewmean         | 551      |
| eval_eplenmean          | 213      |
| eval_qs                 | 244.8372 |
| eval_qs_difference      | 82       |
| eval_time_elapsed       | 5        |
| total timesteps         | 50001    |
--------------------------------------
---------------------------------------
| act_time                | 23        |
| current_lr              | 0.0003    |
| discount_q              | 1.61      |
| env_time                | 77        |
| ep_rewmean              | 376       |
| episodes                | 1328      |
| eplenmean               | 150       |
| fps                     | 19        |
| mean 100 episode reward | 376       |
| n_updates               | 50400     |
| q_grad_norm             | 5653.5938 |
| qfs_loss                | 139.24817 |
| qs_abs_difference       | 57.6      |
| qs_difference           | 56.4      |
| qs_mean                 | 255.78407 |
| time_elapsed            | 2570      |
| total timesteps         | 50138     |
| train_time              | 670       |
| update_time             | 1762      |
---------------------------------------
---------------------------------------
| act_time                | 24        |
| current_lr              | 0.0003    |
| discount_q              | 0.114     |
| env_time                | 79        |
| ep_rewmean              | 396       |
| episodes                | 1332      |
| eplenmean               | 156       |
| fps                     | 19        |
| mean 100 episode reward | 396       |
| n_updates               | 52400     |
| q_grad_norm             | 6328.395  |
| qfs_loss                | 155.44032 |
| qs_abs_difference       | 62.4      |
| qs_difference           | 61.9      |
| qs_mean                 | 267.31805 |
| time_elapsed            | 2657      |
| total timesteps         | 51143     |
| train_time              | 696       |
| update_time             | 1819      |
---------------------------------------
---------------------------------------
| act_time                | 24        |
| current_lr              | 0.0003    |
| discount_q              | 4.47      |
| env_time                | 80        |
| ep_rewmean              | 400       |
| episodes                | 1336      |
| eplenmean               | 157       |
| fps                     | 19        |
| mean 100 episode reward | 400       |
| n_updates               | 53600     |
| q_grad_norm             | 6364.45   |
| qfs_loss                | 146.98631 |
| qs_abs_difference       | 46.2      |
| qs_difference           | 45.7      |
| qs_mean                 | 255.74825 |
| time_elapsed            | 2710      |
| total timesteps         | 51757     |
| train_time              | 712       |
| update_time             | 1854      |
---------------------------------------
---------------------------------------
| act_time                | 25        |
| current_lr              | 0.0003    |
| discount_q              | 0.043     |
| env_time                | 82        |
| ep_rewmean              | 414       |
| episodes                | 1340      |
| eplenmean               | 162       |
| fps                     | 18        |
| mean 100 episode reward | 414       |
| n_updates               | 55800     |
| q_grad_norm             | 5425.6587 |
| qfs_loss                | 128.9423  |
| qs_abs_difference       | 76.4      |
| qs_difference           | 75.9      |
| qs_mean                 | 278.78015 |
| time_elapsed            | 2807      |
| total timesteps         | 52843     |
| train_time              | 741       |
| update_time             | 1920      |
---------------------------------------
---------------------------------------
| act_time                | 26        |
| current_lr              | 0.0003    |
| discount_q              | 0.057     |
| env_time                | 83        |
| ep_rewmean              | 431       |
| episodes                | 1344      |
| eplenmean               | 168       |
| fps                     | 18        |
| mean 100 episode reward | 431       |
| n_updates               | 58000     |
| q_grad_norm             | 6182.321  |
| qfs_loss                | 159.34828 |
| qs_abs_difference       | 33.9      |
| qs_difference           | 32.8      |
| qs_mean                 | 271.8914  |
| time_elapsed            | 2905      |
| total timesteps         | 53958     |
| train_time              | 770       |
| update_time             | 1986      |
---------------------------------------
---------------------------------------
| act_time                | 26        |
| current_lr              | 0.0003    |
| discount_q              | 10.7      |
| env_time                | 84        |
| ep_rewmean              | 429       |
| episodes                | 1348      |
| eplenmean               | 168       |
| fps                     | 18        |
| mean 100 episode reward | 429       |
| n_updates               | 59200     |
| q_grad_norm             | 6806.398  |
| qfs_loss                | 148.51987 |
| qs_abs_difference       | 78.6      |
| qs_difference           | 78.6      |
| qs_mean                 | 268.7443  |
| time_elapsed            | 2958      |
| total timesteps         | 54517     |
| train_time              | 785       |
| update_time             | 2023      |
---------------------------------------
---------------------------------------
| act_time                | 27        |
| current_lr              | 0.0003    |
| discount_q              | 2.08      |
| env_time                | 85        |
| ep_rewmean              | 424       |
| episodes                | 1352      |
| eplenmean               | 166       |
| fps                     | 18        |
| mean 100 episode reward | 424       |
| n_updates               | 60000     |
| q_grad_norm             | 6243.523  |
| qfs_loss                | 153.55302 |
| qs_abs_difference       | 253       |
| qs_difference           | 253       |
| qs_mean                 | 303.46707 |
| time_elapsed            | 2995      |
| total timesteps         | 54934     |
| train_time              | 796       |
| update_time             | 2047      |
---------------------------------------
---------------------------------------
| act_time                | 28        |
| current_lr              | 0.0003    |
| discount_q              | 0.0327    |
| env_time                | 87        |
| ep_rewmean              | 442       |
| episodes                | 1356      |
| eplenmean               | 171       |
| fps                     | 18        |
| mean 100 episode reward | 442       |
| n_updates               | 62200     |
| q_grad_norm             | 6172.0967 |
| qfs_loss                | 138.08372 |
| qs_abs_difference       | 85.8      |
| qs_difference           | 85.8      |
| qs_mean                 | 294.58643 |
| time_elapsed            | 3094      |
| total timesteps         | 56054     |
| train_time              | 825       |
| update_time             | 2114      |
---------------------------------------
---------------------------------------
| act_time                | 28        |
| current_lr              | 0.0003    |
| discount_q              | 0.127     |
| env_time                | 88        |
| ep_rewmean              | 456       |
| episodes                | 1360      |
| eplenmean               | 175       |
| fps                     | 17        |
| mean 100 episode reward | 456       |
| n_updates               | 64200     |
| q_grad_norm             | 6233.786  |
| qfs_loss                | 129.50652 |
| qs_abs_difference       | 64.7      |
| qs_difference           | 64.7      |
| qs_mean                 | 285.8069  |
| time_elapsed            | 3185      |
| total timesteps         | 57052     |
| train_time              | 851       |
| update_time             | 2176      |
---------------------------------------
---------------------------------------
| act_time                | 29        |
| current_lr              | 0.0003    |
| discount_q              | 2.09      |
| env_time                | 89        |
| ep_rewmean              | 454       |
| episodes                | 1364      |
| eplenmean               | 174       |
| fps                     | 17        |
| mean 100 episode reward | 454       |
| n_updates               | 65000     |
| q_grad_norm             | 6198.5386 |
| qfs_loss                | 134.56325 |
| qs_abs_difference       | 257       |
| qs_difference           | 257       |
| qs_mean                 | 304.83145 |
| time_elapsed            | 3221      |
| total timesteps         | 57460     |
| train_time              | 861       |
| update_time             | 2201      |
---------------------------------------
---------------------------------------
| act_time                | 29        |
| current_lr              | 0.0003    |
| discount_q              | 7.62      |
| env_time                | 90        |
| ep_rewmean              | 454       |
| episodes                | 1368      |
| eplenmean               | 173       |
| fps                     | 17        |
| mean 100 episode reward | 454       |
| n_updates               | 66000     |
| q_grad_norm             | 6292.1816 |
| qfs_loss                | 148.80049 |
| qs_abs_difference       | 69.5      |
| qs_difference           | 68.9      |
| qs_mean                 | 252.28072 |
| time_elapsed            | 3266      |
| total timesteps         | 57983     |
| train_time              | 875       |
| update_time             | 2232      |
---------------------------------------
---------------------------------------
| act_time                | 30        |
| current_lr              | 0.0003    |
| discount_q              | 0.0359    |
| env_time                | 91        |
| ep_rewmean              | 476       |
| episodes                | 1372      |
| eplenmean               | 178       |
| fps                     | 17        |
| mean 100 episode reward | 476       |
| n_updates               | 68400     |
| q_grad_norm             | 5641.464  |
| qfs_loss                | 122.4209  |
| qs_abs_difference       | 30        |
| qs_difference           | 25.6      |
| qs_mean                 | 272.77078 |
| time_elapsed            | 3377      |
| total timesteps         | 59152     |
| train_time              | 906       |
| update_time             | 2308      |
---------------------------------------
---------------------------------------
| act_time                | 31        |
| current_lr              | 0.0003    |
| discount_q              | 0.785     |
| env_time                | 93        |
| ep_rewmean              | 492       |
| episodes                | 1376      |
| eplenmean               | 182       |
| fps                     | 17        |
| mean 100 episode reward | 492       |
| n_updates               | 70000     |
| q_grad_norm             | 6621.321  |
| qfs_loss                | 163.50826 |
| qs_abs_difference       | 76.9      |
| qs_difference           | 72.9      |
| qs_mean                 | 270.10916 |
| time_elapsed            | 3451      |
| total timesteps         | 59944     |
| train_time              | 927       |
| update_time             | 2359      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 308       |
| eval_abs_qs_difference  | 22.542025 |
| eval_discount_q         | 248       |
| eval_ep_rewmean         | 938       |
| eval_eplenmean          | 273       |
| eval_qs                 | 259.2483  |
| eval_qs_difference      | 5.18      |
| eval_time_elapsed       | 6         |
| total timesteps         | 60001     |
---------------------------------------
---------------------------------------
| act_time                | 32        |
| current_lr              | 0.0003    |
| discount_q              | 0.055     |
| env_time                | 94        |
| ep_rewmean              | 520       |
| episodes                | 1380      |
| eplenmean               | 190       |
| fps                     | 17        |
| mean 100 episode reward | 520       |
| n_updates               | 72200     |
| q_grad_norm             | 6839.2095 |
| qfs_loss                | 152.17545 |
| qs_abs_difference       | 49.6      |
| qs_difference           | 48.1      |
| qs_mean                 | 265.93597 |
| time_elapsed            | 3559      |
| total timesteps         | 61076     |
| train_time              | 956       |
| update_time             | 2428      |
---------------------------------------
---------------------------------------
| act_time                | 32        |
| current_lr              | 0.0003    |
| discount_q              | 0.0442    |
| env_time                | 96        |
| ep_rewmean              | 540       |
| episodes                | 1384      |
| eplenmean               | 195       |
| fps                     | 16        |
| mean 100 episode reward | 540       |
| n_updates               | 74400     |
| q_grad_norm             | 6122.241  |
| qfs_loss                | 128.66527 |
| qs_abs_difference       | 98.8      |
| qs_difference           | 98.4      |
| qs_mean                 | 310.92606 |
| time_elapsed            | 3734      |
| total timesteps         | 62167     |
| train_time              | 984       |
| update_time             | 2572      |
---------------------------------------
---------------------------------------
| act_time                | 33        |
| current_lr              | 0.0003    |
| discount_q              | 3.47      |
| env_time                | 97        |
| ep_rewmean              | 548       |
| episodes                | 1388      |
| eplenmean               | 196       |
| fps                     | 16        |
| mean 100 episode reward | 548       |
| n_updates               | 75800     |
| q_grad_norm             | 5829.873  |
| qfs_loss                | 125.70245 |
| qs_abs_difference       | 40.6      |
| qs_difference           | 40        |
| qs_mean                 | 289.69846 |
| time_elapsed            | 3799      |
| total timesteps         | 62878     |
| train_time              | 1002      |
| update_time             | 2617      |
---------------------------------------
---------------------------------------
| act_time                | 34        |
| current_lr              | 0.0003    |
| discount_q              | 0.0129    |
| env_time                | 99        |
| ep_rewmean              | 560       |
| episodes                | 1392      |
| eplenmean               | 200       |
| fps                     | 16        |
| mean 100 episode reward | 560       |
| n_updates               | 78400     |
| q_grad_norm             | 6444.0786 |
| qfs_loss                | 156.62465 |
| qs_abs_difference       | 75.9      |
| qs_difference           | 75.3      |
| qs_mean                 | 305.0269  |
| time_elapsed            | 3939      |
| total timesteps         | 64193     |
| train_time              | 1037      |
| update_time             | 2719      |
---------------------------------------
---------------------------------------
| act_time                | 35        |
| current_lr              | 0.0003    |
| discount_q              | 0.106     |
| env_time                | 101       |
| ep_rewmean              | 581       |
| episodes                | 1396      |
| eplenmean               | 206       |
| fps                     | 16        |
| mean 100 episode reward | 581       |
| n_updates               | 80400     |
| q_grad_norm             | 6558.27   |
| qfs_loss                | 131.69673 |
| qs_abs_difference       | 93.1      |
| qs_difference           | 92.6      |
| qs_mean                 | 302.11853 |
| time_elapsed            | 4033      |
| total timesteps         | 65194     |
| train_time              | 1063      |
| update_time             | 2785      |
---------------------------------------
---------------------------------------
| act_time                | 35        |
| current_lr              | 0.0003    |
| discount_q              | 0.0104    |
| env_time                | 102       |
| ep_rewmean              | 593       |
| episodes                | 1400      |
| eplenmean               | 207       |
| fps                     | 16        |
| mean 100 episode reward | 593       |
| n_updates               | 82200     |
| q_grad_norm             | 7039.4546 |
| qfs_loss                | 143.84879 |
| qs_abs_difference       | 274       |
| qs_difference           | 274       |
| qs_mean                 | 312.01764 |
| time_elapsed            | 4119      |
| total timesteps         | 66098     |
| train_time              | 1086      |
| update_time             | 2844      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 0.0141    |
| env_time                | 103       |
| ep_rewmean              | 602       |
| episodes                | 1404      |
| eplenmean               | 210       |
| fps                     | 15        |
| mean 100 episode reward | 602       |
| n_updates               | 84000     |
| q_grad_norm             | 6580.8257 |
| qfs_loss                | 130.56139 |
| qs_abs_difference       | 280       |
| qs_difference           | 280       |
| qs_mean                 | 310.14926 |
| time_elapsed            | 4204      |
| total timesteps         | 66948     |
| train_time              | 1109      |
| update_time             | 2905      |
---------------------------------------
---------------------------------------
| act_time                | 37        |
| current_lr              | 0.0003    |
| discount_q              | 3.54      |
| env_time                | 104       |
| ep_rewmean              | 614       |
| episodes                | 1408      |
| eplenmean               | 214       |
| fps                     | 15        |
| mean 100 episode reward | 614       |
| n_updates               | 85400     |
| q_grad_norm             | 7126.168  |
| qfs_loss                | 163.34459 |
| qs_abs_difference       | 141       |
| qs_difference           | 141       |
| qs_mean                 | 336.5508  |
| time_elapsed            | 4272      |
| total timesteps         | 67638     |
| train_time              | 1128      |
| update_time             | 2952      |
---------------------------------------
---------------------------------------
| act_time                | 37        |
| current_lr              | 0.0003    |
| discount_q              | 0.0188    |
| env_time                | 106       |
| ep_rewmean              | 633       |
| episodes                | 1412      |
| eplenmean               | 221       |
| fps                     | 15        |
| mean 100 episode reward | 633       |
| n_updates               | 87400     |
| q_grad_norm             | 7258.998  |
| qfs_loss                | 160.60078 |
| qs_abs_difference       | 211       |
| qs_difference           | 211       |
| qs_mean                 | 326.01797 |
| time_elapsed            | 4368      |
| total timesteps         | 68680     |
| train_time              | 1154      |
| update_time             | 3019      |
---------------------------------------
---------------------------------------
| act_time                | 38        |
| current_lr              | 0.0003    |
| discount_q              | 0.0167    |
| env_time                | 108       |
| ep_rewmean              | 648       |
| episodes                | 1416      |
| eplenmean               | 226       |
| fps                     | 15        |
| mean 100 episode reward | 648       |
| n_updates               | 90000     |
| q_grad_norm             | 6291.7183 |
| qfs_loss                | 147.98184 |
| qs_abs_difference       | 68.3      |
| qs_difference           | 66.5      |
| qs_mean                 | 280.79504 |
| time_elapsed            | 4493      |
| total timesteps         | 69926     |
| train_time              | 1187      |
| update_time             | 3107      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 393       |
| eval_abs_qs_difference  | 71.891525 |
| eval_discount_q         | 207       |
| eval_ep_rewmean         | 978       |
| eval_eplenmean          | 341       |
| eval_qs                 | 288.34344 |
| eval_qs_difference      | 70.7      |
| eval_time_elapsed       | 8         |
| total timesteps         | 70001     |
---------------------------------------
---------------------------------------
| act_time                | 40        |
| current_lr              | 0.0003    |
| discount_q              | 0.000846  |
| env_time                | 110       |
| ep_rewmean              | 672       |
| episodes                | 1420      |
| eplenmean               | 232       |
| fps                     | 15        |
| mean 100 episode reward | 672       |
| n_updates               | 93000     |
| q_grad_norm             | 7315.6836 |
| qfs_loss                | 157.36069 |
| qs_abs_difference       | 38.9      |
| qs_difference           | 38.3      |
| qs_mean                 | 278.08954 |
| time_elapsed            | 4647      |
| total timesteps         | 71493     |
| train_time              | 1226      |
| update_time             | 3210      |
---------------------------------------
---------------------------------------
| act_time                | 41        |
| current_lr              | 0.0003    |
| discount_q              | 0.000712  |
| env_time                | 113       |
| ep_rewmean              | 693       |
| episodes                | 1424      |
| eplenmean               | 236       |
| fps                     | 15        |
| mean 100 episode reward | 693       |
| n_updates               | 96000     |
| q_grad_norm             | 5959.9443 |
| qfs_loss                | 131.97206 |
| qs_abs_difference       | 30        |
| qs_difference           | 29.1      |
| qs_mean                 | 259.11084 |
| time_elapsed            | 4797      |
| total timesteps         | 72996     |
| train_time              | 1264      |
| update_time             | 3318      |
---------------------------------------
---------------------------------------
| act_time                | 42        |
| current_lr              | 0.0003    |
| discount_q              | 0.0128    |
| env_time                | 115       |
| ep_rewmean              | 713       |
| episodes                | 1428      |
| eplenmean               | 242       |
| fps                     | 15        |
| mean 100 episode reward | 713       |
| n_updates               | 98800     |
| q_grad_norm             | 6814.3877 |
| qfs_loss                | 145.1414  |
| qs_abs_difference       | 62.7      |
| qs_difference           | 61.2      |
| qs_mean                 | 293.2237  |
| time_elapsed            | 4931      |
| total timesteps         | 74304     |
| train_time              | 1301      |
| update_time             | 3413      |
---------------------------------------
---------------------------------------
| act_time                | 43        |
| current_lr              | 0.0003    |
| discount_q              | 0.0467    |
| env_time                | 116       |
| ep_rewmean              | 716       |
| episodes                | 1432      |
| eplenmean               | 243       |
| fps                     | 14        |
| mean 100 episode reward | 716       |
| n_updates               | 101000    |
| q_grad_norm             | 6128.6963 |
| qfs_loss                | 161.03535 |
| qs_abs_difference       | 39.6      |
| qs_difference           | 37.8      |
| qs_mean                 | 272.66373 |
| time_elapsed            | 5040      |
| total timesteps         | 75411     |
| train_time              | 1328      |
| update_time             | 3491      |
---------------------------------------
----------------------------------------
| act_time                | 43         |
| current_lr              | 0.0003     |
| discount_q              | 4.03       |
| env_time                | 118        |
| ep_rewmean              | 725        |
| episodes                | 1436       |
| eplenmean               | 246        |
| fps                     | 14         |
| mean 100 episode reward | 725        |
| n_updates               | 102800     |
| q_grad_norm             | 5127.888   |
| qfs_loss                | 116.501045 |
| qs_abs_difference       | 71.1       |
| qs_difference           | 71.1       |
| qs_mean                 | 336.18332  |
| time_elapsed            | 5130       |
| total timesteps         | 76343      |
| train_time              | 1351       |
| update_time             | 3556       |
----------------------------------------
---------------------------------------
| act_time                | 44        |
| current_lr              | 0.0003    |
| discount_q              | 0.261     |
| env_time                | 119       |
| ep_rewmean              | 725       |
| episodes                | 1440      |
| eplenmean               | 245       |
| fps                     | 14        |
| mean 100 episode reward | 725       |
| n_updates               | 104800    |
| q_grad_norm             | 6059.3066 |
| qfs_loss                | 119.53163 |
| qs_abs_difference       | 57.7      |
| qs_difference           | 57        |
| qs_mean                 | 287.2271  |
| time_elapsed            | 5230      |
| total timesteps         | 77317     |
| train_time              | 1376      |
| update_time             | 3628      |
---------------------------------------
---------------------------------------
| act_time                | 45        |
| current_lr              | 0.0003    |
| discount_q              | 0.0294    |
| env_time                | 121       |
| ep_rewmean              | 736       |
| episodes                | 1444      |
| eplenmean               | 247       |
| fps                     | 14        |
| mean 100 episode reward | 736       |
| n_updates               | 107400    |
| q_grad_norm             | 6110.2515 |
| qfs_loss                | 130.44038 |
| qs_abs_difference       | 18.3      |
| qs_difference           | 16.5      |
| qs_mean                 | 299.0854  |
| time_elapsed            | 5368      |
| total timesteps         | 78679     |
| train_time              | 1417      |
| update_time             | 3722      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 430       |
| eval_abs_qs_difference  | 93.29609  |
| eval_discount_q         | 215       |
| eval_ep_rewmean         | 696       |
| eval_eplenmean          | 253       |
| eval_qs                 | 283.02136 |
| eval_qs_difference      | 92.7      |
| eval_time_elapsed       | 4         |
| total timesteps         | 80001     |
---------------------------------------
---------------------------------------
| act_time                | 46        |
| current_lr              | 0.0003    |
| discount_q              | 1.25      |
| env_time                | 123       |
| ep_rewmean              | 766       |
| episodes                | 1448      |
| eplenmean               | 257       |
| fps                     | 14        |
| mean 100 episode reward | 766       |
| n_updates               | 110600    |
| q_grad_norm             | 6227.9424 |
| qfs_loss                | 140.06894 |
| qs_abs_difference       | 65.3      |
| qs_difference           | 65.1      |
| qs_mean                 | 336.3872  |
| time_elapsed            | 5586      |
| total timesteps         | 80205     |
| train_time              | 1492      |
| update_time             | 3857      |
---------------------------------------
---------------------------------------
| act_time                | 47        |
| current_lr              | 0.0003    |
| discount_q              | 0.000108  |
| env_time                | 125       |
| ep_rewmean              | 797       |
| episodes                | 1452      |
| eplenmean               | 267       |
| fps                     | 14        |
| mean 100 episode reward | 797       |
| n_updates               | 113200    |
| q_grad_norm             | 6725.013  |
| qfs_loss                | 146.4992  |
| qs_abs_difference       | 280       |
| qs_difference           | 280       |
| qs_mean                 | 323.11014 |
| time_elapsed            | 5739      |
| total timesteps         | 81588     |
| train_time              | 1540      |
| update_time             | 3958      |
---------------------------------------
---------------------------------------
| act_time                | 48        |
| current_lr              | 0.0003    |
| discount_q              | 0.0106    |
| env_time                | 127       |
| ep_rewmean              | 804       |
| episodes                | 1456      |
| eplenmean               | 268       |
| fps                     | 14        |
| mean 100 episode reward | 804       |
| n_updates               | 115800    |
| q_grad_norm             | 6575.36   |
| qfs_loss                | 133.80098 |
| qs_abs_difference       | 47.3      |
| qs_difference           | 47        |
| qs_mean                 | 287.36707 |
| time_elapsed            | 5869      |
| total timesteps         | 82899     |
| train_time              | 1572      |
| update_time             | 4053      |
---------------------------------------
---------------------------------------
| act_time                | 49        |
| current_lr              | 0.0003    |
| discount_q              | 0.00967   |
| env_time                | 129       |
| ep_rewmean              | 818       |
| episodes                | 1460      |
| eplenmean               | 272       |
| fps                     | 14        |
| mean 100 episode reward | 818       |
| n_updates               | 118600    |
| q_grad_norm             | 6270.9    |
| qfs_loss                | 137.28992 |
| qs_abs_difference       | 30.9      |
| qs_difference           | 29.6      |
| qs_mean                 | 288.18402 |
| time_elapsed            | 6008      |
| total timesteps         | 84245     |
| train_time              | 1607      |
| update_time             | 4154      |
---------------------------------------
---------------------------------------
| act_time                | 50        |
| current_lr              | 0.0003    |
| discount_q              | 0.0754    |
| env_time                | 130       |
| ep_rewmean              | 841       |
| episodes                | 1464      |
| eplenmean               | 279       |
| fps                     | 13        |
| mean 100 episode reward | 841       |
| n_updates               | 120800    |
| q_grad_norm             | 6839.022  |
| qfs_loss                | 163.98639 |
| qs_abs_difference       | 25.3      |
| qs_difference           | 15.4      |
| qs_mean                 | 270.3619  |
| time_elapsed            | 6118      |
| total timesteps         | 85330     |
| train_time              | 1635      |
| update_time             | 4233      |
---------------------------------------
---------------------------------------
| act_time                | 51        |
| current_lr              | 0.0003    |
| discount_q              | 0.00336   |
| env_time                | 132       |
| ep_rewmean              | 874       |
| episodes                | 1468      |
| eplenmean               | 289       |
| fps                     | 13        |
| mean 100 episode reward | 874       |
| n_updates               | 123800    |
| q_grad_norm             | 5756.6074 |
| qfs_loss                | 111.93871 |
| qs_abs_difference       | 30.5      |
| qs_difference           | 29.7      |
| qs_mean                 | 290.70056 |
| time_elapsed            | 6268      |
| total timesteps         | 86841     |
| train_time              | 1673      |
| update_time             | 4342      |
---------------------------------------
----------------------------------------
| act_time                | 52         |
| current_lr              | 0.0003     |
| discount_q              | 9.66e-05   |
| env_time                | 135        |
| ep_rewmean              | 895        |
| episodes                | 1472       |
| eplenmean               | 295        |
| fps                     | 13         |
| mean 100 episode reward | 895        |
| n_updates               | 127400     |
| q_grad_norm             | 5321.587   |
| qfs_loss                | 114.358604 |
| qs_abs_difference       | 40.1       |
| qs_difference           | 39.6       |
| qs_mean                 | 293.1634   |
| time_elapsed            | 6451       |
| total timesteps         | 88635      |
| train_time              | 1718       |
| update_time             | 4476       |
----------------------------------------
---------------------------------------
| eval mean 100 episod... | 612       |
| eval_abs_qs_difference  | 46.124763 |
| eval_discount_q         | 235       |
| eval_ep_rewmean         | 1.87e+03  |
| eval_eplenmean          | 588       |
| eval_qs                 | 310.3236  |
| eval_qs_difference      | 42.5      |
| eval_time_elapsed       | 10        |
| total timesteps         | 90001     |
---------------------------------------
----------------------------------------
| act_time                | 53         |
| current_lr              | 0.0003     |
| discount_q              | 0.00128    |
| env_time                | 137        |
| ep_rewmean              | 919        |
| episodes                | 1476       |
| eplenmean               | 302        |
| fps                     | 13         |
| mean 100 episode reward | 919        |
| n_updates               | 130400     |
| q_grad_norm             | 4921.661   |
| qfs_loss                | 108.317184 |
| qs_abs_difference       | 133        |
| qs_difference           | 133        |
| qs_mean                 | 324.4664   |
| time_elapsed            | 6614       |
| total timesteps         | 90132      |
| train_time              | 1756       |
| update_time             | 4587       |
----------------------------------------
---------------------------------------
| act_time                | 54        |
| current_lr              | 0.0003    |
| discount_q              | 0.0324    |
| env_time                | 138       |
| ep_rewmean              | 924       |
| episodes                | 1480      |
| eplenmean               | 302       |
| fps                     | 13        |
| mean 100 episode reward | 924       |
| n_updates               | 132800    |
| q_grad_norm             | 5496.052  |
| qfs_loss                | 121.26548 |
| qs_abs_difference       | 20.2      |
| qs_difference           | 19.6      |
| qs_mean                 | 275.23273 |
| time_elapsed            | 6737      |
| total timesteps         | 91306     |
| train_time              | 1786      |
| update_time             | 4677      |
---------------------------------------
---------------------------------------
| act_time                | 54        |
| current_lr              | 0.0003    |
| discount_q              | 0.0982    |
| env_time                | 139       |
| ep_rewmean              | 928       |
| episodes                | 1484      |
| eplenmean               | 302       |
| fps                     | 13        |
| mean 100 episode reward | 928       |
| n_updates               | 135000    |
| q_grad_norm             | 5364.8433 |
| qfs_loss                | 107.54371 |
| qs_abs_difference       | 34.7      |
| qs_difference           | 30.4      |
| qs_mean                 | 286.60498 |
| time_elapsed            | 6855      |
| total timesteps         | 92408     |
| train_time              | 1814      |
| update_time             | 4765      |
---------------------------------------
---------------------------------------
| act_time                | 55        |
| current_lr              | 0.0003    |
| discount_q              | 0.0111    |
| env_time                | 141       |
| ep_rewmean              | 939       |
| episodes                | 1488      |
| eplenmean               | 306       |
| fps                     | 13        |
| mean 100 episode reward | 939       |
| n_updates               | 137000    |
| q_grad_norm             | 4933.1543 |
| qfs_loss                | 108.46735 |
| qs_abs_difference       | 220       |
| qs_difference           | 220       |
| qs_mean                 | 317.98257 |
| time_elapsed            | 6959      |
| total timesteps         | 93456     |
| train_time              | 1839      |
| update_time             | 4841      |
---------------------------------------
--------------------------------------
| act_time                | 56       |
| current_lr              | 0.0003   |
| discount_q              | 0.000466 |
| env_time                | 143      |
| ep_rewmean              | 939      |
| episodes                | 1492     |
| eplenmean               | 305      |
| fps                     | 13       |
| mean 100 episode reward | 939      |
| n_updates               | 139400   |
| q_grad_norm             | 5850.527 |
| qfs_loss                | 125.9414 |
| qs_abs_difference       | 260      |
| qs_difference           | 260      |
| qs_mean                 | 303.1402 |
| time_elapsed            | 7083     |
| total timesteps         | 94693    |
| train_time              | 1869     |
| update_time             | 4933     |
--------------------------------------
---------------------------------------
| act_time                | 57        |
| current_lr              | 0.0003    |
| discount_q              | 0.00111   |
| env_time                | 144       |
| ep_rewmean              | 952       |
| episodes                | 1496      |
| eplenmean               | 309       |
| fps                     | 13        |
| mean 100 episode reward | 952       |
| n_updates               | 142200    |
| q_grad_norm             | 5279.563  |
| qfs_loss                | 128.72305 |
| qs_abs_difference       | 179       |
| qs_difference           | 179       |
| qs_mean                 | 325.76553 |
| time_elapsed            | 7230      |
| total timesteps         | 96066     |
| train_time              | 1904      |
| update_time             | 5041      |
---------------------------------------
---------------------------------------
| act_time                | 57        |
| current_lr              | 0.0003    |
| discount_q              | 0.00416   |
| env_time                | 146       |
| ep_rewmean              | 963       |
| episodes                | 1500      |
| eplenmean               | 312       |
| fps                     | 13        |
| mean 100 episode reward | 963       |
| n_updates               | 144800    |
| q_grad_norm             | 5640.0254 |
| qfs_loss                | 121.60239 |
| qs_abs_difference       | 169       |
| qs_difference           | 169       |
| qs_mean                 | 320.76715 |
| time_elapsed            | 7367      |
| total timesteps         | 97326     |
| train_time              | 1937      |
| update_time             | 5143      |
---------------------------------------
---------------------------------------
| act_time                | 58        |
| current_lr              | 0.0003    |
| discount_q              | 0.000222  |
| env_time                | 148       |
| ep_rewmean              | 997       |
| episodes                | 1504      |
| eplenmean               | 322       |
| fps                     | 13        |
| mean 100 episode reward | 997       |
| n_updates               | 148400    |
| q_grad_norm             | 5337.302  |
| qfs_loss                | 116.02988 |
| qs_abs_difference       | 27.7      |
| qs_difference           | 25.7      |
| qs_mean                 | 299.86197 |
| time_elapsed            | 7559      |
| total timesteps         | 99132     |
| train_time              | 1983      |
| update_time             | 5286      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 763       |
| eval_abs_qs_difference  | 17.633425 |
| eval_discount_q         | 255       |
| eval_ep_rewmean         | 1.34e+03  |
| eval_eplenmean          | 392       |
| eval_qs                 | 291.37054 |
| eval_qs_difference      | 14.4      |
| eval_time_elapsed       | 7         |
| total timesteps         | 100001    |
---------------------------------------
---------------------------------------
| act_time                | 59        |
| current_lr              | 0.0003    |
| discount_q              | 0.00842   |
| env_time                | 149       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1508      |
| eplenmean               | 325       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 150400    |
| q_grad_norm             | 6370.299  |
| qfs_loss                | 128.26297 |
| qs_abs_difference       | 248       |
| qs_difference           | 248       |
| qs_mean                 | 310.28687 |
| time_elapsed            | 7673      |
| total timesteps         | 100136    |
| train_time              | 2008      |
| update_time             | 5365      |
---------------------------------------
---------------------------------------
| act_time                | 60        |
| current_lr              | 0.0003    |
| discount_q              | 0.00195   |
| env_time                | 151       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1512      |
| eplenmean               | 328       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 153200    |
| q_grad_norm             | 5608.628  |
| qfs_loss                | 117.47141 |
| qs_abs_difference       | 29.9      |
| qs_difference           | 29.5      |
| qs_mean                 | 255.72281 |
| time_elapsed            | 7820      |
| total timesteps         | 101523    |
| train_time              | 2043      |
| update_time             | 5473      |
---------------------------------------
---------------------------------------
| act_time                | 61        |
| current_lr              | 0.0003    |
| discount_q              | 0.251     |
| env_time                | 153       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1516      |
| eplenmean               | 327       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 155200    |
| q_grad_norm             | 4885.6416 |
| qfs_loss                | 109.17935 |
| qs_abs_difference       | 18.7      |
| qs_difference           | 14.1      |
| qs_mean                 | 289.65073 |
| time_elapsed            | 7922      |
| total timesteps         | 102579    |
| train_time              | 2068      |
| update_time             | 5548      |
---------------------------------------
---------------------------------------
| act_time                | 61        |
| current_lr              | 0.0003    |
| discount_q              | 0.289     |
| env_time                | 154       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1520      |
| eplenmean               | 321       |
| fps                     | 12        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 157200    |
| q_grad_norm             | 5395.3286 |
| qfs_loss                | 109.51736 |
| qs_abs_difference       | 55        |
| qs_difference           | 54.9      |
| qs_mean                 | 283.4954  |
| time_elapsed            | 8025      |
| total timesteps         | 103548    |
| train_time              | 2094      |
| update_time             | 5623      |
---------------------------------------
---------------------------------------
| act_time                | 62        |
| current_lr              | 0.0003    |
| discount_q              | 1.67      |
| env_time                | 155       |
| ep_rewmean              | 986       |
| episodes                | 1524      |
| eplenmean               | 313       |
| fps                     | 12        |
| mean 100 episode reward | 986       |
| n_updates               | 158800    |
| q_grad_norm             | 3805.8584 |
| qfs_loss                | 81.40308  |
| qs_abs_difference       | 42.2      |
| qs_difference           | 40.8      |
| qs_mean                 | 272.52863 |
| time_elapsed            | 8106      |
| total timesteps         | 104318    |
| train_time              | 2114      |
| update_time             | 5682      |
---------------------------------------
---------------------------------------
| act_time                | 63        |
| current_lr              | 0.0003    |
| discount_q              | 0.0233    |
| env_time                | 157       |
| ep_rewmean              | 990       |
| episodes                | 1528      |
| eplenmean               | 314       |
| fps                     | 12        |
| mean 100 episode reward | 990       |
| n_updates               | 161400    |
| q_grad_norm             | 4993.8555 |
| qfs_loss                | 132.01309 |
| qs_abs_difference       | 18.1      |
| qs_difference           | 17.9      |
| qs_mean                 | 298.4449  |
| time_elapsed            | 8237      |
| total timesteps         | 105663    |
| train_time              | 2146      |
| update_time             | 5778      |
---------------------------------------
---------------------------------------
| act_time                | 64        |
| current_lr              | 0.0003    |
| discount_q              | 0.000929  |
| env_time                | 159       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1532      |
| eplenmean               | 323       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 165400    |
| q_grad_norm             | 4045.382  |
| qfs_loss                | 89.3669   |
| qs_abs_difference       | 39        |
| qs_difference           | 38.7      |
| qs_mean                 | 322.08948 |
| time_elapsed            | 8436      |
| total timesteps         | 107664    |
| train_time              | 2197      |
| update_time             | 5922      |
---------------------------------------
---------------------------------------
| act_time                | 65        |
| current_lr              | 0.0003    |
| discount_q              | 0.153     |
| env_time                | 161       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1536      |
| eplenmean               | 326       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 168000    |
| q_grad_norm             | 5108.223  |
| qfs_loss                | 113.73562 |
| qs_abs_difference       | 10.6      |
| qs_difference           | 9.94      |
| qs_mean                 | 301.90063 |
| time_elapsed            | 8561      |
| total timesteps         | 108913    |
| train_time              | 2230      |
| update_time             | 6012      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 814       |
| eval_abs_qs_difference  | 176.99916 |
| eval_discount_q         | 168       |
| eval_ep_rewmean         | 396       |
| eval_eplenmean          | 153       |
| eval_qs                 | 308.46286 |
| eval_qs_difference      | 177       |
| eval_time_elapsed       | 2         |
| total timesteps         | 110001    |
---------------------------------------
---------------------------------------
| act_time                | 66        |
| current_lr              | 0.0003    |
| discount_q              | 1.25e-08  |
| env_time                | 164       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 1540      |
| eplenmean               | 338       |
| fps                     | 12        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 172400    |
| q_grad_norm             | 4598.5576 |
| qfs_loss                | 101.77089 |
| qs_abs_difference       | 263       |
| qs_difference           | 263       |
| qs_mean                 | 297.23398 |
| time_elapsed            | 8777      |
| total timesteps         | 111165    |
| train_time              | 2286      |
| update_time             | 6163      |
---------------------------------------
--------------------------------------
| act_time                | 67       |
| current_lr              | 0.0003   |
| discount_q              | 0.00114  |
| env_time                | 166      |
| ep_rewmean              | 1.09e+03 |
| episodes                | 1544     |
| eplenmean               | 342      |
| fps                     | 12       |
| mean 100 episode reward | 1.09e+03 |
| n_updates               | 175800   |
| q_grad_norm             | 3129.625 |
| qfs_loss                | 70.32494 |
| qs_abs_difference       | 11.3     |
| qs_difference           | 10.2     |
| qs_mean                 | 300.3236 |
| time_elapsed            | 8938     |
| total timesteps         | 112895   |
| train_time              | 2330     |
| update_time             | 6276     |
--------------------------------------
---------------------------------------
| act_time                | 68        |
| current_lr              | 0.0003    |
| discount_q              | 0.0397    |
| env_time                | 167       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 1548      |
| eplenmean               | 339       |
| fps                     | 12        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 178200    |
| q_grad_norm             | 5099.552  |
| qfs_loss                | 112.67987 |
| qs_abs_difference       | 14        |
| qs_difference           | -4.02     |
| qs_mean                 | 274.5022  |
| time_elapsed            | 9050      |
| total timesteps         | 114091    |
| train_time              | 2361      |
| update_time             | 6355      |
---------------------------------------
---------------------------------------
| act_time                | 68        |
| current_lr              | 0.0003    |
| discount_q              | 1.04      |
| env_time                | 169       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 1552      |
| eplenmean               | 334       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 180000    |
| q_grad_norm             | 3693.5222 |
| qfs_loss                | 91.759254 |
| qs_abs_difference       | 47.6      |
| qs_difference           | 47        |
| qs_mean                 | 287.93936 |
| time_elapsed            | 9132      |
| total timesteps         | 114943    |
| train_time              | 2384      |
| update_time             | 6412      |
---------------------------------------
---------------------------------------
| act_time                | 69        |
| current_lr              | 0.0003    |
| discount_q              | 0.101     |
| env_time                | 170       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1556      |
| eplenmean               | 330       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 182000    |
| q_grad_norm             | 4535.459  |
| qfs_loss                | 116.09114 |
| qs_abs_difference       | 53.1      |
| qs_difference           | 53.1      |
| qs_mean                 | 265.27496 |
| time_elapsed            | 9222      |
| total timesteps         | 115916    |
| train_time              | 2409      |
| update_time             | 6475      |
---------------------------------------
--------------------------------------
| act_time                | 69       |
| current_lr              | 0.0003   |
| discount_q              | 0.354    |
| env_time                | 171      |
| ep_rewmean              | 1.05e+03 |
| episodes                | 1560     |
| eplenmean               | 325      |
| fps                     | 12       |
| mean 100 episode reward | 1.05e+03 |
| n_updates               | 183600   |
| q_grad_norm             | 4123.277 |
| qfs_loss                | 97.26412 |
| qs_abs_difference       | 23       |
| qs_difference           | 9.79     |
| qs_mean                 | 235.1613 |
| time_elapsed            | 9295     |
| total timesteps         | 116778   |
| train_time              | 2429     |
| update_time             | 6526     |
--------------------------------------
---------------------------------------
| act_time                | 70        |
| current_lr              | 0.0003    |
| discount_q              | 12.1      |
| env_time                | 172       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1564      |
| eplenmean               | 324       |
| fps                     | 12        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 185400    |
| q_grad_norm             | 4718.109  |
| qfs_loss                | 109.13505 |
| qs_abs_difference       | 72.7      |
| qs_difference           | 72.3      |
| qs_mean                 | 339.0068  |
| time_elapsed            | 9376      |
| total timesteps         | 117682    |
| train_time              | 2452      |
| update_time             | 6582      |
---------------------------------------
---------------------------------------
| act_time                | 71        |
| current_lr              | 0.0003    |
| discount_q              | 0.0402    |
| env_time                | 174       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1568      |
| eplenmean               | 319       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 187600    |
| q_grad_norm             | 4272.964  |
| qfs_loss                | 103.98298 |
| qs_abs_difference       | 166       |
| qs_difference           | 166       |
| qs_mean                 | 330.69156 |
| time_elapsed            | 9471      |
| total timesteps         | 118710    |
| train_time              | 2481      |
| update_time             | 6646      |
---------------------------------------
---------------------------------------
| act_time                | 72        |
| current_lr              | 0.0003    |
| discount_q              | 2.54      |
| env_time                | 175       |
| ep_rewmean              | 998       |
| episodes                | 1572      |
| eplenmean               | 311       |
| fps                     | 12        |
| mean 100 episode reward | 998       |
| n_updates               | 189600    |
| q_grad_norm             | 5346.7437 |
| qfs_loss                | 144.5373  |
| qs_abs_difference       | 37.2      |
| qs_difference           | 37.2      |
| qs_mean                 | 322.21332 |
| time_elapsed            | 9557      |
| total timesteps         | 119731    |
| train_time              | 2507      |
| update_time             | 6703      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 894       |
| eval_abs_qs_difference  | 22.866106 |
| eval_discount_q         | 241       |
| eval_ep_rewmean         | 1.02e+03  |
| eval_eplenmean          | 303       |
| eval_qs                 | 271.81857 |
| eval_qs_difference      | 14.8      |
| eval_time_elapsed       | 7         |
| total timesteps         | 120001    |
---------------------------------------
---------------------------------------
| act_time                | 72        |
| current_lr              | 0.0003    |
| discount_q              | 0.0818    |
| env_time                | 177       |
| ep_rewmean              | 985       |
| episodes                | 1576      |
| eplenmean               | 306       |
| fps                     | 12        |
| mean 100 episode reward | 984       |
| n_updates               | 191600    |
| q_grad_norm             | 4463.741  |
| qfs_loss                | 128.04637 |
| qs_abs_difference       | 47.4      |
| qs_difference           | 47.4      |
| qs_mean                 | 276.15698 |
| time_elapsed            | 9650      |
| total timesteps         | 120769    |
| train_time              | 2533      |
| update_time             | 6759      |
---------------------------------------
---------------------------------------
| act_time                | 73        |
| current_lr              | 0.0003    |
| discount_q              | 0.957     |
| env_time                | 178       |
| ep_rewmean              | 966       |
| episodes                | 1580      |
| eplenmean               | 302       |
| fps                     | 12        |
| mean 100 episode reward | 966       |
| n_updates               | 193000    |
| q_grad_norm             | 4131.4976 |
| qfs_loss                | 108.95755 |
| qs_abs_difference       | 90.1      |
| qs_difference           | 90.1      |
| qs_mean                 | 266.3073  |
| time_elapsed            | 9708      |
| total timesteps         | 121475    |
| train_time              | 2551      |
| update_time             | 6798      |
---------------------------------------
---------------------------------------
| act_time                | 74        |
| current_lr              | 0.0003    |
| discount_q              | 0.177     |
| env_time                | 180       |
| ep_rewmean              | 961       |
| episodes                | 1584      |
| eplenmean               | 300       |
| fps                     | 12        |
| mean 100 episode reward | 961       |
| n_updates               | 195000    |
| q_grad_norm             | 4367.5864 |
| qfs_loss                | 117.22541 |
| qs_abs_difference       | 19.8      |
| qs_difference           | 16.7      |
| qs_mean                 | 261.37997 |
| time_elapsed            | 9792      |
| total timesteps         | 122436    |
| train_time              | 2577      |
| update_time             | 6852      |
---------------------------------------
---------------------------------------
| act_time                | 74        |
| current_lr              | 0.0003    |
| discount_q              | 0.263     |
| env_time                | 181       |
| ep_rewmean              | 960       |
| episodes                | 1588      |
| eplenmean               | 299       |
| fps                     | 12        |
| mean 100 episode reward | 960       |
| n_updates               | 196800    |
| q_grad_norm             | 4127.2065 |
| qfs_loss                | 103.8382  |
| qs_abs_difference       | 32.3      |
| qs_difference           | 32.3      |
| qs_mean                 | 281.3776  |
| time_elapsed            | 9866      |
| total timesteps         | 123365    |
| train_time              | 2601      |
| update_time             | 6901      |
---------------------------------------
---------------------------------------
| act_time                | 75        |
| current_lr              | 0.0003    |
| discount_q              | 0.0547    |
| env_time                | 183       |
| ep_rewmean              | 959       |
| episodes                | 1592      |
| eplenmean               | 298       |
| fps                     | 12        |
| mean 100 episode reward | 959       |
| n_updates               | 199000    |
| q_grad_norm             | 3894.8345 |
| qfs_loss                | 92.71557  |
| qs_abs_difference       | 21.2      |
| qs_difference           | 20.4      |
| qs_mean                 | 268.27948 |
| time_elapsed            | 9955      |
| total timesteps         | 124450    |
| train_time              | 2629      |
| update_time             | 6959      |
---------------------------------------
---------------------------------------
| act_time                | 76        |
| current_lr              | 0.0003    |
| discount_q              | 1.42      |
| env_time                | 184       |
| ep_rewmean              | 939       |
| episodes                | 1596      |
| eplenmean               | 292       |
| fps                     | 12        |
| mean 100 episode reward | 939       |
| n_updates               | 200600    |
| q_grad_norm             | 3700.7727 |
| qfs_loss                | 97.161995 |
| qs_abs_difference       | 41.9      |
| qs_difference           | 41.7      |
| qs_mean                 | 284.48895 |
| time_elapsed            | 10019     |
| total timesteps         | 125216    |
| train_time              | 2650      |
| update_time             | 7000      |
---------------------------------------
---------------------------------------
| act_time                | 76        |
| current_lr              | 0.0003    |
| discount_q              | 0.214     |
| env_time                | 186       |
| ep_rewmean              | 933       |
| episodes                | 1600      |
| eplenmean               | 289       |
| fps                     | 12        |
| mean 100 episode reward | 933       |
| n_updates               | 202600    |
| q_grad_norm             | 3648.4802 |
| qfs_loss                | 76.7832   |
| qs_abs_difference       | 23.5      |
| qs_difference           | 21.8      |
| qs_mean                 | 273.68292 |
| time_elapsed            | 10098     |
| total timesteps         | 126212    |
| train_time              | 2676      |
| update_time             | 7050      |
---------------------------------------
---------------------------------------
| act_time                | 77        |
| current_lr              | 0.0003    |
| discount_q              | 0.00938   |
| env_time                | 188       |
| ep_rewmean              | 912       |
| episodes                | 1604      |
| eplenmean               | 283       |
| fps                     | 12        |
| mean 100 episode reward | 912       |
| n_updates               | 204800    |
| q_grad_norm             | 4540.4736 |
| qfs_loss                | 108.38508 |
| qs_abs_difference       | 128       |
| qs_difference           | 128       |
| qs_mean                 | 308.2203  |
| time_elapsed            | 10186     |
| total timesteps         | 127390    |
| train_time              | 2705      |
| update_time             | 7105      |
---------------------------------------
----------------------------------------
| act_time                | 78         |
| current_lr              | 0.0003     |
| discount_q              | 0.61       |
| env_time                | 189        |
| ep_rewmean              | 897        |
| episodes                | 1608       |
| eplenmean               | 279        |
| fps                     | 12         |
| mean 100 episode reward | 897        |
| n_updates               | 206000     |
| q_grad_norm             | 4396.4175  |
| qfs_loss                | 112.687355 |
| qs_abs_difference       | 223        |
| qs_difference           | 223        |
| qs_mean                 | 301.1054   |
| time_elapsed            | 10233      |
| total timesteps         | 127988     |
| train_time              | 2720       |
| update_time             | 7135       |
----------------------------------------
---------------------------------------
| act_time                | 78        |
| current_lr              | 0.0003    |
| discount_q              | 0.683     |
| env_time                | 190       |
| ep_rewmean              | 877       |
| episodes                | 1612      |
| eplenmean               | 274       |
| fps                     | 12        |
| mean 100 episode reward | 877       |
| n_updates               | 207800    |
| q_grad_norm             | 4864.051  |
| qfs_loss                | 96.25046  |
| qs_abs_difference       | 114       |
| qs_difference           | 114       |
| qs_mean                 | 331.04395 |
| time_elapsed            | 10304     |
| total timesteps         | 128889    |
| train_time              | 2744      |
| update_time             | 7181      |
---------------------------------------
---------------------------------------
| act_time                | 79        |
| current_lr              | 0.0003    |
| discount_q              | 3.08      |
| env_time                | 191       |
| ep_rewmean              | 864       |
| episodes                | 1616      |
| eplenmean               | 270       |
| fps                     | 12        |
| mean 100 episode reward | 864       |
| n_updates               | 209400    |
| q_grad_norm             | 4421.01   |
| qfs_loss                | 99.41612  |
| qs_abs_difference       | 11.9      |
| qs_difference           | 8.96      |
| qs_mean                 | 273.95532 |
| time_elapsed            | 10366     |
| total timesteps         | 129613    |
| train_time              | 2764      |
| update_time             | 7220      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.1e+03   |
| eval_abs_qs_difference  | 44.37928  |
| eval_discount_q         | 251       |
| eval_ep_rewmean         | 2.31e+03  |
| eval_eplenmean          | 732       |
| eval_qs                 | 321.90836 |
| eval_qs_difference      | 42.3      |
| eval_time_elapsed       | 17        |
| total timesteps         | 130001    |
---------------------------------------
---------------------------------------
| act_time                | 80        |
| current_lr              | 0.0003    |
| discount_q              | 0.121     |
| env_time                | 193       |
| ep_rewmean              | 869       |
| episodes                | 1620      |
| eplenmean               | 271       |
| fps                     | 12        |
| mean 100 episode reward | 869       |
| n_updates               | 211400    |
| q_grad_norm             | 4182.458  |
| qfs_loss                | 103.85438 |
| qs_abs_difference       | 32.4      |
| qs_difference           | 32.3      |
| qs_mean                 | 288.87952 |
| time_elapsed            | 10463     |
| total timesteps         | 130667    |
| train_time              | 2790      |
| update_time             | 7270      |
---------------------------------------
---------------------------------------
| act_time                | 81        |
| current_lr              | 0.0003    |
| discount_q              | 0.0619    |
| env_time                | 195       |
| ep_rewmean              | 886       |
| episodes                | 1624      |
| eplenmean               | 276       |
| fps                     | 12        |
| mean 100 episode reward | 886       |
| n_updates               | 213800    |
| q_grad_norm             | 5111.162  |
| qfs_loss                | 114.30873 |
| qs_abs_difference       | 35.5      |
| qs_difference           | 35.2      |
| qs_mean                 | 300.11868 |
| time_elapsed            | 10557     |
| total timesteps         | 131868    |
| train_time              | 2822      |
| update_time             | 7330      |
---------------------------------------
---------------------------------------
| act_time                | 81        |
| current_lr              | 0.0003    |
| discount_q              | 0.277     |
| env_time                | 196       |
| ep_rewmean              | 873       |
| episodes                | 1628      |
| eplenmean               | 272       |
| fps                     | 12        |
| mean 100 episode reward | 873       |
| n_updates               | 215800    |
| q_grad_norm             | 3329.1396 |
| qfs_loss                | 85.524666 |
| qs_abs_difference       | 16.8      |
| qs_difference           | 16.6      |
| qs_mean                 | 279.34964 |
| time_elapsed            | 10635     |
| total timesteps         | 132844    |
| train_time              | 2848      |
| update_time             | 7380      |
---------------------------------------
---------------------------------------
| act_time                | 82        |
| current_lr              | 0.0003    |
| discount_q              | 0.0786    |
| env_time                | 198       |
| ep_rewmean              | 844       |
| episodes                | 1632      |
| eplenmean               | 263       |
| fps                     | 12        |
| mean 100 episode reward | 844       |
| n_updates               | 218000    |
| q_grad_norm             | 3849.9028 |
| qfs_loss                | 84.81547  |
| qs_abs_difference       | 33.4      |
| qs_difference           | 31        |
| qs_mean                 | 277.77176 |
| time_elapsed            | 10720     |
| total timesteps         | 133929    |
| train_time              | 2876      |
| update_time             | 7433      |
---------------------------------------
---------------------------------------
| act_time                | 83        |
| current_lr              | 0.0003    |
| discount_q              | 0.232     |
| env_time                | 200       |
| ep_rewmean              | 839       |
| episodes                | 1636      |
| eplenmean               | 261       |
| fps                     | 12        |
| mean 100 episode reward | 840       |
| n_updates               | 220000    |
| q_grad_norm             | 4412.226  |
| qfs_loss                | 111.26556 |
| qs_abs_difference       | 10.3      |
| qs_difference           | 6.74      |
| qs_mean                 | 287.4702  |
| time_elapsed            | 10798     |
| total timesteps         | 134977    |
| train_time              | 2902      |
| update_time             | 7482      |
---------------------------------------
---------------------------------------
| act_time                | 84        |
| current_lr              | 0.0003    |
| discount_q              | 0.0772    |
| env_time                | 202       |
| ep_rewmean              | 804       |
| episodes                | 1640      |
| eplenmean               | 248       |
| fps                     | 12        |
| mean 100 episode reward | 804       |
| n_updates               | 222200    |
| q_grad_norm             | 3406.3826 |
| qfs_loss                | 64.47316  |
| qs_abs_difference       | 37.6      |
| qs_difference           | 37.6      |
| qs_mean                 | 268.62988 |
| time_elapsed            | 10883     |
| total timesteps         | 136000    |
| train_time              | 2931      |
| update_time             | 7535      |
---------------------------------------
---------------------------------------
| act_time                | 84        |
| current_lr              | 0.0003    |
| discount_q              | 0.953     |
| env_time                | 203       |
| ep_rewmean              | 772       |
| episodes                | 1644      |
| eplenmean               | 239       |
| fps                     | 12        |
| mean 100 episode reward | 772       |
| n_updates               | 223600    |
| q_grad_norm             | 4699.4424 |
| qfs_loss                | 86.1552   |
| qs_abs_difference       | 25.7      |
| qs_difference           | 23.9      |
| qs_mean                 | 264.69073 |
| time_elapsed            | 10937     |
| total timesteps         | 136784    |
| train_time              | 2949      |
| update_time             | 7569      |
---------------------------------------
---------------------------------------
| act_time                | 85        |
| current_lr              | 0.0003    |
| discount_q              | 0.968     |
| env_time                | 204       |
| ep_rewmean              | 760       |
| episodes                | 1648      |
| eplenmean               | 236       |
| fps                     | 12        |
| mean 100 episode reward | 760       |
| n_updates               | 225400    |
| q_grad_norm             | 3950.0952 |
| qfs_loss                | 76.82413  |
| qs_abs_difference       | 9.01      |
| qs_difference           | 8.37      |
| qs_mean                 | 281.9262  |
| time_elapsed            | 11006     |
| total timesteps         | 137649    |
| train_time              | 2973      |
| update_time             | 7613      |
---------------------------------------
----------------------------------------
| act_time                | 86         |
| current_lr              | 0.0003     |
| discount_q              | 0.0923     |
| env_time                | 205        |
| ep_rewmean              | 758        |
| episodes                | 1652       |
| eplenmean               | 234        |
| fps                     | 12         |
| mean 100 episode reward | 758        |
| n_updates               | 226800     |
| q_grad_norm             | 4443.793   |
| qfs_loss                | 115.646935 |
| qs_abs_difference       | 249        |
| qs_difference           | 249        |
| qs_mean                 | 300.31253  |
| time_elapsed            | 11060      |
| total timesteps         | 138378     |
| train_time              | 2991       |
| update_time             | 7646       |
----------------------------------------
--------------------------------------
| act_time                | 86       |
| current_lr              | 0.0003   |
| discount_q              | 1.31     |
| env_time                | 206      |
| ep_rewmean              | 752      |
| episodes                | 1656     |
| eplenmean               | 232      |
| fps                     | 12       |
| mean 100 episode reward | 752      |
| n_updates               | 228400   |
| q_grad_norm             | 4110.084 |
| qfs_loss                | 92.99861 |
| qs_abs_difference       | 18.7     |
| qs_difference           | 18.4     |
| qs_mean                 | 265.7728 |
| time_elapsed            | 11121    |
| total timesteps         | 139143   |
| train_time              | 3012     |
| update_time             | 7685     |
--------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.18e+03  |
| eval_abs_qs_difference  | 14.326874 |
| eval_discount_q         | 255       |
| eval_ep_rewmean         | 1.2e+03   |
| eval_eplenmean          | 348       |
| eval_qs                 | 284.0689  |
| eval_qs_difference      | 11.4      |
| eval_time_elapsed       | 8         |
| total timesteps         | 140001    |
---------------------------------------
---------------------------------------
| act_time                | 87        |
| current_lr              | 0.0003    |
| discount_q              | 0.000771  |
| env_time                | 208       |
| ep_rewmean              | 764       |
| episodes                | 1660      |
| eplenmean               | 236       |
| fps                     | 12        |
| mean 100 episode reward | 764       |
| n_updates               | 230800    |
| q_grad_norm             | 3917.6418 |
| qfs_loss                | 81.794685 |
| qs_abs_difference       | 238       |
| qs_difference           | 238       |
| qs_mean                 | 293.61917 |
| time_elapsed            | 11222     |
| total timesteps         | 140366    |
| train_time              | 3043      |
| update_time             | 7743      |
---------------------------------------
---------------------------------------
| act_time                | 88        |
| current_lr              | 0.0003    |
| discount_q              | 0.391     |
| env_time                | 210       |
| ep_rewmean              | 767       |
| episodes                | 1664      |
| eplenmean               | 236       |
| fps                     | 12        |
| mean 100 episode reward | 767       |
| n_updates               | 232600    |
| q_grad_norm             | 5496.9805 |
| qfs_loss                | 127.54793 |
| qs_abs_difference       | 34.5      |
| qs_difference           | 34.5      |
| qs_mean                 | 274.4476  |
| time_elapsed            | 11291     |
| total timesteps         | 141265    |
| train_time              | 3066      |
| update_time             | 7786      |
---------------------------------------
---------------------------------------
| act_time                | 88        |
| current_lr              | 0.0003    |
| discount_q              | 0.289     |
| env_time                | 211       |
| ep_rewmean              | 755       |
| episodes                | 1668      |
| eplenmean               | 232       |
| fps                     | 12        |
| mean 100 episode reward | 755       |
| n_updates               | 234000    |
| q_grad_norm             | 3674.5635 |
| qfs_loss                | 70.76442  |
| qs_abs_difference       | 235       |
| qs_difference           | 235       |
| qs_mean                 | 308.7272  |
| time_elapsed            | 11344     |
| total timesteps         | 141936    |
| train_time              | 3084      |
| update_time             | 7820      |
---------------------------------------
---------------------------------------
| act_time                | 89        |
| current_lr              | 0.0003    |
| discount_q              | 0.0976    |
| env_time                | 212       |
| ep_rewmean              | 755       |
| episodes                | 1672      |
| eplenmean               | 232       |
| fps                     | 12        |
| mean 100 episode reward | 755       |
| n_updates               | 235800    |
| q_grad_norm             | 3821.4119 |
| qfs_loss                | 79.21164  |
| qs_abs_difference       | 53.3      |
| qs_difference           | 52.7      |
| qs_mean                 | 248.30113 |
| time_elapsed            | 11413     |
| total timesteps         | 142896    |
| train_time              | 3108      |
| update_time             | 7863      |
---------------------------------------
---------------------------------------
| act_time                | 89        |
| current_lr              | 0.0003    |
| discount_q              | 1.21      |
| env_time                | 213       |
| ep_rewmean              | 747       |
| episodes                | 1676      |
| eplenmean               | 229       |
| fps                     | 12        |
| mean 100 episode reward | 747       |
| n_updates               | 237400    |
| q_grad_norm             | 6344.355  |
| qfs_loss                | 145.91322 |
| qs_abs_difference       | 19.5      |
| qs_difference           | 18.1      |
| qs_mean                 | 262.33725 |
| time_elapsed            | 11474     |
| total timesteps         | 143675    |
| train_time              | 3129      |
| update_time             | 7901      |
---------------------------------------
---------------------------------------
| act_time                | 90        |
| current_lr              | 0.0003    |
| discount_q              | 0.131     |
| env_time                | 215       |
| ep_rewmean              | 748       |
| episodes                | 1680      |
| eplenmean               | 229       |
| fps                     | 12        |
| mean 100 episode reward | 748       |
| n_updates               | 238800    |
| q_grad_norm             | 3405.4104 |
| qfs_loss                | 65.52484  |
| qs_abs_difference       | 236       |
| qs_difference           | 236       |
| qs_mean                 | 294.86273 |
| time_elapsed            | 11528     |
| total timesteps         | 144383    |
| train_time              | 3147      |
| update_time             | 7934      |
---------------------------------------
---------------------------------------
| act_time                | 91        |
| current_lr              | 0.0003    |
| discount_q              | 0.293     |
| env_time                | 216       |
| ep_rewmean              | 744       |
| episodes                | 1684      |
| eplenmean               | 228       |
| fps                     | 12        |
| mean 100 episode reward | 744       |
| n_updates               | 240600    |
| q_grad_norm             | 4860.1914 |
| qfs_loss                | 116.09796 |
| qs_abs_difference       | 30        |
| qs_difference           | 27.6      |
| qs_mean                 | 232.65085 |
| time_elapsed            | 11596     |
| total timesteps         | 145217    |
| train_time              | 3170      |
| update_time             | 7977      |
---------------------------------------
---------------------------------------
| act_time                | 91        |
| current_lr              | 0.0003    |
| discount_q              | 0.0884    |
| env_time                | 217       |
| ep_rewmean              | 745       |
| episodes                | 1688      |
| eplenmean               | 228       |
| fps                     | 12        |
| mean 100 episode reward | 745       |
| n_updates               | 242600    |
| q_grad_norm             | 3847.9868 |
| qfs_loss                | 66.03386  |
| qs_abs_difference       | 45.2      |
| qs_difference           | 44.7      |
| qs_mean                 | 262.91522 |
| time_elapsed            | 11672     |
| total timesteps         | 146208    |
| train_time              | 3196      |
| update_time             | 8024      |
---------------------------------------
---------------------------------------
| act_time                | 92        |
| current_lr              | 0.0003    |
| discount_q              | 0.182     |
| env_time                | 219       |
| ep_rewmean              | 733       |
| episodes                | 1692      |
| eplenmean               | 226       |
| fps                     | 12        |
| mean 100 episode reward | 733       |
| n_updates               | 244200    |
| q_grad_norm             | 4925.6333 |
| qfs_loss                | 135.67493 |
| qs_abs_difference       | 168       |
| qs_difference           | 168       |
| qs_mean                 | 321.97208 |
| time_elapsed            | 11732     |
| total timesteps         | 147062    |
| train_time              | 3217      |
| update_time             | 8062      |
---------------------------------------
---------------------------------------
| act_time                | 93        |
| current_lr              | 0.0003    |
| discount_q              | 0.00173   |
| env_time                | 221       |
| ep_rewmean              | 759       |
| episodes                | 1696      |
| eplenmean               | 233       |
| fps                     | 12        |
| mean 100 episode reward | 759       |
| n_updates               | 247200    |
| q_grad_norm             | 4534.316  |
| qfs_loss                | 102.29497 |
| qs_abs_difference       | 21        |
| qs_difference           | 16.1      |
| qs_mean                 | 269.014   |
| time_elapsed            | 11847     |
| total timesteps         | 148505    |
| train_time              | 3256      |
| update_time             | 8133      |
---------------------------------------
---------------------------------------
| act_time                | 94        |
| current_lr              | 0.0003    |
| discount_q              | 0.00209   |
| env_time                | 223       |
| ep_rewmean              | 770       |
| episodes                | 1700      |
| eplenmean               | 235       |
| fps                     | 12        |
| mean 100 episode reward | 770       |
| n_updates               | 249600    |
| q_grad_norm             | 5099.8286 |
| qfs_loss                | 98.03527  |
| qs_abs_difference       | 99.4      |
| qs_difference           | 99.2      |
| qs_mean                 | 223.47131 |
| time_elapsed            | 11938     |
| total timesteps         | 149746    |
| train_time              | 3287      |
| update_time             | 8189      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.2e+03   |
| eval_abs_qs_difference  | 23.481892 |
| eval_discount_q         | 251       |
| eval_ep_rewmean         | 1.02e+03  |
| eval_eplenmean          | 296       |
| eval_qs                 | 282.7257  |
| eval_qs_difference      | 21.6      |
| eval_time_elapsed       | 7         |
| total timesteps         | 150001    |
---------------------------------------
---------------------------------------
| act_time                | 95        |
| current_lr              | 0.0003    |
| discount_q              | 0.0311    |
| env_time                | 225       |
| ep_rewmean              | 764       |
| episodes                | 1704      |
| eplenmean               | 233       |
| fps                     | 12        |
| mean 100 episode reward | 764       |
| n_updates               | 251600    |
| q_grad_norm             | 6503.669  |
| qfs_loss                | 123.68458 |
| qs_abs_difference       | 108       |
| qs_difference           | 108       |
| qs_mean                 | 217.89255 |
| time_elapsed            | 12020     |
| total timesteps         | 150710    |
| train_time              | 3313      |
| update_time             | 8237      |
---------------------------------------
---------------------------------------
| act_time                | 95        |
| current_lr              | 0.0003    |
| discount_q              | 4.34      |
| env_time                | 225       |
| ep_rewmean              | 762       |
| episodes                | 1708      |
| eplenmean               | 233       |
| fps                     | 12        |
| mean 100 episode reward | 762       |
| n_updates               | 252600    |
| q_grad_norm             | 5673.5327 |
| qfs_loss                | 110.91501 |
| qs_abs_difference       | 144       |
| qs_difference           | 144       |
| qs_mean                 | 323.87314 |
| time_elapsed            | 12059     |
| total timesteps         | 151275    |
| train_time              | 3326      |
| update_time             | 8260      |
---------------------------------------
----------------------------------------
| act_time                | 96         |
| current_lr              | 0.0003     |
| discount_q              | 0.257      |
| env_time                | 227        |
| ep_rewmean              | 769        |
| episodes                | 1712       |
| eplenmean               | 234        |
| fps                     | 12         |
| mean 100 episode reward | 769        |
| n_updates               | 254600     |
| q_grad_norm             | 5033.7056  |
| qfs_loss                | 101.524666 |
| qs_abs_difference       | 15         |
| qs_difference           | 11.5       |
| qs_mean                 | 285.2259   |
| time_elapsed            | 12135      |
| total timesteps         | 152284     |
| train_time              | 3352       |
| update_time             | 8308       |
----------------------------------------
---------------------------------------
| act_time                | 97        |
| current_lr              | 0.0003    |
| discount_q              | 0.426     |
| env_time                | 228       |
| ep_rewmean              | 780       |
| episodes                | 1716      |
| eplenmean               | 236       |
| fps                     | 12        |
| mean 100 episode reward | 780       |
| n_updates               | 256600    |
| q_grad_norm             | 4381.7676 |
| qfs_loss                | 79.16858  |
| qs_abs_difference       | 17.1      |
| qs_difference           | 10.5      |
| qs_mean                 | 282.90845 |
| time_elapsed            | 12210     |
| total timesteps         | 153244    |
| train_time              | 3378      |
| update_time             | 8355      |
---------------------------------------
----------------------------------------
| act_time                | 97         |
| current_lr              | 0.0003     |
| discount_q              | 0.345      |
| env_time                | 230        |
| ep_rewmean              | 776        |
| episodes                | 1720       |
| eplenmean               | 235        |
| fps                     | 12         |
| mean 100 episode reward | 776        |
| n_updates               | 258400     |
| q_grad_norm             | 5106.4717  |
| qfs_loss                | 118.037285 |
| qs_abs_difference       | 27.4       |
| qs_difference           | 27         |
| qs_mean                 | 285.20935  |
| time_elapsed            | 12279      |
| total timesteps         | 154181     |
| train_time              | 3402       |
| update_time             | 8397       |
----------------------------------------
---------------------------------------
| act_time                | 98        |
| current_lr              | 0.0003    |
| discount_q              | 0.359     |
| env_time                | 231       |
| ep_rewmean              | 762       |
| episodes                | 1724      |
| eplenmean               | 231       |
| fps                     | 12        |
| mean 100 episode reward | 762       |
| n_updates               | 260000    |
| q_grad_norm             | 5172.1045 |
| qfs_loss                | 82.16877  |
| qs_abs_difference       | 70.9      |
| qs_difference           | 70.9      |
| qs_mean                 | 251.29947 |
| time_elapsed            | 12340     |
| total timesteps         | 154980    |
| train_time              | 3422      |
| update_time             | 8435      |
---------------------------------------
---------------------------------------
| act_time                | 99        |
| current_lr              | 0.0003    |
| discount_q              | 0.0132    |
| env_time                | 233       |
| ep_rewmean              | 769       |
| episodes                | 1728      |
| eplenmean               | 233       |
| fps                     | 12        |
| mean 100 episode reward | 769       |
| n_updates               | 262400    |
| q_grad_norm             | 3084.7966 |
| qfs_loss                | 64.01461  |
| qs_abs_difference       | 139       |
| qs_difference           | 139       |
| qs_mean                 | 330.69873 |
| time_elapsed            | 12431     |
| total timesteps         | 156169    |
| train_time              | 3454      |
| update_time             | 8492      |
---------------------------------------
---------------------------------------
| act_time                | 99        |
| current_lr              | 0.0003    |
| discount_q              | 0.581     |
| env_time                | 234       |
| ep_rewmean              | 753       |
| episodes                | 1732      |
| eplenmean               | 229       |
| fps                     | 12        |
| mean 100 episode reward | 753       |
| n_updates               | 263800    |
| q_grad_norm             | 4336.6074 |
| qfs_loss                | 100.3778  |
| qs_abs_difference       | 120       |
| qs_difference           | 120       |
| qs_mean                 | 250.63618 |
| time_elapsed            | 12483     |
| total timesteps         | 156865    |
| train_time              | 3472      |
| update_time             | 8525      |
---------------------------------------
---------------------------------------
| act_time                | 100       |
| current_lr              | 0.0003    |
| discount_q              | 0.014     |
| env_time                | 236       |
| ep_rewmean              | 753       |
| episodes                | 1736      |
| eplenmean               | 230       |
| fps                     | 12        |
| mean 100 episode reward | 753       |
| n_updates               | 266000    |
| q_grad_norm             | 5047.428  |
| qfs_loss                | 95.70777  |
| qs_abs_difference       | 77.1      |
| qs_difference           | 76.1      |
| qs_mean                 | 228.30498 |
| time_elapsed            | 12567     |
| total timesteps         | 157974    |
| train_time              | 3500      |
| update_time             | 8577      |
---------------------------------------
--------------------------------------
| act_time                | 101      |
| current_lr              | 0.0003   |
| discount_q              | 0.00193  |
| env_time                | 237      |
| ep_rewmean              | 749      |
| episodes                | 1740     |
| eplenmean               | 230      |
| fps                     | 12       |
| mean 100 episode reward | 749      |
| n_updates               | 268000   |
| q_grad_norm             | 3504.75  |
| qfs_loss                | 87.98171 |
| qs_abs_difference       | 249      |
| qs_difference           | 249      |
| qs_mean                 | 269.5983 |
| time_elapsed            | 12642    |
| total timesteps         | 158974   |
| train_time              | 3526     |
| update_time             | 8623     |
--------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.15e+03  |
| eval_abs_qs_difference  | 168.6065  |
| eval_discount_q         | 139       |
| eval_ep_rewmean         | 439       |
| eval_eplenmean          | 141       |
| eval_qs                 | 289.16418 |
| eval_qs_difference      | 165       |
| eval_time_elapsed       | 3         |
| total timesteps         | 160001    |
---------------------------------------
--------------------------------------
| act_time                | 102      |
| current_lr              | 0.0003   |
| discount_q              | 0.00351  |
| env_time                | 240      |
| ep_rewmean              | 775      |
| episodes                | 1744     |
| eplenmean               | 237      |
| fps                     | 12       |
| mean 100 episode reward | 775      |
| n_updates               | 271000   |
| q_grad_norm             | 4481.301 |
| qfs_loss                | 84.15625 |
| qs_abs_difference       | 5.99     |
| qs_difference           | -0.338   |
| qs_mean                 | 289.3792 |
| time_elapsed            | 12759    |
| total timesteps         | 160437   |
| train_time              | 3565     |
| update_time             | 8694     |
--------------------------------------
---------------------------------------
| act_time                | 103       |
| current_lr              | 0.0003    |
| discount_q              | 0.0227    |
| env_time                | 242       |
| ep_rewmean              | 792       |
| episodes                | 1748      |
| eplenmean               | 241       |
| fps                     | 12        |
| mean 100 episode reward | 792       |
| n_updates               | 273600    |
| q_grad_norm             | 4914.076  |
| qfs_loss                | 97.77833  |
| qs_abs_difference       | 13.5      |
| qs_difference           | 2.25      |
| qs_mean                 | 297.91974 |
| time_elapsed            | 12857     |
| total timesteps         | 161745    |
| train_time              | 3599      |
| update_time             | 8755      |
---------------------------------------
---------------------------------------
| act_time                | 104       |
| current_lr              | 0.0003    |
| discount_q              | 0.0251    |
| env_time                | 244       |
| ep_rewmean              | 811       |
| episodes                | 1752      |
| eplenmean               | 245       |
| fps                     | 12        |
| mean 100 episode reward | 811       |
| n_updates               | 276000    |
| q_grad_norm             | 4760.0996 |
| qfs_loss                | 93.92066  |
| qs_abs_difference       | 18.5      |
| qs_difference           | 14        |
| qs_mean                 | 276.61316 |
| time_elapsed            | 12948     |
| total timesteps         | 162921    |
| train_time              | 3630      |
| update_time             | 8811      |
---------------------------------------
---------------------------------------
| act_time                | 105       |
| current_lr              | 0.0003    |
| discount_q              | 0.241     |
| env_time                | 245       |
| ep_rewmean              | 819       |
| episodes                | 1756      |
| eplenmean               | 248       |
| fps                     | 12        |
| mean 100 episode reward | 819       |
| n_updates               | 278000    |
| q_grad_norm             | 3894.0562 |
| qfs_loss                | 79.16537  |
| qs_abs_difference       | 36.5      |
| qs_difference           | 36.2      |
| qs_mean                 | 298.55328 |
| time_elapsed            | 13023     |
| total timesteps         | 163917    |
| train_time              | 3656      |
| update_time             | 8857      |
---------------------------------------
---------------------------------------
| act_time                | 105       |
| current_lr              | 0.0003    |
| discount_q              | 0.151     |
| env_time                | 247       |
| ep_rewmean              | 816       |
| episodes                | 1760      |
| eplenmean               | 246       |
| fps                     | 12        |
| mean 100 episode reward | 816       |
| n_updates               | 280200    |
| q_grad_norm             | 7030.668  |
| qfs_loss                | 143.88823 |
| qs_abs_difference       | 8.42      |
| qs_difference           | 2.82      |
| qs_mean                 | 300.03326 |
| time_elapsed            | 13105     |
| total timesteps         | 165008    |
| train_time              | 3685      |
| update_time             | 8909      |
---------------------------------------
---------------------------------------
| act_time                | 106       |
| current_lr              | 0.0003    |
| discount_q              | 0.00442   |
| env_time                | 249       |
| ep_rewmean              | 823       |
| episodes                | 1764      |
| eplenmean               | 248       |
| fps                     | 12        |
| mean 100 episode reward | 823       |
| n_updates               | 282200    |
| q_grad_norm             | 3573.9084 |
| qfs_loss                | 78.35762  |
| qs_abs_difference       | 244       |
| qs_difference           | 244       |
| qs_mean                 | 308.12076 |
| time_elapsed            | 13181     |
| total timesteps         | 166072    |
| train_time              | 3711      |
| update_time             | 8955      |
---------------------------------------
--------------------------------------
| act_time                | 107      |
| current_lr              | 0.0003   |
| discount_q              | 0.0509   |
| env_time                | 251      |
| ep_rewmean              | 849      |
| episodes                | 1768     |
| eplenmean               | 255      |
| fps                     | 12       |
| mean 100 episode reward | 849      |
| n_updates               | 284800   |
| q_grad_norm             | 4195.968 |
| qfs_loss                | 75.78827 |
| qs_abs_difference       | 13.8     |
| qs_difference           | 0.369    |
| qs_mean                 | 320.9946 |
| time_elapsed            | 13279    |
| total timesteps         | 167389   |
| train_time              | 3745     |
| update_time             | 9016     |
--------------------------------------
---------------------------------------
| act_time                | 108       |
| current_lr              | 0.0003    |
| discount_q              | 0.00266   |
| env_time                | 253       |
| ep_rewmean              | 871       |
| episodes                | 1772      |
| eplenmean               | 260       |
| fps                     | 12        |
| mean 100 episode reward | 871       |
| n_updates               | 288000    |
| q_grad_norm             | 3796.585  |
| qfs_loss                | 70.69375  |
| qs_abs_difference       | 77.1      |
| qs_difference           | 77.1      |
| qs_mean                 | 356.98676 |
| time_elapsed            | 13400     |
| total timesteps         | 168940    |
| train_time              | 3786      |
| update_time             | 9091      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.28e+03  |
| eval_abs_qs_difference  | 25.492317 |
| eval_discount_q         | 267       |
| eval_ep_rewmean         | 2.01e+03  |
| eval_eplenmean          | 558       |
| eval_qs                 | 319.2587  |
| eval_qs_difference      | 20.4      |
| eval_time_elapsed       | 13        |
| total timesteps         | 170001    |
---------------------------------------
---------------------------------------
| act_time                | 110       |
| current_lr              | 0.0003    |
| discount_q              | 1.04e-05  |
| env_time                | 256       |
| ep_rewmean              | 917       |
| episodes                | 1776      |
| eplenmean               | 272       |
| fps                     | 12        |
| mean 100 episode reward | 916       |
| n_updates               | 291800    |
| q_grad_norm             | 4343.068  |
| qfs_loss                | 77.735695 |
| qs_abs_difference       | 21        |
| qs_difference           | 17.7      |
| qs_mean                 | 279.06412 |
| time_elapsed            | 13556     |
| total timesteps         | 170893    |
| train_time              | 3836      |
| update_time             | 9180      |
---------------------------------------
---------------------------------------
| act_time                | 111       |
| current_lr              | 0.0003    |
| discount_q              | 0.00716   |
| env_time                | 258       |
| ep_rewmean              | 944       |
| episodes                | 1780      |
| eplenmean               | 279       |
| fps                     | 12        |
| mean 100 episode reward | 944       |
| n_updates               | 294600    |
| q_grad_norm             | 5074.1772 |
| qfs_loss                | 96.421814 |
| qs_abs_difference       | 39.5      |
| qs_difference           | 38.7      |
| qs_mean                 | 311.01495 |
| time_elapsed            | 13661     |
| total timesteps         | 172292    |
| train_time              | 3872      |
| update_time             | 9245      |
---------------------------------------
---------------------------------------
| act_time                | 112       |
| current_lr              | 0.0003    |
| discount_q              | 0.0023    |
| env_time                | 261       |
| ep_rewmean              | 980       |
| episodes                | 1784      |
| eplenmean               | 288       |
| fps                     | 12        |
| mean 100 episode reward | 980       |
| n_updates               | 298200    |
| q_grad_norm             | 5433.5425 |
| qfs_loss                | 105.78037 |
| qs_abs_difference       | 22.2      |
| qs_difference           | 22.1      |
| qs_mean                 | 344.9194  |
| time_elapsed            | 13796     |
| total timesteps         | 174051    |
| train_time              | 3919      |
| update_time             | 9329      |
---------------------------------------
---------------------------------------
| act_time                | 113       |
| current_lr              | 0.0003    |
| discount_q              | 0.0687    |
| env_time                | 264       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1788      |
| eplenmean               | 297       |
| fps                     | 12        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 301800    |
| q_grad_norm             | 3989.9495 |
| qfs_loss                | 87.52013  |
| qs_abs_difference       | 49.5      |
| qs_difference           | 48.4      |
| qs_mean                 | 378.39825 |
| time_elapsed            | 13932     |
| total timesteps         | 175874    |
| train_time              | 3966      |
| update_time             | 9412      |
---------------------------------------
---------------------------------------
| act_time                | 115       |
| current_lr              | 0.0003    |
| discount_q              | 9.93e-06  |
| env_time                | 267       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1792      |
| eplenmean               | 309       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 306000    |
| q_grad_norm             | 3895.8071 |
| qfs_loss                | 74.366455 |
| qs_abs_difference       | 17        |
| qs_difference           | 14.5      |
| qs_mean                 | 312.17316 |
| time_elapsed            | 14089     |
| total timesteps         | 177952    |
| train_time              | 4020      |
| update_time             | 9510      |
---------------------------------------
---------------------------------------
| act_time                | 116       |
| current_lr              | 0.0003    |
| discount_q              | 0.0406    |
| env_time                | 269       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 1796      |
| eplenmean               | 307       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 308400    |
| q_grad_norm             | 2018.7046 |
| qfs_loss                | 42.7215   |
| qs_abs_difference       | 30.4      |
| qs_difference           | 30.3      |
| qs_mean                 | 305.14417 |
| time_elapsed            | 14180     |
| total timesteps         | 179182    |
| train_time              | 4051      |
| update_time             | 9566      |
---------------------------------------
--------------------------------------
| act_time                | 116      |
| current_lr              | 0.0003   |
| discount_q              | 0.131    |
| env_time                | 270      |
| ep_rewmean              | 1.03e+03 |
| episodes                | 1800     |
| eplenmean               | 301      |
| fps                     | 12       |
| mean 100 episode reward | 1.03e+03 |
| n_updates               | 309800   |
| q_grad_norm             | 3094.327 |
| qfs_loss                | 67.92918 |
| qs_abs_difference       | 261      |
| qs_difference           | 261      |
| qs_mean                 | 289.8327 |
| time_elapsed            | 14232    |
| total timesteps         | 179805   |
| train_time              | 4070     |
| update_time             | 9598     |
--------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.37e+03  |
| eval_abs_qs_difference  | 15.006499 |
| eval_discount_q         | 267       |
| eval_ep_rewmean         | 2.56e+03  |
| eval_eplenmean          | 668       |
| eval_qs                 | 331.5639  |
| eval_qs_difference      | -11.4     |
| eval_time_elapsed       | 15        |
| total timesteps         | 180001    |
---------------------------------------
---------------------------------------
| act_time                | 118       |
| current_lr              | 0.0003    |
| discount_q              | 9.19e-07  |
| env_time                | 273       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 1804      |
| eplenmean               | 311       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 313600    |
| q_grad_norm             | 3878.485  |
| qfs_loss                | 70.63082  |
| qs_abs_difference       | 220       |
| qs_difference           | 220       |
| qs_mean                 | 330.77768 |
| time_elapsed            | 14391     |
| total timesteps         | 181794    |
| train_time              | 4119      |
| update_time             | 9686      |
---------------------------------------
---------------------------------------
| act_time                | 119       |
| current_lr              | 0.0003    |
| discount_q              | 0.000393  |
| env_time                | 276       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 1808      |
| eplenmean               | 322       |
| fps                     | 12        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 317000    |
| q_grad_norm             | 4656.7964 |
| qfs_loss                | 85.35219  |
| qs_abs_difference       | 26.1      |
| qs_difference           | 26        |
| qs_mean                 | 305.5947  |
| time_elapsed            | 14518     |
| total timesteps         | 183453    |
| train_time              | 4163      |
| update_time             | 9765      |
---------------------------------------
---------------------------------------
| act_time                | 120       |
| current_lr              | 0.0003    |
| discount_q              | 0.0056    |
| env_time                | 278       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 1812      |
| eplenmean               | 325       |
| fps                     | 12        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 319800    |
| q_grad_norm             | 4934.8438 |
| qfs_loss                | 90.67942  |
| qs_abs_difference       | 47.3      |
| qs_difference           | 45.2      |
| qs_mean                 | 300.94278 |
| time_elapsed            | 14623     |
| total timesteps         | 184813    |
| train_time              | 4200      |
| update_time             | 9830      |
---------------------------------------
---------------------------------------
| act_time                | 121       |
| current_lr              | 0.0003    |
| discount_q              | 0.924     |
| env_time                | 279       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 1816      |
| eplenmean               | 324       |
| fps                     | 12        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 321400    |
| q_grad_norm             | 5612.058  |
| qfs_loss                | 117.0921  |
| qs_abs_difference       | 23.5      |
| qs_difference           | 23.4      |
| qs_mean                 | 298.69287 |
| time_elapsed            | 14683     |
| total timesteps         | 185692    |
| train_time              | 4221      |
| update_time             | 9867      |
---------------------------------------
---------------------------------------
| act_time                | 122       |
| current_lr              | 0.0003    |
| discount_q              | 0.0236    |
| env_time                | 281       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 1820      |
| eplenmean               | 327       |
| fps                     | 12        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 324000    |
| q_grad_norm             | 2577.7327 |
| qfs_loss                | 51.026733 |
| qs_abs_difference       | 36        |
| qs_difference           | 35.8      |
| qs_mean                 | 305.9394  |
| time_elapsed            | 14780     |
| total timesteps         | 186924    |
| train_time              | 4254      |
| update_time             | 9927      |
---------------------------------------
---------------------------------------
| act_time                | 122       |
| current_lr              | 0.0003    |
| discount_q              | 0.121     |
| env_time                | 283       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1824      |
| eplenmean               | 330       |
| fps                     | 12        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 326000    |
| q_grad_norm             | 4332.2437 |
| qfs_loss                | 97.11242  |
| qs_abs_difference       | 44.3      |
| qs_difference           | 42.4      |
| qs_mean                 | 301.9618  |
| time_elapsed            | 14855     |
| total timesteps         | 187971    |
| train_time              | 4280      |
| update_time             | 9974      |
---------------------------------------
---------------------------------------
| act_time                | 123       |
| current_lr              | 0.0003    |
| discount_q              | 0.00164   |
| env_time                | 285       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1828      |
| eplenmean               | 331       |
| fps                     | 12        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 328600    |
| q_grad_norm             | 2966.6194 |
| qfs_loss                | 59.281204 |
| qs_abs_difference       | 214       |
| qs_difference           | 214       |
| qs_mean                 | 335.59485 |
| time_elapsed            | 14953     |
| total timesteps         | 189237    |
| train_time              | 4314      |
| update_time             | 10035     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.45e+03  |
| eval_abs_qs_difference  | 10.777826 |
| eval_discount_q         | 270       |
| eval_ep_rewmean         | 2.19e+03  |
| eval_eplenmean          | 570       |
| eval_qs                 | 328.6554  |
| eval_qs_difference      | -3.67     |
| eval_time_elapsed       | 13        |
| total timesteps         | 190001    |
---------------------------------------
---------------------------------------
| act_time                | 124       |
| current_lr              | 0.0003    |
| discount_q              | 0.003     |
| env_time                | 287       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 1832      |
| eplenmean               | 338       |
| fps                     | 12        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 331600    |
| q_grad_norm             | 3671.7412 |
| qfs_loss                | 70.71176  |
| qs_abs_difference       | 23.7      |
| qs_difference           | 23        |
| qs_mean                 | 308.3667  |
| time_elapsed            | 15079     |
| total timesteps         | 190709    |
| train_time              | 4353      |
| update_time             | 10104     |
---------------------------------------
---------------------------------------
| act_time                | 125       |
| current_lr              | 0.0003    |
| discount_q              | 0.0263    |
| env_time                | 288       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 1836      |
| eplenmean               | 336       |
| fps                     | 12        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 333200    |
| q_grad_norm             | 4122.777  |
| qfs_loss                | 82.34633  |
| qs_abs_difference       | 263       |
| qs_difference           | 263       |
| qs_mean                 | 305.27185 |
| time_elapsed            | 15139     |
| total timesteps         | 191545    |
| train_time              | 4374      |
| update_time             | 10141     |
---------------------------------------
---------------------------------------
| act_time                | 126       |
| current_lr              | 0.0003    |
| discount_q              | 0.0004    |
| env_time                | 291       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1840      |
| eplenmean               | 343       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 336600    |
| q_grad_norm             | 3582.8926 |
| qfs_loss                | 81.37086  |
| qs_abs_difference       | 17.9      |
| qs_difference           | 14.9      |
| qs_mean                 | 308.4544  |
| time_elapsed            | 15266     |
| total timesteps         | 193233    |
| train_time              | 4418      |
| update_time             | 10220     |
---------------------------------------
---------------------------------------
| act_time                | 127       |
| current_lr              | 0.0003    |
| discount_q              | 0.00288   |
| env_time                | 293       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1844      |
| eplenmean               | 342       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 339400    |
| q_grad_norm             | 4075.0337 |
| qfs_loss                | 79.60984  |
| qs_abs_difference       | 31        |
| qs_difference           | 31        |
| qs_mean                 | 306.81525 |
| time_elapsed            | 15372     |
| total timesteps         | 194686    |
| train_time              | 4454      |
| update_time             | 10285     |
---------------------------------------
--------------------------------------
| act_time                | 128      |
| current_lr              | 0.0003   |
| discount_q              | 0.21     |
| env_time                | 295      |
| ep_rewmean              | 1.19e+03 |
| episodes                | 1848     |
| eplenmean               | 339      |
| fps                     | 12       |
| mean 100 episode reward | 1.19e+03 |
| n_updates               | 341400   |
| q_grad_norm             | 3547.969 |
| qfs_loss                | 80.38002 |
| qs_abs_difference       | 38.3     |
| qs_difference           | 37.2     |
| qs_mean                 | 299.5373 |
| time_elapsed            | 15447    |
| total timesteps         | 195687   |
| train_time              | 4480     |
| update_time             | 10331    |
--------------------------------------
---------------------------------------
| act_time                | 129       |
| current_lr              | 0.0003    |
| discount_q              | 0.0194    |
| env_time                | 296       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 1852      |
| eplenmean               | 336       |
| fps                     | 12        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 343200    |
| q_grad_norm             | 2791.882  |
| qfs_loss                | 63.40016  |
| qs_abs_difference       | 261       |
| qs_difference           | 261       |
| qs_mean                 | 301.78046 |
| time_elapsed            | 15514     |
| total timesteps         | 196543    |
| train_time              | 4504      |
| update_time             | 10373     |
---------------------------------------
--------------------------------------
| act_time                | 130      |
| current_lr              | 0.0003   |
| discount_q              | 0.00529  |
| env_time                | 299      |
| ep_rewmean              | 1.2e+03  |
| episodes                | 1856     |
| eplenmean               | 342      |
| fps                     | 12       |
| mean 100 episode reward | 1.2e+03  |
| n_updates               | 346200   |
| q_grad_norm             | 4564.284 |
| qfs_loss                | 90.06543 |
| qs_abs_difference       | 25       |
| qs_difference           | 22.2     |
| qs_mean                 | 330.7863 |
| time_elapsed            | 15627    |
| total timesteps         | 198091   |
| train_time              | 4543     |
| update_time             | 10443    |
--------------------------------------
---------------------------------------
| act_time                | 131       |
| current_lr              | 0.0003    |
| discount_q              | 8.6e-05   |
| env_time                | 301       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 1860      |
| eplenmean               | 348       |
| fps                     | 12        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 349800    |
| q_grad_norm             | 2912.6987 |
| qfs_loss                | 68.162315 |
| qs_abs_difference       | 26.8      |
| qs_difference           | 24.4      |
| qs_mean                 | 281.9413  |
| time_elapsed            | 15762     |
| total timesteps         | 199845    |
| train_time              | 4589      |
| update_time             | 10527     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.69e+03  |
| eval_abs_qs_difference  | 31.726534 |
| eval_discount_q         | 251       |
| eval_ep_rewmean         | 2.89e+03  |
| eval_eplenmean          | 808       |
| eval_qs                 | 354.0614  |
| eval_qs_difference      | 26.5      |
| eval_time_elapsed       | 19        |
| total timesteps         | 200001    |
---------------------------------------
---------------------------------------
| act_time                | 133       |
| current_lr              | 0.0003    |
| discount_q              | 0.00287   |
| env_time                | 305       |
| ep_rewmean              | 1.26e+03  |
| episodes                | 1864      |
| eplenmean               | 358       |
| fps                     | 12        |
| mean 100 episode reward | 1.26e+03  |
| n_updates               | 353800    |
| q_grad_norm             | 3048.9612 |
| qfs_loss                | 63.4743   |
| qs_abs_difference       | 9.27      |
| qs_difference           | 7.45      |
| qs_mean                 | 354.6461  |
| time_elapsed            | 15933     |
| total timesteps         | 201882    |
| train_time              | 4641      |
| update_time             | 10620     |
---------------------------------------
---------------------------------------
| act_time                | 134       |
| current_lr              | 0.0003    |
| discount_q              | 0.0165    |
| env_time                | 307       |
| ep_rewmean              | 1.26e+03  |
| episodes                | 1868      |
| eplenmean               | 358       |
| fps                     | 12        |
| mean 100 episode reward | 1.26e+03  |
| n_updates               | 356600    |
| q_grad_norm             | 4406.009  |
| qfs_loss                | 98.22555  |
| qs_abs_difference       | 21.7      |
| qs_difference           | 21.4      |
| qs_mean                 | 319.73486 |
| time_elapsed            | 16038     |
| total timesteps         | 203215    |
| train_time              | 4678      |
| update_time             | 10685     |
---------------------------------------
---------------------------------------
| act_time                | 135       |
| current_lr              | 0.0003    |
| discount_q              | 0.0385    |
| env_time                | 309       |
| ep_rewmean              | 1.25e+03  |
| episodes                | 1872      |
| eplenmean               | 355       |
| fps                     | 12        |
| mean 100 episode reward | 1.25e+03  |
| n_updates               | 359000    |
| q_grad_norm             | 3001.9985 |
| qfs_loss                | 48.36468  |
| qs_abs_difference       | 8.53      |
| qs_difference           | -1.13     |
| qs_mean                 | 297.045   |
| time_elapsed            | 16128     |
| total timesteps         | 204415    |
| train_time              | 4709      |
| update_time             | 10741     |
---------------------------------------
---------------------------------------
| act_time                | 136       |
| current_lr              | 0.0003    |
| discount_q              | 3.07e-05  |
| env_time                | 312       |
| ep_rewmean              | 1.25e+03  |
| episodes                | 1876      |
| eplenmean               | 354       |
| fps                     | 12        |
| mean 100 episode reward | 1.25e+03  |
| n_updates               | 362800    |
| q_grad_norm             | 3422.074  |
| qfs_loss                | 73.2683   |
| qs_abs_difference       | 11.6      |
| qs_difference           | 10.6      |
| qs_mean                 | 307.62534 |
| time_elapsed            | 16271     |
| total timesteps         | 206340    |
| train_time              | 4758      |
| update_time             | 10829     |
---------------------------------------
---------------------------------------
| act_time                | 138       |
| current_lr              | 0.0003    |
| discount_q              | 4.7e-06   |
| env_time                | 314       |
| ep_rewmean              | 1.26e+03  |
| episodes                | 1880      |
| eplenmean               | 358       |
| fps                     | 12        |
| mean 100 episode reward | 1.26e+03  |
| n_updates               | 366200    |
| q_grad_norm             | 3217.3337 |
| qfs_loss                | 80.81711  |
| qs_abs_difference       | 259       |
| qs_difference           | 259       |
| qs_mean                 | 319.1441  |
| time_elapsed            | 16398     |
| total timesteps         | 208074    |
| train_time              | 4803      |
| update_time             | 10908     |
---------------------------------------
---------------------------------------
| act_time                | 138       |
| current_lr              | 0.0003    |
| discount_q              | 13.2      |
| env_time                | 315       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1884      |
| eplenmean               | 343       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 366800    |
| q_grad_norm             | 2737.065  |
| qfs_loss                | 47.146717 |
| qs_abs_difference       | 253       |
| qs_difference           | 253       |
| qs_mean                 | 321.37384 |
| time_elapsed            | 16421     |
| total timesteps         | 208348    |
| train_time              | 4810      |
| update_time             | 10922     |
---------------------------------------
---------------------------------------
| act_time                | 138       |
| current_lr              | 0.0003    |
| discount_q              | 0.107     |
| env_time                | 316       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 1888      |
| eplenmean               | 332       |
| fps                     | 12        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 368200    |
| q_grad_norm             | 2593.9912 |
| qfs_loss                | 62.00108  |
| qs_abs_difference       | 247       |
| qs_difference           | 246       |
| qs_mean                 | 296.0346  |
| time_elapsed            | 16473     |
| total timesteps         | 209074    |
| train_time              | 4829      |
| update_time             | 10954     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.74e+03  |
| eval_abs_qs_difference  | 22.792784 |
| eval_discount_q         | 268       |
| eval_ep_rewmean         | 1.12e+03  |
| eval_eplenmean          | 305       |
| eval_qs                 | 301.50092 |
| eval_qs_difference      | 20.1      |
| eval_time_elapsed       | 7         |
| total timesteps         | 210001    |
---------------------------------------
---------------------------------------
| act_time                | 139       |
| current_lr              | 0.0003    |
| discount_q              | 0.00446   |
| env_time                | 318       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1892      |
| eplenmean               | 326       |
| fps                     | 12        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 371200    |
| q_grad_norm             | 3065.6016 |
| qfs_loss                | 60.083496 |
| qs_abs_difference       | 46.6      |
| qs_difference           | 46.6      |
| qs_mean                 | 330.67773 |
| time_elapsed            | 16593     |
| total timesteps         | 210524    |
| train_time              | 4868      |
| update_time             | 11024     |
---------------------------------------
---------------------------------------
| act_time                | 140       |
| current_lr              | 0.0003    |
| discount_q              | 0.0015    |
| env_time                | 320       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 1896      |
| eplenmean               | 327       |
| fps                     | 12        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 374000    |
| q_grad_norm             | 2372.478  |
| qfs_loss                | 52.715355 |
| qs_abs_difference       | 35.1      |
| qs_difference           | 34.8      |
| qs_mean                 | 252.49925 |
| time_elapsed            | 16699     |
| total timesteps         | 211914    |
| train_time              | 4904      |
| update_time             | 11090     |
---------------------------------------
---------------------------------------
| act_time                | 142       |
| current_lr              | 0.0003    |
| discount_q              | 0.000125  |
| env_time                | 323       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1900      |
| eplenmean               | 340       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 377600    |
| q_grad_norm             | 3337.4219 |
| qfs_loss                | 71.75309  |
| qs_abs_difference       | 10.8      |
| qs_difference           | 4.15      |
| qs_mean                 | 316.46658 |
| time_elapsed            | 16834     |
| total timesteps         | 213762    |
| train_time              | 4951      |
| update_time             | 11173     |
---------------------------------------
---------------------------------------
| act_time                | 143       |
| current_lr              | 0.0003    |
| discount_q              | 0.000242  |
| env_time                | 326       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1904      |
| eplenmean               | 337       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 381200    |
| q_grad_norm             | 4047.6213 |
| qfs_loss                | 80.66249  |
| qs_abs_difference       | 17.2      |
| qs_difference           | 14.7      |
| qs_mean                 | 313.8958  |
| time_elapsed            | 16969     |
| total timesteps         | 215504    |
| train_time              | 4998      |
| update_time             | 11257     |
---------------------------------------
---------------------------------------
| act_time                | 145       |
| current_lr              | 0.0003    |
| discount_q              | 2.37e-09  |
| env_time                | 330       |
| ep_rewmean              | 1.24e+03  |
| episodes                | 1908      |
| eplenmean               | 349       |
| fps                     | 12        |
| mean 100 episode reward | 1.24e+03  |
| n_updates               | 386800    |
| q_grad_norm             | 2916.4346 |
| qfs_loss                | 58.553432 |
| qs_abs_difference       | 16.2      |
| qs_difference           | 15.9      |
| qs_mean                 | 292.28745 |
| time_elapsed            | 17179     |
| total timesteps         | 218318    |
| train_time              | 5070      |
| update_time             | 11387     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.62e+03  |
| eval_abs_qs_difference  | 15.615523 |
| eval_discount_q         | 266       |
| eval_ep_rewmean         | 1.07e+03  |
| eval_eplenmean          | 289       |
| eval_qs                 | 281.7228  |
| eval_qs_difference      | 9.9       |
| eval_time_elapsed       | 6         |
| total timesteps         | 220001    |
---------------------------------------
---------------------------------------
| act_time                | 147       |
| current_lr              | 0.0003    |
| discount_q              | 0.00101   |
| env_time                | 333       |
| ep_rewmean              | 1.27e+03  |
| episodes                | 1912      |
| eplenmean               | 355       |
| fps                     | 12        |
| mean 100 episode reward | 1.27e+03  |
| n_updates               | 390800    |
| q_grad_norm             | 2827.412  |
| qfs_loss                | 54.985493 |
| qs_abs_difference       | 16        |
| qs_difference           | 15.2      |
| qs_mean                 | 351.86368 |
| time_elapsed            | 17335     |
| total timesteps         | 220329    |
| train_time              | 5122      |
| update_time             | 11479     |
---------------------------------------
---------------------------------------
| act_time                | 149       |
| current_lr              | 0.0003    |
| discount_q              | 1.3e-07   |
| env_time                | 338       |
| ep_rewmean              | 1.35e+03  |
| episodes                | 1916      |
| eplenmean               | 374       |
| fps                     | 12        |
| mean 100 episode reward | 1.35e+03  |
| n_updates               | 396200    |
| q_grad_norm             | 3175.9556 |
| qfs_loss                | 63.464233 |
| qs_abs_difference       | 21.8      |
| qs_difference           | 19.2      |
| qs_mean                 | 349.99484 |
| time_elapsed            | 17536     |
| total timesteps         | 223093    |
| train_time              | 5192      |
| update_time             | 11603     |
---------------------------------------
---------------------------------------
| act_time                | 151       |
| current_lr              | 0.0003    |
| discount_q              | 3.69e-06  |
| env_time                | 342       |
| ep_rewmean              | 1.39e+03  |
| episodes                | 1920      |
| eplenmean               | 386       |
| fps                     | 12        |
| mean 100 episode reward | 1.39e+03  |
| n_updates               | 401200    |
| q_grad_norm             | 2678.8916 |
| qfs_loss                | 48.132935 |
| qs_abs_difference       | 28.2      |
| qs_difference           | 28.1      |
| qs_mean                 | 351.5651  |
| time_elapsed            | 17721     |
| total timesteps         | 225528    |
| train_time              | 5257      |
| update_time             | 11717     |
---------------------------------------
---------------------------------------
| act_time                | 152       |
| current_lr              | 0.0003    |
| discount_q              | 5.57e-05  |
| env_time                | 345       |
| ep_rewmean              | 1.44e+03  |
| episodes                | 1924      |
| eplenmean               | 397       |
| fps                     | 12        |
| mean 100 episode reward | 1.44e+03  |
| n_updates               | 405400    |
| q_grad_norm             | 2980.3154 |
| qfs_loss                | 55.622345 |
| qs_abs_difference       | 18.6      |
| qs_difference           | 16.8      |
| qs_mean                 | 348.52707 |
| time_elapsed            | 17877     |
| total timesteps         | 227677    |
| train_time              | 5312      |
| update_time             | 11812     |
---------------------------------------
---------------------------------------
| act_time                | 153       |
| current_lr              | 0.0003    |
| discount_q              | 0.00322   |
| env_time                | 348       |
| ep_rewmean              | 1.46e+03  |
| episodes                | 1928      |
| eplenmean               | 402       |
| fps                     | 12        |
| mean 100 episode reward | 1.46e+03  |
| n_updates               | 409000    |
| q_grad_norm             | 2493.8127 |
| qfs_loss                | 42.96229  |
| qs_abs_difference       | 24        |
| qs_difference           | 23.7      |
| qs_mean                 | 346.09677 |
| time_elapsed            | 18010     |
| total timesteps         | 229427    |
| train_time              | 5359      |
| update_time             | 11894     |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 1.68e+03 |
| eval_abs_qs_difference  | 10.75534 |
| eval_discount_q         | 282      |
| eval_ep_rewmean         | 2.06e+03 |
| eval_eplenmean          | 528      |
| eval_qs                 | 335.3119 |
| eval_qs_difference      | 1.47     |
| eval_time_elapsed       | 12       |
| total timesteps         | 230001   |
--------------------------------------
---------------------------------------
| act_time                | 155       |
| current_lr              | 0.0003    |
| discount_q              | 0.000214  |
| env_time                | 351       |
| ep_rewmean              | 1.47e+03  |
| episodes                | 1932      |
| eplenmean               | 406       |
| fps                     | 12        |
| mean 100 episode reward | 1.47e+03  |
| n_updates               | 412600    |
| q_grad_norm             | 2575.489  |
| qfs_loss                | 55.81649  |
| qs_abs_difference       | 22.2      |
| qs_difference           | 21.4      |
| qs_mean                 | 338.43524 |
| time_elapsed            | 18156     |
| total timesteps         | 231285    |
| train_time              | 5406      |
| update_time             | 11975     |
---------------------------------------
---------------------------------------
| act_time                | 156       |
| current_lr              | 0.0003    |
| discount_q              | 0.00105   |
| env_time                | 353       |
| ep_rewmean              | 1.51e+03  |
| episodes                | 1936      |
| eplenmean               | 415       |
| fps                     | 12        |
| mean 100 episode reward | 1.51e+03  |
| n_updates               | 416200    |
| q_grad_norm             | 2198.6392 |
| qfs_loss                | 46.655205 |
| qs_abs_difference       | 16.1      |
| qs_difference           | 16        |
| qs_mean                 | 336.85785 |
| time_elapsed            | 18288     |
| total timesteps         | 233007    |
| train_time              | 5453      |
| update_time             | 12056     |
---------------------------------------
---------------------------------------
| act_time                | 157       |
| current_lr              | 0.0003    |
| discount_q              | 0.011     |
| env_time                | 355       |
| ep_rewmean              | 1.5e+03   |
| episodes                | 1940      |
| eplenmean               | 410       |
| fps                     | 12        |
| mean 100 episode reward | 1.5e+03   |
| n_updates               | 418600    |
| q_grad_norm             | 1239.772  |
| qfs_loss                | 26.37761  |
| qs_abs_difference       | 14.6      |
| qs_difference           | 13.7      |
| qs_mean                 | 282.01132 |
| time_elapsed            | 18377     |
| total timesteps         | 234268    |
| train_time              | 5484      |
| update_time             | 12110     |
---------------------------------------
---------------------------------------
| act_time                | 159       |
| current_lr              | 0.0003    |
| discount_q              | 9.05e-06  |
| env_time                | 359       |
| ep_rewmean              | 1.54e+03  |
| episodes                | 1944      |
| eplenmean               | 420       |
| fps                     | 12        |
| mean 100 episode reward | 1.54e+03  |
| n_updates               | 423600    |
| q_grad_norm             | 2176.1582 |
| qfs_loss                | 45.025047 |
| qs_abs_difference       | 14.2      |
| qs_difference           | 10.5      |
| qs_mean                 | 350.84262 |
| time_elapsed            | 18560     |
| total timesteps         | 236718    |
| train_time              | 5549      |
| update_time             | 12222     |
---------------------------------------
---------------------------------------
| act_time                | 160       |
| current_lr              | 0.0003    |
| discount_q              | 0.0138    |
| env_time                | 361       |
| ep_rewmean              | 1.56e+03  |
| episodes                | 1948      |
| eplenmean               | 425       |
| fps                     | 12        |
| mean 100 episode reward | 1.56e+03  |
| n_updates               | 426400    |
| q_grad_norm             | 2032.4396 |
| qfs_loss                | 41.479538 |
| qs_abs_difference       | 25.7      |
| qs_difference           | 25.6      |
| qs_mean                 | 333.5     |
| time_elapsed            | 18663     |
| total timesteps         | 238150    |
| train_time              | 5585      |
| update_time             | 12285     |
---------------------------------------
---------------------------------------
| act_time                | 161       |
| current_lr              | 0.0003    |
| discount_q              | 0.0185    |
| env_time                | 363       |
| ep_rewmean              | 1.56e+03  |
| episodes                | 1952      |
| eplenmean               | 426       |
| fps                     | 12        |
| mean 100 episode reward | 1.56e+03  |
| n_updates               | 428400    |
| q_grad_norm             | 973.31116 |
| qfs_loss                | 24.18074  |
| qs_abs_difference       | 223       |
| qs_difference           | 223       |
| qs_mean                 | 338.32938 |
| time_elapsed            | 18736     |
| total timesteps         | 239188    |
| train_time              | 5611      |
| update_time             | 12329     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.79e+03  |
| eval_abs_qs_difference  | 22.89491  |
| eval_discount_q         | 278       |
| eval_ep_rewmean         | 1.97e+03  |
| eval_eplenmean          | 517       |
| eval_qs                 | 342.30713 |
| eval_qs_difference      | 14.9      |
| eval_time_elapsed       | 12        |
| total timesteps         | 240001    |
---------------------------------------
---------------------------------------
| act_time                | 162       |
| current_lr              | 0.0003    |
| discount_q              | 1.03e-05  |
| env_time                | 366       |
| ep_rewmean              | 1.57e+03  |
| episodes                | 1956      |
| eplenmean               | 429       |
| fps                     | 12        |
| mean 100 episode reward | 1.57e+03  |
| n_updates               | 432000    |
| q_grad_norm             | 2198.7559 |
| qfs_loss                | 41.21266  |
| qs_abs_difference       | 224       |
| qs_difference           | 224       |
| qs_mean                 | 336.48312 |
| time_elapsed            | 18880     |
| total timesteps         | 240968    |
| train_time              | 5658      |
| update_time             | 12409     |
---------------------------------------
---------------------------------------
| act_time                | 163       |
| current_lr              | 0.0003    |
| discount_q              | 0.00381   |
| env_time                | 368       |
| ep_rewmean              | 1.57e+03  |
| episodes                | 1960      |
| eplenmean               | 427       |
| fps                     | 12        |
| mean 100 episode reward | 1.57e+03  |
| n_updates               | 435200    |
| q_grad_norm             | 2599.3008 |
| qfs_loss                | 57.729195 |
| qs_abs_difference       | 5.8       |
| qs_difference           | -2.78     |
| qs_mean                 | 331.9579  |
| time_elapsed            | 18997     |
| total timesteps         | 242548    |
| train_time              | 5700      |
| update_time             | 12481     |
---------------------------------------
---------------------------------------
| act_time                | 164       |
| current_lr              | 0.0003    |
| discount_q              | 0.000501  |
| env_time                | 371       |
| ep_rewmean              | 1.55e+03  |
| episodes                | 1964      |
| eplenmean               | 422       |
| fps                     | 12        |
| mean 100 episode reward | 1.55e+03  |
| n_updates               | 438400    |
| q_grad_norm             | 1608.8821 |
| qfs_loss                | 34.625534 |
| qs_abs_difference       | 20.8      |
| qs_difference           | 20.3      |
| qs_mean                 | 291.17847 |
| time_elapsed            | 19113     |
| total timesteps         | 244109    |
| train_time              | 5742      |
| update_time             | 12551     |
---------------------------------------
---------------------------------------
| act_time                | 165       |
| current_lr              | 0.0003    |
| discount_q              | 0.00749   |
| env_time                | 372       |
| ep_rewmean              | 1.54e+03  |
| episodes                | 1968      |
| eplenmean               | 419       |
| fps                     | 12        |
| mean 100 episode reward | 1.54e+03  |
| n_updates               | 440400    |
| q_grad_norm             | 2007.2549 |
| qfs_loss                | 39.761826 |
| qs_abs_difference       | 256       |
| qs_difference           | 256       |
| qs_mean                 | 329.4049  |
| time_elapsed            | 19186     |
| total timesteps         | 245132    |
| train_time              | 5768      |
| update_time             | 12595     |
---------------------------------------
---------------------------------------
| act_time                | 166       |
| current_lr              | 0.0003    |
| discount_q              | 0.678     |
| env_time                | 373       |
| ep_rewmean              | 1.53e+03  |
| episodes                | 1972      |
| eplenmean               | 415       |
| fps                     | 12        |
| mean 100 episode reward | 1.53e+03  |
| n_updates               | 442000    |
| q_grad_norm             | 1579.4092 |
| qfs_loss                | 28.75553  |
| qs_abs_difference       | 8.34      |
| qs_difference           | 4.11      |
| qs_mean                 | 279.45453 |
| time_elapsed            | 19244     |
| total timesteps         | 245961    |
| train_time              | 5788      |
| update_time             | 12630     |
---------------------------------------
---------------------------------------
| act_time                | 167       |
| current_lr              | 0.0003    |
| discount_q              | 0.00807   |
| env_time                | 376       |
| ep_rewmean              | 1.52e+03  |
| episodes                | 1976      |
| eplenmean               | 411       |
| fps                     | 12        |
| mean 100 episode reward | 1.52e+03  |
| n_updates               | 444800    |
| q_grad_norm             | 1525.143  |
| qfs_loss                | 29.225348 |
| qs_abs_difference       | 4.37      |
| qs_difference           | 0.411     |
| qs_mean                 | 327.73657 |
| time_elapsed            | 19346     |
| total timesteps         | 247391    |
| train_time              | 5825      |
| update_time             | 12692     |
---------------------------------------
---------------------------------------
| act_time                | 168       |
| current_lr              | 0.0003    |
| discount_q              | 0.00674   |
| env_time                | 378       |
| ep_rewmean              | 1.52e+03  |
| episodes                | 1980      |
| eplenmean               | 409       |
| fps                     | 12        |
| mean 100 episode reward | 1.52e+03  |
| n_updates               | 448000    |
| q_grad_norm             | 1701.0045 |
| qfs_loss                | 28.050112 |
| qs_abs_difference       | 4.79      |
| qs_difference           | 1.17      |
| qs_mean                 | 337.99365 |
| time_elapsed            | 19462     |
| total timesteps         | 248942    |
| train_time              | 5866      |
| update_time             | 12762     |
---------------------------------------
---------------------------------------
| act_time                | 169       |
| current_lr              | 0.0003    |
| discount_q              | 0.0938    |
| env_time                | 379       |
| ep_rewmean              | 1.54e+03  |
| episodes                | 1984      |
| eplenmean               | 414       |
| fps                     | 12        |
| mean 100 episode reward | 1.54e+03  |
| n_updates               | 449600    |
| q_grad_norm             | 1716.8469 |
| qfs_loss                | 42.62358  |
| qs_abs_difference       | 251       |
| qs_difference           | 251       |
| qs_mean                 | 332.38693 |
| time_elapsed            | 19520     |
| total timesteps         | 249726    |
| train_time              | 5887      |
| update_time             | 12797     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.9e+03   |
| eval_abs_qs_difference  | 39.265408 |
| eval_discount_q         | 262       |
| eval_ep_rewmean         | 1.33e+03  |
| eval_eplenmean          | 364       |
| eval_qs                 | 318.00803 |
| eval_qs_difference      | 36        |
| eval_time_elapsed       | 8         |
| total timesteps         | 250001    |
---------------------------------------
---------------------------------------
| act_time                | 169       |
| current_lr              | 0.0003    |
| discount_q              | 2         |
| env_time                | 381       |
| ep_rewmean              | 1.54e+03  |
| episodes                | 1988      |
| eplenmean               | 415       |
| fps                     | 12        |
| mean 100 episode reward | 1.54e+03  |
| n_updates               | 451200    |
| q_grad_norm             | 2001.9325 |
| qfs_loss                | 41.371773 |
| qs_abs_difference       | 7.3       |
| qs_difference           | 4.03      |
| qs_mean                 | 312.51605 |
| time_elapsed            | 19587     |
| total timesteps         | 250551    |
| train_time              | 5908      |
| update_time             | 12832     |
---------------------------------------
---------------------------------------
| act_time                | 170       |
| current_lr              | 0.0003    |
| discount_q              | 0.0445    |
| env_time                | 382       |
| ep_rewmean              | 1.54e+03  |
| episodes                | 1992      |
| eplenmean               | 412       |
| fps                     | 12        |
| mean 100 episode reward | 1.54e+03  |
| n_updates               | 453400    |
| q_grad_norm             | 1566.4778 |
| qfs_loss                | 31.81447  |
| qs_abs_difference       | 8.03      |
| qs_difference           | 6.36      |
| qs_mean                 | 296.9198  |
| time_elapsed            | 19666     |
| total timesteps         | 251691    |
| train_time              | 5937      |
| update_time             | 12880     |
---------------------------------------
---------------------------------------
| act_time                | 171       |
| current_lr              | 0.0003    |
| discount_q              | 0.053     |
| env_time                | 384       |
| ep_rewmean              | 1.53e+03  |
| episodes                | 1996      |
| eplenmean               | 408       |
| fps                     | 12        |
| mean 100 episode reward | 1.53e+03  |
| n_updates               | 455600    |
| q_grad_norm             | 2007.8386 |
| qfs_loss                | 43.91976  |
| qs_abs_difference       | 49.3      |
| qs_difference           | 49.2      |
| qs_mean                 | 283.68274 |
| time_elapsed            | 19746     |
| total timesteps         | 252737    |
| train_time              | 5965      |
| update_time             | 12928     |
---------------------------------------
---------------------------------------
| act_time                | 172       |
| current_lr              | 0.0003    |
| discount_q              | 0.00134   |
| env_time                | 386       |
| ep_rewmean              | 1.51e+03  |
| episodes                | 2000      |
| eplenmean               | 405       |
| fps                     | 12        |
| mean 100 episode reward | 1.51e+03  |
| n_updates               | 458600    |
| q_grad_norm             | 2221.5354 |
| qfs_loss                | 40.965717 |
| qs_abs_difference       | 6.63      |
| qs_difference           | -1.5      |
| qs_mean                 | 294.02197 |
| time_elapsed            | 19854     |
| total timesteps         | 254221    |
| train_time              | 6004      |
| update_time             | 12994     |
---------------------------------------
---------------------------------------
| act_time                | 173       |
| current_lr              | 0.0003    |
| discount_q              | 0.0404    |
| env_time                | 389       |
| ep_rewmean              | 1.5e+03   |
| episodes                | 2004      |
| eplenmean               | 400       |
| fps                     | 12        |
| mean 100 episode reward | 1.5e+03   |
| n_updates               | 461200    |
| q_grad_norm             | 1728.936  |
| qfs_loss                | 36.77284  |
| qs_abs_difference       | 26.5      |
| qs_difference           | 26.1      |
| qs_mean                 | 343.77917 |
| time_elapsed            | 19949     |
| total timesteps         | 255554    |
| train_time              | 6038      |
| update_time             | 13051     |
---------------------------------------
---------------------------------------
| act_time                | 174       |
| current_lr              | 0.0003    |
| discount_q              | 0.012     |
| env_time                | 391       |
| ep_rewmean              | 1.44e+03  |
| episodes                | 2008      |
| eplenmean               | 386       |
| fps                     | 12        |
| mean 100 episode reward | 1.44e+03  |
| n_updates               | 464000    |
| q_grad_norm             | 1279.4331 |
| qfs_loss                | 26.06876  |
| qs_abs_difference       | 35.5      |
| qs_difference           | 35.1      |
| qs_mean                 | 328.2779  |
| time_elapsed            | 20050     |
| total timesteps         | 256911    |
| train_time              | 6074      |
| update_time             | 13112     |
---------------------------------------
---------------------------------------
| act_time                | 175       |
| current_lr              | 0.0003    |
| discount_q              | 0.152     |
| env_time                | 392       |
| ep_rewmean              | 1.41e+03  |
| episodes                | 2012      |
| eplenmean               | 377       |
| fps                     | 12        |
| mean 100 episode reward | 1.41e+03  |
| n_updates               | 466200    |
| q_grad_norm             | 1433.4095 |
| qfs_loss                | 37.55031  |
| qs_abs_difference       | 39.6      |
| qs_difference           | 39.6      |
| qs_mean                 | 328.75174 |
| time_elapsed            | 20129     |
| total timesteps         | 258013    |
| train_time              | 6103      |
| update_time             | 13160     |
---------------------------------------
---------------------------------------
| act_time                | 176       |
| current_lr              | 0.0003    |
| discount_q              | 0.00648   |
| env_time                | 395       |
| ep_rewmean              | 1.36e+03  |
| episodes                | 2016      |
| eplenmean               | 363       |
| fps                     | 12        |
| mean 100 episode reward | 1.36e+03  |
| n_updates               | 469000    |
| q_grad_norm             | 1568.8595 |
| qfs_loss                | 31.599014 |
| qs_abs_difference       | 13        |
| qs_difference           | 12.9      |
| qs_mean                 | 320.63837 |
| time_elapsed            | 20230     |
| total timesteps         | 259402    |
| train_time              | 6139      |
| update_time             | 13221     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.8e+03   |
| eval_abs_qs_difference  | 11.21927  |
| eval_discount_q         | 277       |
| eval_ep_rewmean         | 1.04e+03  |
| eval_eplenmean          | 266       |
| eval_qs                 | 296.96146 |
| eval_qs_difference      | 8.35      |
| eval_time_elapsed       | 6         |
| total timesteps         | 260001    |
---------------------------------------
---------------------------------------
| act_time                | 177       |
| current_lr              | 0.0003    |
| discount_q              | 0.0373    |
| env_time                | 397       |
| ep_rewmean              | 1.32e+03  |
| episodes                | 2020      |
| eplenmean               | 352       |
| fps                     | 12        |
| mean 100 episode reward | 1.32e+03  |
| n_updates               | 471400    |
| q_grad_norm             | 1670.1519 |
| qfs_loss                | 30.91419  |
| qs_abs_difference       | 52.4      |
| qs_difference           | 52.4      |
| qs_mean                 | 337.30405 |
| time_elapsed            | 20323     |
| total timesteps         | 260692    |
| train_time              | 6171      |
| update_time             | 13273     |
---------------------------------------
---------------------------------------
| act_time                | 178       |
| current_lr              | 0.0003    |
| discount_q              | 0.00113   |
| env_time                | 398       |
| ep_rewmean              | 1.28e+03  |
| episodes                | 2024      |
| eplenmean               | 342       |
| fps                     | 12        |
| mean 100 episode reward | 1.28e+03  |
| n_updates               | 473800    |
| q_grad_norm             | 1555.6774 |
| qfs_loss                | 46.46874  |
| qs_abs_difference       | 256       |
| qs_difference           | 256       |
| qs_mean                 | 304.67258 |
| time_elapsed            | 20410     |
| total timesteps         | 261875    |
| train_time              | 6202      |
| update_time             | 13326     |
---------------------------------------
---------------------------------------
| act_time                | 179       |
| current_lr              | 0.0003    |
| discount_q              | 0.578     |
| env_time                | 400       |
| ep_rewmean              | 1.25e+03  |
| episodes                | 2028      |
| eplenmean               | 336       |
| fps                     | 12        |
| mean 100 episode reward | 1.25e+03  |
| n_updates               | 476000    |
| q_grad_norm             | 1578.3799 |
| qfs_loss                | 32.383682 |
| qs_abs_difference       | 35.3      |
| qs_difference           | 34.9      |
| qs_mean                 | 336.39252 |
| time_elapsed            | 20489     |
| total timesteps         | 262980    |
| train_time              | 6231      |
| update_time             | 13373     |
---------------------------------------
---------------------------------------
| act_time                | 179       |
| current_lr              | 0.0003    |
| discount_q              | 0.953     |
| env_time                | 402       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 2032      |
| eplenmean               | 327       |
| fps                     | 12        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 478000    |
| q_grad_norm             | 1116.2522 |
| qfs_loss                | 20.57021  |
| qs_abs_difference       | 6.9       |
| qs_difference           | 5.06      |
| qs_mean                 | 336.2062  |
| time_elapsed            | 20562     |
| total timesteps         | 263973    |
| train_time              | 6257      |
| update_time             | 13417     |
---------------------------------------
---------------------------------------
| act_time                | 181       |
| current_lr              | 0.0003    |
| discount_q              | 0.000883  |
| env_time                | 404       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 2036      |
| eplenmean               | 327       |
| fps                     | 12        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 481600    |
| q_grad_norm             | 2245.469  |
| qfs_loss                | 46.18164  |
| qs_abs_difference       | 6.76      |
| qs_difference           | -2.77     |
| qs_mean                 | 344.79688 |
| time_elapsed            | 20692     |
| total timesteps         | 265735    |
| train_time              | 6303      |
| update_time             | 13496     |
---------------------------------------
---------------------------------------
| act_time                | 182       |
| current_lr              | 0.0003    |
| discount_q              | 0.00435   |
| env_time                | 406       |
| ep_rewmean              | 1.23e+03  |
| episodes                | 2040      |
| eplenmean               | 328       |
| fps                     | 12        |
| mean 100 episode reward | 1.23e+03  |
| n_updates               | 484200    |
| q_grad_norm             | 1333.7584 |
| qfs_loss                | 27.387457 |
| qs_abs_difference       | 20.4      |
| qs_difference           | 20.1      |
| qs_mean                 | 278.9775  |
| time_elapsed            | 20785     |
| total timesteps         | 267039    |
| train_time              | 6337      |
| update_time             | 13552     |
---------------------------------------
---------------------------------------
| act_time                | 182       |
| current_lr              | 0.0003    |
| discount_q              | 0.352     |
| env_time                | 408       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2044      |
| eplenmean               | 312       |
| fps                     | 12        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 486000    |
| q_grad_norm             | 1530.8789 |
| qfs_loss                | 29.348106 |
| qs_abs_difference       | 42.3      |
| qs_difference           | 40.7      |
| qs_mean                 | 293.00174 |
| time_elapsed            | 20851     |
| total timesteps         | 267940    |
| train_time              | 6361      |
| update_time             | 13592     |
---------------------------------------
---------------------------------------
| act_time                | 183       |
| current_lr              | 0.0003    |
| discount_q              | 0.698     |
| env_time                | 409       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2048      |
| eplenmean               | 306       |
| fps                     | 12        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 487600    |
| q_grad_norm             | 1023.7726 |
| qfs_loss                | 21.830755 |
| qs_abs_difference       | 17.6      |
| qs_difference           | 17.6      |
| qs_mean                 | 297.33246 |
| time_elapsed            | 20908     |
| total timesteps         | 268794    |
| train_time              | 6381      |
| update_time             | 13627     |
---------------------------------------
---------------------------------------
| act_time                | 184       |
| current_lr              | 0.0003    |
| discount_q              | 0.0245    |
| env_time                | 411       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2052      |
| eplenmean               | 308       |
| fps                     | 12        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 490000    |
| q_grad_norm             | 2148.9866 |
| qfs_loss                | 54.49293  |
| qs_abs_difference       | 71.1      |
| qs_difference           | 71.1      |
| qs_mean                 | 338.5496  |
| time_elapsed            | 20995     |
| total timesteps         | 269980    |
| train_time              | 6413      |
| update_time             | 13679     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.72e+03  |
| eval_abs_qs_difference  | 28.497509 |
| eval_discount_q         | 270       |
| eval_ep_rewmean         | 1.62e+03  |
| eval_eplenmean          | 424       |
| eval_qs                 | 338.29422 |
| eval_qs_difference      | 24.2      |
| eval_time_elapsed       | 10        |
| total timesteps         | 270001    |
---------------------------------------
---------------------------------------
| act_time                | 184       |
| current_lr              | 0.0003    |
| discount_q              | 0.115     |
| env_time                | 412       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 2056      |
| eplenmean               | 300       |
| fps                     | 12        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 492000    |
| q_grad_norm             | 2253.0022 |
| qfs_loss                | 54.260498 |
| qs_abs_difference       | 21.4      |
| qs_difference           | 19.1      |
| qs_mean                 | 284.0629  |
| time_elapsed            | 21078     |
| total timesteps         | 270968    |
| train_time              | 6439      |
| update_time             | 13722     |
---------------------------------------
--------------------------------------
| act_time                | 185      |
| current_lr              | 0.0003   |
| discount_q              | 0.508    |
| env_time                | 414      |
| ep_rewmean              | 1.1e+03  |
| episodes                | 2060     |
| eplenmean               | 293      |
| fps                     | 12       |
| mean 100 episode reward | 1.1e+03  |
| n_updates               | 493800   |
| q_grad_norm             | 2173.153 |
| qfs_loss                | 43.67066 |
| qs_abs_difference       | 7.49     |
| qs_difference           | 6.45     |
| qs_mean                 | 296.6206 |
| time_elapsed            | 21142    |
| total timesteps         | 271862   |
| train_time              | 6462     |
| update_time             | 13762    |
--------------------------------------
---------------------------------------
| act_time                | 186       |
| current_lr              | 0.0003    |
| discount_q              | 0.0835    |
| env_time                | 415       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2064      |
| eplenmean               | 286       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 495600    |
| q_grad_norm             | 3194.9797 |
| qfs_loss                | 63.876675 |
| qs_abs_difference       | 220       |
| qs_difference           | 220       |
| qs_mean                 | 355.6956  |
| time_elapsed            | 21208     |
| total timesteps         | 272750    |
| train_time              | 6486      |
| update_time             | 13801     |
---------------------------------------
---------------------------------------
| act_time                | 187       |
| current_lr              | 0.0003    |
| discount_q              | 0.0855    |
| env_time                | 417       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2068      |
| eplenmean               | 287       |
| fps                     | 12        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 497800    |
| q_grad_norm             | 1929.9425 |
| qfs_loss                | 39.685593 |
| qs_abs_difference       | 7.46      |
| qs_difference           | 6.29      |
| qs_mean                 | 300.52765 |
| time_elapsed            | 21287     |
| total timesteps         | 273828    |
| train_time              | 6514      |
| update_time             | 13849     |
---------------------------------------
---------------------------------------
| act_time                | 187       |
| current_lr              | 0.0003    |
| discount_q              | 0.0998    |
| env_time                | 418       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2072      |
| eplenmean               | 289       |
| fps                     | 12        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 499800    |
| q_grad_norm             | 1632.4926 |
| qfs_loss                | 38.076088 |
| qs_abs_difference       | 15.5      |
| qs_difference           | 15.1      |
| qs_mean                 | 303.74243 |
| time_elapsed            | 21360     |
| total timesteps         | 274885    |
| train_time              | 6540      |
| update_time             | 13893     |
---------------------------------------
---------------------------------------
| act_time                | 188       |
| current_lr              | 0.0003    |
| discount_q              | 0.228     |
| env_time                | 420       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2076      |
| eplenmean               | 285       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 501800    |
| q_grad_norm             | 2832.2993 |
| qfs_loss                | 58.916832 |
| qs_abs_difference       | 18.5      |
| qs_difference           | 18.2      |
| qs_mean                 | 308.68167 |
| time_elapsed            | 21432     |
| total timesteps         | 275868    |
| train_time              | 6566      |
| update_time             | 13937     |
---------------------------------------
---------------------------------------
| act_time                | 189       |
| current_lr              | 0.0003    |
| discount_q              | 0.0191    |
| env_time                | 422       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2080      |
| eplenmean               | 282       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 504200    |
| q_grad_norm             | 2089.0522 |
| qfs_loss                | 47.711685 |
| qs_abs_difference       | 26.2      |
| qs_difference           | 25.9      |
| qs_mean                 | 313.96042 |
| time_elapsed            | 21520     |
| total timesteps         | 277098    |
| train_time              | 6598      |
| update_time             | 13990     |
---------------------------------------
---------------------------------------
| act_time                | 190       |
| current_lr              | 0.0003    |
| discount_q              | 0.441     |
| env_time                | 423       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2084      |
| eplenmean               | 283       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 506200    |
| q_grad_norm             | 1720.047  |
| qfs_loss                | 35.208996 |
| qs_abs_difference       | 11.2      |
| qs_difference           | 10.3      |
| qs_mean                 | 305.1254  |
| time_elapsed            | 21592     |
| total timesteps         | 278022    |
| train_time              | 6624      |
| update_time             | 14034     |
---------------------------------------
---------------------------------------
| act_time                | 190       |
| current_lr              | 0.0003    |
| discount_q              | 0.196     |
| env_time                | 425       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2088      |
| eplenmean               | 285       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 508200    |
| q_grad_norm             | 1628.3785 |
| qfs_loss                | 35.483303 |
| qs_abs_difference       | 18.5      |
| qs_difference           | 18.1      |
| qs_mean                 | 316.6572  |
| time_elapsed            | 21665     |
| total timesteps         | 279057    |
| train_time              | 6650      |
| update_time             | 14078     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.56e+03  |
| eval_abs_qs_difference  | 168.73654 |
| eval_discount_q         | 213       |
| eval_ep_rewmean         | 634       |
| eval_eplenmean          | 206       |
| eval_qs                 | 359.3346  |
| eval_qs_difference      | 169       |
| eval_time_elapsed       | 5         |
| total timesteps         | 280001    |
---------------------------------------
---------------------------------------
| act_time                | 191       |
| current_lr              | 0.0003    |
| discount_q              | 0.0798    |
| env_time                | 427       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2092      |
| eplenmean               | 285       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 510600    |
| q_grad_norm             | 2139.1133 |
| qfs_loss                | 45.500465 |
| qs_abs_difference       | 18.7      |
| qs_difference           | 17.9      |
| qs_mean                 | 321.39487 |
| time_elapsed            | 21757     |
| total timesteps         | 280225    |
| train_time              | 6681      |
| update_time             | 14131     |
---------------------------------------
---------------------------------------
| act_time                | 192       |
| current_lr              | 0.0003    |
| discount_q              | 0.00898   |
| env_time                | 429       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2096      |
| eplenmean               | 287       |
| fps                     | 12        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 513000    |
| q_grad_norm             | 2043.305  |
| qfs_loss                | 34.226433 |
| qs_abs_difference       | 166       |
| qs_difference           | 166       |
| qs_mean                 | 362.73322 |
| time_elapsed            | 21845     |
| total timesteps         | 281447    |
| train_time              | 6712      |
| update_time             | 14184     |
---------------------------------------
---------------------------------------
| act_time                | 193       |
| current_lr              | 0.0003    |
| discount_q              | 2.45      |
| env_time                | 430       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2100      |
| eplenmean               | 280       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 514400    |
| q_grad_norm             | 1677.4485 |
| qfs_loss                | 33.567875 |
| qs_abs_difference       | 4.16      |
| qs_difference           | -1.07     |
| qs_mean                 | 289.307   |
| time_elapsed            | 21896     |
| total timesteps         | 282172    |
| train_time              | 6730      |
| update_time             | 14215     |
---------------------------------------
---------------------------------------
| act_time                | 194       |
| current_lr              | 0.0003    |
| discount_q              | 0.0413    |
| env_time                | 431       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2104      |
| eplenmean               | 277       |
| fps                     | 12        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 516800    |
| q_grad_norm             | 1669.0765 |
| qfs_loss                | 45.195343 |
| qs_abs_difference       | 18.7      |
| qs_difference           | 18        |
| qs_mean                 | 294.0334  |
| time_elapsed            | 21983     |
| total timesteps         | 283303    |
| train_time              | 6762      |
| update_time             | 14268     |
---------------------------------------
---------------------------------------
| act_time                | 194       |
| current_lr              | 0.0003    |
| discount_q              | 0.257     |
| env_time                | 433       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2108      |
| eplenmean               | 273       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 518600    |
| q_grad_norm             | 1357.2202 |
| qfs_loss                | 26.988832 |
| qs_abs_difference       | 8.16      |
| qs_difference           | 6.19      |
| qs_mean                 | 287.57663 |
| time_elapsed            | 22049     |
| total timesteps         | 284238    |
| train_time              | 6785      |
| update_time             | 14308     |
---------------------------------------
---------------------------------------
| act_time                | 195       |
| current_lr              | 0.0003    |
| discount_q              | 0.0207    |
| env_time                | 435       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2112      |
| eplenmean               | 274       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 521000    |
| q_grad_norm             | 2851.9312 |
| qfs_loss                | 42.043808 |
| qs_abs_difference       | 6.65      |
| qs_difference           | 2.22      |
| qs_mean                 | 290.15414 |
| time_elapsed            | 22137     |
| total timesteps         | 285440    |
| train_time              | 6816      |
| update_time             | 14362     |
---------------------------------------
---------------------------------------
| act_time                | 196       |
| current_lr              | 0.0003    |
| discount_q              | 0.104     |
| env_time                | 436       |
| ep_rewmean              | 1e+03     |
| episodes                | 2116      |
| eplenmean               | 268       |
| fps                     | 12        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 522400    |
| q_grad_norm             | 2417.4407 |
| qfs_loss                | 39.75782  |
| qs_abs_difference       | 271       |
| qs_difference           | 271       |
| qs_mean                 | 336.84824 |
| time_elapsed            | 22188     |
| total timesteps         | 286185    |
| train_time              | 6835      |
| update_time             | 14393     |
---------------------------------------
---------------------------------------
| act_time                | 196       |
| current_lr              | 0.0003    |
| discount_q              | 0.167     |
| env_time                | 437       |
| ep_rewmean              | 989       |
| episodes                | 2120      |
| eplenmean               | 265       |
| fps                     | 12        |
| mean 100 episode reward | 989       |
| n_updates               | 524400    |
| q_grad_norm             | 2727.2422 |
| qfs_loss                | 44.145493 |
| qs_abs_difference       | 37        |
| qs_difference           | 36.9      |
| qs_mean                 | 302.31207 |
| time_elapsed            | 22261     |
| total timesteps         | 287169    |
| train_time              | 6861      |
| update_time             | 14437     |
---------------------------------------
---------------------------------------
| act_time                | 197       |
| current_lr              | 0.0003    |
| discount_q              | 0.0357    |
| env_time                | 439       |
| ep_rewmean              | 990       |
| episodes                | 2124      |
| eplenmean               | 264       |
| fps                     | 12        |
| mean 100 episode reward | 990       |
| n_updates               | 526800    |
| q_grad_norm             | 3646.845  |
| qfs_loss                | 62.796375 |
| qs_abs_difference       | 29.1      |
| qs_difference           | 27.2      |
| qs_mean                 | 295.69653 |
| time_elapsed            | 22349     |
| total timesteps         | 288305    |
| train_time              | 6892      |
| update_time             | 14490     |
---------------------------------------
---------------------------------------
| act_time                | 198       |
| current_lr              | 0.0003    |
| discount_q              | 0.0573    |
| env_time                | 441       |
| ep_rewmean              | 996       |
| episodes                | 2128      |
| eplenmean               | 265       |
| fps                     | 12        |
| mean 100 episode reward | 996       |
| n_updates               | 529000    |
| q_grad_norm             | 1968.7828 |
| qfs_loss                | 34.928253 |
| qs_abs_difference       | 13.7      |
| qs_difference           | 13.3      |
| qs_mean                 | 312.66483 |
| time_elapsed            | 22429     |
| total timesteps         | 289478    |
| train_time              | 6921      |
| update_time             | 14539     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.35e+03  |
| eval_abs_qs_difference  | 42.18857  |
| eval_discount_q         | 270       |
| eval_ep_rewmean         | 1.04e+03  |
| eval_eplenmean          | 283       |
| eval_qs                 | 314.08093 |
| eval_qs_difference      | 40.8      |
| eval_time_elapsed       | 6         |
| total timesteps         | 290001    |
---------------------------------------
---------------------------------------
| act_time                | 199       |
| current_lr              | 0.0003    |
| discount_q              | 0.0196    |
| env_time                | 443       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2132      |
| eplenmean               | 267       |
| fps                     | 12        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 531400    |
| q_grad_norm             | 1788.0264 |
| qfs_loss                | 29.249477 |
| qs_abs_difference       | 21.8      |
| qs_difference           | 21.7      |
| qs_mean                 | 278.17273 |
| time_elapsed            | 22524     |
| total timesteps         | 290631    |
| train_time              | 6952      |
| update_time             | 14593     |
---------------------------------------
--------------------------------------
| act_time                | 200      |
| current_lr              | 0.0003   |
| discount_q              | 0.0837   |
| env_time                | 444      |
| ep_rewmean              | 978      |
| episodes                | 2136     |
| eplenmean               | 259      |
| fps                     | 12       |
| mean 100 episode reward | 978      |
| n_updates               | 533400   |
| q_grad_norm             | 2592.914 |
| qfs_loss                | 40.80299 |
| qs_abs_difference       | 10.2     |
| qs_difference           | 0.961    |
| qs_mean                 | 279.925  |
| time_elapsed            | 22597    |
| total timesteps         | 291667   |
| train_time              | 6978     |
| update_time             | 14637    |
--------------------------------------
--------------------------------------
| act_time                | 201      |
| current_lr              | 0.0003   |
| discount_q              | 0.0375   |
| env_time                | 446      |
| ep_rewmean              | 972      |
| episodes                | 2140     |
| eplenmean               | 258      |
| fps                     | 12       |
| mean 100 episode reward | 972      |
| n_updates               | 535800   |
| q_grad_norm             | 2133.094 |
| qfs_loss                | 39.86652 |
| qs_abs_difference       | 18.5     |
| qs_difference           | 18       |
| qs_mean                 | 303.6294 |
| time_elapsed            | 22685    |
| total timesteps         | 292824   |
| train_time              | 7009     |
| update_time             | 14691    |
--------------------------------------
---------------------------------------
| act_time                | 202       |
| current_lr              | 0.0003    |
| discount_q              | 0.164     |
| env_time                | 448       |
| ep_rewmean              | 987       |
| episodes                | 2144      |
| eplenmean               | 262       |
| fps                     | 12        |
| mean 100 episode reward | 987       |
| n_updates               | 538400    |
| q_grad_norm             | 2461.5627 |
| qfs_loss                | 40.37306  |
| qs_abs_difference       | 9.93      |
| qs_difference           | 4.92      |
| qs_mean                 | 341.9766  |
| time_elapsed            | 22780     |
| total timesteps         | 294123    |
| train_time              | 7043      |
| update_time             | 14749     |
---------------------------------------
---------------------------------------
| act_time                | 202       |
| current_lr              | 0.0003    |
| discount_q              | 0.0678    |
| env_time                | 450       |
| ep_rewmean              | 1e+03     |
| episodes                | 2148      |
| eplenmean               | 266       |
| fps                     | 12        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 540800    |
| q_grad_norm             | 1880.8665 |
| qfs_loss                | 27.631853 |
| qs_abs_difference       | 8.1       |
| qs_difference           | 5.47      |
| qs_mean                 | 326.41736 |
| time_elapsed            | 22868     |
| total timesteps         | 295346    |
| train_time              | 7074      |
| update_time             | 14802     |
---------------------------------------
---------------------------------------
| act_time                | 203       |
| current_lr              | 0.0003    |
| discount_q              | 0.0459    |
| env_time                | 452       |
| ep_rewmean              | 1e+03     |
| episodes                | 2152      |
| eplenmean               | 266       |
| fps                     | 12        |
| mean 100 episode reward | 1.00e+03  |
| n_updates               | 543200    |
| q_grad_norm             | 2221.6824 |
| qfs_loss                | 33.72633  |
| qs_abs_difference       | 14.5      |
| qs_difference           | 10.9      |
| qs_mean                 | 320.53986 |
| time_elapsed            | 22956     |
| total timesteps         | 296547    |
| train_time              | 7105      |
| update_time             | 14856     |
---------------------------------------
---------------------------------------
| act_time                | 204       |
| current_lr              | 0.0003    |
| discount_q              | 0.0395    |
| env_time                | 454       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2156      |
| eplenmean               | 268       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 545600    |
| q_grad_norm             | 2342.149  |
| qfs_loss                | 40.297993 |
| qs_abs_difference       | 10.4      |
| qs_difference           | -6.33     |
| qs_mean                 | 325.3999  |
| time_elapsed            | 23043     |
| total timesteps         | 297789    |
| train_time              | 7136      |
| update_time             | 14909     |
---------------------------------------
---------------------------------------
| act_time                | 205       |
| current_lr              | 0.0003    |
| discount_q              | 0.0112    |
| env_time                | 456       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2160      |
| eplenmean               | 271       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 548200    |
| q_grad_norm             | 2322.1182 |
| qfs_loss                | 36.780293 |
| qs_abs_difference       | 11.4      |
| qs_difference           | 7.89      |
| qs_mean                 | 277.20767 |
| time_elapsed            | 23138     |
| total timesteps         | 299006    |
| train_time              | 7170      |
| update_time             | 14967     |
---------------------------------------
---------------------------------------
| act_time                | 206       |
| current_lr              | 0.0003    |
| discount_q              | 0.925     |
| env_time                | 457       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2164      |
| eplenmean               | 271       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 549800    |
| q_grad_norm             | 2507.8904 |
| qfs_loss                | 42.435474 |
| qs_abs_difference       | 13        |
| qs_difference           | 12.9      |
| qs_mean                 | 311.6977  |
| time_elapsed            | 23198     |
| total timesteps         | 299870    |
| train_time              | 7191      |
| update_time             | 15003     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.32e+03  |
| eval_abs_qs_difference  | 13.706641 |
| eval_discount_q         | 281       |
| eval_ep_rewmean         | 1.13e+03  |
| eval_eplenmean          | 284       |
| eval_qs                 | 308.59845 |
| eval_qs_difference      | 9.58      |
| eval_time_elapsed       | 6         |
| total timesteps         | 300001    |
---------------------------------------
---------------------------------------
| act_time                | 206       |
| current_lr              | 0.0003    |
| discount_q              | 0.325     |
| env_time                | 459       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2168      |
| eplenmean               | 269       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 551600    |
| q_grad_norm             | 1694.7161 |
| qfs_loss                | 32.85006  |
| qs_abs_difference       | 23.6      |
| qs_difference           | 23.6      |
| qs_mean                 | 283.9312  |
| time_elapsed            | 23271     |
| total timesteps         | 300757    |
| train_time              | 7214      |
| update_time             | 15044     |
---------------------------------------
---------------------------------------
| act_time                | 207       |
| current_lr              | 0.0003    |
| discount_q              | 0.0722    |
| env_time                | 460       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2172      |
| eplenmean               | 270       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 553800    |
| q_grad_norm             | 2517.8218 |
| qfs_loss                | 38.679848 |
| qs_abs_difference       | 11        |
| qs_difference           | 6.78      |
| qs_mean                 | 296.641   |
| time_elapsed            | 23352     |
| total timesteps         | 301835    |
| train_time              | 7243      |
| update_time             | 15093     |
---------------------------------------
---------------------------------------
| act_time                | 208       |
| current_lr              | 0.0003    |
| discount_q              | 0.0324    |
| env_time                | 462       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2176      |
| eplenmean               | 271       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 556200    |
| q_grad_norm             | 3285.7234 |
| qfs_loss                | 50.385643 |
| qs_abs_difference       | 17.7      |
| qs_difference           | 17.2      |
| qs_mean                 | 311.5457  |
| time_elapsed            | 23440     |
| total timesteps         | 303006    |
| train_time              | 7274      |
| update_time             | 15147     |
---------------------------------------
---------------------------------------
| act_time                | 209       |
| current_lr              | 0.0003    |
| discount_q              | 0.0104    |
| env_time                | 464       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2180      |
| eplenmean               | 272       |
| fps                     | 12        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 558800    |
| q_grad_norm             | 1746.612  |
| qfs_loss                | 27.092724 |
| qs_abs_difference       | 7.85      |
| qs_difference           | 3.81      |
| qs_mean                 | 313.60873 |
| time_elapsed            | 23536     |
| total timesteps         | 304323    |
| train_time              | 7308      |
| update_time             | 15205     |
---------------------------------------
---------------------------------------
| act_time                | 210       |
| current_lr              | 0.0003    |
| discount_q              | 0.105     |
| env_time                | 466       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2184      |
| eplenmean               | 274       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 560800    |
| q_grad_norm             | 2200.9875 |
| qfs_loss                | 33.97486  |
| qs_abs_difference       | 19.2      |
| qs_difference           | 17.6      |
| qs_mean                 | 304.8738  |
| time_elapsed            | 23609     |
| total timesteps         | 305388    |
| train_time              | 7334      |
| update_time             | 15250     |
---------------------------------------
---------------------------------------
| act_time                | 210       |
| current_lr              | 0.0003    |
| discount_q              | 0.826     |
| env_time                | 466       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2188      |
| eplenmean               | 266       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 561400    |
| q_grad_norm             | 2355.5227 |
| qfs_loss                | 36.384422 |
| qs_abs_difference       | 285       |
| qs_difference           | 285       |
| qs_mean                 | 292.17316 |
| time_elapsed            | 23631     |
| total timesteps         | 305670    |
| train_time              | 7342      |
| update_time             | 15264     |
---------------------------------------
---------------------------------------
| act_time                | 210       |
| current_lr              | 0.0003    |
| discount_q              | 5.97      |
| env_time                | 466       |
| ep_rewmean              | 973       |
| episodes                | 2192      |
| eplenmean               | 255       |
| fps                     | 12        |
| mean 100 episode reward | 973       |
| n_updates               | 561600    |
| q_grad_norm             | 2126.1743 |
| qfs_loss                | 39.793613 |
| qs_abs_difference       | 288       |
| qs_difference           | 288       |
| qs_mean                 | 292.6947  |
| time_elapsed            | 23639     |
| total timesteps         | 305722    |
| train_time              | 7345      |
| update_time             | 15268     |
---------------------------------------
--------------------------------------
| act_time                | 210      |
| current_lr              | 0.0003   |
| discount_q              | 6.19     |
| env_time                | 466      |
| ep_rewmean              | 929      |
| episodes                | 2196     |
| eplenmean               | 243      |
| fps                     | 12       |
| mean 100 episode reward | 928      |
| n_updates               | 561600   |
| qs_abs_difference       | 288      |
| qs_difference           | 288      |
| qs_mean                 | 292.8721 |
| time_elapsed            | 23639    |
| total timesteps         | 305773   |
| train_time              | 7345     |
| update_time             | 15268    |
--------------------------------------
---------------------------------------
| act_time                | 210       |
| current_lr              | 0.0003    |
| discount_q              | 20.6      |
| env_time                | 467       |
| ep_rewmean              | 904       |
| episodes                | 2200      |
| eplenmean               | 237       |
| fps                     | 12        |
| mean 100 episode reward | 904       |
| n_updates               | 561800    |
| q_grad_norm             | 3778.309  |
| qfs_loss                | 63.929813 |
| qs_abs_difference       | 295       |
| qs_difference           | 295       |
| qs_mean                 | 312.42227 |
| time_elapsed            | 23646     |
| total timesteps         | 305867    |
| train_time              | 7347      |
| update_time             | 15273     |
---------------------------------------
---------------------------------------
| act_time                | 210       |
| current_lr              | 0.0003    |
| discount_q              | 17.5      |
| env_time                | 467       |
| ep_rewmean              | 863       |
| episodes                | 2204      |
| eplenmean               | 227       |
| fps                     | 12        |
| mean 100 episode reward | 863       |
| n_updates               | 562000    |
| q_grad_norm             | 2660.9512 |
| qfs_loss                | 44.96608  |
| qs_abs_difference       | 293       |
| qs_difference           | 293       |
| qs_mean                 | 315.42236 |
| time_elapsed            | 23654     |
| total timesteps         | 305997    |
| train_time              | 7350      |
| update_time             | 15277     |
---------------------------------------
---------------------------------------
| act_time                | 211       |
| current_lr              | 0.0003    |
| discount_q              | 15.1      |
| env_time                | 467       |
| ep_rewmean              | 829       |
| episodes                | 2208      |
| eplenmean               | 219       |
| fps                     | 12        |
| mean 100 episode reward | 830       |
| n_updates               | 562400    |
| q_grad_norm             | 2078.7412 |
| qfs_loss                | 34.237938 |
| qs_abs_difference       | 288       |
| qs_difference           | 288       |
| qs_mean                 | 309.09064 |
| time_elapsed            | 23668     |
| total timesteps         | 306137    |
| train_time              | 7355      |
| update_time             | 15286     |
---------------------------------------
---------------------------------------
| act_time                | 211       |
| current_lr              | 0.0003    |
| discount_q              | 13.4      |
| env_time                | 467       |
| ep_rewmean              | 785       |
| episodes                | 2212      |
| eplenmean               | 208       |
| fps                     | 12        |
| mean 100 episode reward | 785       |
| n_updates               | 562600    |
| q_grad_norm             | 2192.5576 |
| qfs_loss                | 36.011513 |
| qs_abs_difference       | 282       |
| qs_difference           | 282       |
| qs_mean                 | 301.79788 |
| time_elapsed            | 23676     |
| total timesteps         | 306287    |
| train_time              | 7358      |
| update_time             | 15291     |
---------------------------------------
---------------------------------------
| act_time                | 211       |
| current_lr              | 0.0003    |
| discount_q              | 1.46      |
| env_time                | 468       |
| ep_rewmean              | 770       |
| episodes                | 2216      |
| eplenmean               | 205       |
| fps                     | 12        |
| mean 100 episode reward | 770       |
| n_updates               | 563400    |
| q_grad_norm             | 2294.6018 |
| qfs_loss                | 42.16319  |
| qs_abs_difference       | 271       |
| qs_difference           | 271       |
| qs_mean                 | 292.5744  |
| time_elapsed            | 23706     |
| total timesteps         | 306661    |
| train_time              | 7368      |
| update_time             | 15309     |
---------------------------------------
---------------------------------------
| act_time                | 212       |
| current_lr              | 0.0003    |
| discount_q              | 0.427     |
| env_time                | 469       |
| ep_rewmean              | 771       |
| episodes                | 2220      |
| eplenmean               | 204       |
| fps                     | 12        |
| mean 100 episode reward | 772       |
| n_updates               | 565400    |
| q_grad_norm             | 2145.7861 |
| qfs_loss                | 42.341045 |
| qs_abs_difference       | 7.89      |
| qs_difference           | 6.35      |
| qs_mean                 | 318.6693  |
| time_elapsed            | 23780     |
| total timesteps         | 307611    |
| train_time              | 7394      |
| update_time             | 15355     |
---------------------------------------
---------------------------------------
| act_time                | 212       |
| current_lr              | 0.0003    |
| discount_q              | 3.9       |
| env_time                | 470       |
| ep_rewmean              | 756       |
| episodes                | 2224      |
| eplenmean               | 200       |
| fps                     | 12        |
| mean 100 episode reward | 756       |
| n_updates               | 566800    |
| q_grad_norm             | 2425.093  |
| qfs_loss                | 36.10892  |
| qs_abs_difference       | 15.1      |
| qs_difference           | 14.3      |
| qs_mean                 | 317.19415 |
| time_elapsed            | 23833     |
| total timesteps         | 308329    |
| train_time              | 7412      |
| update_time             | 15388     |
---------------------------------------
---------------------------------------
| act_time                | 213       |
| current_lr              | 0.0003    |
| discount_q              | 0.0165    |
| env_time                | 472       |
| ep_rewmean              | 762       |
| episodes                | 2228      |
| eplenmean               | 201       |
| fps                     | 12        |
| mean 100 episode reward | 762       |
| n_updates               | 569200    |
| q_grad_norm             | 1129.1337 |
| qfs_loss                | 24.188522 |
| qs_abs_difference       | 10.3      |
| qs_difference           | 6.51      |
| qs_mean                 | 308.08795 |
| time_elapsed            | 23923     |
| total timesteps         | 309577    |
| train_time              | 7444      |
| update_time             | 15443     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.31e+03  |
| eval_abs_qs_difference  | 17.822214 |
| eval_discount_q         | 276       |
| eval_ep_rewmean         | 1.04e+03  |
| eval_eplenmean          | 267       |
| eval_qs                 | 299.2854  |
| eval_qs_difference      | 13.5      |
| eval_time_elapsed       | 6         |
| total timesteps         | 310001    |
---------------------------------------
---------------------------------------
| act_time                | 214       |
| current_lr              | 0.0003    |
| discount_q              | 0.0335    |
| env_time                | 474       |
| ep_rewmean              | 764       |
| episodes                | 2232      |
| eplenmean               | 202       |
| fps                     | 12        |
| mean 100 episode reward | 764       |
| n_updates               | 571600    |
| q_grad_norm             | 2696.5093 |
| qfs_loss                | 42.66157  |
| qs_abs_difference       | 11.1      |
| qs_difference           | 10.7      |
| qs_mean                 | 320.32474 |
| time_elapsed            | 24018     |
| total timesteps         | 310783    |
| train_time              | 7475      |
| update_time             | 15498     |
---------------------------------------
---------------------------------------
| act_time                | 215       |
| current_lr              | 0.0003    |
| discount_q              | 0.027     |
| env_time                | 476       |
| ep_rewmean              | 776       |
| episodes                | 2236      |
| eplenmean               | 205       |
| fps                     | 12        |
| mean 100 episode reward | 776       |
| n_updates               | 574400    |
| q_grad_norm             | 1881.0724 |
| qfs_loss                | 28.376585 |
| qs_abs_difference       | 9.71      |
| qs_difference           | 9.47      |
| qs_mean                 | 335.49503 |
| time_elapsed            | 24122     |
| total timesteps         | 312125    |
| train_time              | 7511      |
| update_time             | 15562     |
---------------------------------------
---------------------------------------
| act_time                | 216       |
| current_lr              | 0.0003    |
| discount_q              | 0.0704    |
| env_time                | 478       |
| ep_rewmean              | 775       |
| episodes                | 2240      |
| eplenmean               | 204       |
| fps                     | 12        |
| mean 100 episode reward | 775       |
| n_updates               | 576600    |
| q_grad_norm             | 2067.6187 |
| qfs_loss                | 31.333647 |
| qs_abs_difference       | 14.8      |
| qs_difference           | 13.9      |
| qs_mean                 | 317.15384 |
| time_elapsed            | 24205     |
| total timesteps         | 313242    |
| train_time              | 7540      |
| update_time             | 15613     |
---------------------------------------
---------------------------------------
| act_time                | 217       |
| current_lr              | 0.0003    |
| discount_q              | 0.0225    |
| env_time                | 480       |
| ep_rewmean              | 777       |
| episodes                | 2244      |
| eplenmean               | 204       |
| fps                     | 12        |
| mean 100 episode reward | 777       |
| n_updates               | 579200    |
| q_grad_norm             | 2657.2603 |
| qfs_loss                | 42.290062 |
| qs_abs_difference       | 14        |
| qs_difference           | 13.6      |
| qs_mean                 | 329.6763  |
| time_elapsed            | 24302     |
| total timesteps         | 314545    |
| train_time              | 7574      |
| update_time             | 15673     |
---------------------------------------
---------------------------------------
| act_time                | 218       |
| current_lr              | 0.0003    |
| discount_q              | 0.00466   |
| env_time                | 482       |
| ep_rewmean              | 786       |
| episodes                | 2248      |
| eplenmean               | 207       |
| fps                     | 12        |
| mean 100 episode reward | 786       |
| n_updates               | 582200    |
| q_grad_norm             | 2492.0269 |
| qfs_loss                | 40.25383  |
| qs_abs_difference       | 9.48      |
| qs_difference           | 6.23      |
| qs_mean                 | 326.14954 |
| time_elapsed            | 24414     |
| total timesteps         | 316011    |
| train_time              | 7613      |
| update_time             | 15742     |
---------------------------------------
---------------------------------------
| act_time                | 219       |
| current_lr              | 0.0003    |
| discount_q              | 0.00974   |
| env_time                | 485       |
| ep_rewmean              | 798       |
| episodes                | 2252      |
| eplenmean               | 210       |
| fps                     | 12        |
| mean 100 episode reward | 798       |
| n_updates               | 585200    |
| q_grad_norm             | 1514.9365 |
| qfs_loss                | 26.473099 |
| qs_abs_difference       | 7.78      |
| qs_difference           | 4.29      |
| qs_mean                 | 346.65823 |
| time_elapsed            | 24526     |
| total timesteps         | 317502    |
| train_time              | 7652      |
| update_time             | 15811     |
---------------------------------------
---------------------------------------
| act_time                | 220       |
| current_lr              | 0.0003    |
| discount_q              | 0.0376    |
| env_time                | 487       |
| ep_rewmean              | 794       |
| episodes                | 2256      |
| eplenmean               | 209       |
| fps                     | 12        |
| mean 100 episode reward | 794       |
| n_updates               | 587600    |
| q_grad_norm             | 1812.2434 |
| qfs_loss                | 31.267433 |
| qs_abs_difference       | 27.1      |
| qs_difference           | 27        |
| qs_mean                 | 314.40265 |
| time_elapsed            | 24616     |
| total timesteps         | 318704    |
| train_time              | 7683      |
| update_time             | 15866     |
---------------------------------------
---------------------------------------
| act_time                | 221       |
| current_lr              | 0.0003    |
| discount_q              | 0.00972   |
| env_time                | 489       |
| ep_rewmean              | 795       |
| episodes                | 2260      |
| eplenmean               | 210       |
| fps                     | 12        |
| mean 100 episode reward | 795       |
| n_updates               | 590000    |
| q_grad_norm             | 1460.9006 |
| qfs_loss                | 27.275497 |
| qs_abs_difference       | 21.7      |
| qs_difference           | 20.2      |
| qs_mean                 | 306.04236 |
| time_elapsed            | 24706     |
| total timesteps         | 319991    |
| train_time              | 7714      |
| update_time             | 15922     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.29e+03  |
| eval_abs_qs_difference  | 36.357586 |
| eval_discount_q         | 285       |
| eval_ep_rewmean         | 1.53e+03  |
| eval_eplenmean          | 403       |
| eval_qs                 | 341.44464 |
| eval_qs_difference      | 35.1      |
| eval_time_elapsed       | 9         |
| total timesteps         | 320001    |
---------------------------------------
---------------------------------------
| act_time                | 222       |
| current_lr              | 0.0003    |
| discount_q              | 0.00234   |
| env_time                | 491       |
| ep_rewmean              | 818       |
| episodes                | 2264      |
| eplenmean               | 216       |
| fps                     | 12        |
| mean 100 episode reward | 818       |
| n_updates               | 593000    |
| q_grad_norm             | 1609.4531 |
| qfs_loss                | 25.529644 |
| qs_abs_difference       | 9.29      |
| qs_difference           | 4.62      |
| qs_mean                 | 326.92642 |
| time_elapsed            | 24828     |
| total timesteps         | 321481    |
| train_time              | 7753      |
| update_time             | 15991     |
---------------------------------------
---------------------------------------
| act_time                | 223       |
| current_lr              | 0.0003    |
| discount_q              | 0.0251    |
| env_time                | 493       |
| ep_rewmean              | 835       |
| episodes                | 2268      |
| eplenmean               | 220       |
| fps                     | 12        |
| mean 100 episode reward | 835       |
| n_updates               | 595600    |
| q_grad_norm             | 1566.789  |
| qfs_loss                | 29.783995 |
| qs_abs_difference       | 9.26      |
| qs_difference           | 7.99      |
| qs_mean                 | 328.11688 |
| time_elapsed            | 24925     |
| total timesteps         | 322745    |
| train_time              | 7787      |
| update_time             | 16051     |
---------------------------------------
---------------------------------------
| act_time                | 224       |
| current_lr              | 0.0003    |
| discount_q              | 0.0612    |
| env_time                | 495       |
| ep_rewmean              | 836       |
| episodes                | 2272      |
| eplenmean               | 220       |
| fps                     | 12        |
| mean 100 episode reward | 836       |
| n_updates               | 597800    |
| q_grad_norm             | 1797.7783 |
| qfs_loss                | 30.980242 |
| qs_abs_difference       | 13.2      |
| qs_difference           | 11.8      |
| qs_mean                 | 308.45758 |
| time_elapsed            | 25007     |
| total timesteps         | 323846    |
| train_time              | 7816      |
| update_time             | 16102     |
---------------------------------------
---------------------------------------
| act_time                | 225       |
| current_lr              | 0.0003    |
| discount_q              | 0.0229    |
| env_time                | 496       |
| ep_rewmean              | 839       |
| episodes                | 2276      |
| eplenmean               | 220       |
| fps                     | 12        |
| mean 100 episode reward | 840       |
| n_updates               | 600200    |
| q_grad_norm             | 2244.003  |
| qfs_loss                | 36.036663 |
| qs_abs_difference       | 22.8      |
| qs_difference           | 22.6      |
| qs_mean                 | 308.27148 |
| time_elapsed            | 25097     |
| total timesteps         | 325030    |
| train_time              | 7847      |
| update_time             | 16157     |
---------------------------------------
---------------------------------------
| act_time                | 226       |
| current_lr              | 0.0003    |
| discount_q              | 0.0072    |
| env_time                | 499       |
| ep_rewmean              | 837       |
| episodes                | 2280      |
| eplenmean               | 220       |
| fps                     | 12        |
| mean 100 episode reward | 837       |
| n_updates               | 602800    |
| q_grad_norm             | 2618.2146 |
| qfs_loss                | 46.58887  |
| qs_abs_difference       | 15        |
| qs_difference           | 14.5      |
| qs_mean                 | 315.36615 |
| time_elapsed            | 25195     |
| total timesteps         | 326365    |
| train_time              | 7881      |
| update_time             | 16217     |
---------------------------------------
---------------------------------------
| act_time                | 227       |
| current_lr              | 0.0003    |
| discount_q              | 0.00806   |
| env_time                | 501       |
| ep_rewmean              | 856       |
| episodes                | 2284      |
| eplenmean               | 225       |
| fps                     | 12        |
| mean 100 episode reward | 856       |
| n_updates               | 605800    |
| q_grad_norm             | 1848.8423 |
| qfs_loss                | 31.720488 |
| qs_abs_difference       | 10.3      |
| qs_difference           | 9.48      |
| qs_mean                 | 340.43997 |
| time_elapsed            | 25307     |
| total timesteps         | 327864    |
| train_time              | 7920      |
| update_time             | 16286     |
---------------------------------------
---------------------------------------
| act_time                | 228       |
| current_lr              | 0.0003    |
| discount_q              | 0.00446   |
| env_time                | 503       |
| ep_rewmean              | 887       |
| episodes                | 2288      |
| eplenmean               | 233       |
| fps                     | 12        |
| mean 100 episode reward | 887       |
| n_updates               | 608000    |
| q_grad_norm             | 1954.476  |
| qfs_loss                | 40.33343  |
| qs_abs_difference       | 271       |
| qs_difference           | 271       |
| qs_mean                 | 339.40128 |
| time_elapsed            | 25390     |
| total timesteps         | 328928    |
| train_time              | 7949      |
| update_time             | 16338     |
---------------------------------------
---------------------------------------
| act_time                | 228       |
| current_lr              | 0.0003    |
| discount_q              | 0.224     |
| env_time                | 504       |
| ep_rewmean              | 922       |
| episodes                | 2292      |
| eplenmean               | 241       |
| fps                     | 12        |
| mean 100 episode reward | 922       |
| n_updates               | 609800    |
| q_grad_norm             | 3595.4119 |
| qfs_loss                | 51.60254  |
| qs_abs_difference       | 14.8      |
| qs_difference           | 6.81      |
| qs_mean                 | 271.91345 |
| time_elapsed            | 25457     |
| total timesteps         | 329835    |
| train_time              | 7972      |
| update_time             | 16379     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.23e+03  |
| eval_abs_qs_difference  | 7.73313   |
| eval_discount_q         | 279       |
| eval_ep_rewmean         | 1.62e+03  |
| eval_eplenmean          | 408       |
| eval_qs                 | 324.61633 |
| eval_qs_difference      | -0.505    |
| eval_time_elapsed       | 9         |
| total timesteps         | 330001    |
---------------------------------------
---------------------------------------
| act_time                | 229       |
| current_lr              | 0.0003    |
| discount_q              | 0.0179    |
| env_time                | 506       |
| ep_rewmean              | 967       |
| episodes                | 2296      |
| eplenmean               | 253       |
| fps                     | 12        |
| mean 100 episode reward | 967       |
| n_updates               | 612200    |
| q_grad_norm             | 2672.5254 |
| qfs_loss                | 51.44885  |
| qs_abs_difference       | 9.77      |
| qs_difference           | 6.05      |
| qs_mean                 | 289.40726 |
| time_elapsed            | 25557     |
| total timesteps         | 331041    |
| train_time              | 8004      |
| update_time             | 16435     |
---------------------------------------
---------------------------------------
| act_time                | 230       |
| current_lr              | 0.0003    |
| discount_q              | 0.0867    |
| env_time                | 508       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2300      |
| eplenmean               | 264       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 614600    |
| q_grad_norm             | 2232.7827 |
| qfs_loss                | 29.168129 |
| qs_abs_difference       | 5.16      |
| qs_difference           | 3.03      |
| qs_mean                 | 341.3012  |
| time_elapsed            | 25648     |
| total timesteps         | 332282    |
| train_time              | 8035      |
| update_time             | 16491     |
---------------------------------------
---------------------------------------
| act_time                | 231       |
| current_lr              | 0.0003    |
| discount_q              | 0.0717    |
| env_time                | 509       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2304      |
| eplenmean               | 273       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 616600    |
| q_grad_norm             | 2978.1047 |
| qfs_loss                | 51.11024  |
| qs_abs_difference       | 90.9      |
| qs_difference           | 90.9      |
| qs_mean                 | 323.47775 |
| time_elapsed            | 25723     |
| total timesteps         | 333279    |
| train_time              | 8061      |
| update_time             | 16538     |
---------------------------------------
---------------------------------------
| act_time                | 231       |
| current_lr              | 0.0003    |
| discount_q              | 1.03      |
| env_time                | 511       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2308      |
| eplenmean               | 279       |
| fps                     | 12        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 618200    |
| q_grad_norm             | 1745.3328 |
| qfs_loss                | 29.94637  |
| qs_abs_difference       | 11        |
| qs_difference           | 1.96      |
| qs_mean                 | 279.21368 |
| time_elapsed            | 25784     |
| total timesteps         | 334046    |
| train_time              | 8082      |
| update_time             | 16576     |
---------------------------------------
---------------------------------------
| act_time                | 232       |
| current_lr              | 0.0003    |
| discount_q              | 0.14      |
| env_time                | 512       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 2312      |
| eplenmean               | 288       |
| fps                     | 12        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 620400    |
| q_grad_norm             | 2209.606  |
| qfs_loss                | 38.962494 |
| qs_abs_difference       | 11        |
| qs_difference           | 10.4      |
| qs_mean                 | 319.54047 |
| time_elapsed            | 25866     |
| total timesteps         | 335100    |
| train_time              | 8110      |
| update_time             | 16627     |
---------------------------------------
---------------------------------------
| act_time                | 233       |
| current_lr              | 0.0003    |
| discount_q              | 0.0314    |
| env_time                | 514       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2316      |
| eplenmean               | 297       |
| fps                     | 12        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 622800    |
| q_grad_norm             | 1429.0999 |
| qfs_loss                | 24.943308 |
| qs_abs_difference       | 5.62      |
| qs_difference           | -0.57     |
| qs_mean                 | 337.79855 |
| time_elapsed            | 25957     |
| total timesteps         | 336399    |
| train_time              | 8141      |
| update_time             | 16683     |
---------------------------------------
---------------------------------------
| act_time                | 234       |
| current_lr              | 0.0003    |
| discount_q              | 0.0142    |
| env_time                | 516       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2320      |
| eplenmean               | 301       |
| fps                     | 12        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 625400    |
| q_grad_norm             | 2795.2324 |
| qfs_loss                | 40.001938 |
| qs_abs_difference       | 29.1      |
| qs_difference           | 28.3      |
| qs_mean                 | 324.9951  |
| time_elapsed            | 26055     |
| total timesteps         | 337699    |
| train_time              | 8175      |
| update_time             | 16744     |
---------------------------------------
---------------------------------------
| act_time                | 235       |
| current_lr              | 0.0003    |
| discount_q              | 0.00242   |
| env_time                | 518       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2324      |
| eplenmean               | 307       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 628000    |
| q_grad_norm             | 2580.244  |
| qfs_loss                | 38.751865 |
| qs_abs_difference       | 164       |
| qs_difference           | 164       |
| qs_mean                 | 352.36118 |
| time_elapsed            | 26153     |
| total timesteps         | 338991    |
| train_time              | 8209      |
| update_time             | 16805     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.14e+03  |
| eval_abs_qs_difference  | 182.87144 |
| eval_discount_q         | 160       |
| eval_ep_rewmean         | 483       |
| eval_eplenmean          | 138       |
| eval_qs                 | 328.89908 |
| eval_qs_difference      | 180       |
| eval_time_elapsed       | 3         |
| total timesteps         | 340001    |
---------------------------------------
---------------------------------------
| act_time                | 236       |
| current_lr              | 0.0003    |
| discount_q              | 0.0147    |
| env_time                | 520       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2328      |
| eplenmean               | 306       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 630400    |
| q_grad_norm             | 1829.8867 |
| qfs_loss                | 36.130554 |
| qs_abs_difference       | 19.3      |
| qs_difference           | 18.2      |
| qs_mean                 | 288.4741  |
| time_elapsed            | 26247     |
| total timesteps         | 340190    |
| train_time              | 8240      |
| update_time             | 16861     |
---------------------------------------
---------------------------------------
| act_time                | 237       |
| current_lr              | 0.0003    |
| discount_q              | 0.0639    |
| env_time                | 522       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2332      |
| eplenmean               | 305       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 632800    |
| q_grad_norm             | 2580.905  |
| qfs_loss                | 35.846603 |
| qs_abs_difference       | 6.7       |
| qs_difference           | 4.59      |
| qs_mean                 | 315.3758  |
| time_elapsed            | 26337     |
| total timesteps         | 341322    |
| train_time              | 8272      |
| update_time             | 16917     |
---------------------------------------
---------------------------------------
| act_time                | 238       |
| current_lr              | 0.0003    |
| discount_q              | 0.0272    |
| env_time                | 524       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2336      |
| eplenmean               | 305       |
| fps                     | 12        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 635200    |
| q_grad_norm             | 1968.489  |
| qfs_loss                | 31.92306  |
| qs_abs_difference       | 13.5      |
| qs_difference           | 12.1      |
| qs_mean                 | 333.00812 |
| time_elapsed            | 26428     |
| total timesteps         | 342592    |
| train_time              | 8303      |
| update_time             | 16973     |
---------------------------------------
---------------------------------------
| act_time                | 239       |
| current_lr              | 0.0003    |
| discount_q              | 0.00428   |
| env_time                | 526       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2340      |
| eplenmean               | 307       |
| fps                     | 12        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 638000    |
| q_grad_norm             | 2113.903  |
| qfs_loss                | 32.721584 |
| qs_abs_difference       | 23.8      |
| qs_difference           | 23.8      |
| qs_mean                 | 315.34506 |
| time_elapsed            | 26534     |
| total timesteps         | 343967    |
| train_time              | 8339      |
| update_time             | 17039     |
---------------------------------------
---------------------------------------
| act_time                | 239       |
| current_lr              | 0.0003    |
| discount_q              | 5.26      |
| env_time                | 527       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2344      |
| eplenmean               | 301       |
| fps                     | 12        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 639400    |
| q_grad_norm             | 1509.923  |
| qfs_loss                | 32.54722  |
| qs_abs_difference       | 24.6      |
| qs_difference           | 24.3      |
| qs_mean                 | 312.66602 |
| time_elapsed            | 26587     |
| total timesteps         | 344614    |
| train_time              | 8358      |
| update_time             | 17072     |
---------------------------------------
---------------------------------------
| act_time                | 240       |
| current_lr              | 0.0003    |
| discount_q              | 0.147     |
| env_time                | 529       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2348      |
| eplenmean               | 296       |
| fps                     | 12        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 641400    |
| q_grad_norm             | 1861.0571 |
| qfs_loss                | 35.097828 |
| qs_abs_difference       | 21.3      |
| qs_difference           | 21.3      |
| qs_mean                 | 312.39624 |
| time_elapsed            | 26663     |
| total timesteps         | 345627    |
| train_time              | 8384      |
| update_time             | 17119     |
---------------------------------------
---------------------------------------
| act_time                | 241       |
| current_lr              | 0.0003    |
| discount_q              | 0.000406  |
| env_time                | 531       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2352      |
| eplenmean               | 297       |
| fps                     | 12        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 644600    |
| q_grad_norm             | 1873.153  |
| qfs_loss                | 38.268147 |
| qs_abs_difference       | 21.3      |
| qs_difference           | 21        |
| qs_mean                 | 306.15482 |
| time_elapsed            | 26784     |
| total timesteps         | 347215    |
| train_time              | 8426      |
| update_time             | 17194     |
---------------------------------------
---------------------------------------
| act_time                | 242       |
| current_lr              | 0.0003    |
| discount_q              | 0.168     |
| env_time                | 533       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2356      |
| eplenmean               | 296       |
| fps                     | 12        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 646600    |
| q_grad_norm             | 1990.8888 |
| qfs_loss                | 33.329655 |
| qs_abs_difference       | 10.8      |
| qs_difference           | 10.2      |
| qs_mean                 | 330.2888  |
| time_elapsed            | 26860     |
| total timesteps         | 348283    |
| train_time              | 8452      |
| update_time             | 17241     |
---------------------------------------
---------------------------------------
| act_time                | 243       |
| current_lr              | 0.0003    |
| discount_q              | 0.0603    |
| env_time                | 535       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2360      |
| eplenmean               | 294       |
| fps                     | 12        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 649000    |
| q_grad_norm             | 2316.076  |
| qfs_loss                | 39.316483 |
| qs_abs_difference       | 3.71      |
| qs_difference           | -2.44     |
| qs_mean                 | 316.51007 |
| time_elapsed            | 26951     |
| total timesteps         | 349418    |
| train_time              | 8483      |
| update_time             | 17298     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.14e+03  |
| eval_abs_qs_difference  | 9.973161  |
| eval_discount_q         | 298       |
| eval_ep_rewmean         | 1.25e+03  |
| eval_eplenmean          | 294       |
| eval_qs                 | 316.67618 |
| eval_qs_difference      | -7.26     |
| eval_time_elapsed       | 7         |
| total timesteps         | 350001    |
---------------------------------------
---------------------------------------
| act_time                | 244       |
| current_lr              | 0.0003    |
| discount_q              | 0.013     |
| env_time                | 537       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2364      |
| eplenmean               | 291       |
| fps                     | 12        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 651400    |
| q_grad_norm             | 1646.3586 |
| qfs_loss                | 27.670343 |
| qs_abs_difference       | 122       |
| qs_difference           | 122       |
| qs_mean                 | 367.78497 |
| time_elapsed            | 27049     |
| total timesteps         | 350627    |
| train_time              | 8514      |
| update_time             | 17355     |
---------------------------------------
---------------------------------------
| act_time                | 245       |
| current_lr              | 0.0003    |
| discount_q              | 0.0561    |
| env_time                | 538       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2368      |
| eplenmean               | 290       |
| fps                     | 12        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 653600    |
| q_grad_norm             | 1200.1835 |
| qfs_loss                | 24.96931  |
| qs_abs_difference       | 29.2      |
| qs_difference           | 28.8      |
| qs_mean                 | 314.81116 |
| time_elapsed            | 27133     |
| total timesteps         | 351752    |
| train_time              | 8543      |
| update_time             | 17407     |
---------------------------------------
---------------------------------------
| act_time                | 245       |
| current_lr              | 0.0003    |
| discount_q              | 0.17      |
| env_time                | 540       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2372      |
| eplenmean               | 288       |
| fps                     | 12        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 655400    |
| q_grad_norm             | 1765.0748 |
| qfs_loss                | 38.84501  |
| qs_abs_difference       | 93.1      |
| qs_difference           | 93.1      |
| qs_mean                 | 333.3134  |
| time_elapsed            | 27201     |
| total timesteps         | 352677    |
| train_time              | 8566      |
| update_time             | 17449     |
---------------------------------------
---------------------------------------
| act_time                | 246       |
| current_lr              | 0.0003    |
| discount_q              | 0.0768    |
| env_time                | 542       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2376      |
| eplenmean               | 288       |
| fps                     | 12        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 657600    |
| q_grad_norm             | 1339.0721 |
| qfs_loss                | 23.387249 |
| qs_abs_difference       | 12.7      |
| qs_difference           | 12.2      |
| qs_mean                 | 321.68915 |
| time_elapsed            | 27284     |
| total timesteps         | 353789    |
| train_time              | 8595      |
| update_time             | 17501     |
---------------------------------------
---------------------------------------
| act_time                | 247       |
| current_lr              | 0.0003    |
| discount_q              | 0.135     |
| env_time                | 543       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 2380      |
| eplenmean               | 284       |
| fps                     | 12        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 659600    |
| q_grad_norm             | 2260.0789 |
| qfs_loss                | 40.68427  |
| qs_abs_difference       | 63.8      |
| qs_difference           | 63.8      |
| qs_mean                 | 337.15927 |
| time_elapsed            | 27360     |
| total timesteps         | 354773    |
| train_time              | 8621      |
| update_time             | 17548     |
---------------------------------------
---------------------------------------
| act_time                | 248       |
| current_lr              | 0.0003    |
| discount_q              | 0.0943    |
| env_time                | 545       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2384      |
| eplenmean               | 280       |
| fps                     | 12        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 661800    |
| q_grad_norm             | 1669.7798 |
| qfs_loss                | 32.02339  |
| qs_abs_difference       | 14.4      |
| qs_difference           | 14.4      |
| qs_mean                 | 307.78845 |
| time_elapsed            | 27444     |
| total timesteps         | 355816    |
| train_time              | 8650      |
| update_time             | 17600     |
---------------------------------------
---------------------------------------
| act_time                | 248       |
| current_lr              | 0.0003    |
| discount_q              | 0.0902    |
| env_time                | 546       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2388      |
| eplenmean               | 279       |
| fps                     | 12        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 663800    |
| q_grad_norm             | 1438.0358 |
| qfs_loss                | 26.947577 |
| qs_abs_difference       | 6.91      |
| qs_difference           | 2.49      |
| qs_mean                 | 298.1857  |
| time_elapsed            | 27519     |
| total timesteps         | 356858    |
| train_time              | 8676      |
| update_time             | 17647     |
---------------------------------------
---------------------------------------
| act_time                | 249       |
| current_lr              | 0.0003    |
| discount_q              | 0.142     |
| env_time                | 548       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2392      |
| eplenmean               | 280       |
| fps                     | 12        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 665800    |
| q_grad_norm             | 2177.0605 |
| qfs_loss                | 33.799393 |
| qs_abs_difference       | 33.1      |
| qs_difference           | 33.1      |
| qs_mean                 | 324.67316 |
| time_elapsed            | 27595     |
| total timesteps         | 357875    |
| train_time              | 8702      |
| update_time             | 17694     |
---------------------------------------
---------------------------------------
| act_time                | 250       |
| current_lr              | 0.0003    |
| discount_q              | 0.0891    |
| env_time                | 549       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2396      |
| eplenmean               | 276       |
| fps                     | 12        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 667400    |
| q_grad_norm             | 1480.3193 |
| qfs_loss                | 28.158985 |
| qs_abs_difference       | 287       |
| qs_difference           | 287       |
| qs_mean                 | 347.7754  |
| time_elapsed            | 27656     |
| total timesteps         | 358619    |
| train_time              | 8723      |
| update_time             | 17732     |
---------------------------------------
---------------------------------------
| act_time                | 250       |
| current_lr              | 0.0003    |
| discount_q              | 2.71      |
| env_time                | 551       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2400      |
| eplenmean               | 273       |
| fps                     | 12        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 669200    |
| q_grad_norm             | 1595.538  |
| qfs_loss                | 32.076977 |
| qs_abs_difference       | 19.7      |
| qs_difference           | 17        |
| qs_mean                 | 345.2323  |
| time_elapsed            | 27725     |
| total timesteps         | 359580    |
| train_time              | 8746      |
| update_time             | 17775     |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 1.09e+03 |
| eval_abs_qs_difference  | 28.86448 |
| eval_discount_q         | 286      |
| eval_ep_rewmean         | 1.09e+03 |
| eval_eplenmean          | 270      |
| eval_qs                 | 321.7247 |
| eval_qs_difference      | 26.3     |
| eval_time_elapsed       | 6        |
| total timesteps         | 360001   |
--------------------------------------
---------------------------------------
| act_time                | 251       |
| current_lr              | 0.0003    |
| discount_q              | 0.0771    |
| env_time                | 552       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2404      |
| eplenmean               | 274       |
| fps                     | 12        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 671400    |
| q_grad_norm             | 1922.4822 |
| qfs_loss                | 40.222622 |
| qs_abs_difference       | 17.1      |
| qs_difference           | 14.6      |
| qs_mean                 | 302.25473 |
| time_elapsed            | 27815     |
| total timesteps         | 360635    |
| train_time              | 8775      |
| update_time             | 17827     |
---------------------------------------
---------------------------------------
| act_time                | 252       |
| current_lr              | 0.0003    |
| discount_q              | 0.00304   |
| env_time                | 555       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2408      |
| eplenmean               | 280       |
| fps                     | 12        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 674200    |
| q_grad_norm             | 1141.2253 |
| qfs_loss                | 22.629612 |
| qs_abs_difference       | 50.4      |
| qs_difference           | 50.4      |
| qs_mean                 | 343.21844 |
| time_elapsed            | 27921     |
| total timesteps         | 362079    |
| train_time              | 8811      |
| update_time             | 17893     |
---------------------------------------
---------------------------------------
| act_time                | 253       |
| current_lr              | 0.0003    |
| discount_q              | 0.0909    |
| env_time                | 556       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2412      |
| eplenmean               | 280       |
| fps                     | 12        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 676400    |
| q_grad_norm             | 1842.6752 |
| qfs_loss                | 34.566788 |
| qs_abs_difference       | 12.6      |
| qs_difference           | 12.1      |
| qs_mean                 | 305.987   |
| time_elapsed            | 28005     |
| total timesteps         | 363120    |
| train_time              | 8840      |
| update_time             | 17945     |
---------------------------------------
---------------------------------------
| act_time                | 254       |
| current_lr              | 0.0003    |
| discount_q              | 0.0321    |
| env_time                | 558       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2416      |
| eplenmean               | 279       |
| fps                     | 12        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 678600    |
| q_grad_norm             | 2282.8103 |
| qfs_loss                | 54.809746 |
| qs_abs_difference       | 71.2      |
| qs_difference           | 71.2      |
| qs_mean                 | 342.43567 |
| time_elapsed            | 28088     |
| total timesteps         | 364250    |
| train_time              | 8868      |
| update_time             | 17997     |
---------------------------------------
---------------------------------------
| act_time                | 255       |
| current_lr              | 0.0003    |
| discount_q              | 0.0996    |
| env_time                | 560       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2420      |
| eplenmean               | 276       |
| fps                     | 12        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 680600    |
| q_grad_norm             | 2819.5178 |
| qfs_loss                | 42.512524 |
| qs_abs_difference       | 24        |
| qs_difference           | 23.9      |
| qs_mean                 | 308.82986 |
| time_elapsed            | 28164     |
| total timesteps         | 365276    |
| train_time              | 8894      |
| update_time             | 18045     |
---------------------------------------
---------------------------------------
| act_time                | 256       |
| current_lr              | 0.0003    |
| discount_q              | 0.095     |
| env_time                | 561       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2424      |
| eplenmean               | 274       |
| fps                     | 12        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 682800    |
| q_grad_norm             | 2058.8618 |
| qfs_loss                | 45.184082 |
| qs_abs_difference       | 9.64      |
| qs_difference           | 7.68      |
| qs_mean                 | 319.28363 |
| time_elapsed            | 28248     |
| total timesteps         | 366357    |
| train_time              | 8923      |
| update_time             | 18097     |
---------------------------------------
---------------------------------------
| act_time                | 256       |
| current_lr              | 0.0003    |
| discount_q              | 0.0465    |
| env_time                | 563       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2428      |
| eplenmean               | 273       |
| fps                     | 12        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 685000    |
| q_grad_norm             | 2010.4817 |
| qfs_loss                | 34.449688 |
| qs_abs_difference       | 10.1      |
| qs_difference           | -7.24     |
| qs_mean                 | 306.53647 |
| time_elapsed            | 28332     |
| total timesteps         | 367483    |
| train_time              | 8952      |
| update_time             | 18149     |
---------------------------------------
---------------------------------------
| act_time                | 257       |
| current_lr              | 0.0003    |
| discount_q              | 0.0546    |
| env_time                | 565       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2432      |
| eplenmean               | 273       |
| fps                     | 12        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 687200    |
| q_grad_norm             | 1058.286  |
| qfs_loss                | 25.342657 |
| qs_abs_difference       | 11.4      |
| qs_difference           | 10.1      |
| qs_mean                 | 309.43768 |
| time_elapsed            | 28416     |
| total timesteps         | 368591    |
| train_time              | 8980      |
| update_time             | 18202     |
---------------------------------------
---------------------------------------
| act_time                | 258       |
| current_lr              | 0.0003    |
| discount_q              | 0.0363    |
| env_time                | 566       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2436      |
| eplenmean               | 272       |
| fps                     | 12        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 689600    |
| q_grad_norm             | 1858.2249 |
| qfs_loss                | 33.264534 |
| qs_abs_difference       | 16.7      |
| qs_difference           | 15.5      |
| qs_mean                 | 325.05682 |
| time_elapsed            | 28508     |
| total timesteps         | 369776    |
| train_time              | 9012      |
| update_time             | 18259     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.14e+03  |
| eval_abs_qs_difference  | 12.096158 |
| eval_discount_q         | 294       |
| eval_ep_rewmean         | 1.22e+03  |
| eval_eplenmean          | 295       |
| eval_qs                 | 321.9965  |
| eval_qs_difference      | 7.71      |
| eval_time_elapsed       | 7         |
| total timesteps         | 370001    |
---------------------------------------
---------------------------------------
| act_time                | 258       |
| current_lr              | 0.0003    |
| discount_q              | 0.125     |
| env_time                | 567       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2440      |
| eplenmean               | 263       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 690600    |
| q_grad_norm             | 2067.172  |
| qfs_loss                | 35.899017 |
| qs_abs_difference       | 301       |
| qs_difference           | 301       |
| qs_mean                 | 309.02615 |
| time_elapsed            | 28553     |
| total timesteps         | 370245    |
| train_time              | 9025      |
| update_time             | 18283     |
---------------------------------------
---------------------------------------
| act_time                | 259       |
| current_lr              | 0.0003    |
| discount_q              | 58        |
| env_time                | 567       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2444      |
| eplenmean               | 257       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 690800    |
| q_grad_norm             | 2258.5618 |
| qfs_loss                | 36.39576  |
| qs_abs_difference       | 287       |
| qs_difference           | 287       |
| qs_mean                 | 345.94717 |
| time_elapsed            | 28561     |
| total timesteps         | 370339    |
| train_time              | 9027      |
| update_time             | 18287     |
---------------------------------------
---------------------------------------
| act_time                | 259       |
| current_lr              | 0.0003    |
| discount_q              | 0.0265    |
| env_time                | 569       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2448      |
| eplenmean               | 259       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 693200    |
| q_grad_norm             | 2288.87   |
| qfs_loss                | 39.838825 |
| qs_abs_difference       | 9.02      |
| qs_difference           | 7.16      |
| qs_mean                 | 308.59805 |
| time_elapsed            | 28652     |
| total timesteps         | 371517    |
| train_time              | 9059      |
| update_time             | 18344     |
---------------------------------------
---------------------------------------
| act_time                | 260       |
| current_lr              | 0.0003    |
| discount_q              | 1.35      |
| env_time                | 570       |
| ep_rewmean              | 999       |
| episodes                | 2452      |
| eplenmean               | 251       |
| fps                     | 12        |
| mean 100 episode reward | 999       |
| n_updates               | 694800    |
| q_grad_norm             | 2496.074  |
| qfs_loss                | 41.303905 |
| qs_abs_difference       | 31.3      |
| qs_difference           | 30.6      |
| qs_mean                 | 315.78665 |
| time_elapsed            | 28713     |
| total timesteps         | 372311    |
| train_time              | 9079      |
| update_time             | 18382     |
---------------------------------------
---------------------------------------
| act_time                | 260       |
| current_lr              | 0.0003    |
| discount_q              | 18        |
| env_time                | 571       |
| ep_rewmean              | 959       |
| episodes                | 2456      |
| eplenmean               | 242       |
| fps                     | 12        |
| mean 100 episode reward | 959       |
| n_updates               | 695000    |
| q_grad_norm             | 2477.6694 |
| qfs_loss                | 46.436787 |
| qs_abs_difference       | 247       |
| qs_difference           | 247       |
| qs_mean                 | 286.85013 |
| time_elapsed            | 28721     |
| total timesteps         | 372496    |
| train_time              | 9082      |
| update_time             | 18387     |
---------------------------------------
---------------------------------------
| act_time                | 261       |
| current_lr              | 0.0003    |
| discount_q              | 0.351     |
| env_time                | 572       |
| ep_rewmean              | 938       |
| episodes                | 2460      |
| eplenmean               | 238       |
| fps                     | 12        |
| mean 100 episode reward | 938       |
| n_updates               | 696600    |
| q_grad_norm             | 1888.6843 |
| qfs_loss                | 41.532803 |
| qs_abs_difference       | 223       |
| qs_difference           | 223       |
| qs_mean                 | 358.4924  |
| time_elapsed            | 28781     |
| total timesteps         | 373246    |
| train_time              | 9103      |
| update_time             | 18425     |
---------------------------------------
---------------------------------------
| act_time                | 262       |
| current_lr              | 0.0003    |
| discount_q              | 0.0247    |
| env_time                | 574       |
| ep_rewmean              | 947       |
| episodes                | 2464      |
| eplenmean               | 241       |
| fps                     | 12        |
| mean 100 episode reward | 947       |
| n_updates               | 699400    |
| q_grad_norm             | 2200.4834 |
| qfs_loss                | 41.455902 |
| qs_abs_difference       | 11.8      |
| qs_difference           | 8.51      |
| qs_mean                 | 347.74918 |
| time_elapsed            | 28888     |
| total timesteps         | 374691    |
| train_time              | 9139      |
| update_time             | 18491     |
---------------------------------------
---------------------------------------
| act_time                | 263       |
| current_lr              | 0.0003    |
| discount_q              | 0.00547   |
| env_time                | 577       |
| ep_rewmean              | 966       |
| episodes                | 2468      |
| eplenmean               | 246       |
| fps                     | 12        |
| mean 100 episode reward | 966       |
| n_updates               | 702800    |
| q_grad_norm             | 2458.8367 |
| qfs_loss                | 40.666172 |
| qs_abs_difference       | 13.4      |
| qs_difference           | 12.6      |
| qs_mean                 | 358.106   |
| time_elapsed            | 29018     |
| total timesteps         | 376328    |
| train_time              | 9183      |
| update_time             | 18572     |
---------------------------------------
---------------------------------------
| act_time                | 264       |
| current_lr              | 0.0003    |
| discount_q              | 0.037     |
| env_time                | 579       |
| ep_rewmean              | 973       |
| episodes                | 2472      |
| eplenmean               | 248       |
| fps                     | 12        |
| mean 100 episode reward | 973       |
| n_updates               | 705000    |
| q_grad_norm             | 2152.7292 |
| qfs_loss                | 39.749146 |
| qs_abs_difference       | 12.4      |
| qs_difference           | 9.21      |
| qs_mean                 | 297.64417 |
| time_elapsed            | 29102     |
| total timesteps         | 377439    |
| train_time              | 9212      |
| update_time             | 18625     |
---------------------------------------
---------------------------------------
| act_time                | 265       |
| current_lr              | 0.0003    |
| discount_q              | 0.0729    |
| env_time                | 580       |
| ep_rewmean              | 973       |
| episodes                | 2476      |
| eplenmean               | 248       |
| fps                     | 12        |
| mean 100 episode reward | 972       |
| n_updates               | 707200    |
| q_grad_norm             | 2452.8225 |
| qfs_loss                | 39.030956 |
| qs_abs_difference       | 25.9      |
| qs_difference           | 25.5      |
| qs_mean                 | 329.1846  |
| time_elapsed            | 29186     |
| total timesteps         | 378546    |
| train_time              | 9241      |
| update_time             | 18678     |
---------------------------------------
---------------------------------------
| act_time                | 266       |
| current_lr              | 0.0003    |
| discount_q              | 0.0801    |
| env_time                | 582       |
| ep_rewmean              | 981       |
| episodes                | 2480      |
| eplenmean               | 249       |
| fps                     | 12        |
| mean 100 episode reward | 981       |
| n_updates               | 709600    |
| q_grad_norm             | 2596.8916 |
| qfs_loss                | 46.039886 |
| qs_abs_difference       | 8.15      |
| qs_difference           | 3.86      |
| qs_mean                 | 338.3073  |
| time_elapsed            | 29278     |
| total timesteps         | 379717    |
| train_time              | 9272      |
| update_time             | 18735     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.15e+03  |
| eval_abs_qs_difference  | 61.184986 |
| eval_discount_q         | 278       |
| eval_ep_rewmean         | 1.02e+03  |
| eval_eplenmean          | 261       |
| eval_qs                 | 333.578   |
| eval_qs_difference      | 57.7      |
| eval_time_elapsed       | 6         |
| total timesteps         | 380001    |
---------------------------------------
---------------------------------------
| act_time                | 267       |
| current_lr              | 0.0003    |
| discount_q              | 0.00418   |
| env_time                | 584       |
| ep_rewmean              | 996       |
| episodes                | 2484      |
| eplenmean               | 253       |
| fps                     | 12        |
| mean 100 episode reward | 996       |
| n_updates               | 712400    |
| q_grad_norm             | 1731.6306 |
| qfs_loss                | 36.259415 |
| qs_abs_difference       | 19.4      |
| qs_difference           | 19.1      |
| qs_mean                 | 323.74426 |
| time_elapsed            | 29391     |
| total timesteps         | 381116    |
| train_time              | 9308      |
| update_time             | 18802     |
---------------------------------------
---------------------------------------
| act_time                | 268       |
| current_lr              | 0.0003    |
| discount_q              | 0.0292    |
| env_time                | 586       |
| ep_rewmean              | 1e+03     |
| episodes                | 2488      |
| eplenmean               | 255       |
| fps                     | 12        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 714800    |
| q_grad_norm             | 2019.2928 |
| qfs_loss                | 31.939821 |
| qs_abs_difference       | 10.1      |
| qs_difference           | 8.1       |
| qs_mean                 | 320.29056 |
| time_elapsed            | 29484     |
| total timesteps         | 382318    |
| train_time              | 9340      |
| update_time             | 18860     |
---------------------------------------
---------------------------------------
| act_time                | 268       |
| current_lr              | 0.0003    |
| discount_q              | 0.317     |
| env_time                | 588       |
| ep_rewmean              | 999       |
| episodes                | 2492      |
| eplenmean               | 254       |
| fps                     | 12        |
| mean 100 episode reward | 999       |
| n_updates               | 716600    |
| q_grad_norm             | 1585.2386 |
| qfs_loss                | 26.435204 |
| qs_abs_difference       | 28.9      |
| qs_difference           | 28.5      |
| qs_mean                 | 329.13892 |
| time_elapsed            | 29554     |
| total timesteps         | 383299    |
| train_time              | 9363      |
| update_time             | 18904     |
---------------------------------------
---------------------------------------
| act_time                | 269       |
| current_lr              | 0.0003    |
| discount_q              | 0.00447   |
| env_time                | 590       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2496      |
| eplenmean               | 261       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 719600    |
| q_grad_norm             | 2455.1443 |
| qfs_loss                | 43.399483 |
| qs_abs_difference       | 22        |
| qs_difference           | 20.6      |
| qs_mean                 | 331.5137  |
| time_elapsed            | 29669     |
| total timesteps         | 384711    |
| train_time              | 9402      |
| update_time             | 18977     |
---------------------------------------
---------------------------------------
| act_time                | 270       |
| current_lr              | 0.0003    |
| discount_q              | 0.126     |
| env_time                | 592       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2500      |
| eplenmean               | 262       |
| fps                     | 12        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 721800    |
| q_grad_norm             | 1803.0153 |
| qfs_loss                | 34.74031  |
| qs_abs_difference       | 8.61      |
| qs_difference           | 7.38      |
| qs_mean                 | 334.34164 |
| time_elapsed            | 29754     |
| total timesteps         | 385811    |
| train_time              | 9430      |
| update_time             | 19031     |
---------------------------------------
---------------------------------------
| act_time                | 271       |
| current_lr              | 0.0003    |
| discount_q              | 0.00544   |
| env_time                | 594       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2504      |
| eplenmean               | 264       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 724200    |
| q_grad_norm             | 3417.5154 |
| qfs_loss                | 47.853638 |
| qs_abs_difference       | 28.6      |
| qs_difference           | 24.5      |
| qs_mean                 | 276.30112 |
| time_elapsed            | 29846     |
| total timesteps         | 387077    |
| train_time              | 9461      |
| update_time             | 19088     |
---------------------------------------
---------------------------------------
| act_time                | 272       |
| current_lr              | 0.0003    |
| discount_q              | 0.0818    |
| env_time                | 596       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2508      |
| eplenmean               | 263       |
| fps                     | 12        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 726800    |
| q_grad_norm             | 2015.2677 |
| qfs_loss                | 33.88591  |
| qs_abs_difference       | 16.1      |
| qs_difference           | 15.8      |
| qs_mean                 | 357.80017 |
| time_elapsed            | 29947     |
| total timesteps         | 388397    |
| train_time              | 9495      |
| update_time             | 19152     |
---------------------------------------
---------------------------------------
| act_time                | 273       |
| current_lr              | 0.0003    |
| discount_q              | 0.0666    |
| env_time                | 598       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2512      |
| eplenmean               | 265       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 729400    |
| q_grad_norm             | 3263.1282 |
| qfs_loss                | 61.151554 |
| qs_abs_difference       | 14.9      |
| qs_difference           | 14.6      |
| qs_mean                 | 349.65887 |
| time_elapsed            | 30046     |
| total timesteps         | 389625    |
| train_time              | 9529      |
| update_time             | 19215     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.1e+03   |
| eval_abs_qs_difference  | 61.956738 |
| eval_discount_q         | 233       |
| eval_ep_rewmean         | 592       |
| eval_eplenmean          | 168       |
| eval_qs                 | 270.8114  |
| eval_qs_difference      | 59.7      |
| eval_time_elapsed       | 4         |
| total timesteps         | 390001    |
---------------------------------------
---------------------------------------
| act_time                | 274       |
| current_lr              | 0.0003    |
| discount_q              | 0.0224    |
| env_time                | 600       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2516      |
| eplenmean               | 266       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 731800    |
| q_grad_norm             | 1757.5507 |
| qfs_loss                | 32.775467 |
| qs_abs_difference       | 14.3      |
| qs_difference           | 13.5      |
| qs_mean                 | 321.8134  |
| time_elapsed            | 30143     |
| total timesteps         | 390837    |
| train_time              | 9560      |
| update_time             | 19273     |
---------------------------------------
---------------------------------------
| act_time                | 275       |
| current_lr              | 0.0003    |
| discount_q              | 0.013     |
| env_time                | 602       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2520      |
| eplenmean               | 271       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 735000    |
| q_grad_norm             | 2795.3772 |
| qfs_loss                | 53.44221  |
| qs_abs_difference       | 23.3      |
| qs_difference           | 23.3      |
| qs_mean                 | 361.33002 |
| time_elapsed            | 30265     |
| total timesteps         | 392404    |
| train_time              | 9601      |
| update_time             | 19349     |
---------------------------------------
---------------------------------------
| act_time                | 276       |
| current_lr              | 0.0003    |
| discount_q              | 0.0217    |
| env_time                | 604       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2524      |
| eplenmean               | 273       |
| fps                     | 12        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 737400    |
| q_grad_norm             | 2377.392  |
| qfs_loss                | 45.490685 |
| qs_abs_difference       | 5.32      |
| qs_difference           | 3.37      |
| qs_mean                 | 333.10538 |
| time_elapsed            | 30358     |
| total timesteps         | 393662    |
| train_time              | 9632      |
| update_time             | 19408     |
---------------------------------------
---------------------------------------
| act_time                | 276       |
| current_lr              | 0.0003    |
| discount_q              | 0.00958   |
| env_time                | 605       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2528      |
| eplenmean               | 269       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 738800    |
| q_grad_norm             | 2660.01   |
| qfs_loss                | 43.13801  |
| qs_abs_difference       | 306       |
| qs_difference           | 306       |
| qs_mean                 | 313.59082 |
| time_elapsed            | 30417     |
| total timesteps         | 394385    |
| train_time              | 9650      |
| update_time             | 19448     |
---------------------------------------
---------------------------------------
| act_time                | 277       |
| current_lr              | 0.0003    |
| discount_q              | 0.529     |
| env_time                | 606       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2532      |
| eplenmean               | 267       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 740800    |
| q_grad_norm             | 2218.3699 |
| qfs_loss                | 34.923283 |
| qs_abs_difference       | 31.3      |
| qs_difference           | 30.6      |
| qs_mean                 | 329.18665 |
| time_elapsed            | 30497     |
| total timesteps         | 395307    |
| train_time              | 9677      |
| update_time             | 19497     |
---------------------------------------
---------------------------------------
| act_time                | 278       |
| current_lr              | 0.0003    |
| discount_q              | 0.0168    |
| env_time                | 609       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2536      |
| eplenmean               | 269       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 743400    |
| q_grad_norm             | 2187.8044 |
| qfs_loss                | 41.911552 |
| qs_abs_difference       | 8.67      |
| qs_difference           | 5.76      |
| qs_mean                 | 353.1175  |
| time_elapsed            | 30599     |
| total timesteps         | 396697    |
| train_time              | 9713      |
| update_time             | 19561     |
---------------------------------------
---------------------------------------
| act_time                | 279       |
| current_lr              | 0.0003    |
| discount_q              | 0.0126    |
| env_time                | 611       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2540      |
| eplenmean               | 278       |
| fps                     | 12        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 746200    |
| q_grad_norm             | 2724.2678 |
| qfs_loss                | 47.504215 |
| qs_abs_difference       | 15.7      |
| qs_difference           | 14.4      |
| qs_mean                 | 336.9398  |
| time_elapsed            | 30710     |
| total timesteps         | 398045    |
| train_time              | 9748      |
| update_time             | 19633     |
---------------------------------------
---------------------------------------
| act_time                | 280       |
| current_lr              | 0.0003    |
| discount_q              | 0.142     |
| env_time                | 612       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2544      |
| eplenmean               | 290       |
| fps                     | 12        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 748800    |
| q_grad_norm             | 1986.764  |
| qfs_loss                | 33.137985 |
| qs_abs_difference       | 9.82      |
| qs_difference           | 9.59      |
| qs_mean                 | 363.44284 |
| time_elapsed            | 30815     |
| total timesteps         | 399344    |
| train_time              | 9780      |
| update_time             | 19702     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.05e+03  |
| eval_abs_qs_difference  | 46.495975 |
| eval_discount_q         | 245       |
| eval_ep_rewmean         | 625       |
| eval_eplenmean          | 171       |
| eval_qs                 | 265.0177  |
| eval_qs_difference      | 42        |
| eval_time_elapsed       | 3         |
| total timesteps         | 400001    |
---------------------------------------
total runtime: 30880.27321910858s
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 1, 'comment': 'hopper_gem+tbp_1', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_1
max_step:  1000
Box(-inf, inf, (11,), float64) Box(-1.0, 1.0, (3,), float32)
max_step:  1000
seed=1, logdir=./log_gem/mujoco/gem+tbp/hopper_gem+tbp_1
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/run/train.py:30: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-05-04 23:28:33.775016: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-05-04 23:28:33.808608: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz
2022-05-04 23:28:33.809437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c50ddf0290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-05-04 23:28:33.809489: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:98: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/policies.py:283: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:138: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:203: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:226: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:251: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:261: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:264: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

GEM Agent Here
TD3 Update Memory Many Agent here
here (?, 1)
model building finished
----------------------------------------
| eval mean 100 episod... | 4          |
| eval_abs_qs_difference  | 2.794242   |
| eval_discount_q         | 3.9        |
| eval_ep_rewmean         | 3.99       |
| eval_eplenmean          | 7.45       |
| eval_qs                 | -1.1445915 |
| eval_qs_difference      | -2.79      |
| eval_time_elapsed       | 0          |
| total timesteps         | 1          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.63        |
| env_time                | 0           |
| ep_rewmean              | 16.5        |
| episodes                | 4           |
| eplenmean               | 24.2        |
| fps                     | 102         |
| mean 100 episode reward | 16.5        |
| n_updates               | 0           |
| qs_abs_difference       | 3.63        |
| qs_difference           | -3.63       |
| qs_mean                 | -0.40539163 |
| time_elapsed            | 0           |
| total timesteps         | 97          |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.92        |
| env_time                | 0           |
| ep_rewmean              | 14          |
| episodes                | 8           |
| eplenmean               | 23.4        |
| fps                     | 132         |
| mean 100 episode reward | 14          |
| n_updates               | 0           |
| qs_abs_difference       | 6.13        |
| qs_difference           | -6.13       |
| qs_mean                 | -0.74884766 |
| time_elapsed            | 1           |
| total timesteps         | 187         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 1.67        |
| env_time                | 0           |
| ep_rewmean              | 17.7        |
| episodes                | 12          |
| eplenmean               | 24.9        |
| fps                     | 180         |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 1.55        |
| qs_difference           | -0.827      |
| qs_mean                 | -0.21636021 |
| time_elapsed            | 1           |
| total timesteps         | 299         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 11.8       |
| env_time                | 0          |
| ep_rewmean              | 17.9       |
| episodes                | 16         |
| eplenmean               | 24.5       |
| fps                     | 204        |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 14.3       |
| qs_difference           | -14.3      |
| qs_mean                 | -0.6225972 |
| time_elapsed            | 1          |
| total timesteps         | 392        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.27       |
| env_time                | 0          |
| ep_rewmean              | 17.1       |
| episodes                | 20         |
| eplenmean               | 24.4       |
| fps                     | 225        |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 8.03       |
| qs_difference           | -8.03      |
| qs_mean                 | -0.5218938 |
| time_elapsed            | 2          |
| total timesteps         | 487        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.38       |
| env_time                | 1          |
| ep_rewmean              | 16.3       |
| episodes                | 24         |
| eplenmean               | 23.7       |
| fps                     | 235        |
| mean 100 episode reward | 16.3       |
| n_updates               | 0          |
| qs_abs_difference       | 7.03       |
| qs_difference           | -7.03      |
| qs_mean                 | -0.5914198 |
| time_elapsed            | 2          |
| total timesteps         | 569        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.66       |
| env_time                | 1          |
| ep_rewmean              | 16.2       |
| episodes                | 28         |
| eplenmean               | 23.8       |
| fps                     | 246        |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 2.48       |
| qs_difference           | -2.47      |
| qs_mean                 | -0.4179953 |
| time_elapsed            | 2          |
| total timesteps         | 666        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 12.2       |
| env_time                | 1          |
| ep_rewmean              | 15.8       |
| episodes                | 32         |
| eplenmean               | 23.2       |
| fps                     | 254        |
| mean 100 episode reward | 15.8       |
| n_updates               | 0          |
| qs_abs_difference       | 11.8       |
| qs_difference           | -11.8      |
| qs_mean                 | -0.5274129 |
| time_elapsed            | 2          |
| total timesteps         | 743        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.77        |
| env_time                | 1           |
| ep_rewmean              | 15.6        |
| episodes                | 36          |
| eplenmean               | 22.7        |
| fps                     | 254         |
| mean 100 episode reward | 15.6        |
| n_updates               | 0           |
| qs_abs_difference       | 2.45        |
| qs_difference           | -2          |
| qs_mean                 | -0.45669273 |
| time_elapsed            | 3           |
| total timesteps         | 816         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.84        |
| env_time                | 1           |
| ep_rewmean              | 15.2        |
| episodes                | 40          |
| eplenmean               | 22.4        |
| fps                     | 264         |
| mean 100 episode reward | 15.2        |
| n_updates               | 0           |
| qs_abs_difference       | 6.35        |
| qs_difference           | -6.35       |
| qs_mean                 | -0.55426246 |
| time_elapsed            | 3           |
| total timesteps         | 897         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.33        |
| env_time                | 1           |
| ep_rewmean              | 15.3        |
| episodes                | 44          |
| eplenmean               | 22          |
| fps                     | 260         |
| mean 100 episode reward | 15.3        |
| n_updates               | 0           |
| qs_abs_difference       | 8.19        |
| qs_difference           | -8.19       |
| qs_mean                 | -0.65994966 |
| time_elapsed            | 3           |
| total timesteps         | 968         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.45        |
| env_time                | 1           |
| ep_rewmean              | 15.2        |
| episodes                | 48          |
| eplenmean               | 22.5        |
| fps                     | 263         |
| mean 100 episode reward | 15.2        |
| n_updates               | 0           |
| qs_abs_difference       | 5.91        |
| qs_difference           | -5.91       |
| qs_mean                 | -0.55404216 |
| time_elapsed            | 4           |
| total timesteps         | 1078        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.79       |
| env_time                | 1          |
| ep_rewmean              | 15.1       |
| episodes                | 52         |
| eplenmean               | 22.3       |
| fps                     | 262        |
| mean 100 episode reward | 15.1       |
| n_updates               | 0          |
| qs_abs_difference       | 3.36       |
| qs_difference           | -3.36      |
| qs_mean                 | -0.5004859 |
| time_elapsed            | 4          |
| total timesteps         | 1161       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 13.5        |
| env_time                | 2           |
| ep_rewmean              | 15.2        |
| episodes                | 56          |
| eplenmean               | 22.7        |
| fps                     | 261         |
| mean 100 episode reward | 15.2        |
| n_updates               | 0           |
| qs_abs_difference       | 12.6        |
| qs_difference           | -12.6       |
| qs_mean                 | -0.52596223 |
| time_elapsed            | 4           |
| total timesteps         | 1269        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.62        |
| env_time                | 2           |
| ep_rewmean              | 15.1        |
| episodes                | 60          |
| eplenmean               | 22.3        |
| fps                     | 256         |
| mean 100 episode reward | 15.1        |
| n_updates               | 0           |
| qs_abs_difference       | 4.85        |
| qs_difference           | -4.85       |
| qs_mean                 | -0.48045218 |
| time_elapsed            | 5           |
| total timesteps         | 1340        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.14        |
| env_time                | 2           |
| ep_rewmean              | 15.6        |
| episodes                | 64          |
| eplenmean               | 22.5        |
| fps                     | 254         |
| mean 100 episode reward | 15.6        |
| n_updates               | 0           |
| qs_abs_difference       | 7.06        |
| qs_difference           | -7.06       |
| qs_mean                 | -0.60617554 |
| time_elapsed            | 5           |
| total timesteps         | 1440        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 2.55       |
| env_time                | 2          |
| ep_rewmean              | 16.6       |
| episodes                | 68         |
| eplenmean               | 23.1       |
| fps                     | 253        |
| mean 100 episode reward | 16.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.29       |
| qs_difference           | -5.29      |
| qs_mean                 | -0.8119919 |
| time_elapsed            | 6          |
| total timesteps         | 1571       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.8         |
| env_time                | 2           |
| ep_rewmean              | 16.5        |
| episodes                | 72          |
| eplenmean               | 22.8        |
| fps                     | 249         |
| mean 100 episode reward | 16.5        |
| n_updates               | 0           |
| qs_abs_difference       | 5.6         |
| qs_difference           | -5.6        |
| qs_mean                 | -0.80212325 |
| time_elapsed            | 6           |
| total timesteps         | 1642        |
| train_time              | 0           |
| update_time             | 2           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.1        |
| env_time                | 2          |
| ep_rewmean              | 16.7       |
| episodes                | 76         |
| eplenmean               | 22.9       |
| fps                     | 247        |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.64       |
| qs_difference           | -3.64      |
| qs_mean                 | -0.5739442 |
| time_elapsed            | 7          |
| total timesteps         | 1740       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.43       |
| env_time                | 2          |
| ep_rewmean              | 16.7       |
| episodes                | 80         |
| eplenmean               | 22.9       |
| fps                     | 242        |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 4.78       |
| qs_difference           | -4.78      |
| qs_mean                 | -0.7489146 |
| time_elapsed            | 7          |
| total timesteps         | 1829       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 8.76      |
| env_time                | 3         |
| ep_rewmean              | 17.3      |
| episodes                | 84        |
| eplenmean               | 23        |
| fps                     | 241       |
| mean 100 episode reward | 17.3      |
| n_updates               | 0         |
| qs_abs_difference       | 9.64      |
| qs_difference           | -9.64     |
| qs_mean                 | -0.646459 |
| time_elapsed            | 8         |
| total timesteps         | 1933      |
| train_time              | 0         |
| update_time             | 3         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.17       |
| env_time                | 3          |
| ep_rewmean              | 17.5       |
| episodes                | 88         |
| eplenmean               | 23.2       |
| fps                     | 239        |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 6.17       |
| qs_difference           | -6.17      |
| qs_mean                 | -0.5864463 |
| time_elapsed            | 8          |
| total timesteps         | 2039       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.06       |
| env_time                | 3          |
| ep_rewmean              | 17.3       |
| episodes                | 92         |
| eplenmean               | 23         |
| fps                     | 234        |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 5.99       |
| qs_difference           | -5.99      |
| qs_mean                 | -0.8757317 |
| time_elapsed            | 9          |
| total timesteps         | 2119       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 10.5       |
| env_time                | 3          |
| ep_rewmean              | 17.8       |
| episodes                | 96         |
| eplenmean               | 23.4       |
| fps                     | 233        |
| mean 100 episode reward | 17.8       |
| n_updates               | 0          |
| qs_abs_difference       | 11.2       |
| qs_difference           | -11.2      |
| qs_mean                 | -0.5204112 |
| time_elapsed            | 9          |
| total timesteps         | 2242       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 18.5       |
| env_time                | 3          |
| ep_rewmean              | 17.8       |
| episodes                | 100        |
| eplenmean               | 23.3       |
| fps                     | 228        |
| mean 100 episode reward | 17.8       |
| n_updates               | 0          |
| qs_abs_difference       | 15.5       |
| qs_difference           | -15.5      |
| qs_mean                 | -0.5193583 |
| time_elapsed            | 10         |
| total timesteps         | 2326       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.74       |
| env_time                | 3          |
| ep_rewmean              | 17.5       |
| episodes                | 104        |
| eplenmean               | 22.9       |
| fps                     | 231        |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.32       |
| qs_difference           | -4.32      |
| qs_mean                 | -0.4401888 |
| time_elapsed            | 10         |
| total timesteps         | 2389       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 14.9       |
| env_time                | 3          |
| ep_rewmean              | 17.9       |
| episodes                | 108        |
| eplenmean               | 23.1       |
| fps                     | 220        |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 16.6       |
| qs_difference           | -16.6      |
| qs_mean                 | -0.5779292 |
| time_elapsed            | 11         |
| total timesteps         | 2502       |
| train_time              | 0          |
| update_time             | 5          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.73        |
| env_time                | 4           |
| ep_rewmean              | 18.6        |
| episodes                | 112         |
| eplenmean               | 23.4        |
| fps                     | 219         |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 13.7        |
| qs_difference           | -13.7       |
| qs_mean                 | -0.84597206 |
| time_elapsed            | 12          |
| total timesteps         | 2639        |
| train_time              | 0           |
| update_time             | 5           |
-----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 7.35      |
| env_time                | 4         |
| ep_rewmean              | 18.5      |
| episodes                | 116       |
| eplenmean               | 23.3      |
| fps                     | 215       |
| mean 100 episode reward | 18.5      |
| n_updates               | 0         |
| qs_abs_difference       | 7.71      |
| qs_difference           | -7.71     |
| qs_mean                 | -0.646826 |
| time_elapsed            | 12        |
| total timesteps         | 2723      |
| train_time              | 0         |
| update_time             | 6         |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 9.14        |
| env_time                | 4           |
| ep_rewmean              | 19.1        |
| episodes                | 120         |
| eplenmean               | 23.5        |
| fps                     | 212         |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 12.1        |
| qs_difference           | -12.1       |
| qs_mean                 | -0.40571314 |
| time_elapsed            | 13          |
| total timesteps         | 2841        |
| train_time              | 0           |
| update_time             | 6           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 21.2        |
| env_time                | 4           |
| ep_rewmean              | 19.7        |
| episodes                | 124         |
| eplenmean               | 23.8        |
| fps                     | 209         |
| mean 100 episode reward | 19.7        |
| n_updates               | 0           |
| qs_abs_difference       | 24.4        |
| qs_difference           | -24.4       |
| qs_mean                 | -0.76569784 |
| time_elapsed            | 14          |
| total timesteps         | 2952        |
| train_time              | 0           |
| update_time             | 7           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.01        |
| env_time                | 4           |
| ep_rewmean              | 19.7        |
| episodes                | 128         |
| eplenmean               | 23.8        |
| fps                     | 206         |
| mean 100 episode reward | 19.7        |
| n_updates               | 0           |
| qs_abs_difference       | 2.1         |
| qs_difference           | -2.01       |
| qs_mean                 | -0.51587915 |
| time_elapsed            | 14          |
| total timesteps         | 3048        |
| train_time              | 0           |
| update_time             | 7           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.58        |
| env_time                | 5           |
| ep_rewmean              | 19.8        |
| episodes                | 132         |
| eplenmean               | 24          |
| fps                     | 203         |
| mean 100 episode reward | 19.8        |
| n_updates               | 0           |
| qs_abs_difference       | 4.41        |
| qs_difference           | -3.66       |
| qs_mean                 | -0.36507326 |
| time_elapsed            | 15          |
| total timesteps         | 3142        |
| train_time              | 0           |
| update_time             | 7           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 9.32       |
| env_time                | 5          |
| ep_rewmean              | 19.7       |
| episodes                | 136        |
| eplenmean               | 24         |
| fps                     | 199        |
| mean 100 episode reward | 19.7       |
| n_updates               | 0          |
| qs_abs_difference       | 7.98       |
| qs_difference           | -7.98      |
| qs_mean                 | -0.6243866 |
| time_elapsed            | 16         |
| total timesteps         | 3215       |
| train_time              | 0          |
| update_time             | 8          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.32        |
| env_time                | 5           |
| ep_rewmean              | 19.7        |
| episodes                | 140         |
| eplenmean               | 23.7        |
| fps                     | 202         |
| mean 100 episode reward | 19.7        |
| n_updates               | 0           |
| qs_abs_difference       | 7.15        |
| qs_difference           | -7.15       |
| qs_mean                 | -0.72895575 |
| time_elapsed            | 16          |
| total timesteps         | 3271        |
| train_time              | 0           |
| update_time             | 8           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.58       |
| env_time                | 5          |
| ep_rewmean              | 19.8       |
| episodes                | 144        |
| eplenmean               | 23.9       |
| fps                     | 199        |
| mean 100 episode reward | 19.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.93       |
| qs_difference           | -4.93      |
| qs_mean                 | -0.8848623 |
| time_elapsed            | 16         |
| total timesteps         | 3358       |
| train_time              | 0          |
| update_time             | 8          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.52        |
| env_time                | 5           |
| ep_rewmean              | 19.6        |
| episodes                | 148         |
| eplenmean               | 23.4        |
| fps                     | 195         |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 1.83        |
| qs_difference           | -1.55       |
| qs_mean                 | -0.14721848 |
| time_elapsed            | 17          |
| total timesteps         | 3422        |
| train_time              | 0           |
| update_time             | 9           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.7         |
| env_time                | 5           |
| ep_rewmean              | 19.7        |
| episodes                | 152         |
| eplenmean               | 23.5        |
| fps                     | 192         |
| mean 100 episode reward | 19.7        |
| n_updates               | 0           |
| qs_abs_difference       | 7.11        |
| qs_difference           | -7.11       |
| qs_mean                 | -0.56517214 |
| time_elapsed            | 18          |
| total timesteps         | 3507        |
| train_time              | 0           |
| update_time             | 10          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.71       |
| env_time                | 5          |
| ep_rewmean              | 19.5       |
| episodes                | 156        |
| eplenmean               | 23.2       |
| fps                     | 194        |
| mean 100 episode reward | 19.5       |
| n_updates               | 0          |
| qs_abs_difference       | 2.6        |
| qs_difference           | -2.6       |
| qs_mean                 | -0.4080957 |
| time_elapsed            | 18         |
| total timesteps         | 3586       |
| train_time              | 0          |
| update_time             | 10         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.97       |
| env_time                | 5          |
| ep_rewmean              | 19.4       |
| episodes                | 160        |
| eplenmean               | 23.3       |
| fps                     | 191        |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 6.34       |
| qs_difference           | -6.34      |
| qs_mean                 | -0.5593513 |
| time_elapsed            | 19         |
| total timesteps         | 3667       |
| train_time              | 0          |
| update_time             | 10         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.75       |
| env_time                | 5          |
| ep_rewmean              | 18.9       |
| episodes                | 164        |
| eplenmean               | 22.8       |
| fps                     | 187        |
| mean 100 episode reward | 18.9       |
| n_updates               | 0          |
| qs_abs_difference       | 2.71       |
| qs_difference           | -2.71      |
| qs_mean                 | -0.5344957 |
| time_elapsed            | 19         |
| total timesteps         | 3717       |
| train_time              | 0          |
| update_time             | 11         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.89        |
| env_time                | 5           |
| ep_rewmean              | 18.4        |
| episodes                | 168         |
| eplenmean               | 22.5        |
| fps                     | 185         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 12.5        |
| qs_difference           | -12.5       |
| qs_mean                 | -0.73579293 |
| time_elapsed            | 20          |
| total timesteps         | 3824        |
| train_time              | 0           |
| update_time             | 11          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.68       |
| env_time                | 6          |
| ep_rewmean              | 18.5       |
| episodes                | 172        |
| eplenmean               | 22.8       |
| fps                     | 182        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.11       |
| qs_difference           | -4.11      |
| qs_mean                 | -0.3604145 |
| time_elapsed            | 21         |
| total timesteps         | 3925       |
| train_time              | 0          |
| update_time             | 12         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.06        |
| env_time                | 6           |
| ep_rewmean              | 18.8        |
| episodes                | 176         |
| eplenmean               | 23          |
| fps                     | 180         |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 2.9         |
| qs_difference           | -2.44       |
| qs_mean                 | -0.25121877 |
| time_elapsed            | 22          |
| total timesteps         | 4039        |
| train_time              | 0           |
| update_time             | 12          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.97       |
| env_time                | 6          |
| ep_rewmean              | 18.7       |
| episodes                | 180        |
| eplenmean               | 23         |
| fps                     | 177        |
| mean 100 episode reward | 18.7       |
| n_updates               | 0          |
| qs_abs_difference       | 5.32       |
| qs_difference           | -5.32      |
| qs_mean                 | -0.5915356 |
| time_elapsed            | 23         |
| total timesteps         | 4132       |
| train_time              | 0          |
| update_time             | 13         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.77        |
| env_time                | 6           |
| ep_rewmean              | 18.2        |
| episodes                | 184         |
| eplenmean               | 22.8        |
| fps                     | 174         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 5.45        |
| qs_difference           | -5.45       |
| qs_mean                 | -0.85498077 |
| time_elapsed            | 24          |
| total timesteps         | 4210        |
| train_time              | 0           |
| update_time             | 14          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.66       |
| env_time                | 6          |
| ep_rewmean              | 17.9       |
| episodes                | 188        |
| eplenmean               | 22.6       |
| fps                     | 177        |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 2.89       |
| qs_difference           | -2.71      |
| qs_mean                 | -0.5499122 |
| time_elapsed            | 24         |
| total timesteps         | 4296       |
| train_time              | 0          |
| update_time             | 14         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.74       |
| env_time                | 6          |
| ep_rewmean              | 18.1       |
| episodes                | 192        |
| eplenmean               | 22.6       |
| fps                     | 175        |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 8.71       |
| qs_difference           | -8.71      |
| qs_mean                 | -0.7095113 |
| time_elapsed            | 25         |
| total timesteps         | 4382       |
| train_time              | 0          |
| update_time             | 14         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.6         |
| env_time                | 6           |
| ep_rewmean              | 17.9        |
| episodes                | 196         |
| eplenmean               | 22.6        |
| fps                     | 168         |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 2.02        |
| qs_difference           | -1.58       |
| qs_mean                 | -0.36325252 |
| time_elapsed            | 26          |
| total timesteps         | 4500        |
| train_time              | 0           |
| update_time             | 16          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.81        |
| env_time                | 7           |
| ep_rewmean              | 17.6        |
| episodes                | 200         |
| eplenmean               | 22.3        |
| fps                     | 170         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 3.55        |
| qs_difference           | -3.55       |
| qs_mean                 | -0.49580088 |
| time_elapsed            | 26          |
| total timesteps         | 4560        |
| train_time              | 0           |
| update_time             | 16          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.51       |
| env_time                | 7          |
| ep_rewmean              | 17.9       |
| episodes                | 204        |
| eplenmean               | 22.7       |
| fps                     | 168        |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 4.26       |
| qs_difference           | -3.51      |
| qs_mean                 | -0.4548546 |
| time_elapsed            | 27         |
| total timesteps         | 4657       |
| train_time              | 0          |
| update_time             | 16         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 9.29       |
| env_time                | 7          |
| ep_rewmean              | 17.7       |
| episodes                | 208        |
| eplenmean               | 22.4       |
| fps                     | 166        |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 10.2       |
| qs_difference           | -10.2      |
| qs_mean                 | -0.6589744 |
| time_elapsed            | 28         |
| total timesteps         | 4740       |
| train_time              | 0          |
| update_time             | 17         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.81        |
| env_time                | 7           |
| ep_rewmean              | 16.8        |
| episodes                | 212         |
| eplenmean               | 22          |
| fps                     | 164         |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.93        |
| qs_difference           | -5.93       |
| qs_mean                 | -0.49366826 |
| time_elapsed            | 29          |
| total timesteps         | 4839        |
| train_time              | 0           |
| update_time             | 18          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 9.45       |
| env_time                | 7          |
| ep_rewmean              | 16.8       |
| episodes                | 216        |
| eplenmean               | 21.9       |
| fps                     | 162        |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 6.66       |
| qs_difference           | -6.66      |
| qs_mean                 | -0.5499273 |
| time_elapsed            | 30         |
| total timesteps         | 4918       |
| train_time              | 0          |
| update_time             | 19         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 2.94        |
| env_time                | 7           |
| ep_rewmean              | 16.6        |
| episodes                | 220         |
| eplenmean               | 21.7        |
| fps                     | 161         |
| mean 100 episode reward | 16.6        |
| n_updates               | 0           |
| qs_abs_difference       | 4.56        |
| qs_difference           | -4.56       |
| qs_mean                 | -0.95465404 |
| time_elapsed            | 31          |
| total timesteps         | 5014        |
| train_time              | 0           |
| update_time             | 19          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 50.6       |
| env_time                | 7          |
| ep_rewmean              | 17.6       |
| episodes                | 224        |
| eplenmean               | 22.1       |
| fps                     | 160        |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 65         |
| qs_difference           | -65        |
| qs_mean                 | -0.5658708 |
| time_elapsed            | 32         |
| total timesteps         | 5158       |
| train_time              | 0          |
| update_time             | 20         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.72       |
| env_time                | 7          |
| ep_rewmean              | 18.1       |
| episodes                | 228        |
| eplenmean               | 22.1       |
| fps                     | 158        |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 6.41       |
| qs_difference           | -6.41      |
| qs_mean                 | -0.6554665 |
| time_elapsed            | 33         |
| total timesteps         | 5253       |
| train_time              | 0          |
| update_time             | 21         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.71       |
| env_time                | 8          |
| ep_rewmean              | 18.3       |
| episodes                | 232        |
| eplenmean               | 22.1       |
| fps                     | 156        |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 5.45       |
| qs_difference           | -5.45      |
| qs_mean                 | -0.7238987 |
| time_elapsed            | 34         |
| total timesteps         | 5354       |
| train_time              | 0          |
| update_time             | 22         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.08        |
| env_time                | 8           |
| ep_rewmean              | 18.8        |
| episodes                | 236         |
| eplenmean               | 22.4        |
| fps                     | 155         |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 7.94        |
| qs_difference           | -7.94       |
| qs_mean                 | -0.74288875 |
| time_elapsed            | 35          |
| total timesteps         | 5451        |
| train_time              | 0           |
| update_time             | 23          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.94       |
| env_time                | 8          |
| ep_rewmean              | 19.1       |
| episodes                | 240        |
| eplenmean               | 22.6       |
| fps                     | 153        |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 7.26       |
| qs_difference           | -7.26      |
| qs_mean                 | -0.6592624 |
| time_elapsed            | 36         |
| total timesteps         | 5526       |
| train_time              | 0          |
| update_time             | 23         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.85        |
| env_time                | 8           |
| ep_rewmean              | 19          |
| episodes                | 244         |
| eplenmean               | 22.6        |
| fps                     | 151         |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 7.22        |
| qs_difference           | -7.22       |
| qs_mean                 | -0.62686884 |
| time_elapsed            | 37          |
| total timesteps         | 5619        |
| train_time              | 0           |
| update_time             | 24          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.74       |
| env_time                | 8          |
| ep_rewmean              | 19.1       |
| episodes                | 248        |
| eplenmean               | 22.9       |
| fps                     | 150        |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.19       |
| qs_difference           | -5.19      |
| qs_mean                 | -0.5192394 |
| time_elapsed            | 38         |
| total timesteps         | 5710       |
| train_time              | 0          |
| update_time             | 25         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.7         |
| env_time                | 8           |
| ep_rewmean              | 19.2        |
| episodes                | 252         |
| eplenmean               | 23          |
| fps                     | 148         |
| mean 100 episode reward | 19.2        |
| n_updates               | 0           |
| qs_abs_difference       | 3.71        |
| qs_difference           | -3.39       |
| qs_mean                 | -0.51601017 |
| time_elapsed            | 39          |
| total timesteps         | 5805        |
| train_time              | 0           |
| update_time             | 26          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.19        |
| env_time                | 8           |
| ep_rewmean              | 20.2        |
| episodes                | 256         |
| eplenmean               | 23.3        |
| fps                     | 147         |
| mean 100 episode reward | 20.2        |
| n_updates               | 0           |
| qs_abs_difference       | 7.59        |
| qs_difference           | -7.59       |
| qs_mean                 | -0.59744644 |
| time_elapsed            | 40          |
| total timesteps         | 5919        |
| train_time              | 0           |
| update_time             | 27          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 16.7        |
| env_time                | 8           |
| ep_rewmean              | 20.2        |
| episodes                | 260         |
| eplenmean               | 23.1        |
| fps                     | 148         |
| mean 100 episode reward | 20.2        |
| n_updates               | 0           |
| qs_abs_difference       | 12.3        |
| qs_difference           | -12.3       |
| qs_mean                 | -0.59990317 |
| time_elapsed            | 40          |
| total timesteps         | 5979        |
| train_time              | 0           |
| update_time             | 27          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.07        |
| env_time                | 8           |
| ep_rewmean              | 20.4        |
| episodes                | 264         |
| eplenmean               | 23.4        |
| fps                     | 146         |
| mean 100 episode reward | 20.4        |
| n_updates               | 0           |
| qs_abs_difference       | 6.39        |
| qs_difference           | -6.39       |
| qs_mean                 | -0.58268964 |
| time_elapsed            | 41          |
| total timesteps         | 6053        |
| train_time              | 0           |
| update_time             | 28          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.87       |
| env_time                | 9          |
| ep_rewmean              | 20.4       |
| episodes                | 268        |
| eplenmean               | 23.4       |
| fps                     | 145        |
| mean 100 episode reward | 20.4       |
| n_updates               | 0          |
| qs_abs_difference       | 4.49       |
| qs_difference           | -4.49      |
| qs_mean                 | -0.6743751 |
| time_elapsed            | 42         |
| total timesteps         | 6166       |
| train_time              | 0          |
| update_time             | 29         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 12.4       |
| env_time                | 9          |
| ep_rewmean              | 20.4       |
| episodes                | 272        |
| eplenmean               | 23.2       |
| fps                     | 143        |
| mean 100 episode reward | 20.4       |
| n_updates               | 0          |
| qs_abs_difference       | 11.3       |
| qs_difference           | -11.3      |
| qs_mean                 | -0.5385134 |
| time_elapsed            | 43         |
| total timesteps         | 6247       |
| train_time              | 0          |
| update_time             | 30         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.32        |
| env_time                | 9           |
| ep_rewmean              | 19.8        |
| episodes                | 276         |
| eplenmean               | 23          |
| fps                     | 141         |
| mean 100 episode reward | 19.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.53        |
| qs_difference           | -5.53       |
| qs_mean                 | -0.57270956 |
| time_elapsed            | 44          |
| total timesteps         | 6335        |
| train_time              | 0           |
| update_time             | 31          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.58        |
| env_time                | 9           |
| ep_rewmean              | 19.6        |
| episodes                | 280         |
| eplenmean               | 22.8        |
| fps                     | 140         |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 2.31        |
| qs_difference           | -2.31       |
| qs_mean                 | -0.27841645 |
| time_elapsed            | 45          |
| total timesteps         | 6411        |
| train_time              | 0           |
| update_time             | 31          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.49        |
| env_time                | 9           |
| ep_rewmean              | 19.4        |
| episodes                | 284         |
| eplenmean               | 22.6        |
| fps                     | 141         |
| mean 100 episode reward | 19.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.08        |
| qs_difference           | -3.08       |
| qs_mean                 | -0.59417236 |
| time_elapsed            | 45          |
| total timesteps         | 6472        |
| train_time              | 0           |
| update_time             | 31          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 21          |
| env_time                | 9           |
| ep_rewmean              | 19.5        |
| episodes                | 288         |
| eplenmean               | 22.6        |
| fps                     | 139         |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 15.6        |
| qs_difference           | -15.6       |
| qs_mean                 | -0.45110393 |
| time_elapsed            | 46          |
| total timesteps         | 6553        |
| train_time              | 0           |
| update_time             | 32          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.6        |
| env_time                | 9          |
| ep_rewmean              | 19.4       |
| episodes                | 292        |
| eplenmean               | 22.7       |
| fps                     | 138        |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 7.94       |
| qs_difference           | -7.94      |
| qs_mean                 | -0.8574295 |
| time_elapsed            | 48         |
| total timesteps         | 6650       |
| train_time              | 0          |
| update_time             | 33         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.74       |
| env_time                | 9          |
| ep_rewmean              | 19         |
| episodes                | 296        |
| eplenmean               | 22.2       |
| fps                     | 136        |
| mean 100 episode reward | 19         |
| n_updates               | 0          |
| qs_abs_difference       | 6.23       |
| qs_difference           | -6.23      |
| qs_mean                 | -0.8844359 |
| time_elapsed            | 49         |
| total timesteps         | 6716       |
| train_time              | 0          |
| update_time             | 34         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.55       |
| env_time                | 9          |
| ep_rewmean              | 19.2       |
| episodes                | 300        |
| eplenmean               | 22.3       |
| fps                     | 137        |
| mean 100 episode reward | 19.2       |
| n_updates               | 0          |
| qs_abs_difference       | 6.2        |
| qs_difference           | -6.2       |
| qs_mean                 | -0.6471842 |
| time_elapsed            | 49         |
| total timesteps         | 6786       |
| train_time              | 0          |
| update_time             | 34         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 16.3       |
| env_time                | 10         |
| ep_rewmean              | 19.6       |
| episodes                | 304        |
| eplenmean               | 22.4       |
| fps                     | 136        |
| mean 100 episode reward | 19.6       |
| n_updates               | 0          |
| qs_abs_difference       | 21.8       |
| qs_difference           | -21.8      |
| qs_mean                 | -0.6603824 |
| time_elapsed            | 50         |
| total timesteps         | 6894       |
| train_time              | 0          |
| update_time             | 35         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.5         |
| env_time                | 10          |
| ep_rewmean              | 20.6        |
| episodes                | 308         |
| eplenmean               | 22.9        |
| fps                     | 132         |
| mean 100 episode reward | 20.6        |
| n_updates               | 0           |
| qs_abs_difference       | 6.59        |
| qs_difference           | -6.59       |
| qs_mean                 | -0.74208814 |
| time_elapsed            | 52          |
| total timesteps         | 7029        |
| train_time              | 0           |
| update_time             | 38          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 2.01        |
| env_time                | 10          |
| ep_rewmean              | 20.8        |
| episodes                | 312         |
| eplenmean               | 23.2        |
| fps                     | 131         |
| mean 100 episode reward | 20.8        |
| n_updates               | 0           |
| qs_abs_difference       | 2.46        |
| qs_difference           | -2.46       |
| qs_mean                 | -0.32300487 |
| time_elapsed            | 54          |
| total timesteps         | 7158        |
| train_time              | 0           |
| update_time             | 39          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.39       |
| env_time                | 10         |
| ep_rewmean              | 20.9       |
| episodes                | 316        |
| eplenmean               | 23.4       |
| fps                     | 130        |
| mean 100 episode reward | 20.9       |
| n_updates               | 0          |
| qs_abs_difference       | 6.28       |
| qs_difference           | -6.28      |
| qs_mean                 | -0.6061406 |
| time_elapsed            | 55         |
| total timesteps         | 7254       |
| train_time              | 0          |
| update_time             | 40         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.8         |
| env_time                | 10          |
| ep_rewmean              | 20.5        |
| episodes                | 320         |
| eplenmean               | 23.1        |
| fps                     | 128         |
| mean 100 episode reward | 20.5        |
| n_updates               | 0           |
| qs_abs_difference       | 6.75        |
| qs_difference           | -6.75       |
| qs_mean                 | -0.64056206 |
| time_elapsed            | 56          |
| total timesteps         | 7321        |
| train_time              | 0           |
| update_time             | 41          |
-----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 14.6      |
| env_time                | 10        |
| ep_rewmean              | 19.4      |
| episodes                | 324       |
| eplenmean               | 22.6      |
| fps                     | 127       |
| mean 100 episode reward | 19.4      |
| n_updates               | 0         |
| qs_abs_difference       | 17.5      |
| qs_difference           | -17.5     |
| qs_mean                 | -0.700634 |
| time_elapsed            | 58        |
| total timesteps         | 7422      |
| train_time              | 0         |
| update_time             | 42        |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.71       |
| env_time                | 10         |
| ep_rewmean              | 18.7       |
| episodes                | 328        |
| eplenmean               | 22.4       |
| fps                     | 128        |
| mean 100 episode reward | 18.7       |
| n_updates               | 0          |
| qs_abs_difference       | 8.3        |
| qs_difference           | -8.3       |
| qs_mean                 | -0.8033855 |
| time_elapsed            | 58         |
| total timesteps         | 7491       |
| train_time              | 0          |
| update_time             | 42         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.31        |
| env_time                | 11          |
| ep_rewmean              | 19          |
| episodes                | 332         |
| eplenmean               | 22.5        |
| fps                     | 125         |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 8.81        |
| qs_difference           | -8.81       |
| qs_mean                 | -0.63216233 |
| time_elapsed            | 60          |
| total timesteps         | 7602        |
| train_time              | 0           |
| update_time             | 44          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 14.5       |
| env_time                | 11         |
| ep_rewmean              | 18.8       |
| episodes                | 336        |
| eplenmean               | 22.5       |
| fps                     | 126        |
| mean 100 episode reward | 18.8       |
| n_updates               | 0          |
| qs_abs_difference       | 14.3       |
| qs_difference           | -14.3      |
| qs_mean                 | -0.5454675 |
| time_elapsed            | 60         |
| total timesteps         | 7699       |
| train_time              | 0          |
| update_time             | 44         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.08        |
| env_time                | 11          |
| ep_rewmean              | 18.6        |
| episodes                | 340         |
| eplenmean               | 22.5        |
| fps                     | 125         |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 4.3         |
| qs_difference           | -4.3        |
| qs_mean                 | -0.64817643 |
| time_elapsed            | 62          |
| total timesteps         | 7779        |
| train_time              | 0           |
| update_time             | 45          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 12.8       |
| env_time                | 11         |
| ep_rewmean              | 18.6       |
| episodes                | 344        |
| eplenmean               | 22.6       |
| fps                     | 124        |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 11.9       |
| qs_difference           | -11.9      |
| qs_mean                 | -0.5655578 |
| time_elapsed            | 63         |
| total timesteps         | 7876       |
| train_time              | 0          |
| update_time             | 46         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.46       |
| env_time                | 11         |
| ep_rewmean              | 18.7       |
| episodes                | 348        |
| eplenmean               | 22.5       |
| fps                     | 122        |
| mean 100 episode reward | 18.7       |
| n_updates               | 0          |
| qs_abs_difference       | 5          |
| qs_difference           | -5         |
| qs_mean                 | -0.7011649 |
| time_elapsed            | 64         |
| total timesteps         | 7956       |
| train_time              | 0          |
| update_time             | 47         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.96        |
| env_time                | 11          |
| ep_rewmean              | 18.3        |
| episodes                | 352         |
| eplenmean               | 22.1        |
| fps                     | 121         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 2.56        |
| qs_difference           | -2.56       |
| qs_mean                 | -0.20866154 |
| time_elapsed            | 66          |
| total timesteps         | 8012        |
| train_time              | 0           |
| update_time             | 49          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.26        |
| env_time                | 11          |
| ep_rewmean              | 18.1        |
| episodes                | 356         |
| eplenmean               | 22          |
| fps                     | 120         |
| mean 100 episode reward | 18.1        |
| n_updates               | 0           |
| qs_abs_difference       | 6.33        |
| qs_difference           | -6.33       |
| qs_mean                 | -0.55248374 |
| time_elapsed            | 67          |
| total timesteps         | 8116        |
| train_time              | 0           |
| update_time             | 50          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.89       |
| env_time                | 11         |
| ep_rewmean              | 18.3       |
| episodes                | 360        |
| eplenmean               | 22.5       |
| fps                     | 119        |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 5.34       |
| qs_difference           | -5.34      |
| qs_mean                 | -0.5891856 |
| time_elapsed            | 68         |
| total timesteps         | 8226       |
| train_time              | 0          |
| update_time             | 51         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.66       |
| env_time                | 11         |
| ep_rewmean              | 18.4       |
| episodes                | 364        |
| eplenmean               | 22.6       |
| fps                     | 118        |
| mean 100 episode reward | 18.4       |
| n_updates               | 0          |
| qs_abs_difference       | 5.15       |
| qs_difference           | -5.15      |
| qs_mean                 | -0.7849391 |
| time_elapsed            | 70         |
| total timesteps         | 8308       |
| train_time              | 0          |
| update_time             | 52         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 12.4        |
| env_time                | 12          |
| ep_rewmean              | 18.2        |
| episodes                | 368         |
| eplenmean               | 22.1        |
| fps                     | 119         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 11.1        |
| qs_difference           | -11.1       |
| qs_mean                 | -0.61693347 |
| time_elapsed            | 70          |
| total timesteps         | 8380        |
| train_time              | 0           |
| update_time             | 52          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 9.32       |
| env_time                | 12         |
| ep_rewmean              | 18.1       |
| episodes                | 372        |
| eplenmean               | 21.9       |
| fps                     | 117        |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 9.12       |
| qs_difference           | -9.12      |
| qs_mean                 | -0.6929707 |
| time_elapsed            | 71         |
| total timesteps         | 8440       |
| train_time              | 0          |
| update_time             | 54         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 16.4        |
| env_time                | 12          |
| ep_rewmean              | 18.2        |
| episodes                | 376         |
| eplenmean               | 21.7        |
| fps                     | 116         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 15.7        |
| qs_difference           | -15.7       |
| qs_mean                 | -0.72994965 |
| time_elapsed            | 73          |
| total timesteps         | 8506        |
| train_time              | 0           |
| update_time             | 55          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.03        |
| env_time                | 12          |
| ep_rewmean              | 18.1        |
| episodes                | 380         |
| eplenmean               | 21.7        |
| fps                     | 117         |
| mean 100 episode reward | 18.1        |
| n_updates               | 0           |
| qs_abs_difference       | 3.19        |
| qs_difference           | -3.19       |
| qs_mean                 | -0.47698194 |
| time_elapsed            | 73          |
| total timesteps         | 8583        |
| train_time              | 0           |
| update_time             | 55          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 21.1        |
| env_time                | 12          |
| ep_rewmean              | 18.7        |
| episodes                | 384         |
| eplenmean               | 22          |
| fps                     | 115         |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 23.4        |
| qs_difference           | -23.4       |
| qs_mean                 | -0.69071436 |
| time_elapsed            | 74          |
| total timesteps         | 8676        |
| train_time              | 0           |
| update_time             | 56          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.74       |
| env_time                | 12         |
| ep_rewmean              | 19.4       |
| episodes                | 388        |
| eplenmean               | 22.4       |
| fps                     | 115        |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 6.48       |
| qs_difference           | -6.48      |
| qs_mean                 | -0.6172739 |
| time_elapsed            | 76         |
| total timesteps         | 8788       |
| train_time              | 0          |
| update_time             | 58         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.81        |
| env_time                | 12          |
| ep_rewmean              | 19.1        |
| episodes                | 392         |
| eplenmean               | 22          |
| fps                     | 113         |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 5.6         |
| qs_difference           | -5.6        |
| qs_mean                 | -0.59171283 |
| time_elapsed            | 77          |
| total timesteps         | 8846        |
| train_time              | 0           |
| update_time             | 59          |
-----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 9.11      |
| env_time                | 12        |
| ep_rewmean              | 19.5      |
| episodes                | 396       |
| eplenmean               | 22.3      |
| fps                     | 112       |
| mean 100 episode reward | 19.5      |
| n_updates               | 0         |
| qs_abs_difference       | 13        |
| qs_difference           | -13       |
| qs_mean                 | -0.820385 |
| time_elapsed            | 79        |
| total timesteps         | 8950      |
| train_time              | 0         |
| update_time             | 60        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 7.27      |
| env_time                | 12        |
| ep_rewmean              | 19.4      |
| episodes                | 400       |
| eplenmean               | 22.2      |
| fps                     | 111       |
| mean 100 episode reward | 19.4      |
| n_updates               | 0         |
| qs_abs_difference       | 6.52      |
| qs_difference           | -6.52     |
| qs_mean                 | -0.671813 |
| time_elapsed            | 80        |
| total timesteps         | 9009      |
| train_time              | 0         |
| update_time             | 62        |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 17.6        |
| env_time                | 13          |
| ep_rewmean              | 19.1        |
| episodes                | 404         |
| eplenmean               | 22          |
| fps                     | 112         |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 18.8        |
| qs_difference           | -18.8       |
| qs_mean                 | -0.70423377 |
| time_elapsed            | 81          |
| total timesteps         | 9098        |
| train_time              | 0           |
| update_time             | 62          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.48        |
| env_time                | 13          |
| ep_rewmean              | 17.9        |
| episodes                | 408         |
| eplenmean               | 21.3        |
| fps                     | 110         |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 1.84        |
| qs_difference           | -1.43       |
| qs_mean                 | -0.24729352 |
| time_elapsed            | 82          |
| total timesteps         | 9158        |
| train_time              | 0           |
| update_time             | 63          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 25.2        |
| env_time                | 13          |
| ep_rewmean              | 17.6        |
| episodes                | 412         |
| eplenmean               | 20.8        |
| fps                     | 109         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 24.7        |
| qs_difference           | -24.7       |
| qs_mean                 | -0.71178555 |
| time_elapsed            | 84          |
| total timesteps         | 9241        |
| train_time              | 0           |
| update_time             | 64          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.89        |
| env_time                | 13          |
| ep_rewmean              | 17.4        |
| episodes                | 416         |
| eplenmean               | 20.7        |
| fps                     | 108         |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 2.53        |
| qs_difference           | -2.01       |
| qs_mean                 | -0.43274915 |
| time_elapsed            | 85          |
| total timesteps         | 9322        |
| train_time              | 0           |
| update_time             | 66          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 9          |
| env_time                | 13         |
| ep_rewmean              | 17.4       |
| episodes                | 420        |
| eplenmean               | 20.6       |
| fps                     | 109        |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 8.53       |
| qs_difference           | -8.53      |
| qs_mean                 | -0.7410171 |
| time_elapsed            | 85         |
| total timesteps         | 9385       |
| train_time              | 0          |
| update_time             | 66         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 9.56        |
| env_time                | 13          |
| ep_rewmean              | 16.9        |
| episodes                | 424         |
| eplenmean               | 20.4        |
| fps                     | 108         |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 8.24        |
| qs_difference           | -8.24       |
| qs_mean                 | -0.64305615 |
| time_elapsed            | 87          |
| total timesteps         | 9460        |
| train_time              | 0           |
| update_time             | 67          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 11.6        |
| env_time                | 13          |
| ep_rewmean              | 17.4        |
| episodes                | 428         |
| eplenmean               | 20.6        |
| fps                     | 107         |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 14.8        |
| qs_difference           | -14.8       |
| qs_mean                 | -0.74169725 |
| time_elapsed            | 89          |
| total timesteps         | 9551        |
| train_time              | 0           |
| update_time             | 69          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.08       |
| env_time                | 13         |
| ep_rewmean              | 17.6       |
| episodes                | 432        |
| eplenmean               | 20.7       |
| fps                     | 106        |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 6.6        |
| qs_difference           | -6.6       |
| qs_mean                 | -0.7823154 |
| time_elapsed            | 90         |
| total timesteps         | 9670       |
| train_time              | 0          |
| update_time             | 70         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 13.5        |
| env_time                | 14          |
| ep_rewmean              | 17.4        |
| episodes                | 436         |
| eplenmean               | 20.4        |
| fps                     | 105         |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 11.1        |
| qs_difference           | -11.1       |
| qs_mean                 | -0.63102996 |
| time_elapsed            | 92          |
| total timesteps         | 9738        |
| train_time              | 0           |
| update_time             | 72          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.07        |
| env_time                | 14          |
| ep_rewmean              | 18.2        |
| episodes                | 440         |
| eplenmean               | 21.1        |
| fps                     | 104         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 2.92        |
| qs_difference           | -1.31       |
| qs_mean                 | -0.34983602 |
| time_elapsed            | 94          |
| total timesteps         | 9884        |
| train_time              | 0           |
| update_time             | 73          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 16.1        |
| env_time                | 14          |
| ep_rewmean              | 18.3        |
| episodes                | 444         |
| eplenmean               | 21.1        |
| fps                     | 103         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 14.5        |
| qs_difference           | -14.5       |
| qs_mean                 | -0.54687834 |
| time_elapsed            | 96          |
| total timesteps         | 9984        |
| train_time              | 0           |
| update_time             | 75          |
-----------------------------------------
----------------------------------------
| eval mean 100 episod... | 4          |
| eval_abs_qs_difference  | 2.7985003  |
| eval_discount_q         | 3.91       |
| eval_ep_rewmean         | 3.99       |
| eval_eplenmean          | 7.45       |
| eval_qs                 | -1.1448662 |
| eval_qs_difference      | -2.8       |
| eval_time_elapsed       | 0          |
| total timesteps         | 10001      |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 9.02        |
| env_time                | 14          |
| ep_rewmean              | 18.2        |
| episodes                | 448         |
| eplenmean               | 20.8        |
| fps                     | 102         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 8.13        |
| qs_difference           | -8.13       |
| qs_mean                 | -0.89258826 |
| time_elapsed            | 97          |
| total timesteps         | 10035       |
| train_time              | 0           |
| update_time             | 76          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.4         |
| env_time                | 14          |
| ep_rewmean              | 18.2        |
| episodes                | 452         |
| eplenmean               | 20.8        |
| fps                     | 103         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 3.55        |
| qs_difference           | -3.55       |
| qs_mean                 | -0.70664525 |
| time_elapsed            | 97          |
| total timesteps         | 10092       |
| train_time              | 0           |
| update_time             | 76          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.57       |
| env_time                | 14         |
| ep_rewmean              | 17.4       |
| episodes                | 456        |
| eplenmean               | 20.5       |
| fps                     | 102        |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 6.2        |
| qs_difference           | -6.2       |
| qs_mean                 | -0.5979405 |
| time_elapsed            | 99         |
| total timesteps         | 10164      |
| train_time              | 0          |
| update_time             | 78         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.35       |
| env_time                | 14         |
| ep_rewmean              | 17.3       |
| episodes                | 460        |
| eplenmean               | 20.3       |
| fps                     | 101        |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.09       |
| qs_difference           | -4.09      |
| qs_mean                 | -0.6179534 |
| time_elapsed            | 101        |
| total timesteps         | 10253      |
| train_time              | 0          |
| update_time             | 79         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.48        |
| env_time                | 14          |
| ep_rewmean              | 17.2        |
| episodes                | 464         |
| eplenmean               | 20.2        |
| fps                     | 100         |
| mean 100 episode reward | 17.2        |
| n_updates               | 0           |
| qs_abs_difference       | 5.03        |
| qs_difference           | -5.03       |
| qs_mean                 | -0.66787785 |
| time_elapsed            | 103         |
| total timesteps         | 10327       |
| train_time              | 0           |
| update_time             | 81          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 11.1       |
| env_time                | 14         |
| ep_rewmean              | 17.1       |
| episodes                | 468        |
| eplenmean               | 20.4       |
| fps                     | 99         |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 9.13       |
| qs_difference           | -9.13      |
| qs_mean                 | -0.4613396 |
| time_elapsed            | 104        |
| total timesteps         | 10415      |
| train_time              | 0          |
| update_time             | 83         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.53       |
| env_time                | 14         |
| ep_rewmean              | 17         |
| episodes                | 472        |
| eplenmean               | 20.4       |
| fps                     | 99         |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 4.85       |
| qs_difference           | -4.85      |
| qs_mean                 | -0.7108769 |
| time_elapsed            | 104        |
| total timesteps         | 10478      |
| train_time              | 0          |
| update_time             | 83         |
----------------------------------------
--------------------------------------
| act_time                | 1        |
| current_lr              | 0.0003   |
| discount_q              | 4.77     |
| env_time                | 15       |
| ep_rewmean              | 17.7     |
| episodes                | 476      |
| eplenmean               | 21       |
| fps                     | 97       |
| mean 100 episode reward | 17.7     |
| n_updates               | 0        |
| qs_abs_difference       | 9.24     |
| qs_difference           | -9.24    |
| qs_mean                 | -0.8476  |
| time_elapsed            | 108      |
| total timesteps         | 10605    |
| train_time              | 0        |
| update_time             | 86       |
--------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 35.6        |
| env_time                | 15          |
| ep_rewmean              | 18.4        |
| episodes                | 480         |
| eplenmean               | 21.4        |
| fps                     | 97          |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 42          |
| qs_difference           | -42         |
| qs_mean                 | -0.50191426 |
| time_elapsed            | 110         |
| total timesteps         | 10725       |
| train_time              | 0           |
| update_time             | 87          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 8.3        |
| env_time                | 15         |
| ep_rewmean              | 18.1       |
| episodes                | 484        |
| eplenmean               | 21.2       |
| fps                     | 97         |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 8.8        |
| qs_difference           | -8.8       |
| qs_mean                 | -0.7196342 |
| time_elapsed            | 110        |
| total timesteps         | 10797      |
| train_time              | 0          |
| update_time             | 87         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.29       |
| env_time                | 15         |
| ep_rewmean              | 17.5       |
| episodes                | 488        |
| eplenmean               | 20.8       |
| fps                     | 96         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.4        |
| qs_difference           | -4.4       |
| qs_mean                 | -0.6193458 |
| time_elapsed            | 112        |
| total timesteps         | 10871      |
| train_time              | 0          |
| update_time             | 89         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.31        |
| env_time                | 15          |
| ep_rewmean              | 17.6        |
| episodes                | 492         |
| eplenmean               | 21.3        |
| fps                     | 96          |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 2.72        |
| qs_difference           | -1.29       |
| qs_mean                 | -0.27819273 |
| time_elapsed            | 114         |
| total timesteps         | 10972       |
| train_time              | 0           |
| update_time             | 91          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.81        |
| env_time                | 16          |
| ep_rewmean              | 17.2        |
| episodes                | 496         |
| eplenmean               | 20.9        |
| fps                     | 94          |
| mean 100 episode reward | 17.2        |
| n_updates               | 0           |
| qs_abs_difference       | 2.84        |
| qs_difference           | -1.67       |
| qs_mean                 | -0.38310206 |
| time_elapsed            | 116         |
| total timesteps         | 11043       |
| train_time              | 0           |
| update_time             | 93          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.53        |
| env_time                | 16          |
| ep_rewmean              | 17.3        |
| episodes                | 500         |
| eplenmean               | 21          |
| fps                     | 92          |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 8.07        |
| qs_difference           | -8.07       |
| qs_mean                 | -0.70137185 |
| time_elapsed            | 120         |
| total timesteps         | 11112       |
| train_time              | 0           |
| update_time             | 96          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.39        |
| env_time                | 16          |
| ep_rewmean              | 17.2        |
| episodes                | 504         |
| eplenmean               | 21          |
| fps                     | 93          |
| mean 100 episode reward | 17.2        |
| n_updates               | 0           |
| qs_abs_difference       | 7.76        |
| qs_difference           | -7.76       |
| qs_mean                 | -0.54069203 |
| time_elapsed            | 120         |
| total timesteps         | 11195       |
| train_time              | 0           |
| update_time             | 96          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.34       |
| env_time                | 16         |
| ep_rewmean              | 17.5       |
| episodes                | 508        |
| eplenmean               | 21.2       |
| fps                     | 92         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 5.68       |
| qs_difference           | -5.68      |
| qs_mean                 | -0.5857356 |
| time_elapsed            | 122        |
| total timesteps         | 11278      |
| train_time              | 0          |
| update_time             | 98         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.24       |
| env_time                | 16         |
| ep_rewmean              | 17.5       |
| episodes                | 512        |
| eplenmean               | 21.5       |
| fps                     | 91         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 5.61       |
| qs_difference           | -5.61      |
| qs_mean                 | -0.5576544 |
| time_elapsed            | 124        |
| total timesteps         | 11389      |
| train_time              | 0          |
| update_time             | 99         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 8.2        |
| env_time                | 16         |
| ep_rewmean              | 17.4       |
| episodes                | 516        |
| eplenmean               | 21.2       |
| fps                     | 90         |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 7.43       |
| qs_difference           | -7.43      |
| qs_mean                 | -0.8238019 |
| time_elapsed            | 126        |
| total timesteps         | 11443      |
| train_time              | 0          |
| update_time             | 101        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.37        |
| env_time                | 17          |
| ep_rewmean              | 17.4        |
| episodes                | 520         |
| eplenmean               | 21.4        |
| fps                     | 89          |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 9.01        |
| qs_difference           | -9.01       |
| qs_mean                 | -0.54184395 |
| time_elapsed            | 128         |
| total timesteps         | 11525       |
| train_time              | 0           |
| update_time             | 103         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 10.9        |
| env_time                | 17          |
| ep_rewmean              | 17.4        |
| episodes                | 524         |
| eplenmean               | 21.5        |
| fps                     | 89          |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 9.02        |
| qs_difference           | -9.02       |
| qs_mean                 | -0.59586287 |
| time_elapsed            | 130         |
| total timesteps         | 11611       |
| train_time              | 0           |
| update_time             | 105         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 15.6       |
| env_time                | 17         |
| ep_rewmean              | 17         |
| episodes                | 528        |
| eplenmean               | 21.2       |
| fps                     | 89         |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 11.2       |
| qs_difference           | -11.2      |
| qs_mean                 | -0.4377624 |
| time_elapsed            | 130        |
| total timesteps         | 11676      |
| train_time              | 0          |
| update_time             | 105        |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 7.85      |
| env_time                | 17        |
| ep_rewmean              | 17.2      |
| episodes                | 532       |
| eplenmean               | 21.5      |
| fps                     | 88        |
| mean 100 episode reward | 17.2      |
| n_updates               | 0         |
| qs_abs_difference       | 14.1      |
| qs_difference           | -14.1     |
| qs_mean                 | -0.635732 |
| time_elapsed            | 134       |
| total timesteps         | 11818     |
| train_time              | 0         |
| update_time             | 109       |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 29.8        |
| env_time                | 17          |
| ep_rewmean              | 18          |
| episodes                | 536         |
| eplenmean               | 22          |
| fps                     | 87          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 35          |
| qs_difference           | -35         |
| qs_mean                 | -0.44337726 |
| time_elapsed            | 136         |
| total timesteps         | 11938       |
| train_time              | 0           |
| update_time             | 110         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.25        |
| env_time                | 17          |
| ep_rewmean              | 16.9        |
| episodes                | 540         |
| eplenmean               | 21.2        |
| fps                     | 86          |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 4.7         |
| qs_difference           | -4.7        |
| qs_mean                 | -0.71813107 |
| time_elapsed            | 138         |
| total timesteps         | 12009       |
| train_time              | 0           |
| update_time             | 112         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 11.3       |
| env_time                | 17         |
| ep_rewmean              | 16.8       |
| episodes                | 544        |
| eplenmean               | 21.2       |
| fps                     | 86         |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 7.64       |
| qs_difference           | -7.61      |
| qs_mean                 | -0.4747228 |
| time_elapsed            | 140        |
| total timesteps         | 12100      |
| train_time              | 0          |
| update_time             | 114        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 3.88       |
| env_time                | 17         |
| ep_rewmean              | 18.1       |
| episodes                | 548        |
| eplenmean               | 21.9       |
| fps                     | 85         |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 6.98       |
| qs_difference           | -6.98      |
| qs_mean                 | -0.7312843 |
| time_elapsed            | 142        |
| total timesteps         | 12230      |
| train_time              | 0          |
| update_time             | 116        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 13.4       |
| env_time                | 18         |
| ep_rewmean              | 18.2       |
| episodes                | 552        |
| eplenmean               | 22         |
| fps                     | 86         |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 10.8       |
| qs_difference           | -10.8      |
| qs_mean                 | -0.6231758 |
| time_elapsed            | 142        |
| total timesteps         | 12290      |
| train_time              | 0          |
| update_time             | 116        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.47        |
| env_time                | 18          |
| ep_rewmean              | 18.5        |
| episodes                | 556         |
| eplenmean               | 22.1        |
| fps                     | 85          |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 4.18        |
| qs_difference           | -4.18       |
| qs_mean                 | -0.34229136 |
| time_elapsed            | 144         |
| total timesteps         | 12379       |
| train_time              | 0           |
| update_time             | 118         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.59       |
| env_time                | 18         |
| ep_rewmean              | 18.4       |
| episodes                | 560        |
| eplenmean               | 22.1       |
| fps                     | 84         |
| mean 100 episode reward | 18.4       |
| n_updates               | 0          |
| qs_abs_difference       | 2.47       |
| qs_difference           | -2.05      |
| qs_mean                 | -0.4193897 |
| time_elapsed            | 146        |
| total timesteps         | 12460      |
| train_time              | 0          |
| update_time             | 120        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.24        |
| env_time                | 18          |
| ep_rewmean              | 18.6        |
| episodes                | 564         |
| eplenmean               | 22          |
| fps                     | 84          |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 6.32        |
| qs_difference           | -6.32       |
| qs_mean                 | -0.73475945 |
| time_elapsed            | 148         |
| total timesteps         | 12531       |
| train_time              | 0           |
| update_time             | 122         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.28       |
| env_time                | 18         |
| ep_rewmean              | 18.6       |
| episodes                | 568        |
| eplenmean               | 21.9       |
| fps                     | 83         |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.2        |
| qs_difference           | -5.2       |
| qs_mean                 | -0.6398037 |
| time_elapsed            | 151        |
| total timesteps         | 12607      |
| train_time              | 0          |
| update_time             | 124        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 15.4       |
| env_time                | 18         |
| ep_rewmean              | 19.4       |
| episodes                | 572        |
| eplenmean               | 22.5       |
| fps                     | 82         |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 19.7       |
| qs_difference           | -19.7      |
| qs_mean                 | -0.7115322 |
| time_elapsed            | 153        |
| total timesteps         | 12728      |
| train_time              | 0          |
| update_time             | 126        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.8         |
| env_time                | 18          |
| ep_rewmean              | 18.5        |
| episodes                | 576         |
| eplenmean               | 22          |
| fps                     | 82          |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 5.5         |
| qs_difference           | -5.5        |
| qs_mean                 | -0.60654116 |
| time_elapsed            | 155         |
| total timesteps         | 12802       |
| train_time              | 0           |
| update_time             | 128         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.72       |
| env_time                | 18         |
| ep_rewmean              | 17.7       |
| episodes                | 580        |
| eplenmean               | 21.3       |
| fps                     | 82         |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 4.13       |
| qs_difference           | -4.13      |
| qs_mean                 | -0.7748722 |
| time_elapsed            | 155        |
| total timesteps         | 12851      |
| train_time              | 0          |
| update_time             | 128        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 9.18        |
| env_time                | 18          |
| ep_rewmean              | 17.7        |
| episodes                | 584         |
| eplenmean               | 21.4        |
| fps                     | 81          |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 8.12        |
| qs_difference           | -8.12       |
| qs_mean                 | -0.51673603 |
| time_elapsed            | 157         |
| total timesteps         | 12936       |
| train_time              | 0           |
| update_time             | 130         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.98        |
| env_time                | 19          |
| ep_rewmean              | 17.7        |
| episodes                | 588         |
| eplenmean               | 21.6        |
| fps                     | 81          |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 5.07        |
| qs_difference           | -4.42       |
| qs_mean                 | -0.48825958 |
| time_elapsed            | 160         |
| total timesteps         | 13030       |
| train_time              | 0           |
| update_time             | 132         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 8.05       |
| env_time                | 19         |
| ep_rewmean              | 18         |
| episodes                | 592        |
| eplenmean               | 21.6       |
| fps                     | 80         |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 10.8       |
| qs_difference           | -10.8      |
| qs_mean                 | -0.6672701 |
| time_elapsed            | 162        |
| total timesteps         | 13131      |
| train_time              | 0          |
| update_time             | 134        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.09        |
| env_time                | 19          |
| ep_rewmean              | 18          |
| episodes                | 596         |
| eplenmean               | 21.5        |
| fps                     | 81          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 4.52        |
| qs_difference           | -4.52       |
| qs_mean                 | -0.64140046 |
| time_elapsed            | 162         |
| total timesteps         | 13190       |
| train_time              | 0           |
| update_time             | 134         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.19        |
| env_time                | 19          |
| ep_rewmean              | 18.3        |
| episodes                | 600         |
| eplenmean               | 21.8        |
| fps                     | 80          |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 7.59        |
| qs_difference           | -7.59       |
| qs_mean                 | -0.72457623 |
| time_elapsed            | 164         |
| total timesteps         | 13295       |
| train_time              | 0           |
| update_time             | 136         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.3         |
| env_time                | 19          |
| ep_rewmean              | 18.1        |
| episodes                | 604         |
| eplenmean               | 21.7        |
| fps                     | 80          |
| mean 100 episode reward | 18.1        |
| n_updates               | 0           |
| qs_abs_difference       | 5.8         |
| qs_difference           | -5.8        |
| qs_mean                 | -0.63038594 |
| time_elapsed            | 166         |
| total timesteps         | 13367       |
| train_time              | 0           |
| update_time             | 138         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.5         |
| env_time                | 19          |
| ep_rewmean              | 18          |
| episodes                | 608         |
| eplenmean               | 21.6        |
| fps                     | 79          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 6.48        |
| qs_difference           | -6.48       |
| qs_mean                 | -0.67709845 |
| time_elapsed            | 169         |
| total timesteps         | 13437       |
| train_time              | 0           |
| update_time             | 140         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.87        |
| env_time                | 19          |
| ep_rewmean              | 17.7        |
| episodes                | 612         |
| eplenmean               | 21.2        |
| fps                     | 78          |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 8.58        |
| qs_difference           | -8.58       |
| qs_mean                 | -0.62786436 |
| time_elapsed            | 171         |
| total timesteps         | 13511       |
| train_time              | 0           |
| update_time             | 142         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.44        |
| env_time                | 19          |
| ep_rewmean              | 18          |
| episodes                | 616         |
| eplenmean               | 21.6        |
| fps                     | 77          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 6.39        |
| qs_difference           | -6.38       |
| qs_mean                 | -0.44314122 |
| time_elapsed            | 174         |
| total timesteps         | 13606       |
| train_time              | 0           |
| update_time             | 145         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.03        |
| env_time                | 20          |
| ep_rewmean              | 18          |
| episodes                | 620         |
| eplenmean               | 21.5        |
| fps                     | 78          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 6.86        |
| qs_difference           | -6.86       |
| qs_mean                 | -0.73294866 |
| time_elapsed            | 175         |
| total timesteps         | 13672       |
| train_time              | 0           |
| update_time             | 145         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 10.6        |
| env_time                | 20          |
| ep_rewmean              | 18.2        |
| episodes                | 624         |
| eplenmean               | 21.4        |
| fps                     | 77          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 9.91        |
| qs_difference           | -9.91       |
| qs_mean                 | -0.63509333 |
| time_elapsed            | 178         |
| total timesteps         | 13756       |
| train_time              | 0           |
| update_time             | 148         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.49        |
| env_time                | 20          |
| ep_rewmean              | 18.3        |
| episodes                | 628         |
| eplenmean               | 21.5        |
| fps                     | 76          |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 4.58        |
| qs_difference           | -4.58       |
| qs_mean                 | -0.46075696 |
| time_elapsed            | 180         |
| total timesteps         | 13826       |
| train_time              | 0           |
| update_time             | 150         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 9.34       |
| env_time                | 20         |
| ep_rewmean              | 17.4       |
| episodes                | 632        |
| eplenmean               | 20.9       |
| fps                     | 75         |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 9.97       |
| qs_difference           | -9.97      |
| qs_mean                 | -0.6277213 |
| time_elapsed            | 183        |
| total timesteps         | 13907      |
| train_time              | 0          |
| update_time             | 153        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 3.62       |
| env_time                | 21         |
| ep_rewmean              | 17.3       |
| episodes                | 636        |
| eplenmean               | 20.8       |
| fps                     | 75         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.54       |
| qs_difference           | -4.54      |
| qs_mean                 | -0.6089567 |
| time_elapsed            | 185        |
| total timesteps         | 14015      |
| train_time              | 0          |
| update_time             | 155        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.23       |
| env_time                | 21         |
| ep_rewmean              | 17.4       |
| episodes                | 640        |
| eplenmean               | 20.8       |
| fps                     | 75         |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 6.81       |
| qs_difference           | -6.81      |
| qs_mean                 | -0.7067308 |
| time_elapsed            | 185        |
| total timesteps         | 14085      |
| train_time              | 0          |
| update_time             | 155        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.3         |
| env_time                | 21          |
| ep_rewmean              | 17.6        |
| episodes                | 644         |
| eplenmean               | 20.9        |
| fps                     | 75          |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 6.41        |
| qs_difference           | -6.41       |
| qs_mean                 | -0.64028573 |
| time_elapsed            | 188         |
| total timesteps         | 14185       |
| train_time              | 0           |
| update_time             | 157         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.85        |
| env_time                | 21          |
| ep_rewmean              | 17.1        |
| episodes                | 648         |
| eplenmean               | 20.8        |
| fps                     | 74          |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 11.3        |
| qs_difference           | -11.3       |
| qs_mean                 | -0.58517027 |
| time_elapsed            | 193         |
| total timesteps         | 14312       |
| train_time              | 0           |
| update_time             | 162         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 13.2       |
| env_time                | 21         |
| ep_rewmean              | 17.3       |
| episodes                | 652        |
| eplenmean               | 21         |
| fps                     | 74         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 13.9       |
| qs_difference           | -13.9      |
| qs_mean                 | -0.6612366 |
| time_elapsed            | 193        |
| total timesteps         | 14386      |
| train_time              | 0          |
| update_time             | 162        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.97        |
| env_time                | 21          |
| ep_rewmean              | 16.9        |
| episodes                | 656         |
| eplenmean               | 20.6        |
| fps                     | 73          |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 7.51        |
| qs_difference           | -7.51       |
| qs_mean                 | -0.82097816 |
| time_elapsed            | 195         |
| total timesteps         | 14443       |
| train_time              | 0           |
| update_time             | 164         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.44       |
| env_time                | 21         |
| ep_rewmean              | 17         |
| episodes                | 660        |
| eplenmean               | 20.5       |
| fps                     | 73         |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 5.38       |
| qs_difference           | -5.38      |
| qs_mean                 | -0.7900614 |
| time_elapsed            | 198        |
| total timesteps         | 14514      |
| train_time              | 0          |
| update_time             | 166        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 15.2        |
| env_time                | 21          |
| ep_rewmean              | 17.1        |
| episodes                | 664         |
| eplenmean               | 20.6        |
| fps                     | 73          |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 14.1        |
| qs_difference           | -14.1       |
| qs_mean                 | -0.60933495 |
| time_elapsed            | 198         |
| total timesteps         | 14591       |
| train_time              | 0           |
| update_time             | 166         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.05        |
| env_time                | 22          |
| ep_rewmean              | 17          |
| episodes                | 668         |
| eplenmean               | 20.5        |
| fps                     | 73          |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 4.62        |
| qs_difference           | -4.62       |
| qs_mean                 | -0.77936083 |
| time_elapsed            | 200         |
| total timesteps         | 14660       |
| train_time              | 0           |
| update_time             | 169         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.5         |
| env_time                | 22          |
| ep_rewmean              | 16.6        |
| episodes                | 672         |
| eplenmean               | 20.3        |
| fps                     | 72          |
| mean 100 episode reward | 16.6        |
| n_updates               | 0           |
| qs_abs_difference       | 3.69        |
| qs_difference           | -3.69       |
| qs_mean                 | -0.37699184 |
| time_elapsed            | 203         |
| total timesteps         | 14759       |
| train_time              | 0           |
| update_time             | 171         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 9.22       |
| env_time                | 22         |
| ep_rewmean              | 16.8       |
| episodes                | 676        |
| eplenmean               | 20.5       |
| fps                     | 72         |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 11.4       |
| qs_difference           | -11.4      |
| qs_mean                 | -0.7197158 |
| time_elapsed            | 205        |
| total timesteps         | 14852      |
| train_time              | 0          |
| update_time             | 173        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.34        |
| env_time                | 22          |
| ep_rewmean              | 17          |
| episodes                | 680         |
| eplenmean               | 21          |
| fps                     | 71          |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 5.01        |
| qs_difference           | -5.01       |
| qs_mean                 | -0.64659214 |
| time_elapsed            | 208         |
| total timesteps         | 14953       |
| train_time              | 0           |
| update_time             | 176         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 42.3        |
| env_time                | 22          |
| ep_rewmean              | 18.1        |
| episodes                | 684         |
| eplenmean               | 21.6        |
| fps                     | 70          |
| mean 100 episode reward | 18.1        |
| n_updates               | 0           |
| qs_abs_difference       | 49.5        |
| qs_difference           | -49.5       |
| qs_mean                 | -0.61061406 |
| time_elapsed            | 213         |
| total timesteps         | 15100       |
| train_time              | 0           |
| update_time             | 181         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 3.44       |
| env_time                | 22         |
| ep_rewmean              | 18         |
| episodes                | 688        |
| eplenmean               | 21.5       |
| fps                     | 71         |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 3.12       |
| qs_difference           | -3.12      |
| qs_mean                 | -0.4810826 |
| time_elapsed            | 213        |
| total timesteps         | 15183      |
| train_time              | 0          |
| update_time             | 181        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.54       |
| env_time                | 23         |
| ep_rewmean              | 17.7       |
| episodes                | 692        |
| eplenmean               | 21.2       |
| fps                     | 70         |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.69       |
| qs_difference           | -3.69      |
| qs_mean                 | -0.5413657 |
| time_elapsed            | 216        |
| total timesteps         | 15255      |
| train_time              | 0          |
| update_time             | 183        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.76        |
| env_time                | 23          |
| ep_rewmean              | 18.1        |
| episodes                | 696         |
| eplenmean               | 21.6        |
| fps                     | 70          |
| mean 100 episode reward | 18.1        |
| n_updates               | 0           |
| qs_abs_difference       | 2.35        |
| qs_difference           | -0.724      |
| qs_mean                 | -0.42776158 |
| time_elapsed            | 218         |
| total timesteps         | 15351       |
| train_time              | 0           |
| update_time             | 185         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.62       |
| env_time                | 23         |
| ep_rewmean              | 18.1       |
| episodes                | 700        |
| eplenmean               | 21.7       |
| fps                     | 69         |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.09       |
| qs_difference           | -5.09      |
| qs_mean                 | -0.5024453 |
| time_elapsed            | 221        |
| total timesteps         | 15469      |
| train_time              | 0          |
| update_time             | 188        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 17.7        |
| env_time                | 23          |
| ep_rewmean              | 18.5        |
| episodes                | 704         |
| eplenmean               | 21.9        |
| fps                     | 69          |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 17.2        |
| qs_difference           | -17.2       |
| qs_mean                 | -0.55000085 |
| time_elapsed            | 224         |
| total timesteps         | 15558       |
| train_time              | 0           |
| update_time             | 190         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 10.6       |
| env_time                | 23         |
| ep_rewmean              | 18.3       |
| episodes                | 708        |
| eplenmean               | 21.8       |
| fps                     | 68         |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 9.09       |
| qs_difference           | -9.09      |
| qs_mean                 | -0.6657574 |
| time_elapsed            | 226        |
| total timesteps         | 15617      |
| train_time              | 0          |
| update_time             | 192        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.92       |
| env_time                | 23         |
| ep_rewmean              | 18.4       |
| episodes                | 712        |
| eplenmean               | 21.9       |
| fps                     | 69         |
| mean 100 episode reward | 18.4       |
| n_updates               | 0          |
| qs_abs_difference       | 3.71       |
| qs_difference           | -3.71      |
| qs_mean                 | -0.6042235 |
| time_elapsed            | 226        |
| total timesteps         | 15696      |
| train_time              | 0          |
| update_time             | 192        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.73       |
| env_time                | 23         |
| ep_rewmean              | 18.2       |
| episodes                | 716        |
| eplenmean               | 21.8       |
| fps                     | 68         |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 6.58       |
| qs_difference           | -6.58      |
| qs_mean                 | -0.6356997 |
| time_elapsed            | 229        |
| total timesteps         | 15786      |
| train_time              | 0          |
| update_time             | 195        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 9.36        |
| env_time                | 23          |
| ep_rewmean              | 18.1        |
| episodes                | 720         |
| eplenmean               | 21.9        |
| fps                     | 67          |
| mean 100 episode reward | 18.1        |
| n_updates               | 0           |
| qs_abs_difference       | 6.53        |
| qs_difference           | -6.53       |
| qs_mean                 | -0.58324546 |
| time_elapsed            | 234         |
| total timesteps         | 15858       |
| train_time              | 0           |
| update_time             | 200         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.83        |
| env_time                | 23          |
| ep_rewmean              | 18.9        |
| episodes                | 724         |
| eplenmean               | 22.1        |
| fps                     | 67          |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 4.72        |
| qs_difference           | -4.72       |
| qs_mean                 | -0.56463885 |
| time_elapsed            | 236         |
| total timesteps         | 15966       |
| train_time              | 0           |
| update_time             | 202         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 30.5        |
| env_time                | 24          |
| ep_rewmean              | 19.4        |
| episodes                | 728         |
| eplenmean               | 22.4        |
| fps                     | 67          |
| mean 100 episode reward | 19.4        |
| n_updates               | 0           |
| qs_abs_difference       | 32.8        |
| qs_difference           | -32.8       |
| qs_mean                 | -0.59310544 |
| time_elapsed            | 239         |
| total timesteps         | 16065       |
| train_time              | 0           |
| update_time             | 205         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 28.6        |
| env_time                | 24          |
| ep_rewmean              | 20          |
| episodes                | 732         |
| eplenmean               | 22.7        |
| fps                     | 66          |
| mean 100 episode reward | 20          |
| n_updates               | 0           |
| qs_abs_difference       | 37.5        |
| qs_difference           | -37.5       |
| qs_mean                 | -0.59216076 |
| time_elapsed            | 242         |
| total timesteps         | 16176       |
| train_time              | 0           |
| update_time             | 207         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.74        |
| env_time                | 24          |
| ep_rewmean              | 19.5        |
| episodes                | 736         |
| eplenmean               | 22.4        |
| fps                     | 66          |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 3.16        |
| qs_difference           | -2.96       |
| qs_mean                 | -0.29301164 |
| time_elapsed            | 245         |
| total timesteps         | 16258       |
| train_time              | 0           |
| update_time             | 210         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.31        |
| env_time                | 24          |
| ep_rewmean              | 19.4        |
| episodes                | 740         |
| eplenmean               | 22.6        |
| fps                     | 65          |
| mean 100 episode reward | 19.4        |
| n_updates               | 0           |
| qs_abs_difference       | 2.06        |
| qs_difference           | -1.64       |
| qs_mean                 | -0.11260262 |
| time_elapsed            | 247         |
| total timesteps         | 16343       |
| train_time              | 0           |
| update_time             | 212         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 7.57        |
| env_time                | 24          |
| ep_rewmean              | 19          |
| episodes                | 744         |
| eplenmean               | 22.2        |
| fps                     | 65          |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 3.99        |
| qs_difference           | -3.99       |
| qs_mean                 | -0.38619655 |
| time_elapsed            | 250         |
| total timesteps         | 16408       |
| train_time              | 0           |
| update_time             | 215         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 9.6        |
| env_time                | 24         |
| ep_rewmean              | 18.2       |
| episodes                | 748        |
| eplenmean               | 21.8       |
| fps                     | 65         |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 7.25       |
| qs_difference           | -7.25      |
| qs_mean                 | -0.5296588 |
| time_elapsed            | 250        |
| total timesteps         | 16496      |
| train_time              | 0          |
| update_time             | 215        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.68       |
| env_time                | 24         |
| ep_rewmean              | 18.2       |
| episodes                | 752        |
| eplenmean               | 21.8       |
| fps                     | 65         |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 4.67       |
| qs_difference           | -4.67      |
| qs_mean                 | -0.6542832 |
| time_elapsed            | 253        |
| total timesteps         | 16568      |
| train_time              | 0          |
| update_time             | 217        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.67       |
| env_time                | 24         |
| ep_rewmean              | 18.2       |
| episodes                | 756        |
| eplenmean               | 21.8       |
| fps                     | 64         |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 4.3        |
| qs_difference           | -4.3       |
| qs_mean                 | -0.8063574 |
| time_elapsed            | 256        |
| total timesteps         | 16622      |
| train_time              | 0          |
| update_time             | 220        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 7.28        |
| env_time                | 25          |
| ep_rewmean              | 18.2        |
| episodes                | 760         |
| eplenmean               | 22          |
| fps                     | 64          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 8.39        |
| qs_difference           | -8.39       |
| qs_mean                 | -0.66987574 |
| time_elapsed            | 259         |
| total timesteps         | 16716       |
| train_time              | 0           |
| update_time             | 223         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 12.1       |
| env_time                | 25         |
| ep_rewmean              | 18         |
| episodes                | 764        |
| eplenmean               | 22.1       |
| fps                     | 64         |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 10.4       |
| qs_difference           | -10.4      |
| qs_mean                 | -0.4468691 |
| time_elapsed            | 261        |
| total timesteps         | 16802      |
| train_time              | 0          |
| update_time             | 225        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.34       |
| env_time                | 25         |
| ep_rewmean              | 18.1       |
| episodes                | 768        |
| eplenmean               | 22.2       |
| fps                     | 64         |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 4.44       |
| qs_difference           | -4.44      |
| qs_mean                 | -0.3672603 |
| time_elapsed            | 262        |
| total timesteps         | 16877      |
| train_time              | 0          |
| update_time             | 225        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.2         |
| env_time                | 25          |
| ep_rewmean              | 17.8        |
| episodes                | 772         |
| eplenmean               | 22          |
| fps                     | 63          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 2.2         |
| qs_difference           | -2.15       |
| qs_mean                 | -0.48067236 |
| time_elapsed            | 264         |
| total timesteps         | 16955       |
| train_time              | 0           |
| update_time             | 228         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.14        |
| env_time                | 25          |
| ep_rewmean              | 18.7        |
| episodes                | 776         |
| eplenmean               | 22.4        |
| fps                     | 63          |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 6.73        |
| qs_difference           | -6.73       |
| qs_mean                 | -0.83186424 |
| time_elapsed            | 267         |
| total timesteps         | 17096       |
| train_time              | 0           |
| update_time             | 231         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.36        |
| env_time                | 25          |
| ep_rewmean              | 18.4        |
| episodes                | 780         |
| eplenmean               | 21.9        |
| fps                     | 63          |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.94        |
| qs_difference           | -3.94       |
| qs_mean                 | -0.31351647 |
| time_elapsed            | 270         |
| total timesteps         | 17146       |
| train_time              | 0           |
| update_time             | 234         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.99       |
| env_time                | 25         |
| ep_rewmean              | 17.4       |
| episodes                | 784        |
| eplenmean               | 21.4       |
| fps                     | 62         |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 5.96       |
| qs_difference           | -5.96      |
| qs_mean                 | -0.5693092 |
| time_elapsed            | 273        |
| total timesteps         | 17245      |
| train_time              | 0          |
| update_time             | 236        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.04       |
| env_time                | 25         |
| ep_rewmean              | 17.5       |
| episodes                | 788        |
| eplenmean               | 21.4       |
| fps                     | 62         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.34       |
| qs_difference           | -3.34      |
| qs_mean                 | -0.5616623 |
| time_elapsed            | 276        |
| total timesteps         | 17325      |
| train_time              | 0          |
| update_time             | 239        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.9        |
| env_time                | 26         |
| ep_rewmean              | 17.5       |
| episodes                | 792        |
| eplenmean               | 21.5       |
| fps                     | 62         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.55       |
| qs_difference           | -2.59      |
| qs_mean                 | -0.3658856 |
| time_elapsed            | 279        |
| total timesteps         | 17406      |
| train_time              | 0          |
| update_time             | 242        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6           |
| env_time                | 26          |
| ep_rewmean              | 17.3        |
| episodes                | 796         |
| eplenmean               | 21.5        |
| fps                     | 62          |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 6.08        |
| qs_difference           | -6.08       |
| qs_mean                 | -0.59050643 |
| time_elapsed            | 279         |
| total timesteps         | 17498       |
| train_time              | 0           |
| update_time             | 242         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.71        |
| env_time                | 26          |
| ep_rewmean              | 17.1        |
| episodes                | 800         |
| eplenmean               | 21.2        |
| fps                     | 62          |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 4.22        |
| qs_difference           | -4.22       |
| qs_mean                 | -0.58207613 |
| time_elapsed            | 282         |
| total timesteps         | 17594       |
| train_time              | 0           |
| update_time             | 245         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.93       |
| env_time                | 26         |
| ep_rewmean              | 16.8       |
| episodes                | 804        |
| eplenmean               | 21.2       |
| fps                     | 61         |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 5.49       |
| qs_difference           | -5.49      |
| qs_mean                 | -0.4781286 |
| time_elapsed            | 285        |
| total timesteps         | 17679      |
| train_time              | 0          |
| update_time             | 247        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.25        |
| env_time                | 26          |
| ep_rewmean              | 16.7        |
| episodes                | 808         |
| eplenmean               | 21.4        |
| fps                     | 61          |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.51        |
| qs_difference           | -3.51       |
| qs_mean                 | -0.37053373 |
| time_elapsed            | 288         |
| total timesteps         | 17755       |
| train_time              | 0           |
| update_time             | 250         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.87        |
| env_time                | 26          |
| ep_rewmean              | 16.6        |
| episodes                | 812         |
| eplenmean               | 21.4        |
| fps                     | 61          |
| mean 100 episode reward | 16.6        |
| n_updates               | 0           |
| qs_abs_difference       | 4.01        |
| qs_difference           | -4.01       |
| qs_mean                 | -0.39473468 |
| time_elapsed            | 291         |
| total timesteps         | 17831       |
| train_time              | 0           |
| update_time             | 253         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5          |
| env_time                | 26         |
| ep_rewmean              | 16.9       |
| episodes                | 816        |
| eplenmean               | 21.7       |
| fps                     | 61         |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 7.18       |
| qs_difference           | -7.18      |
| qs_mean                 | -0.6517545 |
| time_elapsed            | 294        |
| total timesteps         | 17954      |
| train_time              | 0          |
| update_time             | 255        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.47        |
| env_time                | 26          |
| ep_rewmean              | 16.9        |
| episodes                | 820         |
| eplenmean               | 21.6        |
| fps                     | 60          |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 3.09        |
| qs_difference           | -3.09       |
| qs_mean                 | -0.30860278 |
| time_elapsed            | 297         |
| total timesteps         | 18023       |
| train_time              | 0           |
| update_time             | 258         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5          |
| env_time                | 27         |
| ep_rewmean              | 16.5       |
| episodes                | 824        |
| eplenmean               | 21.6       |
| fps                     | 60         |
| mean 100 episode reward | 16.5       |
| n_updates               | 0          |
| qs_abs_difference       | 6.34       |
| qs_difference           | -6.34      |
| qs_mean                 | -0.6923325 |
| time_elapsed            | 300        |
| total timesteps         | 18131      |
| train_time              | 0          |
| update_time             | 261        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.45       |
| env_time                | 27         |
| ep_rewmean              | 16.1       |
| episodes                | 828        |
| eplenmean               | 21.6       |
| fps                     | 60         |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.95       |
| qs_difference           | -5.95      |
| qs_mean                 | -0.5745355 |
| time_elapsed            | 302        |
| total timesteps         | 18224      |
| train_time              | 0          |
| update_time             | 264        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.42       |
| env_time                | 27         |
| ep_rewmean              | 15.3       |
| episodes                | 832        |
| eplenmean               | 21.4       |
| fps                     | 59         |
| mean 100 episode reward | 15.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.93       |
| qs_difference           | -4.93      |
| qs_mean                 | -0.4380734 |
| time_elapsed            | 305        |
| total timesteps         | 18313      |
| train_time              | 0          |
| update_time             | 266        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.53       |
| env_time                | 27         |
| ep_rewmean              | 15.2       |
| episodes                | 836        |
| eplenmean               | 21.2       |
| fps                     | 60         |
| mean 100 episode reward | 15.2       |
| n_updates               | 0          |
| qs_abs_difference       | 6.18       |
| qs_difference           | -6.18      |
| qs_mean                 | -0.6876544 |
| time_elapsed            | 306        |
| total timesteps         | 18377      |
| train_time              | 0          |
| update_time             | 266        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.04       |
| env_time                | 27         |
| ep_rewmean              | 15.4       |
| episodes                | 840        |
| eplenmean               | 21.3       |
| fps                     | 59         |
| mean 100 episode reward | 15.4       |
| n_updates               | 0          |
| qs_abs_difference       | 4.66       |
| qs_difference           | -4.66      |
| qs_mean                 | -0.9511036 |
| time_elapsed            | 309        |
| total timesteps         | 18471      |
| train_time              | 0          |
| update_time             | 269        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.8        |
| env_time                | 27         |
| ep_rewmean              | 15.7       |
| episodes                | 844        |
| eplenmean               | 21.6       |
| fps                     | 59         |
| mean 100 episode reward | 15.7       |
| n_updates               | 0          |
| qs_abs_difference       | 5.6        |
| qs_difference           | -5.6       |
| qs_mean                 | -0.5995099 |
| time_elapsed            | 311        |
| total timesteps         | 18563      |
| train_time              | 0          |
| update_time             | 272        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 19.8       |
| env_time                | 27         |
| ep_rewmean              | 16.3       |
| episodes                | 848        |
| eplenmean               | 21.6       |
| fps                     | 59         |
| mean 100 episode reward | 16.3       |
| n_updates               | 0          |
| qs_abs_difference       | 22.2       |
| qs_difference           | -22.2      |
| qs_mean                 | -0.6882204 |
| time_elapsed            | 315        |
| total timesteps         | 18656      |
| train_time              | 0          |
| update_time             | 275        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.69       |
| env_time                | 27         |
| ep_rewmean              | 16.1       |
| episodes                | 852        |
| eplenmean               | 21.6       |
| fps                     | 58         |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 2.56       |
| qs_difference           | -2.5       |
| qs_mean                 | -0.0957647 |
| time_elapsed            | 318        |
| total timesteps         | 18723      |
| train_time              | 0          |
| update_time             | 278        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.19       |
| env_time                | 27         |
| ep_rewmean              | 16.3       |
| episodes                | 856        |
| eplenmean               | 22         |
| fps                     | 58         |
| mean 100 episode reward | 16.3       |
| n_updates               | 0          |
| qs_abs_difference       | 2.51       |
| qs_difference           | -2.45      |
| qs_mean                 | -0.2102399 |
| time_elapsed            | 321        |
| total timesteps         | 18821      |
| train_time              | 0          |
| update_time             | 281        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 24         |
| env_time                | 28         |
| ep_rewmean              | 16.2       |
| episodes                | 860        |
| eplenmean               | 21.8       |
| fps                     | 58         |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 18.9       |
| qs_difference           | -18.9      |
| qs_mean                 | -0.5374182 |
| time_elapsed            | 321        |
| total timesteps         | 18893      |
| train_time              | 0          |
| update_time             | 281        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.65        |
| env_time                | 28          |
| ep_rewmean              | 16          |
| episodes                | 864         |
| eplenmean               | 21.6        |
| fps                     | 58          |
| mean 100 episode reward | 16          |
| n_updates               | 0           |
| qs_abs_difference       | 2           |
| qs_difference           | -1.85       |
| qs_mean                 | -0.05828644 |
| time_elapsed            | 324         |
| total timesteps         | 18965       |
| train_time              | 0           |
| update_time             | 284         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 17.6       |
| env_time                | 28         |
| ep_rewmean              | 16         |
| episodes                | 868        |
| eplenmean               | 21.7       |
| fps                     | 58         |
| mean 100 episode reward | 16         |
| n_updates               | 0          |
| qs_abs_difference       | 17.4       |
| qs_difference           | -17.4      |
| qs_mean                 | -0.6737794 |
| time_elapsed            | 327        |
| total timesteps         | 19046      |
| train_time              | 0          |
| update_time             | 286        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 9.82       |
| env_time                | 28         |
| ep_rewmean              | 16         |
| episodes                | 872        |
| eplenmean               | 21.5       |
| fps                     | 57         |
| mean 100 episode reward | 16         |
| n_updates               | 0          |
| qs_abs_difference       | 8.4        |
| qs_difference           | -8.4       |
| qs_mean                 | -0.7310728 |
| time_elapsed            | 330        |
| total timesteps         | 19108      |
| train_time              | 0          |
| update_time             | 289        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.07       |
| env_time                | 28         |
| ep_rewmean              | 15.1       |
| episodes                | 876        |
| eplenmean               | 21         |
| fps                     | 58         |
| mean 100 episode reward | 15.1       |
| n_updates               | 0          |
| qs_abs_difference       | 2.88       |
| qs_difference           | -2.88      |
| qs_mean                 | -0.3240926 |
| time_elapsed            | 330        |
| total timesteps         | 19195      |
| train_time              | 0          |
| update_time             | 289        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.12       |
| env_time                | 28         |
| ep_rewmean              | 15.1       |
| episodes                | 880        |
| eplenmean               | 21.1       |
| fps                     | 57         |
| mean 100 episode reward | 15.1       |
| n_updates               | 0          |
| qs_abs_difference       | 3.09       |
| qs_difference           | -3.09      |
| qs_mean                 | -0.3449148 |
| time_elapsed            | 333        |
| total timesteps         | 19259      |
| train_time              | 0          |
| update_time             | 292        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.03       |
| env_time                | 28         |
| ep_rewmean              | 15.2       |
| episodes                | 884        |
| eplenmean               | 20.9       |
| fps                     | 57         |
| mean 100 episode reward | 15.2       |
| n_updates               | 0          |
| qs_abs_difference       | 4.91       |
| qs_difference           | -4.91      |
| qs_mean                 | -0.7640444 |
| time_elapsed            | 336        |
| total timesteps         | 19335      |
| train_time              | 0          |
| update_time             | 295        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.87       |
| env_time                | 28         |
| ep_rewmean              | 15         |
| episodes                | 888        |
| eplenmean               | 20.9       |
| fps                     | 57         |
| mean 100 episode reward | 15         |
| n_updates               | 0          |
| qs_abs_difference       | 4.24       |
| qs_difference           | -4.24      |
| qs_mean                 | -0.5661021 |
| time_elapsed            | 339        |
| total timesteps         | 19410      |
| train_time              | 0          |
| update_time             | 298        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 6.86      |
| env_time                | 28        |
| ep_rewmean              | 14.9      |
| episodes                | 892       |
| eplenmean               | 20.6      |
| fps                     | 57        |
| mean 100 episode reward | 14.9      |
| n_updates               | 0         |
| qs_abs_difference       | 6.54      |
| qs_difference           | -6.54     |
| qs_mean                 | -0.852661 |
| time_elapsed            | 340       |
| total timesteps         | 19466     |
| train_time              | 0         |
| update_time             | 298       |
---------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.63        |
| env_time                | 28          |
| ep_rewmean              | 15.1        |
| episodes                | 896         |
| eplenmean               | 20.6        |
| fps                     | 56          |
| mean 100 episode reward | 15.1        |
| n_updates               | 0           |
| qs_abs_difference       | 6.09        |
| qs_difference           | -6.09       |
| qs_mean                 | -0.55118173 |
| time_elapsed            | 343         |
| total timesteps         | 19563       |
| train_time              | 0           |
| update_time             | 301         |
-----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 10.2      |
| env_time                | 29        |
| ep_rewmean              | 14.9      |
| episodes                | 900       |
| eplenmean               | 20.6      |
| fps                     | 56        |
| mean 100 episode reward | 14.9      |
| n_updates               | 0         |
| qs_abs_difference       | 8.06      |
| qs_difference           | -8.06     |
| qs_mean                 | -0.633819 |
| time_elapsed            | 346       |
| total timesteps         | 19653     |
| train_time              | 0         |
| update_time             | 304       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 8.06       |
| env_time                | 29         |
| ep_rewmean              | 14.8       |
| episodes                | 904        |
| eplenmean               | 20.6       |
| fps                     | 56         |
| mean 100 episode reward | 14.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.23       |
| qs_difference           | -1.21      |
| qs_mean                 | -0.4077943 |
| time_elapsed            | 349        |
| total timesteps         | 19739      |
| train_time              | 0          |
| update_time             | 307        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 2.54       |
| env_time                | 29         |
| ep_rewmean              | 15.8       |
| episodes                | 908        |
| eplenmean               | 21         |
| fps                     | 56         |
| mean 100 episode reward | 15.8       |
| n_updates               | 0          |
| qs_abs_difference       | 3.68       |
| qs_difference           | -3.68      |
| qs_mean                 | -0.5121069 |
| time_elapsed            | 352        |
| total timesteps         | 19852      |
| train_time              | 0          |
| update_time             | 310        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 9.74       |
| env_time                | 29         |
| ep_rewmean              | 15.8       |
| episodes                | 912        |
| eplenmean               | 20.9       |
| fps                     | 55         |
| mean 100 episode reward | 15.8       |
| n_updates               | 0          |
| qs_abs_difference       | 8.51       |
| qs_difference           | -8.51      |
| qs_mean                 | -0.6815316 |
| time_elapsed            | 356        |
| total timesteps         | 19917      |
| train_time              | 0          |
| update_time             | 313        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 3.67      |
| env_time                | 29        |
| ep_rewmean              | 15.8      |
| episodes                | 916       |
| eplenmean               | 20.4      |
| fps                     | 56        |
| mean 100 episode reward | 15.8      |
| n_updates               | 0         |
| qs_abs_difference       | 4.76      |
| qs_difference           | -4.76     |
| qs_mean                 | -0.910652 |
| time_elapsed            | 356       |
| total timesteps         | 19998     |
| train_time              | 0         |
| update_time             | 313       |
---------------------------------------
----------------------------------------
| eval mean 100 episod... | 4          |
| eval_abs_qs_difference  | 2.7890844  |
| eval_discount_q         | 3.92       |
| eval_ep_rewmean         | 4          |
| eval_eplenmean          | 7.55       |
| eval_qs                 | -1.1464441 |
| eval_qs_difference      | -2.79      |
| eval_time_elapsed       | 0          |
| total timesteps         | 20001      |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.71        |
| env_time                | 29          |
| ep_rewmean              | 15.9        |
| episodes                | 920         |
| eplenmean               | 20.5        |
| fps                     | 55          |
| mean 100 episode reward | 15.9        |
| n_updates               | 0           |
| qs_abs_difference       | 3.65        |
| qs_difference           | -3.65       |
| qs_mean                 | -0.50160956 |
| time_elapsed            | 359         |
| total timesteps         | 20072       |
| train_time              | 0           |
| update_time             | 316         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.85        |
| env_time                | 29          |
| ep_rewmean              | 15.4        |
| episodes                | 924         |
| eplenmean               | 20.3        |
| fps                     | 55          |
| mean 100 episode reward | 15.4        |
| n_updates               | 0           |
| qs_abs_difference       | 2.99        |
| qs_difference           | -2.7        |
| qs_mean                 | -0.29339775 |
| time_elapsed            | 362         |
| total timesteps         | 20157       |
| train_time              | 0           |
| update_time             | 320         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.53       |
| env_time                | 29         |
| ep_rewmean              | 16.6       |
| episodes                | 928        |
| eplenmean               | 20.8       |
| fps                     | 55         |
| mean 100 episode reward | 16.6       |
| n_updates               | 0          |
| qs_abs_difference       | 6.75       |
| qs_difference           | -6.75      |
| qs_mean                 | -0.6021263 |
| time_elapsed            | 366        |
| total timesteps         | 20299      |
| train_time              | 0          |
| update_time             | 323        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.23       |
| env_time                | 30         |
| ep_rewmean              | 16.9       |
| episodes                | 932        |
| eplenmean               | 21         |
| fps                     | 54         |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 4.18       |
| qs_difference           | -4.18      |
| qs_mean                 | -0.5185889 |
| time_elapsed            | 374        |
| total timesteps         | 20414      |
| train_time              | 0          |
| update_time             | 331        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 4.48      |
| env_time                | 30        |
| ep_rewmean              | 16.9      |
| episodes                | 936       |
| eplenmean               | 21.2      |
| fps                     | 54        |
| mean 100 episode reward | 16.9      |
| n_updates               | 0         |
| qs_abs_difference       | 3.06      |
| qs_difference           | -3.06     |
| qs_mean                 | -0.317489 |
| time_elapsed            | 378       |
| total timesteps         | 20502     |
| train_time              | 0         |
| update_time             | 334       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.46       |
| env_time                | 30         |
| ep_rewmean              | 16.9       |
| episodes                | 940        |
| eplenmean               | 21.2       |
| fps                     | 54         |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 4.7        |
| qs_difference           | -4.7       |
| qs_mean                 | -0.5029272 |
| time_elapsed            | 378        |
| total timesteps         | 20596      |
| train_time              | 0          |
| update_time             | 334        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.8         |
| env_time                | 30          |
| ep_rewmean              | 16.8        |
| episodes                | 944         |
| eplenmean               | 21.3        |
| fps                     | 54          |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 4.52        |
| qs_difference           | -4.52       |
| qs_mean                 | -0.56162685 |
| time_elapsed            | 381         |
| total timesteps         | 20689       |
| train_time              | 0           |
| update_time             | 338         |
-----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 7.38      |
| env_time                | 30        |
| ep_rewmean              | 16.2      |
| episodes                | 948       |
| eplenmean               | 20.9      |
| fps                     | 53        |
| mean 100 episode reward | 16.2      |
| n_updates               | 0         |
| qs_abs_difference       | 6.16      |
| qs_difference           | -6.16     |
| qs_mean                 | -0.746332 |
| time_elapsed            | 385       |
| total timesteps         | 20748     |
| train_time              | 0         |
| update_time             | 341       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.14       |
| env_time                | 30         |
| ep_rewmean              | 16.1       |
| episodes                | 952        |
| eplenmean               | 20.9       |
| fps                     | 53         |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 3.93       |
| qs_difference           | -3.93      |
| qs_mean                 | -0.8669238 |
| time_elapsed            | 388        |
| total timesteps         | 20816      |
| train_time              | 0          |
| update_time             | 344        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 9.84       |
| env_time                | 30         |
| ep_rewmean              | 16.7       |
| episodes                | 956        |
| eplenmean               | 21         |
| fps                     | 53         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 13.7       |
| qs_difference           | -13.7      |
| qs_mean                 | -0.7214482 |
| time_elapsed            | 392        |
| total timesteps         | 20923      |
| train_time              | 0          |
| update_time             | 347        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 12         |
| env_time                | 30         |
| ep_rewmean              | 16.8       |
| episodes                | 960        |
| eplenmean               | 21.1       |
| fps                     | 53         |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 12         |
| qs_difference           | -12        |
| qs_mean                 | -0.6292883 |
| time_elapsed            | 395        |
| total timesteps         | 21000      |
| train_time              | 0          |
| update_time             | 351        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 9.18        |
| env_time                | 30          |
| ep_rewmean              | 17          |
| episodes                | 964         |
| eplenmean               | 21          |
| fps                     | 53          |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 7.28        |
| qs_difference           | -7.28       |
| qs_mean                 | -0.60330415 |
| time_elapsed            | 395         |
| total timesteps         | 21067       |
| train_time              | 0           |
| update_time             | 351         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.47       |
| env_time                | 31         |
| ep_rewmean              | 17.8       |
| episodes                | 968        |
| eplenmean               | 21.5       |
| fps                     | 53         |
| mean 100 episode reward | 17.8       |
| n_updates               | 0          |
| qs_abs_difference       | 8.72       |
| qs_difference           | -8.72      |
| qs_mean                 | -0.8042667 |
| time_elapsed            | 399        |
| total timesteps         | 21199      |
| train_time              | 0          |
| update_time             | 354        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.61        |
| env_time                | 31          |
| ep_rewmean              | 17.8        |
| episodes                | 972         |
| eplenmean               | 21.9        |
| fps                     | 52          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 3.08        |
| qs_difference           | -3.08       |
| qs_mean                 | -0.45190442 |
| time_elapsed            | 403         |
| total timesteps         | 21295       |
| train_time              | 0           |
| update_time             | 358         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 8.34       |
| env_time                | 31         |
| ep_rewmean              | 17.9       |
| episodes                | 976        |
| eplenmean               | 21.8       |
| fps                     | 52         |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 8.67       |
| qs_difference           | -8.67      |
| qs_mean                 | -0.7344186 |
| time_elapsed            | 406        |
| total timesteps         | 21373      |
| train_time              | 0          |
| update_time             | 361        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.9        |
| env_time                | 31         |
| ep_rewmean              | 18.6       |
| episodes                | 980        |
| eplenmean               | 22.3       |
| fps                     | 52         |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.11       |
| qs_difference           | -5.11      |
| qs_mean                 | -0.5474017 |
| time_elapsed            | 410        |
| total timesteps         | 21493      |
| train_time              | 0          |
| update_time             | 364        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 14.9        |
| env_time                | 31          |
| ep_rewmean              | 18.8        |
| episodes                | 984         |
| eplenmean               | 22.7        |
| fps                     | 51          |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 16.7        |
| qs_difference           | -16.7       |
| qs_mean                 | -0.50456715 |
| time_elapsed            | 417         |
| total timesteps         | 21601       |
| train_time              | 0           |
| update_time             | 371         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.46       |
| env_time                | 31         |
| ep_rewmean              | 19.1       |
| episodes                | 988        |
| eplenmean               | 22.8       |
| fps                     | 51         |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 8.85       |
| qs_difference           | -8.85      |
| qs_mean                 | -0.7386336 |
| time_elapsed            | 417        |
| total timesteps         | 21690      |
| train_time              | 0          |
| update_time             | 371        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 30.5       |
| env_time                | 32         |
| ep_rewmean              | 20         |
| episodes                | 992        |
| eplenmean               | 23.3       |
| fps                     | 51         |
| mean 100 episode reward | 20         |
| n_updates               | 0          |
| qs_abs_difference       | 32.4       |
| qs_difference           | -32.4      |
| qs_mean                 | -0.5696656 |
| time_elapsed            | 421        |
| total timesteps         | 21794      |
| train_time              | 0          |
| update_time             | 375        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 11.7       |
| env_time                | 32         |
| ep_rewmean              | 19.7       |
| episodes                | 996        |
| eplenmean               | 22.9       |
| fps                     | 51         |
| mean 100 episode reward | 19.7       |
| n_updates               | 0          |
| qs_abs_difference       | 8.72       |
| qs_difference           | -8.72      |
| qs_mean                 | -0.6213465 |
| time_elapsed            | 424        |
| total timesteps         | 21853      |
| train_time              | 0          |
| update_time             | 378        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 9.39      |
| env_time                | 32        |
| ep_rewmean              | 19.5      |
| episodes                | 1000      |
| eplenmean               | 22.7      |
| fps                     | 51        |
| mean 100 episode reward | 19.5      |
| n_updates               | 0         |
| qs_abs_difference       | 9         |
| qs_difference           | -9        |
| qs_mean                 | -0.674013 |
| time_elapsed            | 429       |
| total timesteps         | 21921     |
| train_time              | 0         |
| update_time             | 383       |
---------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 11.8        |
| env_time                | 32          |
| ep_rewmean              | 19.6        |
| episodes                | 1004        |
| eplenmean               | 22.6        |
| fps                     | 51          |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 11.2        |
| qs_difference           | -11.2       |
| qs_mean                 | -0.69068843 |
| time_elapsed            | 429         |
| total timesteps         | 21996       |
| train_time              | 0           |
| update_time             | 383         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 7.44        |
| env_time                | 32          |
| ep_rewmean              | 18.6        |
| episodes                | 1008        |
| eplenmean               | 22          |
| fps                     | 50          |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 6.39        |
| qs_difference           | -6.39       |
| qs_mean                 | -0.83672637 |
| time_elapsed            | 433         |
| total timesteps         | 22049       |
| train_time              | 0           |
| update_time             | 387         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.41        |
| env_time                | 32          |
| ep_rewmean              | 18.9        |
| episodes                | 1012        |
| eplenmean               | 22.3        |
| fps                     | 50          |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 3.77        |
| qs_difference           | -3.77       |
| qs_mean                 | -0.50716376 |
| time_elapsed            | 437         |
| total timesteps         | 22143       |
| train_time              | 0           |
| update_time             | 390         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.07        |
| env_time                | 32          |
| ep_rewmean              | 19.2        |
| episodes                | 1016        |
| eplenmean               | 22.6        |
| fps                     | 50          |
| mean 100 episode reward | 19.2        |
| n_updates               | 0           |
| qs_abs_difference       | 8.59        |
| qs_difference           | -8.59       |
| qs_mean                 | -0.68254757 |
| time_elapsed            | 441         |
| total timesteps         | 22254       |
| train_time              | 0           |
| update_time             | 394         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.63       |
| env_time                | 33         |
| ep_rewmean              | 19.5       |
| episodes                | 1020       |
| eplenmean               | 22.8       |
| fps                     | 50         |
| mean 100 episode reward | 19.5       |
| n_updates               | 0          |
| qs_abs_difference       | 5.88       |
| qs_difference           | -5.88      |
| qs_mean                 | -0.7620853 |
| time_elapsed            | 445        |
| total timesteps         | 22350      |
| train_time              | 0          |
| update_time             | 397        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.97       |
| env_time                | 33         |
| ep_rewmean              | 19.6       |
| episodes                | 1024       |
| eplenmean               | 22.6       |
| fps                     | 49         |
| mean 100 episode reward | 19.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.17       |
| qs_difference           | -5.17      |
| qs_mean                 | -0.6319488 |
| time_elapsed            | 448        |
| total timesteps         | 22422      |
| train_time              | 0          |
| update_time             | 401        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 13          |
| env_time                | 33          |
| ep_rewmean              | 18.6        |
| episodes                | 1028        |
| eplenmean               | 22.4        |
| fps                     | 49          |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 11.2        |
| qs_difference           | -11.2       |
| qs_mean                 | -0.43176204 |
| time_elapsed            | 452         |
| total timesteps         | 22535       |
| train_time              | 0           |
| update_time             | 404         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.39       |
| env_time                | 33         |
| ep_rewmean              | 18.2       |
| episodes                | 1032       |
| eplenmean               | 21.8       |
| fps                     | 49         |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 5.98       |
| qs_difference           | -5.98      |
| qs_mean                 | -0.6422968 |
| time_elapsed            | 452        |
| total timesteps         | 22595      |
| train_time              | 0          |
| update_time             | 404        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 2.07        |
| env_time                | 33          |
| ep_rewmean              | 19          |
| episodes                | 1036        |
| eplenmean               | 22          |
| fps                     | 49          |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 2.95        |
| qs_difference           | -2.95       |
| qs_mean                 | -0.61569166 |
| time_elapsed            | 460         |
| total timesteps         | 22706       |
| train_time              | 0           |
| update_time             | 411         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 8.08       |
| env_time                | 33         |
| ep_rewmean              | 19.3       |
| episodes                | 1040       |
| eplenmean               | 22.2       |
| fps                     | 49         |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 9.97       |
| qs_difference           | -9.97      |
| qs_mean                 | -0.5383512 |
| time_elapsed            | 463        |
| total timesteps         | 22813      |
| train_time              | 0          |
| update_time             | 415        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.25        |
| env_time                | 33          |
| ep_rewmean              | 19.2        |
| episodes                | 1044        |
| eplenmean               | 21.8        |
| fps                     | 49          |
| mean 100 episode reward | 19.2        |
| n_updates               | 0           |
| qs_abs_difference       | 3.92        |
| qs_difference           | -3.92       |
| qs_mean                 | -0.47551084 |
| time_elapsed            | 463         |
| total timesteps         | 22869       |
| train_time              | 0           |
| update_time             | 415         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 5.93        |
| env_time                | 33          |
| ep_rewmean              | 19.3        |
| episodes                | 1048        |
| eplenmean               | 22.1        |
| fps                     | 49          |
| mean 100 episode reward | 19.3        |
| n_updates               | 0           |
| qs_abs_difference       | 3.85        |
| qs_difference           | -3.18       |
| qs_mean                 | -0.37181905 |
| time_elapsed            | 467         |
| total timesteps         | 22959       |
| train_time              | 0           |
| update_time             | 419         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 3.67        |
| env_time                | 33          |
| ep_rewmean              | 19.5        |
| episodes                | 1052        |
| eplenmean               | 22.3        |
| fps                     | 48          |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 2.53        |
| qs_difference           | 0.591       |
| qs_mean                 | -0.14962986 |
| time_elapsed            | 471         |
| total timesteps         | 23050       |
| train_time              | 0           |
| update_time             | 422         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 3.29       |
| env_time                | 34         |
| ep_rewmean              | 19.1       |
| episodes                | 1056       |
| eplenmean               | 22.1       |
| fps                     | 48         |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 4.69       |
| qs_difference           | -4.69      |
| qs_mean                 | -0.8967728 |
| time_elapsed            | 475        |
| total timesteps         | 23136      |
| train_time              | 0          |
| update_time             | 426        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 4.94        |
| env_time                | 34          |
| ep_rewmean              | 18.8        |
| episodes                | 1060        |
| eplenmean               | 21.9        |
| fps                     | 48          |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 3.46        |
| qs_difference           | -3.46       |
| qs_mean                 | -0.28575003 |
| time_elapsed            | 475         |
| total timesteps         | 23187       |
| train_time              | 0           |
| update_time             | 426         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 11.5        |
| env_time                | 34          |
| ep_rewmean              | 18.8        |
| episodes                | 1064        |
| eplenmean               | 21.8        |
| fps                     | 48          |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 9.36        |
| qs_difference           | -9.36       |
| qs_mean                 | -0.65163916 |
| time_elapsed            | 479         |
| total timesteps         | 23246       |
| train_time              | 0           |
| update_time             | 430         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 9.7         |
| env_time                | 34          |
| ep_rewmean              | 17.9        |
| episodes                | 1068        |
| eplenmean               | 21.1        |
| fps                     | 48          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 9.74        |
| qs_difference           | -9.74       |
| qs_mean                 | -0.87172294 |
| time_elapsed            | 482         |
| total timesteps         | 23308       |
| train_time              | 0           |
| update_time             | 433         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 10.6       |
| env_time                | 34         |
| ep_rewmean              | 18         |
| episodes                | 1072       |
| eplenmean               | 20.9       |
| fps                     | 48         |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 10.6       |
| qs_difference           | -10.6      |
| qs_mean                 | -0.5020289 |
| time_elapsed            | 483        |
| total timesteps         | 23389      |
| train_time              | 0          |
| update_time             | 433        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 8.61       |
| env_time                | 34         |
| ep_rewmean              | 18.2       |
| episodes                | 1076       |
| eplenmean               | 21.2       |
| fps                     | 48         |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 10.2       |
| qs_difference           | -10.2      |
| qs_mean                 | -0.5392549 |
| time_elapsed            | 489        |
| total timesteps         | 23496      |
| train_time              | 0          |
| update_time             | 439        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 6.77        |
| env_time                | 34          |
| ep_rewmean              | 17.8        |
| episodes                | 1080        |
| eplenmean               | 21.1        |
| fps                     | 47          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.33        |
| qs_difference           | -5.33       |
| qs_mean                 | -0.43973425 |
| time_elapsed            | 493         |
| total timesteps         | 23598       |
| train_time              | 0           |
| update_time             | 443         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 8.75       |
| env_time                | 34         |
| ep_rewmean              | 17.3       |
| episodes                | 1084       |
| eplenmean               | 20.6       |
| fps                     | 47         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 5.61       |
| qs_difference           | -5.61      |
| qs_mean                 | -0.5068376 |
| time_elapsed            | 497        |
| total timesteps         | 23661      |
| train_time              | 0          |
| update_time             | 447        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 41.5       |
| env_time                | 34         |
| ep_rewmean              | 17.9       |
| episodes                | 1088       |
| eplenmean               | 21         |
| fps                     | 47         |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 42.2       |
| qs_difference           | -42.2      |
| qs_mean                 | -0.5870576 |
| time_elapsed            | 501        |
| total timesteps         | 23787      |
| train_time              | 0          |
| update_time             | 451        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 4.21        |
| env_time                | 35          |
| ep_rewmean              | 17.5        |
| episodes                | 1092        |
| eplenmean               | 20.8        |
| fps                     | 47          |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 3.59        |
| qs_difference           | -3.59       |
| qs_mean                 | -0.55830175 |
| time_elapsed            | 505         |
| total timesteps         | 23870       |
| train_time              | 0           |
| update_time             | 454         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 4.01        |
| env_time                | 35          |
| ep_rewmean              | 17.6        |
| episodes                | 1096        |
| eplenmean               | 20.8        |
| fps                     | 47          |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 3.31        |
| qs_difference           | -3.31       |
| qs_mean                 | -0.44624138 |
| time_elapsed            | 509         |
| total timesteps         | 23935       |
| train_time              | 0           |
| update_time             | 458         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 16          |
| env_time                | 35          |
| ep_rewmean              | 17.9        |
| episodes                | 1100        |
| eplenmean               | 20.9        |
| fps                     | 46          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 14.5        |
| qs_difference           | -14.5       |
| qs_mean                 | -0.63792527 |
| time_elapsed            | 513         |
| total timesteps         | 24011       |
| train_time              | 0           |
| update_time             | 462         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 8.72       |
| env_time                | 35         |
| ep_rewmean              | 18.3       |
| episodes                | 1104       |
| eplenmean               | 21.1       |
| fps                     | 46         |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 11.6       |
| qs_difference           | -11.6      |
| qs_mean                 | -0.5652687 |
| time_elapsed            | 517        |
| total timesteps         | 24111      |
| train_time              | 0          |
| update_time             | 466        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 3.49        |
| env_time                | 35          |
| ep_rewmean              | 18.9        |
| episodes                | 1108        |
| eplenmean               | 21.6        |
| fps                     | 46          |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 5.07        |
| qs_difference           | -5.07       |
| qs_mean                 | -0.92888224 |
| time_elapsed            | 521         |
| total timesteps         | 24204       |
| train_time              | 0           |
| update_time             | 470         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 5.61       |
| env_time                | 35         |
| ep_rewmean              | 18.7       |
| episodes                | 1112       |
| eplenmean               | 21.4       |
| fps                     | 46         |
| mean 100 episode reward | 18.7       |
| n_updates               | 0          |
| qs_abs_difference       | 5.99       |
| qs_difference           | -5.99      |
| qs_mean                 | -0.6142168 |
| time_elapsed            | 521        |
| total timesteps         | 24286      |
| train_time              | 0          |
| update_time             | 470        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 11.6       |
| env_time                | 35         |
| ep_rewmean              | 18.4       |
| episodes                | 1116       |
| eplenmean               | 21.2       |
| fps                     | 46         |
| mean 100 episode reward | 18.4       |
| n_updates               | 0          |
| qs_abs_difference       | 13.1       |
| qs_difference           | -13.1      |
| qs_mean                 | -0.6099585 |
| time_elapsed            | 525        |
| total timesteps         | 24377      |
| train_time              | 0          |
| update_time             | 474        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 6.53        |
| env_time                | 35          |
| ep_rewmean              | 18.4        |
| episodes                | 1120        |
| eplenmean               | 21.1        |
| fps                     | 46          |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 6.65        |
| qs_difference           | -6.65       |
| qs_mean                 | -0.63022643 |
| time_elapsed            | 529         |
| total timesteps         | 24465       |
| train_time              | 0           |
| update_time             | 478         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 4.64        |
| env_time                | 36          |
| ep_rewmean              | 18.4        |
| episodes                | 1124        |
| eplenmean               | 21.4        |
| fps                     | 46          |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 2.2         |
| qs_difference           | -1.84       |
| qs_mean                 | -0.33940887 |
| time_elapsed            | 533         |
| total timesteps         | 24567       |
| train_time              | 0           |
| update_time             | 481         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 5.9         |
| env_time                | 36          |
| ep_rewmean              | 18.1        |
| episodes                | 1128        |
| eplenmean               | 21.1        |
| fps                     | 45          |
| mean 100 episode reward | 18.1        |
| n_updates               | 0           |
| qs_abs_difference       | 7.22        |
| qs_difference           | -7.22       |
| qs_mean                 | -0.94647056 |
| time_elapsed            | 537         |
| total timesteps         | 24647       |
| train_time              | 0           |
| update_time             | 485         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 3.09       |
| env_time                | 36         |
| ep_rewmean              | 18         |
| episodes                | 1132       |
| eplenmean               | 21         |
| fps                     | 45         |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 2.17       |
| qs_difference           | -2.17      |
| qs_mean                 | -0.3210756 |
| time_elapsed            | 537        |
| total timesteps         | 24699      |
| train_time              | 0          |
| update_time             | 485        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 5.76       |
| env_time                | 36         |
| ep_rewmean              | 17.2       |
| episodes                | 1136       |
| eplenmean               | 20.9       |
| fps                     | 45         |
| mean 100 episode reward | 17.2       |
| n_updates               | 0          |
| qs_abs_difference       | 5.29       |
| qs_difference           | -5.29      |
| qs_mean                 | -0.5440384 |
| time_elapsed            | 541        |
| total timesteps         | 24796      |
| train_time              | 0          |
| update_time             | 489        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 4.04       |
| env_time                | 36         |
| ep_rewmean              | 16.7       |
| episodes                | 1140       |
| eplenmean               | 20.4       |
| fps                     | 45         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.74       |
| qs_difference           | -3.74      |
| qs_mean                 | -0.7051332 |
| time_elapsed            | 545        |
| total timesteps         | 24850      |
| train_time              | 0          |
| update_time             | 493        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 5.19        |
| env_time                | 36          |
| ep_rewmean              | 17.3        |
| episodes                | 1144        |
| eplenmean               | 21          |
| fps                     | 45          |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 6.91        |
| qs_difference           | -6.91       |
| qs_mean                 | -0.64240855 |
| time_elapsed            | 549         |
| total timesteps         | 24965       |
| train_time              | 0           |
| update_time             | 497         |
-----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 17.8      |
| env_time                | 36        |
| ep_rewmean              | 18.5      |
| episodes                | 1148      |
| eplenmean               | 21.2      |
| fps                     | 44        |
| mean 100 episode reward | 18.5      |
| n_updates               | 200       |
| q_grad_norm             | 26.577236 |
| qfs_loss                | 85.21257  |
| qs_abs_difference       | 26.3      |
| qs_difference           | -26.3     |
| qs_mean                 | -0.498833 |
| time_elapsed            | 558       |
| total timesteps         | 25081     |
| train_time              | 4         |
| update_time             | 501       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 11.4      |
| env_time                | 36        |
| ep_rewmean              | 20.7      |
| episodes                | 1152      |
| eplenmean               | 21.8      |
| fps                     | 44        |
| mean 100 episode reward | 20.7      |
| n_updates               | 600       |
| q_grad_norm             | 42.94029  |
| qfs_loss                | 75.27416  |
| qs_abs_difference       | 10.8      |
| qs_difference           | -2.92     |
| qs_mean                 | 20.713278 |
| time_elapsed            | 571       |
| total timesteps         | 25231     |
| train_time              | 9         |
| update_time             | 508       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 22.8      |
| env_time                | 36        |
| ep_rewmean              | 21.9      |
| episodes                | 1156      |
| eplenmean               | 22        |
| fps                     | 43        |
| mean 100 episode reward | 21.9      |
| n_updates               | 800       |
| q_grad_norm             | 59.717358 |
| qfs_loss                | 71.83703  |
| qs_abs_difference       | 13.3      |
| qs_difference           | -1.06     |
| qs_mean                 | 27.970173 |
| time_elapsed            | 578       |
| total timesteps         | 25339     |
| train_time              | 12        |
| update_time             | 512       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 11.7      |
| env_time                | 37        |
| ep_rewmean              | 24.6      |
| episodes                | 1160      |
| eplenmean               | 23.2      |
| fps                     | 43        |
| mean 100 episode reward | 24.6      |
| n_updates               | 1200      |
| q_grad_norm             | 120.54621 |
| qfs_loss                | 68.80517  |
| qs_abs_difference       | 15.7      |
| qs_difference           | 8.5       |
| qs_mean                 | 36.900784 |
| time_elapsed            | 591       |
| total timesteps         | 25510     |
| train_time              | 17        |
| update_time             | 520       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 20.9      |
| env_time                | 37        |
| ep_rewmean              | 26.2      |
| episodes                | 1164      |
| eplenmean               | 23.7      |
| fps                     | 42        |
| mean 100 episode reward | 26.2      |
| n_updates               | 1400      |
| q_grad_norm             | 148.59038 |
| qfs_loss                | 64.20672  |
| qs_abs_difference       | 20.4      |
| qs_difference           | 18.5      |
| qs_mean                 | 46.340385 |
| time_elapsed            | 597       |
| total timesteps         | 25620     |
| train_time              | 19        |
| update_time             | 524       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 23.7      |
| env_time                | 37        |
| ep_rewmean              | 28.2      |
| episodes                | 1168      |
| eplenmean               | 24.6      |
| fps                     | 42        |
| mean 100 episode reward | 28.2      |
| n_updates               | 1600      |
| q_grad_norm             | 182.38637 |
| qfs_loss                | 61.862896 |
| qs_abs_difference       | 19.3      |
| qs_difference           | 15.5      |
| qs_mean                 | 53.46272  |
| time_elapsed            | 604       |
| total timesteps         | 25769     |
| train_time              | 22        |
| update_time             | 528       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 18        |
| env_time                | 37        |
| ep_rewmean              | 32.5      |
| episodes                | 1172      |
| eplenmean               | 26.6      |
| fps                     | 41        |
| mean 100 episode reward | 32.5      |
| n_updates               | 2200      |
| q_grad_norm             | 297.13373 |
| qfs_loss                | 51.16047  |
| qs_abs_difference       | 27.3      |
| qs_difference           | -12.8     |
| qs_mean                 | 58.485134 |
| time_elapsed            | 624       |
| total timesteps         | 26045     |
| train_time              | 29        |
| update_time             | 540       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 8.87      |
| env_time                | 38        |
| ep_rewmean              | 37        |
| episodes                | 1176      |
| eplenmean               | 28.7      |
| fps                     | 40        |
| mean 100 episode reward | 37        |
| n_updates               | 2800      |
| q_grad_norm             | 383.86194 |
| qfs_loss                | 45.288246 |
| qs_abs_difference       | 10.9      |
| qs_difference           | 3.84      |
| qs_mean                 | 61.40736  |
| time_elapsed            | 647       |
| total timesteps         | 26367     |
| train_time              | 37        |
| update_time             | 554       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 6.88      |
| env_time                | 38        |
| ep_rewmean              | 43        |
| episodes                | 1180      |
| eplenmean               | 31.4      |
| fps                     | 39        |
| mean 100 episode reward | 43        |
| n_updates               | 3600      |
| q_grad_norm             | 529.94885 |
| qfs_loss                | 44.94648  |
| qs_abs_difference       | 8.59      |
| qs_difference           | 3.3       |
| qs_mean                 | 73.30636  |
| time_elapsed            | 675       |
| total timesteps         | 26737     |
| train_time              | 47        |
| update_time             | 571       |
---------------------------------------
----------------------------------------
| act_time                | 4          |
| current_lr              | 0.0003     |
| discount_q              | 9.53       |
| env_time                | 39         |
| ep_rewmean              | 48.7       |
| episodes                | 1184       |
| eplenmean               | 33.9       |
| fps                     | 38         |
| mean 100 episode reward | 48.7       |
| n_updates               | 4200       |
| q_grad_norm             | 725.6364   |
| qfs_loss                | 52.454758  |
| qs_abs_difference       | 42.1       |
| qs_difference           | 42.1       |
| qs_mean                 | 103.659645 |
| time_elapsed            | 698        |
| total timesteps         | 27051      |
| train_time              | 54         |
| update_time             | 586        |
----------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 8.7       |
| env_time                | 39        |
| ep_rewmean              | 54.3      |
| episodes                | 1188      |
| eplenmean               | 36.2      |
| fps                     | 37        |
| mean 100 episode reward | 54.3      |
| n_updates               | 5000      |
| q_grad_norm             | 1076.601  |
| qfs_loss                | 68.7949   |
| qs_abs_difference       | 34.5      |
| qs_difference           | 34.4      |
| qs_mean                 | 117.72701 |
| time_elapsed            | 726       |
| total timesteps         | 27406     |
| train_time              | 65        |
| update_time             | 603       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 6.32      |
| env_time                | 40        |
| ep_rewmean              | 62.3      |
| episodes                | 1192      |
| eplenmean               | 39.4      |
| fps                     | 36        |
| mean 100 episode reward | 62.3      |
| n_updates               | 5800      |
| q_grad_norm             | 1379.866  |
| qfs_loss                | 71.66644  |
| qs_abs_difference       | 38.2      |
| qs_difference           | 38.2      |
| qs_mean                 | 131.70026 |
| time_elapsed            | 757       |
| total timesteps         | 27812     |
| train_time              | 75        |
| update_time             | 621       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 4.29      |
| env_time                | 41        |
| ep_rewmean              | 74.6      |
| episodes                | 1196      |
| eplenmean               | 43.9      |
| fps                     | 35        |
| mean 100 episode reward | 74.6      |
| n_updates               | 6800      |
| q_grad_norm             | 1680.5004 |
| qfs_loss                | 93.21567  |
| qs_abs_difference       | 29.6      |
| qs_difference           | 2.43      |
| qs_mean                 | 135.77782 |
| time_elapsed            | 792       |
| total timesteps         | 28321     |
| train_time              | 88        |
| update_time             | 643       |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 0.811     |
| env_time                | 42        |
| ep_rewmean              | 90.6      |
| episodes                | 1200      |
| eplenmean               | 49.8      |
| fps                     | 34        |
| mean 100 episode reward | 90.6      |
| n_updates               | 8000      |
| q_grad_norm             | 2207.3257 |
| qfs_loss                | 106.87208 |
| qs_abs_difference       | 42.3      |
| qs_difference           | 42.3      |
| qs_mean                 | 167.44223 |
| time_elapsed            | 834       |
| total timesteps         | 28994     |
| train_time              | 103       |
| update_time             | 668       |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 0.697     |
| env_time                | 43        |
| ep_rewmean              | 111       |
| episodes                | 1204      |
| eplenmean               | 56.2      |
| fps                     | 33        |
| mean 100 episode reward | 110       |
| n_updates               | 9600      |
| q_grad_norm             | 3053.2954 |
| qfs_loss                | 125.94464 |
| qs_abs_difference       | 21.6      |
| qs_difference           | 15.1      |
| qs_mean                 | 189.66975 |
| time_elapsed            | 892       |
| total timesteps         | 29731     |
| train_time              | 125       |
| update_time             | 702       |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 102       |
| eval_abs_qs_difference  | 54.754837 |
| eval_discount_q         | 190       |
| eval_ep_rewmean         | 427       |
| eval_eplenmean          | 149       |
| eval_qs                 | 214.54637 |
| eval_qs_difference      | 54.7      |
| eval_time_elapsed       | 3         |
| total timesteps         | 30001     |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 2.05      |
| env_time                | 43        |
| ep_rewmean              | 126       |
| episodes                | 1208      |
| eplenmean               | 61.3      |
| fps                     | 32        |
| mean 100 episode reward | 126       |
| n_updates               | 10800     |
| q_grad_norm             | 3559.778  |
| qfs_loss                | 108.98581 |
| qs_abs_difference       | 59.8      |
| qs_difference           | 59.8      |
| qs_mean                 | 216.69972 |
| time_elapsed            | 939       |
| total timesteps         | 30331     |
| train_time              | 140       |
| update_time             | 729       |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 1.8       |
| env_time                | 44        |
| ep_rewmean              | 144       |
| episodes                | 1212      |
| eplenmean               | 66.7      |
| fps                     | 31        |
| mean 100 episode reward | 144       |
| n_updates               | 12000     |
| q_grad_norm             | 4428.4404 |
| qfs_loss                | 134.1701  |
| qs_abs_difference       | 61.5      |
| qs_difference           | 61.5      |
| qs_mean                 | 232.4851  |
| time_elapsed            | 985       |
| total timesteps         | 30959     |
| train_time              | 156       |
| update_time             | 758       |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 1.5       |
| env_time                | 45        |
| ep_rewmean              | 157       |
| episodes                | 1216      |
| eplenmean               | 71.1      |
| fps                     | 30        |
| mean 100 episode reward | 158       |
| n_updates               | 13000     |
| q_grad_norm             | 4838.1533 |
| qfs_loss                | 135.67886 |
| qs_abs_difference       | 176       |
| qs_difference           | 176       |
| qs_mean                 | 253.45697 |
| time_elapsed            | 1023      |
| total timesteps         | 31486     |
| train_time              | 171       |
| update_time             | 780       |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 4.64      |
| env_time                | 46        |
| ep_rewmean              | 166       |
| episodes                | 1220      |
| eplenmean               | 74.3      |
| fps                     | 30        |
| mean 100 episode reward | 166       |
| n_updates               | 13800     |
| q_grad_norm             | 6298.897  |
| qfs_loss                | 159.97728 |
| qs_abs_difference       | 158       |
| qs_difference           | 158       |
| qs_mean                 | 233.66917 |
| time_elapsed            | 1051      |
| total timesteps         | 31899     |
| train_time              | 179       |
| update_time             | 798       |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 1.79      |
| env_time                | 46        |
| ep_rewmean              | 182       |
| episodes                | 1224      |
| eplenmean               | 79        |
| fps                     | 29        |
| mean 100 episode reward | 182       |
| n_updates               | 15000     |
| q_grad_norm             | 6480.578  |
| qfs_loss                | 152.06636 |
| qs_abs_difference       | 120       |
| qs_difference           | 120       |
| qs_mean                 | 240.34238 |
| time_elapsed            | 1090      |
| total timesteps         | 32472     |
| train_time              | 192       |
| update_time             | 822       |
---------------------------------------
----------------------------------------
| act_time                | 8          |
| current_lr              | 0.0003     |
| discount_q              | 4.48       |
| env_time                | 47         |
| ep_rewmean              | 194        |
| episodes                | 1228       |
| eplenmean               | 83.2       |
| fps                     | 29         |
| mean 100 episode reward | 194        |
| n_updates               | 16000      |
| q_grad_norm             | 5742.541   |
| qfs_loss                | 123.603806 |
| qs_abs_difference       | 104        |
| qs_difference           | 104        |
| qs_mean                 | 248.5443   |
| time_elapsed            | 1122       |
| total timesteps         | 32972      |
| train_time              | 203        |
| update_time             | 843        |
----------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 2.74      |
| env_time                | 48        |
| ep_rewmean              | 207       |
| episodes                | 1232      |
| eplenmean               | 88        |
| fps                     | 28        |
| mean 100 episode reward | 207       |
| n_updates               | 17200     |
| q_grad_norm             | 6669.576  |
| qfs_loss                | 141.53424 |
| qs_abs_difference       | 130       |
| qs_difference           | 130       |
| qs_mean                 | 245.39813 |
| time_elapsed            | 1164      |
| total timesteps         | 33502     |
| train_time              | 216       |
| update_time             | 871       |
---------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 5.15      |
| env_time                | 49        |
| ep_rewmean              | 222       |
| episodes                | 1236      |
| eplenmean               | 92.3      |
| fps                     | 28        |
| mean 100 episode reward | 222       |
| n_updates               | 18200     |
| q_grad_norm             | 6803.0645 |
| qfs_loss                | 162.40292 |
| qs_abs_difference       | 48.7      |
| qs_difference           | 48.6      |
| qs_mean                 | 224.13235 |
| time_elapsed            | 1200      |
| total timesteps         | 34023     |
| train_time              | 227       |
| update_time             | 894       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 2.16      |
| env_time                | 49        |
| ep_rewmean              | 240       |
| episodes                | 1240      |
| eplenmean               | 97.9      |
| fps                     | 27        |
| mean 100 episode reward | 240       |
| n_updates               | 19400     |
| q_grad_norm             | 6694.0283 |
| qfs_loss                | 169.2783  |
| qs_abs_difference       | 54.6      |
| qs_difference           | 53        |
| qs_mean                 | 231.66612 |
| time_elapsed            | 1244      |
| total timesteps         | 34637     |
| train_time              | 241       |
| update_time             | 923       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 4.25      |
| env_time                | 50        |
| ep_rewmean              | 245       |
| episodes                | 1244      |
| eplenmean               | 100       |
| fps                     | 27        |
| mean 100 episode reward | 245       |
| n_updates               | 20000     |
| q_grad_norm             | 7274.3555 |
| qfs_loss                | 179.08313 |
| qs_abs_difference       | 230       |
| qs_difference           | 230       |
| qs_mean                 | 270.8779  |
| time_elapsed            | 1266      |
| total timesteps         | 34964     |
| train_time              | 248       |
| update_time             | 937       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 16.9      |
| env_time                | 50        |
| ep_rewmean              | 252       |
| episodes                | 1248      |
| eplenmean               | 102       |
| fps                     | 27        |
| mean 100 episode reward | 252       |
| n_updates               | 20800     |
| q_grad_norm             | 6811.1313 |
| qfs_loss                | 147.93951 |
| qs_abs_difference       | 123       |
| qs_difference           | 123       |
| qs_mean                 | 254.42401 |
| time_elapsed            | 1297      |
| total timesteps         | 35312     |
| train_time              | 260       |
| update_time             | 955       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 3.26      |
| env_time                | 51        |
| ep_rewmean              | 263       |
| episodes                | 1252      |
| eplenmean               | 106       |
| fps                     | 26        |
| mean 100 episode reward | 263       |
| n_updates               | 21800     |
| q_grad_norm             | 6645.846  |
| qfs_loss                | 164.80566 |
| qs_abs_difference       | 141       |
| qs_difference           | 141       |
| qs_mean                 | 264.42346 |
| time_elapsed            | 1333      |
| total timesteps         | 35820     |
| train_time              | 271       |
| update_time             | 979       |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 3.54      |
| env_time                | 52        |
| ep_rewmean              | 274       |
| episodes                | 1256      |
| eplenmean               | 110       |
| fps                     | 26        |
| mean 100 episode reward | 274       |
| n_updates               | 22800     |
| q_grad_norm             | 6426.368  |
| qfs_loss                | 147.80975 |
| qs_abs_difference       | 113       |
| qs_difference           | 113       |
| qs_mean                 | 244.16174 |
| time_elapsed            | 1366      |
| total timesteps         | 36331     |
| train_time              | 282       |
| update_time             | 1000      |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 2.27      |
| env_time                | 52        |
| ep_rewmean              | 288       |
| episodes                | 1260      |
| eplenmean               | 114       |
| fps                     | 26        |
| mean 100 episode reward | 288       |
| n_updates               | 24000     |
| q_grad_norm             | 7279.042  |
| qfs_loss                | 151.27104 |
| qs_abs_difference       | 86.2      |
| qs_difference           | 86.2      |
| qs_mean                 | 231.23204 |
| time_elapsed            | 1406      |
| total timesteps         | 36904     |
| train_time              | 294       |
| update_time             | 1026      |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 2.68      |
| env_time                | 53        |
| ep_rewmean              | 301       |
| episodes                | 1264      |
| eplenmean               | 118       |
| fps                     | 25        |
| mean 100 episode reward | 300       |
| n_updates               | 25000     |
| q_grad_norm             | 7038.5093 |
| qfs_loss                | 168.84889 |
| qs_abs_difference       | 106       |
| qs_difference           | 106       |
| qs_mean                 | 240.18282 |
| time_elapsed            | 1444      |
| total timesteps         | 37448     |
| train_time              | 307       |
| update_time             | 1050      |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 2.9       |
| env_time                | 54        |
| ep_rewmean              | 312       |
| episodes                | 1268      |
| eplenmean               | 122       |
| fps                     | 25        |
| mean 100 episode reward | 312       |
| n_updates               | 26000     |
| q_grad_norm             | 7050.0    |
| qfs_loss                | 156.50168 |
| qs_abs_difference       | 111       |
| qs_difference           | 111       |
| qs_mean                 | 235.13765 |
| time_elapsed            | 1480      |
| total timesteps         | 37980     |
| train_time              | 318       |
| update_time             | 1074      |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 2.34      |
| env_time                | 55        |
| ep_rewmean              | 322       |
| episodes                | 1272      |
| eplenmean               | 125       |
| fps                     | 25        |
| mean 100 episode reward | 322       |
| n_updates               | 27200     |
| q_grad_norm             | 6294.1636 |
| qfs_loss                | 148.12872 |
| qs_abs_difference       | 94        |
| qs_difference           | 94        |
| qs_mean                 | 235.62912 |
| time_elapsed            | 1528      |
| total timesteps         | 38553     |
| train_time              | 336       |
| update_time             | 1103      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 2.84      |
| env_time                | 55        |
| ep_rewmean              | 331       |
| episodes                | 1276      |
| eplenmean               | 127       |
| fps                     | 24        |
| mean 100 episode reward | 331       |
| n_updates               | 28200     |
| q_grad_norm             | 7216.652  |
| qfs_loss                | 151.59238 |
| qs_abs_difference       | 111       |
| qs_difference           | 111       |
| qs_mean                 | 227.73187 |
| time_elapsed            | 1567      |
| total timesteps         | 39081     |
| train_time              | 347       |
| update_time             | 1129      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 2.78      |
| env_time                | 56        |
| ep_rewmean              | 339       |
| episodes                | 1280      |
| eplenmean               | 129       |
| fps                     | 24        |
| mean 100 episode reward | 339       |
| n_updates               | 29400     |
| q_grad_norm             | 6359.591  |
| qfs_loss                | 118.28021 |
| qs_abs_difference       | 84.4      |
| qs_difference           | 84.4      |
| qs_mean                 | 220.45047 |
| time_elapsed            | 1611      |
| total timesteps         | 39626     |
| train_time              | 360       |
| update_time             | 1159      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 46.6      |
| env_time                | 57        |
| ep_rewmean              | 340       |
| episodes                | 1284      |
| eplenmean               | 129       |
| fps                     | 24        |
| mean 100 episode reward | 340       |
| n_updates               | 30000     |
| q_grad_norm             | 6262.0425 |
| qfs_loss                | 138.28117 |
| qs_abs_difference       | 42.7      |
| qs_difference           | 37.1      |
| qs_mean                 | 216.96779 |
| time_elapsed            | 1631      |
| total timesteps         | 39929     |
| train_time              | 366       |
| update_time             | 1172      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 173       |
| eval_abs_qs_difference  | 40.102356 |
| eval_discount_q         | 198       |
| eval_ep_rewmean         | 452       |
| eval_eplenmean          | 148       |
| eval_qs                 | 210.25731 |
| eval_qs_difference      | 36.8      |
| eval_time_elapsed       | 2         |
| total timesteps         | 40001     |
---------------------------------------
---------------------------------------
| act_time                | 14        |
| current_lr              | 0.0003    |
| discount_q              | 2.4       |
| env_time                | 57        |
| ep_rewmean              | 351       |
| episodes                | 1288      |
| eplenmean               | 131       |
| fps                     | 24        |
| mean 100 episode reward | 351       |
| n_updates               | 31200     |
| q_grad_norm             | 6203.419  |
| qfs_loss                | 145.0901  |
| qs_abs_difference       | 36.4      |
| qs_difference           | 34        |
| qs_mean                 | 204.04362 |
| time_elapsed            | 1676      |
| total timesteps         | 40517     |
| train_time              | 379       |
| update_time             | 1200      |
---------------------------------------
---------------------------------------
| act_time                | 15        |
| current_lr              | 0.0003    |
| discount_q              | 2.99      |
| env_time                | 63        |
| ep_rewmean              | 358       |
| episodes                | 1292      |
| eplenmean               | 133       |
| fps                     | 23        |
| mean 100 episode reward | 358       |
| n_updates               | 32200     |
| q_grad_norm             | 5426.4473 |
| qfs_loss                | 123.20157 |
| qs_abs_difference       | 32.4      |
| qs_difference           | 30.5      |
| qs_mean                 | 203.17355 |
| time_elapsed            | 1746      |
| total timesteps         | 41089     |
| train_time              | 396       |
| update_time             | 1244      |
---------------------------------------
---------------------------------------
| act_time                | 15        |
| current_lr              | 0.0003    |
| discount_q              | 7.12      |
| env_time                | 64        |
| ep_rewmean              | 360       |
| episodes                | 1296      |
| eplenmean               | 133       |
| fps                     | 23        |
| mean 100 episode reward | 360       |
| n_updates               | 33200     |
| q_grad_norm             | 4867.379  |
| qfs_loss                | 100.25168 |
| qs_abs_difference       | 27.7      |
| qs_difference           | 14.1      |
| qs_mean                 | 189.93333 |
| time_elapsed            | 1784      |
| total timesteps         | 41573     |
| train_time              | 408       |
| update_time             | 1270      |
---------------------------------------
---------------------------------------
| act_time                | 15        |
| current_lr              | 0.0003    |
| discount_q              | 2.12      |
| env_time                | 65        |
| ep_rewmean              | 362       |
| episodes                | 1300      |
| eplenmean               | 132       |
| fps                     | 23        |
| mean 100 episode reward | 362       |
| n_updates               | 34400     |
| q_grad_norm             | 5615.3994 |
| qfs_loss                | 119.34315 |
| qs_abs_difference       | 42.6      |
| qs_difference           | 42.6      |
| qs_mean                 | 206.33083 |
| time_elapsed            | 1832      |
| total timesteps         | 42168     |
| train_time              | 422       |
| update_time             | 1302      |
---------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 1.03      |
| env_time                | 66        |
| ep_rewmean              | 362       |
| episodes                | 1304      |
| eplenmean               | 131       |
| fps                     | 22        |
| mean 100 episode reward | 362       |
| n_updates               | 35800     |
| q_grad_norm             | 5729.402  |
| qfs_loss                | 131.03552 |
| qs_abs_difference       | 45.7      |
| qs_difference           | 44.1      |
| qs_mean                 | 210.90813 |
| time_elapsed            | 1886      |
| total timesteps         | 42854     |
| train_time              | 437       |
| update_time             | 1340      |
---------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 1.14      |
| env_time                | 66        |
| ep_rewmean              | 364       |
| episodes                | 1308      |
| eplenmean               | 132       |
| fps                     | 22        |
| mean 100 episode reward | 364       |
| n_updates               | 37200     |
| q_grad_norm             | 6335.2524 |
| qfs_loss                | 138.89716 |
| qs_abs_difference       | 33.5      |
| qs_difference           | 33.5      |
| qs_mean                 | 207.70476 |
| time_elapsed            | 1937      |
| total timesteps         | 43532     |
| train_time              | 452       |
| update_time             | 1374      |
---------------------------------------
---------------------------------------
| act_time                | 18        |
| current_lr              | 0.0003    |
| discount_q              | 0.96      |
| env_time                | 71        |
| ep_rewmean              | 366       |
| episodes                | 1312      |
| eplenmean               | 133       |
| fps                     | 18        |
| mean 100 episode reward | 366       |
| n_updates               | 38600     |
| q_grad_norm             | 6529.197  |
| qfs_loss                | 138.50604 |
| qs_abs_difference       | 52.4      |
| qs_difference           | 52.4      |
| qs_mean                 | 211.24483 |
| time_elapsed            | 2357      |
| total timesteps         | 44221     |
| train_time              | 537       |
| update_time             | 1703      |
---------------------------------------
---------------------------------------
| act_time                | 19        |
| current_lr              | 0.0003    |
| discount_q              | 1.1       |
| env_time                | 90        |
| ep_rewmean              | 369       |
| episodes                | 1316      |
| eplenmean               | 134       |
| fps                     | 18        |
| mean 100 episode reward | 369       |
| n_updates               | 39800     |
| q_grad_norm             | 5018.4883 |
| qfs_loss                | 99.07094  |
| qs_abs_difference       | 91.1      |
| qs_difference           | 90.5      |
| qs_mean                 | 232.6449  |
| time_elapsed            | 2493      |
| total timesteps         | 44891     |
| train_time              | 624       |
| update_time             | 1732      |
---------------------------------------
---------------------------------------
| act_time                | 19        |
| current_lr              | 0.0003    |
| discount_q              | 1.38      |
| env_time                | 91        |
| ep_rewmean              | 378       |
| episodes                | 1320      |
| eplenmean               | 136       |
| fps                     | 17        |
| mean 100 episode reward | 378       |
| n_updates               | 41200     |
| q_grad_norm             | 5741.7427 |
| qfs_loss                | 135.04698 |
| qs_abs_difference       | 108       |
| qs_difference           | 107       |
| qs_mean                 | 236.83809 |
| time_elapsed            | 2550      |
| total timesteps         | 45542     |
| train_time              | 640       |
| update_time             | 1771      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 2.43      |
| env_time                | 91        |
| ep_rewmean              | 377       |
| episodes                | 1324      |
| eplenmean               | 137       |
| fps                     | 17        |
| mean 100 episode reward | 377       |
| n_updates               | 42400     |
| q_grad_norm             | 4538.0493 |
| qfs_loss                | 111.30518 |
| qs_abs_difference       | 66.6      |
| qs_difference           | 66.6      |
| qs_mean                 | 237.90144 |
| time_elapsed            | 2600      |
| total timesteps         | 46156     |
| train_time              | 654       |
| update_time             | 1806      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 5.84      |
| env_time                | 92        |
| ep_rewmean              | 380       |
| episodes                | 1328      |
| eplenmean               | 137       |
| fps                     | 17        |
| mean 100 episode reward | 380       |
| n_updates               | 43400     |
| q_grad_norm             | 5704.7886 |
| qfs_loss                | 138.35274 |
| qs_abs_difference       | 38        |
| qs_difference           | 35.8      |
| qs_mean                 | 210.08098 |
| time_elapsed            | 2641      |
| total timesteps         | 46677     |
| train_time              | 666       |
| update_time             | 1834      |
---------------------------------------
---------------------------------------
| act_time                | 21        |
| current_lr              | 0.0003    |
| discount_q              | 1.23      |
| env_time                | 93        |
| ep_rewmean              | 387       |
| episodes                | 1332      |
| eplenmean               | 138       |
| fps                     | 17        |
| mean 100 episode reward | 387       |
| n_updates               | 44800     |
| q_grad_norm             | 5164.399  |
| qfs_loss                | 119.73992 |
| qs_abs_difference       | 37.1      |
| qs_difference           | 36.8      |
| qs_mean                 | 208.55211 |
| time_elapsed            | 2696      |
| total timesteps         | 47351     |
| train_time              | 682       |
| update_time             | 1871      |
---------------------------------------
---------------------------------------
| act_time                | 21        |
| current_lr              | 0.0003    |
| discount_q              | 1.22      |
| env_time                | 94        |
| ep_rewmean              | 392       |
| episodes                | 1336      |
| eplenmean               | 140       |
| fps                     | 17        |
| mean 100 episode reward | 392       |
| n_updates               | 46200     |
| q_grad_norm             | 4523.357  |
| qfs_loss                | 89.633255 |
| qs_abs_difference       | 24.8      |
| qs_difference           | 23.7      |
| qs_mean                 | 209.02411 |
| time_elapsed            | 2750      |
| total timesteps         | 48040     |
| train_time              | 698       |
| update_time             | 1907      |
---------------------------------------
----------------------------------------
| act_time                | 22         |
| current_lr              | 0.0003     |
| discount_q              | 0.961      |
| env_time                | 95         |
| ep_rewmean              | 396        |
| episodes                | 1340       |
| eplenmean               | 141        |
| fps                     | 17         |
| mean 100 episode reward | 396        |
| n_updates               | 47600      |
| q_grad_norm             | 5246.8833  |
| qfs_loss                | 109.451904 |
| qs_abs_difference       | 15.1       |
| qs_difference           | 11.1       |
| qs_mean                 | 208.42322  |
| time_elapsed            | 2809       |
| total timesteps         | 48751      |
| train_time              | 714        |
| update_time             | 1948       |
----------------------------------------
---------------------------------------
| act_time                | 22        |
| current_lr              | 0.0003    |
| discount_q              | 0.458     |
| env_time                | 96        |
| ep_rewmean              | 415       |
| episodes                | 1344      |
| eplenmean               | 146       |
| fps                     | 17        |
| mean 100 episode reward | 415       |
| n_updates               | 49200     |
| q_grad_norm             | 4891.104  |
| qfs_loss                | 95.45961  |
| qs_abs_difference       | 13.2      |
| qs_difference           | 8.56      |
| qs_mean                 | 220.01816 |
| time_elapsed            | 2876      |
| total timesteps         | 49555     |
| train_time              | 733       |
| update_time             | 1994      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 179       |
| eval_abs_qs_difference  | 181.46515 |
| eval_discount_q         | 112       |
| eval_ep_rewmean         | 184       |
| eval_eplenmean          | 93.3      |
| eval_qs                 | 259.6826  |
| eval_qs_difference      | 181       |
| eval_time_elapsed       | 1         |
| total timesteps         | 50001     |
---------------------------------------
---------------------------------------
| act_time                | 23        |
| current_lr              | 0.0003    |
| discount_q              | 0.821     |
| env_time                | 97        |
| ep_rewmean              | 427       |
| episodes                | 1348      |
| eplenmean               | 150       |
| fps                     | 17        |
| mean 100 episode reward | 427       |
| n_updates               | 50600     |
| q_grad_norm             | 5359.862  |
| qfs_loss                | 115.23072 |
| qs_abs_difference       | 46.7      |
| qs_difference           | 42.8      |
| qs_mean                 | 222.47565 |
| time_elapsed            | 2937      |
| total timesteps         | 50281     |
| train_time              | 749       |
| update_time             | 2036      |
---------------------------------------
---------------------------------------
| act_time                | 23        |
| current_lr              | 0.0003    |
| discount_q              | 0.765     |
| env_time                | 98        |
| ep_rewmean              | 431       |
| episodes                | 1352      |
| eplenmean               | 151       |
| fps                     | 17        |
| mean 100 episode reward | 431       |
| n_updates               | 51800     |
| q_grad_norm             | 4937.008  |
| qfs_loss                | 115.83971 |
| qs_abs_difference       | 185       |
| qs_difference           | 185       |
| qs_mean                 | 261.7245  |
| time_elapsed            | 2984      |
| total timesteps         | 50892     |
| train_time              | 763       |
| update_time             | 2068      |
---------------------------------------
----------------------------------------
| act_time                | 24         |
| current_lr              | 0.0003     |
| discount_q              | 0.388      |
| env_time                | 99         |
| ep_rewmean              | 438        |
| episodes                | 1356       |
| eplenmean               | 154        |
| fps                     | 16         |
| mean 100 episode reward | 438        |
| n_updates               | 53400      |
| q_grad_norm             | 4984.217   |
| qfs_loss                | 109.942116 |
| qs_abs_difference       | 35.6       |
| qs_difference           | 32         |
| qs_mean                 | 222.57852  |
| time_elapsed            | 3052       |
| total timesteps         | 51691      |
| train_time              | 784        |
| update_time             | 2113       |
----------------------------------------
---------------------------------------
| act_time                | 24        |
| current_lr              | 0.0003    |
| discount_q              | 83        |
| env_time                | 99        |
| ep_rewmean              | 429       |
| episodes                | 1360      |
| eplenmean               | 151       |
| fps                     | 16        |
| mean 100 episode reward | 429       |
| n_updates               | 54000     |
| q_grad_norm             | 5007.9243 |
| qfs_loss                | 112.00435 |
| qs_abs_difference       | 46.4      |
| qs_difference           | 38.9      |
| qs_mean                 | 230.1207  |
| time_elapsed            | 3077      |
| total timesteps         | 51963     |
| train_time              | 791       |
| update_time             | 2130      |
---------------------------------------
---------------------------------------
| act_time                | 24        |
| current_lr              | 0.0003    |
| discount_q              | 21.8      |
| env_time                | 100       |
| ep_rewmean              | 427       |
| episodes                | 1364      |
| eplenmean               | 150       |
| fps                     | 16        |
| mean 100 episode reward | 427       |
| n_updates               | 55000     |
| q_grad_norm             | 4754.693  |
| qfs_loss                | 117.49628 |
| qs_abs_difference       | 54        |
| qs_difference           | 51.3      |
| qs_mean                 | 254.30556 |
| time_elapsed            | 3121      |
| total timesteps         | 52417     |
| train_time              | 806       |
| update_time             | 2158      |
---------------------------------------
---------------------------------------
| act_time                | 25        |
| current_lr              | 0.0003    |
| discount_q              | 0.654     |
| env_time                | 101       |
| ep_rewmean              | 438       |
| episodes                | 1368      |
| eplenmean               | 152       |
| fps                     | 16        |
| mean 100 episode reward | 438       |
| n_updates               | 56400     |
| q_grad_norm             | 5839.3237 |
| qfs_loss                | 146.36824 |
| qs_abs_difference       | 49.3      |
| qs_difference           | 46.8      |
| qs_mean                 | 244.42256 |
| time_elapsed            | 3182      |
| total timesteps         | 53188     |
| train_time              | 825       |
| update_time             | 2197      |
---------------------------------------
---------------------------------------
| act_time                | 25        |
| current_lr              | 0.0003    |
| discount_q              | 2.1       |
| env_time                | 102       |
| ep_rewmean              | 432       |
| episodes                | 1372      |
| eplenmean               | 150       |
| fps                     | 16        |
| mean 100 episode reward | 432       |
| n_updates               | 57200     |
| q_grad_norm             | 5052.4478 |
| qfs_loss                | 131.71956 |
| qs_abs_difference       | 224       |
| qs_difference           | 224       |
| qs_mean                 | 265.00613 |
| time_elapsed            | 3215      |
| total timesteps         | 53597     |
| train_time              | 834       |
| update_time             | 2220      |
---------------------------------------
---------------------------------------
| act_time                | 26        |
| current_lr              | 0.0003    |
| discount_q              | 0.713     |
| env_time                | 103       |
| ep_rewmean              | 439       |
| episodes                | 1376      |
| eplenmean               | 154       |
| fps                     | 16        |
| mean 100 episode reward | 439       |
| n_updates               | 59000     |
| q_grad_norm             | 4961.9727 |
| qfs_loss                | 125.23761 |
| qs_abs_difference       | 59.4      |
| qs_difference           | 58.1      |
| qs_mean                 | 266.1229  |
| time_elapsed            | 3288      |
| total timesteps         | 54487     |
| train_time              | 854       |
| update_time             | 2271      |
---------------------------------------
---------------------------------------
| act_time                | 26        |
| current_lr              | 0.0003    |
| discount_q              | 1.54      |
| env_time                | 104       |
| ep_rewmean              | 437       |
| episodes                | 1380      |
| eplenmean               | 153       |
| fps                     | 16        |
| mean 100 episode reward | 437       |
| n_updates               | 60000     |
| q_grad_norm             | 5142.8247 |
| qfs_loss                | 119.44113 |
| qs_abs_difference       | 233       |
| qs_difference           | 233       |
| qs_mean                 | 274.01672 |
| time_elapsed            | 3332      |
| total timesteps         | 54915     |
| train_time              | 866       |
| update_time             | 2302      |
---------------------------------------
---------------------------------------
| act_time                | 27        |
| current_lr              | 0.0003    |
| discount_q              | 18.3      |
| env_time                | 105       |
| ep_rewmean              | 444       |
| episodes                | 1384      |
| eplenmean               | 154       |
| fps                     | 16        |
| mean 100 episode reward | 444       |
| n_updates               | 60800     |
| q_grad_norm             | 4830.339  |
| qfs_loss                | 129.72466 |
| qs_abs_difference       | 19        |
| qs_difference           | 8.96      |
| qs_mean                 | 231.46983 |
| time_elapsed            | 3368      |
| total timesteps         | 55355     |
| train_time              | 875       |
| update_time             | 2327      |
---------------------------------------
---------------------------------------
| act_time                | 28        |
| current_lr              | 0.0003    |
| discount_q              | 0.123     |
| env_time                | 106       |
| ep_rewmean              | 454       |
| episodes                | 1388      |
| eplenmean               | 157       |
| fps                     | 16        |
| mean 100 episode reward | 454       |
| n_updates               | 62600     |
| q_grad_norm             | 5201.941  |
| qfs_loss                | 116.73916 |
| qs_abs_difference       | 38.8      |
| qs_difference           | 38.6      |
| qs_mean                 | 229.53116 |
| time_elapsed            | 3447      |
| total timesteps         | 56262     |
| train_time              | 900       |
| update_time             | 2380      |
---------------------------------------
----------------------------------------
| act_time                | 28         |
| current_lr              | 0.0003     |
| discount_q              | 1.54       |
| env_time                | 107        |
| ep_rewmean              | 459        |
| episodes                | 1392       |
| eplenmean               | 158        |
| fps                     | 16         |
| mean 100 episode reward | 459        |
| n_updates               | 64000      |
| q_grad_norm             | 4913.59    |
| qfs_loss                | 111.956436 |
| qs_abs_difference       | 27.8       |
| qs_difference           | 27.2       |
| qs_mean                 | 239.25868  |
| time_elapsed            | 3505       |
| total timesteps         | 56928      |
| train_time              | 915        |
| update_time             | 2420       |
----------------------------------------
---------------------------------------
| act_time                | 29        |
| current_lr              | 0.0003    |
| discount_q              | 0.691     |
| env_time                | 108       |
| ep_rewmean              | 470       |
| episodes                | 1396      |
| eplenmean               | 161       |
| fps                     | 16        |
| mean 100 episode reward | 470       |
| n_updates               | 65400     |
| q_grad_norm             | 5369.8477 |
| qfs_loss                | 147.38763 |
| qs_abs_difference       | 19.1      |
| qs_difference           | 15.2      |
| qs_mean                 | 239.78171 |
| time_elapsed            | 3566      |
| total timesteps         | 57692     |
| train_time              | 934       |
| update_time             | 2462      |
---------------------------------------
---------------------------------------
| act_time                | 29        |
| current_lr              | 0.0003    |
| discount_q              | 2.02      |
| env_time                | 109       |
| ep_rewmean              | 471       |
| episodes                | 1400      |
| eplenmean               | 161       |
| fps                     | 16        |
| mean 100 episode reward | 471       |
| n_updates               | 66600     |
| q_grad_norm             | 4330.874  |
| qfs_loss                | 108.7118  |
| qs_abs_difference       | 65        |
| qs_difference           | 64.7      |
| qs_mean                 | 237.12178 |
| time_elapsed            | 3621      |
| total timesteps         | 58296     |
| train_time              | 948       |
| update_time             | 2501      |
---------------------------------------
----------------------------------------
| act_time                | 29         |
| current_lr              | 0.0003     |
| discount_q              | 1.48       |
| env_time                | 109        |
| ep_rewmean              | 472        |
| episodes                | 1404       |
| eplenmean               | 161        |
| fps                     | 16         |
| mean 100 episode reward | 472        |
| n_updates               | 68000      |
| q_grad_norm             | 5517.9824  |
| qfs_loss                | 123.972626 |
| qs_abs_difference       | 39         |
| qs_difference           | 39         |
| qs_mean                 | 248.4095   |
| time_elapsed            | 3683       |
| total timesteps         | 58969      |
| train_time              | 964        |
| update_time             | 2545       |
----------------------------------------
----------------------------------------
| act_time                | 30         |
| current_lr              | 0.0003     |
| discount_q              | 1.18       |
| env_time                | 110        |
| ep_rewmean              | 474        |
| episodes                | 1408       |
| eplenmean               | 161        |
| fps                     | 15         |
| mean 100 episode reward | 474        |
| n_updates               | 69400      |
| q_grad_norm             | 5321.305   |
| qfs_loss                | 112.241005 |
| qs_abs_difference       | 58.9       |
| qs_difference           | 58.9       |
| qs_mean                 | 254.80087  |
| time_elapsed            | 3743       |
| total timesteps         | 59653      |
| train_time              | 981        |
| update_time             | 2587       |
----------------------------------------
---------------------------------------
| eval mean 100 episod... | 247       |
| eval_abs_qs_difference  | 33.46788  |
| eval_discount_q         | 237       |
| eval_ep_rewmean         | 694       |
| eval_eplenmean          | 198       |
| eval_qs                 | 257.25232 |
| eval_qs_difference      | 26.3      |
| eval_time_elapsed       | 4         |
| total timesteps         | 60001     |
---------------------------------------
---------------------------------------
| act_time                | 30        |
| current_lr              | 0.0003    |
| discount_q              | 23.7      |
| env_time                | 111       |
| ep_rewmean              | 466       |
| episodes                | 1412      |
| eplenmean               | 158       |
| fps                     | 15        |
| mean 100 episode reward | 466       |
| n_updates               | 70200     |
| q_grad_norm             | 5133.6567 |
| qfs_loss                | 123.01989 |
| qs_abs_difference       | 37.9      |
| qs_difference           | 37        |
| qs_mean                 | 237.57545 |
| time_elapsed            | 3782      |
| total timesteps         | 60039     |
| train_time              | 990       |
| update_time             | 2611      |
---------------------------------------
----------------------------------------
| act_time                | 31         |
| current_lr              | 0.0003     |
| discount_q              | 1.31       |
| env_time                | 112        |
| ep_rewmean              | 470        |
| episodes                | 1416       |
| eplenmean               | 158        |
| fps                     | 15         |
| mean 100 episode reward | 470        |
| n_updates               | 71600      |
| q_grad_norm             | 4648.9126  |
| qfs_loss                | 110.171875 |
| qs_abs_difference       | 51.8       |
| qs_difference           | 51.8       |
| qs_mean                 | 257.1702   |
| time_elapsed            | 3845       |
| total timesteps         | 60732      |
| train_time              | 1006       |
| update_time             | 2656       |
----------------------------------------
---------------------------------------
| act_time                | 31        |
| current_lr              | 0.0003    |
| discount_q              | 3.15      |
| env_time                | 113       |
| ep_rewmean              | 472       |
| episodes                | 1420      |
| eplenmean               | 158       |
| fps                     | 15        |
| mean 100 episode reward | 472       |
| n_updates               | 72800     |
| q_grad_norm             | 5388.051  |
| qfs_loss                | 113.45406 |
| qs_abs_difference       | 70.1      |
| qs_difference           | 69.3      |
| qs_mean                 | 285.91525 |
| time_elapsed            | 3901      |
| total timesteps         | 61374     |
| train_time              | 1021      |
| update_time             | 2696      |
---------------------------------------
---------------------------------------
| act_time                | 32        |
| current_lr              | 0.0003    |
| discount_q              | 1.18      |
| env_time                | 114       |
| ep_rewmean              | 478       |
| episodes                | 1424      |
| eplenmean               | 159       |
| fps                     | 15        |
| mean 100 episode reward | 478       |
| n_updates               | 74200     |
| q_grad_norm             | 5868.747  |
| qfs_loss                | 130.58447 |
| qs_abs_difference       | 47.1      |
| qs_difference           | 47.1      |
| qs_mean                 | 253.05405 |
| time_elapsed            | 3965      |
| total timesteps         | 62065     |
| train_time              | 1037      |
| update_time             | 2742      |
---------------------------------------
---------------------------------------
| act_time                | 32        |
| current_lr              | 0.0003    |
| discount_q              | 2.9       |
| env_time                | 114       |
| ep_rewmean              | 481       |
| episodes                | 1428      |
| eplenmean               | 160       |
| fps                     | 15        |
| mean 100 episode reward | 481       |
| n_updates               | 75400     |
| q_grad_norm             | 5652.629  |
| qfs_loss                | 147.99069 |
| qs_abs_difference       | 84        |
| qs_difference           | 84        |
| qs_mean                 | 251.13765 |
| time_elapsed            | 4017      |
| total timesteps         | 62635     |
| train_time              | 1051      |
| update_time             | 2779      |
---------------------------------------
---------------------------------------
| act_time                | 32        |
| current_lr              | 0.0003    |
| discount_q              | 0.855     |
| env_time                | 115       |
| ep_rewmean              | 483       |
| episodes                | 1432      |
| eplenmean               | 160       |
| fps                     | 15        |
| mean 100 episode reward | 483       |
| n_updates               | 76800     |
| q_grad_norm             | 6125.5356 |
| qfs_loss                | 127.81694 |
| qs_abs_difference       | 138       |
| qs_difference           | 138       |
| qs_mean                 | 310.2439  |
| time_elapsed            | 4078      |
| total timesteps         | 63350     |
| train_time              | 1068      |
| update_time             | 2822      |
---------------------------------------
---------------------------------------
| act_time                | 33        |
| current_lr              | 0.0003    |
| discount_q              | 1.17      |
| env_time                | 116       |
| ep_rewmean              | 485       |
| episodes                | 1436      |
| eplenmean               | 160       |
| fps                     | 15        |
| mean 100 episode reward | 485       |
| n_updates               | 78200     |
| q_grad_norm             | 4990.0225 |
| qfs_loss                | 109.72981 |
| qs_abs_difference       | 35.4      |
| qs_difference           | 35.4      |
| qs_mean                 | 254.92812 |
| time_elapsed            | 4146      |
| total timesteps         | 64068     |
| train_time              | 1084      |
| update_time             | 2872      |
---------------------------------------
---------------------------------------
| act_time                | 33        |
| current_lr              | 0.0003    |
| discount_q              | 6         |
| env_time                | 117       |
| ep_rewmean              | 476       |
| episodes                | 1440      |
| eplenmean               | 158       |
| fps                     | 15        |
| mean 100 episode reward | 476       |
| n_updates               | 79200     |
| q_grad_norm             | 5069.277  |
| qfs_loss                | 111.56619 |
| qs_abs_difference       | 130       |
| qs_difference           | 130       |
| qs_mean                 | 263.69385 |
| time_elapsed            | 4191      |
| total timesteps         | 64530     |
| train_time              | 1096      |
| update_time             | 2904      |
---------------------------------------
---------------------------------------
| act_time                | 34        |
| current_lr              | 0.0003    |
| discount_q              | 1.2       |
| env_time                | 118       |
| ep_rewmean              | 475       |
| episodes                | 1444      |
| eplenmean               | 157       |
| fps                     | 15        |
| mean 100 episode reward | 475       |
| n_updates               | 80600     |
| q_grad_norm             | 5926.9893 |
| qfs_loss                | 127.55427 |
| qs_abs_difference       | 51.4      |
| qs_difference           | 50.8      |
| qs_mean                 | 271.51163 |
| time_elapsed            | 4256      |
| total timesteps         | 65251     |
| train_time              | 1113      |
| update_time             | 2950      |
---------------------------------------
---------------------------------------
| act_time                | 34        |
| current_lr              | 0.0003    |
| discount_q              | 0.741     |
| env_time                | 119       |
| ep_rewmean              | 479       |
| episodes                | 1448      |
| eplenmean               | 157       |
| fps                     | 15        |
| mean 100 episode reward | 479       |
| n_updates               | 82200     |
| q_grad_norm             | 5518.713  |
| qfs_loss                | 114.47757 |
| qs_abs_difference       | 51.9      |
| qs_difference           | 51.4      |
| qs_mean                 | 262.1648  |
| time_elapsed            | 4327      |
| total timesteps         | 66009     |
| train_time              | 1131      |
| update_time             | 3001      |
---------------------------------------
---------------------------------------
| act_time                | 35        |
| current_lr              | 0.0003    |
| discount_q              | 0.76      |
| env_time                | 120       |
| ep_rewmean              | 486       |
| episodes                | 1452      |
| eplenmean               | 159       |
| fps                     | 15        |
| mean 100 episode reward | 486       |
| n_updates               | 83600     |
| q_grad_norm             | 5563.0513 |
| qfs_loss                | 111.76155 |
| qs_abs_difference       | 35.7      |
| qs_difference           | 33.4      |
| qs_mean                 | 249.24411 |
| time_elapsed            | 4394      |
| total timesteps         | 66766     |
| train_time              | 1148      |
| update_time             | 3049      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 0.959     |
| env_time                | 121       |
| ep_rewmean              | 490       |
| episodes                | 1456      |
| eplenmean               | 158       |
| fps                     | 15        |
| mean 100 episode reward | 490       |
| n_updates               | 85200     |
| q_grad_norm             | 5072.426  |
| qfs_loss                | 86.988976 |
| qs_abs_difference       | 75.7      |
| qs_difference           | 75.6      |
| qs_mean                 | 288.70523 |
| time_elapsed            | 4471      |
| total timesteps         | 67534     |
| train_time              | 1167      |
| update_time             | 3105      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 1.39      |
| env_time                | 122       |
| ep_rewmean              | 506       |
| episodes                | 1460      |
| eplenmean               | 163       |
| fps                     | 15        |
| mean 100 episode reward | 506       |
| n_updates               | 86600     |
| q_grad_norm             | 5510.2246 |
| qfs_loss                | 112.69838 |
| qs_abs_difference       | 23.1      |
| qs_difference           | 22.5      |
| qs_mean                 | 248.78181 |
| time_elapsed            | 4534      |
| total timesteps         | 68245     |
| train_time              | 1184      |
| update_time             | 3151      |
---------------------------------------
---------------------------------------
| act_time                | 37        |
| current_lr              | 0.0003    |
| discount_q              | 0.731     |
| env_time                | 123       |
| ep_rewmean              | 519       |
| episodes                | 1464      |
| eplenmean               | 166       |
| fps                     | 14        |
| mean 100 episode reward | 519       |
| n_updates               | 88200     |
| q_grad_norm             | 6084.812  |
| qfs_loss                | 150.83472 |
| qs_abs_difference       | 40.5      |
| qs_difference           | 37.9      |
| qs_mean                 | 266.52954 |
| time_elapsed            | 4610      |
| total timesteps         | 69024     |
| train_time              | 1205      |
| update_time             | 3203      |
---------------------------------------
---------------------------------------
| act_time                | 37        |
| current_lr              | 0.0003    |
| discount_q              | 0.713     |
| env_time                | 124       |
| ep_rewmean              | 518       |
| episodes                | 1468      |
| eplenmean               | 166       |
| fps                     | 14        |
| mean 100 episode reward | 518       |
| n_updates               | 89600     |
| q_grad_norm             | 5505.656  |
| qfs_loss                | 127.82848 |
| qs_abs_difference       | 42.3      |
| qs_difference           | 41.2      |
| qs_mean                 | 238.26103 |
| time_elapsed            | 4678      |
| total timesteps         | 69765     |
| train_time              | 1225      |
| update_time             | 3250      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 311       |
| eval_abs_qs_difference  | 59.8026   |
| eval_discount_q         | 228       |
| eval_ep_rewmean         | 752       |
| eval_eplenmean          | 234       |
| eval_qs                 | 279.09427 |
| eval_qs_difference      | 57.7      |
| eval_time_elapsed       | 5         |
| total timesteps         | 70001     |
---------------------------------------
---------------------------------------
| act_time                | 38        |
| current_lr              | 0.0003    |
| discount_q              | 0.309     |
| env_time                | 125       |
| ep_rewmean              | 538       |
| episodes                | 1472      |
| eplenmean               | 171       |
| fps                     | 14        |
| mean 100 episode reward | 538       |
| n_updates               | 91400     |
| q_grad_norm             | 4891.3687 |
| qfs_loss                | 112.67947 |
| qs_abs_difference       | 37.1      |
| qs_difference           | 34.5      |
| qs_mean                 | 279.4374  |
| time_elapsed            | 4769      |
| total timesteps         | 70680     |
| train_time              | 1246      |
| update_time             | 3313      |
---------------------------------------
---------------------------------------
| act_time                | 38        |
| current_lr              | 0.0003    |
| discount_q              | 5.54      |
| env_time                | 126       |
| ep_rewmean              | 534       |
| episodes                | 1476      |
| eplenmean               | 168       |
| fps                     | 14        |
| mean 100 episode reward | 534       |
| n_updates               | 92600     |
| q_grad_norm             | 5008.045  |
| qfs_loss                | 111.5345  |
| qs_abs_difference       | 62.8      |
| qs_difference           | 62.5      |
| qs_mean                 | 283.02747 |
| time_elapsed            | 4825      |
| total timesteps         | 71264     |
| train_time              | 1260      |
| update_time             | 3353      |
---------------------------------------
---------------------------------------
| act_time                | 39        |
| current_lr              | 0.0003    |
| discount_q              | 0.459     |
| env_time                | 127       |
| ep_rewmean              | 548       |
| episodes                | 1480      |
| eplenmean               | 172       |
| fps                     | 14        |
| mean 100 episode reward | 548       |
| n_updates               | 94200     |
| q_grad_norm             | 4264.0967 |
| qfs_loss                | 105.00813 |
| qs_abs_difference       | 65.5      |
| qs_difference           | 65.1      |
| qs_mean                 | 283.37997 |
| time_elapsed            | 4902      |
| total timesteps         | 72086     |
| train_time              | 1279      |
| update_time             | 3410      |
---------------------------------------
---------------------------------------
| act_time                | 39        |
| current_lr              | 0.0003    |
| discount_q              | 0.0106    |
| env_time                | 128       |
| ep_rewmean              | 563       |
| episodes                | 1484      |
| eplenmean               | 177       |
| fps                     | 14        |
| mean 100 episode reward | 562       |
| n_updates               | 96200     |
| q_grad_norm             | 4831.162  |
| qfs_loss                | 110.03548 |
| qs_abs_difference       | 238       |
| qs_difference           | 238       |
| qs_mean                 | 289.66418 |
| time_elapsed            | 5002      |
| total timesteps         | 73051     |
| train_time              | 1302      |
| update_time             | 3483      |
---------------------------------------
---------------------------------------
| act_time                | 40        |
| current_lr              | 0.0003    |
| discount_q              | 3.48      |
| env_time                | 129       |
| ep_rewmean              | 549       |
| episodes                | 1488      |
| eplenmean               | 173       |
| fps                     | 14        |
| mean 100 episode reward | 549       |
| n_updates               | 97200     |
| q_grad_norm             | 5447.8223 |
| qfs_loss                | 135.71568 |
| qs_abs_difference       | 100       |
| qs_difference           | 100       |
| qs_mean                 | 240.17313 |
| time_elapsed            | 5049      |
| total timesteps         | 73570     |
| train_time              | 1314      |
| update_time             | 3518      |
---------------------------------------
---------------------------------------
| act_time                | 40        |
| current_lr              | 0.0003    |
| discount_q              | 5.19      |
| env_time                | 130       |
| ep_rewmean              | 543       |
| episodes                | 1492      |
| eplenmean               | 172       |
| fps                     | 14        |
| mean 100 episode reward | 543       |
| n_updates               | 98400     |
| q_grad_norm             | 5286.0205 |
| qfs_loss                | 115.74624 |
| qs_abs_difference       | 34.9      |
| qs_difference           | 33.8      |
| qs_mean                 | 231.40234 |
| time_elapsed            | 5105      |
| total timesteps         | 74111     |
| train_time              | 1328      |
| update_time             | 3558      |
---------------------------------------
---------------------------------------
| act_time                | 40        |
| current_lr              | 0.0003    |
| discount_q              | 1.74      |
| env_time                | 131       |
| ep_rewmean              | 537       |
| episodes                | 1496      |
| eplenmean               | 171       |
| fps                     | 14        |
| mean 100 episode reward | 537       |
| n_updates               | 99600     |
| q_grad_norm             | 5329.6294 |
| qfs_loss                | 119.17938 |
| qs_abs_difference       | 32        |
| qs_difference           | 32        |
| qs_mean                 | 233.78302 |
| time_elapsed            | 5165      |
| total timesteps         | 74757     |
| train_time              | 1342      |
| update_time             | 3603      |
---------------------------------------
---------------------------------------
| act_time                | 41        |
| current_lr              | 0.0003    |
| discount_q              | 1.46      |
| env_time                | 132       |
| ep_rewmean              | 540       |
| episodes                | 1500      |
| eplenmean               | 172       |
| fps                     | 14        |
| mean 100 episode reward | 540       |
| n_updates               | 101000    |
| q_grad_norm             | 6871.0737 |
| qfs_loss                | 155.4006  |
| qs_abs_difference       | 68.4      |
| qs_difference           | 68.4      |
| qs_mean                 | 280.54645 |
| time_elapsed            | 5235      |
| total timesteps         | 75482     |
| train_time              | 1359      |
| update_time             | 3654      |
---------------------------------------
---------------------------------------
| act_time                | 42        |
| current_lr              | 0.0003    |
| discount_q              | 0.448     |
| env_time                | 133       |
| ep_rewmean              | 544       |
| episodes                | 1504      |
| eplenmean               | 173       |
| fps                     | 14        |
| mean 100 episode reward | 544       |
| n_updates               | 102800    |
| q_grad_norm             | 4952.809  |
| qfs_loss                | 111.93519 |
| qs_abs_difference       | 54.6      |
| qs_difference           | 51.6      |
| qs_mean                 | 260.9291  |
| time_elapsed            | 5324      |
| total timesteps         | 76305     |
| train_time              | 1380      |
| update_time             | 3720      |
---------------------------------------
----------------------------------------
| act_time                | 42         |
| current_lr              | 0.0003     |
| discount_q              | 1.98       |
| env_time                | 134        |
| ep_rewmean              | 543        |
| episodes                | 1508       |
| eplenmean               | 173        |
| fps                     | 14         |
| mean 100 episode reward | 543        |
| n_updates               | 104000     |
| q_grad_norm             | 5087.8433  |
| qfs_loss                | 105.974884 |
| qs_abs_difference       | 80.5       |
| qs_difference           | 80.1       |
| qs_mean                 | 287.6501   |
| time_elapsed            | 5381       |
| total timesteps         | 76986      |
| train_time              | 1394       |
| update_time             | 3762       |
----------------------------------------
---------------------------------------
| act_time                | 43        |
| current_lr              | 0.0003    |
| discount_q              | 0.795     |
| env_time                | 135       |
| ep_rewmean              | 557       |
| episodes                | 1512      |
| eplenmean               | 177       |
| fps                     | 14        |
| mean 100 episode reward | 557       |
| n_updates               | 105600    |
| q_grad_norm             | 4672.273  |
| qfs_loss                | 95.14145  |
| qs_abs_difference       | 47.5      |
| qs_difference           | 45.6      |
| qs_mean                 | 269.54065 |
| time_elapsed            | 5462      |
| total timesteps         | 77788     |
| train_time              | 1413      |
| update_time             | 3822      |
---------------------------------------
---------------------------------------
| act_time                | 43        |
| current_lr              | 0.0003    |
| discount_q              | 0.733     |
| env_time                | 136       |
| ep_rewmean              | 561       |
| episodes                | 1516      |
| eplenmean               | 178       |
| fps                     | 14        |
| mean 100 episode reward | 561       |
| n_updates               | 107200    |
| q_grad_norm             | 4880.6553 |
| qfs_loss                | 104.08196 |
| qs_abs_difference       | 46.4      |
| qs_difference           | 43.2      |
| qs_mean                 | 253.29143 |
| time_elapsed            | 5543      |
| total timesteps         | 78553     |
| train_time              | 1435      |
| update_time             | 3879      |
---------------------------------------
---------------------------------------
| act_time                | 44        |
| current_lr              | 0.0003    |
| discount_q              | 0.435     |
| env_time                | 137       |
| ep_rewmean              | 569       |
| episodes                | 1520      |
| eplenmean               | 180       |
| fps                     | 14        |
| mean 100 episode reward | 569       |
| n_updates               | 108800    |
| q_grad_norm             | 4176.7627 |
| qfs_loss                | 92.80529  |
| qs_abs_difference       | 65.4      |
| qs_difference           | 65.3      |
| qs_mean                 | 274.84427 |
| time_elapsed            | 5621      |
| total timesteps         | 79383     |
| train_time              | 1454      |
| update_time             | 3936      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 343       |
| eval_abs_qs_difference  | 59.260727 |
| eval_discount_q         | 218       |
| eval_ep_rewmean         | 583       |
| eval_eplenmean          | 179       |
| eval_qs                 | 258.31586 |
| eval_qs_difference      | 56.8      |
| eval_time_elapsed       | 3         |
| total timesteps         | 80001     |
---------------------------------------
---------------------------------------
| act_time                | 44        |
| current_lr              | 0.0003    |
| discount_q              | 0.776     |
| env_time                | 138       |
| ep_rewmean              | 569       |
| episodes                | 1524      |
| eplenmean               | 181       |
| fps                     | 14        |
| mean 100 episode reward | 569       |
| n_updates               | 110400    |
| q_grad_norm             | 5362.5327 |
| qfs_loss                | 117.93027 |
| qs_abs_difference       | 135       |
| qs_difference           | 133       |
| qs_mean                 | 286.75864 |
| time_elapsed            | 5705      |
| total timesteps         | 80138     |
| train_time              | 1473      |
| update_time             | 3996      |
---------------------------------------
---------------------------------------
| act_time                | 45        |
| current_lr              | 0.0003    |
| discount_q              | 1.25      |
| env_time                | 139       |
| ep_rewmean              | 575       |
| episodes                | 1528      |
| eplenmean               | 182       |
| fps                     | 13        |
| mean 100 episode reward | 575       |
| n_updates               | 111800    |
| q_grad_norm             | 4784.227  |
| qfs_loss                | 103.81985 |
| qs_abs_difference       | 49.6      |
| qs_difference           | 49.4      |
| qs_mean                 | 275.94904 |
| time_elapsed            | 5780      |
| total timesteps         | 80864     |
| train_time              | 1489      |
| update_time             | 4053      |
---------------------------------------
---------------------------------------
| act_time                | 45        |
| current_lr              | 0.0003    |
| discount_q              | 0.281     |
| env_time                | 139       |
| ep_rewmean              | 569       |
| episodes                | 1532      |
| eplenmean               | 181       |
| fps                     | 13        |
| mean 100 episode reward | 569       |
| n_updates               | 113000    |
| q_grad_norm             | 4334.831  |
| qfs_loss                | 106.38179 |
| qs_abs_difference       | 258       |
| qs_difference           | 258       |
| qs_mean                 | 298.45895 |
| time_elapsed            | 5839      |
| total timesteps         | 81446     |
| train_time              | 1503      |
| update_time             | 4096      |
---------------------------------------
----------------------------------------
| act_time                | 46         |
| current_lr              | 0.0003     |
| discount_q              | 2.46       |
| env_time                | 140        |
| ep_rewmean              | 566        |
| episodes                | 1536       |
| eplenmean               | 181        |
| fps                     | 13         |
| mean 100 episode reward | 566        |
| n_updates               | 114400     |
| q_grad_norm             | 4872.8486  |
| qfs_loss                | 101.245316 |
| qs_abs_difference       | 57.4       |
| qs_difference           | 56.6       |
| qs_mean                 | 279.18286  |
| time_elapsed            | 5907       |
| total timesteps         | 82164      |
| train_time              | 1520       |
| update_time             | 4147       |
----------------------------------------
---------------------------------------
| act_time                | 46        |
| current_lr              | 0.0003    |
| discount_q              | 11.3      |
| env_time                | 141       |
| ep_rewmean              | 566       |
| episodes                | 1540      |
| eplenmean               | 181       |
| fps                     | 13        |
| mean 100 episode reward | 566       |
| n_updates               | 115400    |
| q_grad_norm             | 4529.5195 |
| qfs_loss                | 93.42557  |
| qs_abs_difference       | 66        |
| qs_difference           | 65        |
| qs_mean                 | 274.84216 |
| time_elapsed            | 5960      |
| total timesteps         | 82652     |
| train_time              | 1531      |
| update_time             | 4186      |
---------------------------------------
----------------------------------------
| act_time                | 47         |
| current_lr              | 0.0003     |
| discount_q              | 0.456      |
| env_time                | 142        |
| ep_rewmean              | 569        |
| episodes                | 1544       |
| eplenmean               | 182        |
| fps                     | 13         |
| mean 100 episode reward | 569        |
| n_updates               | 117000     |
| q_grad_norm             | 5079.9463  |
| qfs_loss                | 107.246506 |
| qs_abs_difference       | 57.2       |
| qs_difference           | 57.2       |
| qs_mean                 | 280.7912   |
| time_elapsed            | 6046       |
| total timesteps         | 83473      |
| train_time              | 1551       |
| update_time             | 4251       |
----------------------------------------
---------------------------------------
| act_time                | 47        |
| current_lr              | 0.0003    |
| discount_q              | 0.59      |
| env_time                | 143       |
| ep_rewmean              | 570       |
| episodes                | 1548      |
| eplenmean               | 182       |
| fps                     | 13        |
| mean 100 episode reward | 570       |
| n_updates               | 118600    |
| q_grad_norm             | 5148.508  |
| qfs_loss                | 123.91441 |
| qs_abs_difference       | 44.1      |
| qs_difference           | 44.1      |
| qs_mean                 | 260.01334 |
| time_elapsed            | 6126      |
| total timesteps         | 84256     |
| train_time              | 1570      |
| update_time             | 4310      |
---------------------------------------
---------------------------------------
| act_time                | 48        |
| current_lr              | 0.0003    |
| discount_q              | 0.749     |
| env_time                | 144       |
| ep_rewmean              | 572       |
| episodes                | 1552      |
| eplenmean               | 183       |
| fps                     | 13        |
| mean 100 episode reward | 572       |
| n_updates               | 120200    |
| q_grad_norm             | 4339.454  |
| qfs_loss                | 79.72312  |
| qs_abs_difference       | 75.6      |
| qs_difference           | 72.4      |
| qs_mean                 | 289.32828 |
| time_elapsed            | 6209      |
| total timesteps         | 85045     |
| train_time              | 1591      |
| update_time             | 4370      |
---------------------------------------
---------------------------------------
| act_time                | 48        |
| current_lr              | 0.0003    |
| discount_q              | 0.0578    |
| env_time                | 146       |
| ep_rewmean              | 582       |
| episodes                | 1556      |
| eplenmean               | 186       |
| fps                     | 13        |
| mean 100 episode reward | 582       |
| n_updates               | 122200    |
| q_grad_norm             | 4947.7783 |
| qfs_loss                | 114.32931 |
| qs_abs_difference       | 67.3      |
| qs_difference           | 67.1      |
| qs_mean                 | 288.50775 |
| time_elapsed            | 6317      |
| total timesteps         | 86086     |
| train_time              | 1616      |
| update_time             | 4451      |
---------------------------------------
---------------------------------------
| act_time                | 49        |
| current_lr              | 0.0003    |
| discount_q              | 0.71      |
| env_time                | 147       |
| ep_rewmean              | 586       |
| episodes                | 1560      |
| eplenmean               | 186       |
| fps                     | 13        |
| mean 100 episode reward | 586       |
| n_updates               | 123800    |
| q_grad_norm             | 5370.72   |
| qfs_loss                | 122.56793 |
| qs_abs_difference       | 81.5      |
| qs_difference           | 80.6      |
| qs_mean                 | 297.0907  |
| time_elapsed            | 6400      |
| total timesteps         | 86878     |
| train_time              | 1635      |
| update_time             | 4512      |
---------------------------------------
---------------------------------------
| act_time                | 50        |
| current_lr              | 0.0003    |
| discount_q              | 0.535     |
| env_time                | 148       |
| ep_rewmean              | 585       |
| episodes                | 1564      |
| eplenmean               | 187       |
| fps                     | 13        |
| mean 100 episode reward | 585       |
| n_updates               | 125400    |
| q_grad_norm             | 4316.7583 |
| qfs_loss                | 89.75587  |
| qs_abs_difference       | 79.7      |
| qs_difference           | 79.7      |
| qs_mean                 | 287.2204  |
| time_elapsed            | 6486      |
| total timesteps         | 87687     |
| train_time              | 1655      |
| update_time             | 4577      |
---------------------------------------
----------------------------------------
| act_time                | 50         |
| current_lr              | 0.0003     |
| discount_q              | 0.0707     |
| env_time                | 149        |
| ep_rewmean              | 593        |
| episodes                | 1568       |
| eplenmean               | 189        |
| fps                     | 13         |
| mean 100 episode reward | 593        |
| n_updates               | 127400     |
| q_grad_norm             | 4410.916   |
| qfs_loss                | 102.399826 |
| qs_abs_difference       | 60.6       |
| qs_difference           | 60.6       |
| qs_mean                 | 261.34937  |
| time_elapsed            | 6595       |
| total timesteps         | 88670      |
| train_time              | 1683       |
| update_time             | 4656       |
----------------------------------------
---------------------------------------
| act_time                | 51        |
| current_lr              | 0.0003    |
| discount_q              | 0.199     |
| env_time                | 151       |
| ep_rewmean              | 594       |
| episodes                | 1572      |
| eplenmean               | 189       |
| fps                     | 13        |
| mean 100 episode reward | 594       |
| n_updates               | 129200    |
| q_grad_norm             | 4629.2827 |
| qfs_loss                | 101.75852 |
| qs_abs_difference       | 87.6      |
| qs_difference           | 87        |
| qs_mean                 | 289.03363 |
| time_elapsed            | 6690      |
| total timesteps         | 89577     |
| train_time              | 1705      |
| update_time             | 4727      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 410       |
| eval_abs_qs_difference  | 50.49388  |
| eval_discount_q         | 225       |
| eval_ep_rewmean         | 689       |
| eval_eplenmean          | 210       |
| eval_qs                 | 259.70056 |
| eval_qs_difference      | 37.8      |
| eval_time_elapsed       | 4         |
| total timesteps         | 90001     |
---------------------------------------
----------------------------------------
| act_time                | 52         |
| current_lr              | 0.0003     |
| discount_q              | 0.142      |
| env_time                | 152        |
| ep_rewmean              | 609        |
| episodes                | 1576       |
| eplenmean               | 193        |
| fps                     | 13         |
| mean 100 episode reward | 609        |
| n_updates               | 131200     |
| q_grad_norm             | 4830.2075  |
| qfs_loss                | 102.661545 |
| qs_abs_difference       | 36.6       |
| qs_difference           | 35.1       |
| qs_mean                 | 287.74615  |
| time_elapsed            | 6806       |
| total timesteps         | 90585      |
| train_time              | 1730       |
| update_time             | 4811       |
----------------------------------------
---------------------------------------
| act_time                | 52        |
| current_lr              | 0.0003    |
| discount_q              | 0.036     |
| env_time                | 153       |
| ep_rewmean              | 620       |
| episodes                | 1580      |
| eplenmean               | 196       |
| fps                     | 13        |
| mean 100 episode reward | 620       |
| n_updates               | 133600    |
| q_grad_norm             | 4221.4224 |
| qfs_loss                | 84.46625  |
| qs_abs_difference       | 42        |
| qs_difference           | 38.5      |
| qs_mean                 | 284.41568 |
| time_elapsed            | 6936      |
| total timesteps         | 91720     |
| train_time              | 1760      |
| update_time             | 4908      |
---------------------------------------
---------------------------------------
| act_time                | 53        |
| current_lr              | 0.0003    |
| discount_q              | 0.0189    |
| env_time                | 155       |
| ep_rewmean              | 628       |
| episodes                | 1584      |
| eplenmean               | 198       |
| fps                     | 13        |
| mean 100 episode reward | 628       |
| n_updates               | 135800    |
| q_grad_norm             | 4212.1914 |
| qfs_loss                | 92.95359  |
| qs_abs_difference       | 138       |
| qs_difference           | 138       |
| qs_mean                 | 321.24158 |
| time_elapsed            | 7060      |
| total timesteps         | 92835     |
| train_time              | 1787      |
| update_time             | 5002      |
---------------------------------------
---------------------------------------
| act_time                | 54        |
| current_lr              | 0.0003    |
| discount_q              | 0.0175    |
| env_time                | 157       |
| ep_rewmean              | 654       |
| episodes                | 1588      |
| eplenmean               | 205       |
| fps                     | 13        |
| mean 100 episode reward | 654       |
| n_updates               | 138200    |
| q_grad_norm             | 3920.6826 |
| qfs_loss                | 89.54192  |
| qs_abs_difference       | 30.3      |
| qs_difference           | 28.9      |
| qs_mean                 | 281.8089  |
| time_elapsed            | 7193      |
| total timesteps         | 94047     |
| train_time              | 1820      |
| update_time             | 5100      |
---------------------------------------
---------------------------------------
| act_time                | 55        |
| current_lr              | 0.0003    |
| discount_q              | 0.0679    |
| env_time                | 158       |
| ep_rewmean              | 669       |
| episodes                | 1592      |
| eplenmean               | 209       |
| fps                     | 12        |
| mean 100 episode reward | 669       |
| n_updates               | 140200    |
| q_grad_norm             | 3925.035  |
| qfs_loss                | 79.98141  |
| qs_abs_difference       | 180       |
| qs_difference           | 180       |
| qs_mean                 | 325.69867 |
| time_elapsed            | 7309      |
| total timesteps         | 95005     |
| train_time              | 1845      |
| update_time             | 5188      |
---------------------------------------
---------------------------------------
| act_time                | 55        |
| current_lr              | 0.0003    |
| discount_q              | 0.0693    |
| env_time                | 159       |
| ep_rewmean              | 677       |
| episodes                | 1596      |
| eplenmean               | 211       |
| fps                     | 12        |
| mean 100 episode reward | 677       |
| n_updates               | 141800    |
| q_grad_norm             | 4967.168  |
| qfs_loss                | 105.51966 |
| qs_abs_difference       | 224       |
| qs_difference           | 224       |
| qs_mean                 | 316.6649  |
| time_elapsed            | 7399      |
| total timesteps         | 95868     |
| train_time              | 1865      |
| update_time             | 5256      |
---------------------------------------
---------------------------------------
| act_time                | 56        |
| current_lr              | 0.0003    |
| discount_q              | 0.0396    |
| env_time                | 160       |
| ep_rewmean              | 677       |
| episodes                | 1600      |
| eplenmean               | 212       |
| fps                     | 12        |
| mean 100 episode reward | 677       |
| n_updates               | 143400    |
| q_grad_norm             | 3699.5332 |
| qfs_loss                | 82.97987  |
| qs_abs_difference       | 256       |
| qs_difference           | 256       |
| qs_mean                 | 290.16968 |
| time_elapsed            | 7490      |
| total timesteps         | 96632     |
| train_time              | 1885      |
| update_time             | 5325      |
---------------------------------------
----------------------------------------
| act_time                | 56         |
| current_lr              | 0.0003     |
| discount_q              | 0.688      |
| env_time                | 161        |
| ep_rewmean              | 678        |
| episodes                | 1604       |
| eplenmean               | 212        |
| fps                     | 12         |
| mean 100 episode reward | 678        |
| n_updates               | 145000     |
| q_grad_norm             | 4481.7676  |
| qfs_loss                | 108.204666 |
| qs_abs_difference       | 41         |
| qs_difference           | 38         |
| qs_mean                 | 284.01047  |
| time_elapsed            | 7582       |
| total timesteps         | 97462      |
| train_time              | 1906       |
| update_time             | 5394       |
----------------------------------------
---------------------------------------
| act_time                | 57        |
| current_lr              | 0.0003    |
| discount_q              | 0.632     |
| env_time                | 163       |
| ep_rewmean              | 687       |
| episodes                | 1608      |
| eplenmean               | 214       |
| fps                     | 12        |
| mean 100 episode reward | 687       |
| n_updates               | 146800    |
| q_grad_norm             | 4673.7754 |
| qfs_loss                | 104.18137 |
| qs_abs_difference       | 104       |
| qs_difference           | 104       |
| qs_mean                 | 335.4246  |
| time_elapsed            | 7684      |
| total timesteps         | 98381     |
| train_time              | 1928      |
| update_time             | 5471      |
---------------------------------------
---------------------------------------
| act_time                | 58        |
| current_lr              | 0.0003    |
| discount_q              | 0.0363    |
| env_time                | 164       |
| ep_rewmean              | 699       |
| episodes                | 1612      |
| eplenmean               | 217       |
| fps                     | 12        |
| mean 100 episode reward | 699       |
| n_updates               | 149200    |
| q_grad_norm             | 4119.1123 |
| qfs_loss                | 86.00961  |
| qs_abs_difference       | 70.3      |
| qs_difference           | 70.3      |
| qs_mean                 | 298.723   |
| time_elapsed            | 7822      |
| total timesteps         | 99509     |
| train_time              | 1959      |
| update_time             | 5577      |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 520      |
| eval_abs_qs_difference  | 48.03778 |
| eval_discount_q         | 252      |
| eval_ep_rewmean         | 1.04e+03 |
| eval_eplenmean          | 304      |
| eval_qs                 | 286.4578 |
| eval_qs_difference      | 27.8     |
| eval_time_elapsed       | 6        |
| total timesteps         | 100001   |
--------------------------------------
---------------------------------------
| act_time                | 59        |
| current_lr              | 0.0003    |
| discount_q              | 0.0247    |
| env_time                | 166       |
| ep_rewmean              | 714       |
| episodes                | 1616      |
| eplenmean               | 221       |
| fps                     | 12        |
| mean 100 episode reward | 714       |
| n_updates               | 151400    |
| q_grad_norm             | 4242.473  |
| qfs_loss                | 93.83688  |
| qs_abs_difference       | 18.5      |
| qs_difference           | 1.9       |
| qs_mean                 | 274.97333 |
| time_elapsed            | 7953      |
| total timesteps         | 100675    |
| train_time              | 1986      |
| update_time             | 5670      |
---------------------------------------
---------------------------------------
| act_time                | 60        |
| current_lr              | 0.0003    |
| discount_q              | 0.0166    |
| env_time                | 168       |
| ep_rewmean              | 723       |
| episodes                | 1620      |
| eplenmean               | 224       |
| fps                     | 12        |
| mean 100 episode reward | 723       |
| n_updates               | 153600    |
| q_grad_norm             | 4165.549  |
| qfs_loss                | 102.26296 |
| qs_abs_difference       | 181       |
| qs_difference           | 181       |
| qs_mean                 | 343.33786 |
| time_elapsed            | 8079      |
| total timesteps         | 101792    |
| train_time              | 2014      |
| update_time             | 5766      |
---------------------------------------
---------------------------------------
| act_time                | 61        |
| current_lr              | 0.0003    |
| discount_q              | 0.048     |
| env_time                | 170       |
| ep_rewmean              | 736       |
| episodes                | 1624      |
| eplenmean               | 228       |
| fps                     | 12        |
| mean 100 episode reward | 736       |
| n_updates               | 156000    |
| q_grad_norm             | 4311.446  |
| qfs_loss                | 87.811005 |
| qs_abs_difference       | 58.3      |
| qs_difference           | 56.3      |
| qs_mean                 | 284.5366  |
| time_elapsed            | 8212      |
| total timesteps         | 102901    |
| train_time              | 2044      |
| update_time             | 5865      |
---------------------------------------
---------------------------------------
| act_time                | 61        |
| current_lr              | 0.0003    |
| discount_q              | 0.115     |
| env_time                | 171       |
| ep_rewmean              | 736       |
| episodes                | 1628      |
| eplenmean               | 229       |
| fps                     | 12        |
| mean 100 episode reward | 736       |
| n_updates               | 157600    |
| q_grad_norm             | 4476.2695 |
| qfs_loss                | 113.48591 |
| qs_abs_difference       | 221       |
| qs_difference           | 221       |
| qs_mean                 | 324.18304 |
| time_elapsed            | 8303      |
| total timesteps         | 103718    |
| train_time              | 2068      |
| update_time             | 5931      |
---------------------------------------
---------------------------------------
| act_time                | 62        |
| current_lr              | 0.0003    |
| discount_q              | 0.351     |
| env_time                | 172       |
| ep_rewmean              | 754       |
| episodes                | 1632      |
| eplenmean               | 233       |
| fps                     | 12        |
| mean 100 episode reward | 754       |
| n_updates               | 159600    |
| q_grad_norm             | 4239.001  |
| qfs_loss                | 99.93632  |
| qs_abs_difference       | 31.9      |
| qs_difference           | 30.6      |
| qs_mean                 | 302.74713 |
| time_elapsed            | 8413      |
| total timesteps         | 104750    |
| train_time              | 2093      |
| update_time             | 6013      |
---------------------------------------
---------------------------------------
| act_time                | 63        |
| current_lr              | 0.0003    |
| discount_q              | 0.216     |
| env_time                | 174       |
| ep_rewmean              | 773       |
| episodes                | 1636      |
| eplenmean               | 238       |
| fps                     | 12        |
| mean 100 episode reward | 773       |
| n_updates               | 162200    |
| q_grad_norm             | 4037.8738 |
| qfs_loss                | 85.213684 |
| qs_abs_difference       | 62.7      |
| qs_difference           | 62.7      |
| qs_mean                 | 328.99115 |
| time_elapsed            | 8555      |
| total timesteps         | 106006    |
| train_time              | 2126      |
| update_time             | 6119      |
---------------------------------------
---------------------------------------
| act_time                | 64        |
| current_lr              | 0.0003    |
| discount_q              | 0.121     |
| env_time                | 176       |
| ep_rewmean              | 794       |
| episodes                | 1640      |
| eplenmean               | 243       |
| fps                     | 12        |
| mean 100 episode reward | 794       |
| n_updates               | 164000    |
| q_grad_norm             | 4043.2607 |
| qfs_loss                | 87.58368  |
| qs_abs_difference       | 97.9      |
| qs_difference           | 97.9      |
| qs_mean                 | 302.53146 |
| time_elapsed            | 8652      |
| total timesteps         | 106984    |
| train_time              | 2151      |
| update_time             | 6188      |
---------------------------------------
---------------------------------------
| act_time                | 64        |
| current_lr              | 0.0003    |
| discount_q              | 0.174     |
| env_time                | 177       |
| ep_rewmean              | 799       |
| episodes                | 1644      |
| eplenmean               | 245       |
| fps                     | 12        |
| mean 100 episode reward | 799       |
| n_updates               | 166000    |
| q_grad_norm             | 4212.2983 |
| qfs_loss                | 102.38906 |
| qs_abs_difference       | 75        |
| qs_difference           | 75        |
| qs_mean                 | 298.82806 |
| time_elapsed            | 8757      |
| total timesteps         | 107986    |
| train_time              | 2176      |
| update_time             | 6266      |
---------------------------------------
---------------------------------------
| act_time                | 65        |
| current_lr              | 0.0003    |
| discount_q              | 9.84      |
| env_time                | 178       |
| ep_rewmean              | 785       |
| episodes                | 1648      |
| eplenmean               | 242       |
| fps                     | 12        |
| mean 100 episode reward | 785       |
| n_updates               | 167000    |
| q_grad_norm             | 3479.0278 |
| qfs_loss                | 78.790184 |
| qs_abs_difference       | 195       |
| qs_difference           | 195       |
| qs_mean                 | 331.4276  |
| time_elapsed            | 8811      |
| total timesteps         | 108418    |
| train_time              | 2189      |
| update_time             | 6305      |
---------------------------------------
---------------------------------------
| act_time                | 66        |
| current_lr              | 0.0003    |
| discount_q              | 0.0148    |
| env_time                | 179       |
| ep_rewmean              | 800       |
| episodes                | 1652      |
| eplenmean               | 246       |
| fps                     | 12        |
| mean 100 episode reward | 800       |
| n_updates               | 169400    |
| q_grad_norm             | 3641.768  |
| qfs_loss                | 84.477165 |
| qs_abs_difference       | 29.7      |
| qs_difference           | 24.2      |
| qs_mean                 | 292.59915 |
| time_elapsed            | 8936      |
| total timesteps         | 109642    |
| train_time              | 2220      |
| update_time             | 6396      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 626       |
| eval_abs_qs_difference  | 35.177177 |
| eval_discount_q         | 243       |
| eval_ep_rewmean         | 957       |
| eval_eplenmean          | 278       |
| eval_qs                 | 285.8189  |
| eval_qs_difference      | 28.3      |
| eval_time_elapsed       | 6         |
| total timesteps         | 110001    |
---------------------------------------
---------------------------------------
| act_time                | 67        |
| current_lr              | 0.0003    |
| discount_q              | 0.0067    |
| env_time                | 181       |
| ep_rewmean              | 809       |
| episodes                | 1656      |
| eplenmean               | 249       |
| fps                     | 12        |
| mean 100 episode reward | 809       |
| n_updates               | 172000    |
| q_grad_norm             | 4503.7495 |
| qfs_loss                | 120.28757 |
| qs_abs_difference       | 46        |
| qs_difference           | 43.2      |
| qs_mean                 | 296.50607 |
| time_elapsed            | 9077      |
| total timesteps         | 110965    |
| train_time              | 2252      |
| update_time             | 6496      |
---------------------------------------
--------------------------------------
| act_time                | 67       |
| current_lr              | 0.0003   |
| discount_q              | 0.0959   |
| env_time                | 183      |
| ep_rewmean              | 817      |
| episodes                | 1660     |
| eplenmean               | 251      |
| fps                     | 12       |
| mean 100 episode reward | 817      |
| n_updates               | 174000   |
| q_grad_norm             | 3288.431 |
| qfs_loss                | 75.05375 |
| qs_abs_difference       | 68       |
| qs_difference           | 67.7     |
| qs_mean                 | 297.983  |
| time_elapsed            | 9178     |
| total timesteps         | 111980   |
| train_time              | 2278     |
| update_time             | 6569     |
--------------------------------------
---------------------------------------
| act_time                | 68        |
| current_lr              | 0.0003    |
| discount_q              | 0.509     |
| env_time                | 184       |
| ep_rewmean              | 822       |
| episodes                | 1664      |
| eplenmean               | 253       |
| fps                     | 12        |
| mean 100 episode reward | 822       |
| n_updates               | 176200    |
| q_grad_norm             | 4124.8037 |
| qfs_loss                | 100.1474  |
| qs_abs_difference       | 35.9      |
| qs_difference           | 35.5      |
| qs_mean                 | 319.0199  |
| time_elapsed            | 9289      |
| total timesteps         | 113001    |
| train_time              | 2305      |
| update_time             | 6649      |
---------------------------------------
---------------------------------------
| act_time                | 69        |
| current_lr              | 0.0003    |
| discount_q              | 0.161     |
| env_time                | 186       |
| ep_rewmean              | 826       |
| episodes                | 1668      |
| eplenmean               | 254       |
| fps                     | 12        |
| mean 100 episode reward | 826       |
| n_updates               | 178200    |
| q_grad_norm             | 3976.5596 |
| qfs_loss                | 101.37363 |
| qs_abs_difference       | 43.6      |
| qs_difference           | 43.5      |
| qs_mean                 | 301.99854 |
| time_elapsed            | 9391      |
| total timesteps         | 114027    |
| train_time              | 2334      |
| update_time             | 6721      |
---------------------------------------
---------------------------------------
| act_time                | 70        |
| current_lr              | 0.0003    |
| discount_q              | 0.454     |
| env_time                | 187       |
| ep_rewmean              | 825       |
| episodes                | 1672      |
| eplenmean               | 253       |
| fps                     | 12        |
| mean 100 episode reward | 825       |
| n_updates               | 180000    |
| q_grad_norm             | 3986.8953 |
| qfs_loss                | 90.76602  |
| qs_abs_difference       | 51.1      |
| qs_difference           | 49.2      |
| qs_mean                 | 293.06876 |
| time_elapsed            | 9478      |
| total timesteps         | 114900    |
| train_time              | 2356      |
| update_time             | 6783      |
---------------------------------------
---------------------------------------
| act_time                | 71        |
| current_lr              | 0.0003    |
| discount_q              | 0.032     |
| env_time                | 189       |
| ep_rewmean              | 831       |
| episodes                | 1676      |
| eplenmean               | 255       |
| fps                     | 12        |
| mean 100 episode reward | 831       |
| n_updates               | 182200    |
| q_grad_norm             | 3864.8513 |
| qfs_loss                | 92.74485  |
| qs_abs_difference       | 27.9      |
| qs_difference           | 27.6      |
| qs_mean                 | 291.07022 |
| time_elapsed            | 9587      |
| total timesteps         | 116053    |
| train_time              | 2384      |
| update_time             | 6861      |
---------------------------------------
---------------------------------------
| act_time                | 71        |
| current_lr              | 0.0003    |
| discount_q              | 0.0396    |
| env_time                | 191       |
| ep_rewmean              | 833       |
| episodes                | 1680      |
| eplenmean               | 255       |
| fps                     | 12        |
| mean 100 episode reward | 833       |
| n_updates               | 184400    |
| q_grad_norm             | 3200.46   |
| qfs_loss                | 69.005936 |
| qs_abs_difference       | 44.2      |
| qs_difference           | 42.4      |
| qs_mean                 | 296.7483  |
| time_elapsed            | 9739      |
| total timesteps         | 117172    |
| train_time              | 2434      |
| update_time             | 6960      |
---------------------------------------
---------------------------------------
| act_time                | 72        |
| current_lr              | 0.0003    |
| discount_q              | 1.61      |
| env_time                | 192       |
| ep_rewmean              | 820       |
| episodes                | 1684      |
| eplenmean               | 251       |
| fps                     | 11        |
| mean 100 episode reward | 820       |
| n_updates               | 186000    |
| q_grad_norm             | 3773.64   |
| qfs_loss                | 95.612236 |
| qs_abs_difference       | 85.2      |
| qs_difference           | 85.2      |
| qs_mean                 | 301.94806 |
| time_elapsed            | 9865      |
| total timesteps         | 117901    |
| train_time              | 2478      |
| update_time             | 7040      |
---------------------------------------
---------------------------------------
| act_time                | 73        |
| current_lr              | 0.0003    |
| discount_q              | 0.787     |
| env_time                | 193       |
| ep_rewmean              | 808       |
| episodes                | 1688      |
| eplenmean               | 247       |
| fps                     | 11        |
| mean 100 episode reward | 808       |
| n_updates               | 187600    |
| q_grad_norm             | 4115.498  |
| qfs_loss                | 112.70246 |
| qs_abs_difference       | 21.3      |
| qs_difference           | 20.7      |
| qs_mean                 | 290.01663 |
| time_elapsed            | 9989      |
| total timesteps         | 118770    |
| train_time              | 2522      |
| update_time             | 7118      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 700       |
| eval_abs_qs_difference  | 49.070694 |
| eval_discount_q         | 242       |
| eval_ep_rewmean         | 1.02e+03  |
| eval_eplenmean          | 319       |
| eval_qs                 | 288.9067  |
| eval_qs_difference      | 47        |
| eval_time_elapsed       | 5         |
| total timesteps         | 120001    |
---------------------------------------
---------------------------------------
| act_time                | 74        |
| current_lr              | 0.0003    |
| discount_q              | 0.00019   |
| env_time                | 195       |
| ep_rewmean              | 840       |
| episodes                | 1692      |
| eplenmean               | 255       |
| fps                     | 11        |
| mean 100 episode reward | 840       |
| n_updates               | 191200    |
| q_grad_norm             | 4262.602  |
| qfs_loss                | 108.05789 |
| qs_abs_difference       | 19.6      |
| qs_difference           | 17.4      |
| qs_mean                 | 303.5495  |
| time_elapsed            | 10268     |
| total timesteps         | 120512    |
| train_time              | 2622      |
| update_time             | 7287      |
---------------------------------------
---------------------------------------
| act_time                | 75        |
| current_lr              | 0.0003    |
| discount_q              | 0.0193    |
| env_time                | 197       |
| ep_rewmean              | 855       |
| episodes                | 1696      |
| eplenmean               | 258       |
| fps                     | 11        |
| mean 100 episode reward | 855       |
| n_updates               | 193400    |
| q_grad_norm             | 4273.625  |
| qfs_loss                | 105.15743 |
| qs_abs_difference       | 65.3      |
| qs_difference           | 65.1      |
| qs_mean                 | 297.2163  |
| time_elapsed            | 10435     |
| total timesteps         | 121688    |
| train_time              | 2684      |
| update_time             | 7389      |
---------------------------------------
---------------------------------------
| act_time                | 75        |
| current_lr              | 0.0003    |
| discount_q              | 0.0737    |
| env_time                | 198       |
| ep_rewmean              | 866       |
| episodes                | 1700      |
| eplenmean               | 260       |
| fps                     | 11        |
| mean 100 episode reward | 866       |
| n_updates               | 195400    |
| q_grad_norm             | 3459.9797 |
| qfs_loss                | 84.17176  |
| qs_abs_difference       | 176       |
| qs_difference           | 176       |
| qs_mean                 | 339.25555 |
| time_elapsed            | 10585     |
| total timesteps         | 122648    |
| train_time              | 2739      |
| update_time             | 7482      |
---------------------------------------
---------------------------------------
| act_time                | 76        |
| current_lr              | 0.0003    |
| discount_q              | 1.69      |
| env_time                | 199       |
| ep_rewmean              | 865       |
| episodes                | 1704      |
| eplenmean               | 260       |
| fps                     | 11        |
| mean 100 episode reward | 865       |
| n_updates               | 197000    |
| q_grad_norm             | 3671.1018 |
| qfs_loss                | 80.86378  |
| qs_abs_difference       | 50.7      |
| qs_difference           | 50.6      |
| qs_mean                 | 305.1128  |
| time_elapsed            | 10705     |
| total timesteps         | 123435    |
| train_time              | 2783      |
| update_time             | 7555      |
---------------------------------------
---------------------------------------
| act_time                | 77        |
| current_lr              | 0.0003    |
| discount_q              | 0.389     |
| env_time                | 201       |
| ep_rewmean              | 864       |
| episodes                | 1708      |
| eplenmean               | 259       |
| fps                     | 11        |
| mean 100 episode reward | 864       |
| n_updates               | 198600    |
| q_grad_norm             | 3648.4026 |
| qfs_loss                | 85.7502   |
| qs_abs_difference       | 87.5      |
| qs_difference           | 87.3      |
| qs_mean                 | 293.41074 |
| time_elapsed            | 10822     |
| total timesteps         | 124282    |
| train_time              | 2826      |
| update_time             | 7628      |
---------------------------------------
---------------------------------------
| act_time                | 77        |
| current_lr              | 0.0003    |
| discount_q              | 4.68      |
| env_time                | 202       |
| ep_rewmean              | 848       |
| episodes                | 1712      |
| eplenmean               | 255       |
| fps                     | 11        |
| mean 100 episode reward | 848       |
| n_updates               | 200000    |
| q_grad_norm             | 3317.8787 |
| qfs_loss                | 87.75943  |
| qs_abs_difference       | 42.5      |
| qs_difference           | 41.8      |
| qs_mean                 | 293.62546 |
| time_elapsed            | 10929     |
| total timesteps         | 124977    |
| train_time              | 2865      |
| update_time             | 7693      |
---------------------------------------
---------------------------------------
| act_time                | 78        |
| current_lr              | 0.0003    |
| discount_q              | 0.0524    |
| env_time                | 203       |
| ep_rewmean              | 852       |
| episodes                | 1716      |
| eplenmean               | 257       |
| fps                     | 11        |
| mean 100 episode reward | 852       |
| n_updates               | 202800    |
| q_grad_norm             | 3920.137  |
| qfs_loss                | 101.11249 |
| qs_abs_difference       | 21.7      |
| qs_difference           | 21.1      |
| qs_mean                 | 320.58038 |
| time_elapsed            | 11134     |
| total timesteps         | 126334    |
| train_time              | 2941      |
| update_time             | 7820      |
---------------------------------------
---------------------------------------
| act_time                | 79        |
| current_lr              | 0.0003    |
| discount_q              | 0.000483  |
| env_time                | 206       |
| ep_rewmean              | 869       |
| episodes                | 1720      |
| eplenmean               | 261       |
| fps                     | 11        |
| mean 100 episode reward | 868       |
| n_updates               | 206000    |
| q_grad_norm             | 4095.279  |
| qfs_loss                | 93.18417  |
| qs_abs_difference       | 101       |
| qs_difference           | 101       |
| qs_mean                 | 318.76346 |
| time_elapsed            | 11370     |
| total timesteps         | 127929    |
| train_time              | 3028      |
| update_time             | 7964      |
---------------------------------------
---------------------------------------
| act_time                | 80        |
| current_lr              | 0.0003    |
| discount_q              | 0.0422    |
| env_time                | 207       |
| ep_rewmean              | 877       |
| episodes                | 1724      |
| eplenmean               | 263       |
| fps                     | 11        |
| mean 100 episode reward | 877       |
| n_updates               | 208400    |
| q_grad_norm             | 3103.1777 |
| qfs_loss                | 75.71451  |
| qs_abs_difference       | 33.1      |
| qs_difference           | 32.4      |
| qs_mean                 | 316.21228 |
| time_elapsed            | 11549     |
| total timesteps         | 129195    |
| train_time              | 3095      |
| update_time             | 8073      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 667       |
| eval_abs_qs_difference  | 232.61841 |
| eval_discount_q         | 60.9      |
| eval_ep_rewmean         | 74.8      |
| eval_eplenmean          | 40.5      |
| eval_qs                 | 267.94998 |
| eval_qs_difference      | 232       |
| eval_time_elapsed       | 0         |
| total timesteps         | 130001    |
---------------------------------------
---------------------------------------
| act_time                | 81        |
| current_lr              | 0.0003    |
| discount_q              | 0.000222  |
| env_time                | 210       |
| ep_rewmean              | 913       |
| episodes                | 1728      |
| eplenmean               | 272       |
| fps                     | 11        |
| mean 100 episode reward | 913       |
| n_updates               | 212000    |
| q_grad_norm             | 3424.5583 |
| qfs_loss                | 90.23119  |
| qs_abs_difference       | 30.5      |
| qs_difference           | 30.3      |
| qs_mean                 | 301.16095 |
| time_elapsed            | 11819     |
| total timesteps         | 130922    |
| train_time              | 3195      |
| update_time             | 8238      |
---------------------------------------
---------------------------------------
| act_time                | 82        |
| current_lr              | 0.0003    |
| discount_q              | 0.0112    |
| env_time                | 211       |
| ep_rewmean              | 909       |
| episodes                | 1732      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 909       |
| n_updates               | 213800    |
| q_grad_norm             | 4084.278  |
| qfs_loss                | 110.17368 |
| qs_abs_difference       | 259       |
| qs_difference           | 259       |
| qs_mean                 | 303.32413 |
| time_elapsed            | 11951     |
| total timesteps         | 131853    |
| train_time              | 3245      |
| update_time             | 8318      |
---------------------------------------
---------------------------------------
| act_time                | 82        |
| current_lr              | 0.0003    |
| discount_q              | 0.437     |
| env_time                | 213       |
| ep_rewmean              | 901       |
| episodes                | 1736      |
| eplenmean               | 268       |
| fps                     | 10        |
| mean 100 episode reward | 901       |
| n_updates               | 215800    |
| q_grad_norm             | 3377.7156 |
| qfs_loss                | 73.73302  |
| qs_abs_difference       | 23.4      |
| qs_difference           | 21.5      |
| qs_mean                 | 311.53564 |
| time_elapsed            | 12098     |
| total timesteps         | 132834    |
| train_time              | 3303      |
| update_time             | 8405      |
---------------------------------------
---------------------------------------
| act_time                | 83        |
| current_lr              | 0.0003    |
| discount_q              | 0.312     |
| env_time                | 214       |
| ep_rewmean              | 898       |
| episodes                | 1740      |
| eplenmean               | 268       |
| fps                     | 10        |
| mean 100 episode reward | 898       |
| n_updates               | 217600    |
| q_grad_norm             | 3996.3972 |
| qfs_loss                | 86.527145 |
| qs_abs_difference       | 68.9      |
| qs_difference           | 68.9      |
| qs_mean                 | 307.71664 |
| time_elapsed            | 12227     |
| total timesteps         | 133745    |
| train_time              | 3348      |
| update_time             | 8486      |
---------------------------------------
---------------------------------------
| act_time                | 84        |
| current_lr              | 0.0003    |
| discount_q              | 0.388     |
| env_time                | 215       |
| ep_rewmean              | 902       |
| episodes                | 1744      |
| eplenmean               | 268       |
| fps                     | 10        |
| mean 100 episode reward | 902       |
| n_updates               | 219600    |
| q_grad_norm             | 4099.0703 |
| qfs_loss                | 99.84302  |
| qs_abs_difference       | 19.1      |
| qs_difference           | 13.7      |
| qs_mean                 | 299.61945 |
| time_elapsed            | 12375     |
| total timesteps         | 134760    |
| train_time              | 3404      |
| update_time             | 8575      |
---------------------------------------
---------------------------------------
| act_time                | 84        |
| current_lr              | 0.0003    |
| discount_q              | 0.172     |
| env_time                | 216       |
| ep_rewmean              | 912       |
| episodes                | 1748      |
| eplenmean               | 271       |
| fps                     | 10        |
| mean 100 episode reward | 912       |
| n_updates               | 221200    |
| q_grad_norm             | 3485.2224 |
| qfs_loss                | 88.715065 |
| qs_abs_difference       | 235       |
| qs_difference           | 235       |
| qs_mean                 | 316.88815 |
| time_elapsed            | 12493     |
| total timesteps         | 135509    |
| train_time              | 3448      |
| update_time             | 8647      |
---------------------------------------
---------------------------------------
| act_time                | 85        |
| current_lr              | 0.0003    |
| discount_q              | 0.0169    |
| env_time                | 218       |
| ep_rewmean              | 918       |
| episodes                | 1752      |
| eplenmean               | 272       |
| fps                     | 10        |
| mean 100 episode reward | 918       |
| n_updates               | 223800    |
| q_grad_norm             | 3798.458  |
| qfs_loss                | 86.82732  |
| qs_abs_difference       | 26.4      |
| qs_difference           | 26        |
| qs_mean                 | 306.05487 |
| time_elapsed            | 12684     |
| total timesteps         | 136814    |
| train_time              | 3520      |
| update_time             | 8763      |
---------------------------------------
---------------------------------------
| act_time                | 86        |
| current_lr              | 0.0003    |
| discount_q              | 0.234     |
| env_time                | 220       |
| ep_rewmean              | 909       |
| episodes                | 1756      |
| eplenmean               | 269       |
| fps                     | 10        |
| mean 100 episode reward | 909       |
| n_updates               | 225800    |
| q_grad_norm             | 3271.3894 |
| qfs_loss                | 60.128613 |
| qs_abs_difference       | 8.12      |
| qs_difference           | 5.36      |
| qs_mean                 | 300.41382 |
| time_elapsed            | 12829     |
| total timesteps         | 137821    |
| train_time              | 3574      |
| update_time             | 8852      |
---------------------------------------
---------------------------------------
| act_time                | 86        |
| current_lr              | 0.0003    |
| discount_q              | 77.3      |
| env_time                | 220       |
| ep_rewmean              | 886       |
| episodes                | 1760      |
| eplenmean               | 262       |
| fps                     | 10        |
| mean 100 episode reward | 886       |
| n_updates               | 226400    |
| q_grad_norm             | 3570.421  |
| qfs_loss                | 77.23286  |
| qs_abs_difference       | 40.5      |
| qs_difference           | 39.9      |
| qs_mean                 | 291.98663 |
| time_elapsed            | 12871     |
| total timesteps         | 138197    |
| train_time              | 3589      |
| update_time             | 8878      |
---------------------------------------
---------------------------------------
| act_time                | 87        |
| current_lr              | 0.0003    |
| discount_q              | 0.211     |
| env_time                | 221       |
| ep_rewmean              | 881       |
| episodes                | 1764      |
| eplenmean               | 261       |
| fps                     | 10        |
| mean 100 episode reward | 882       |
| n_updates               | 228200    |
| q_grad_norm             | 3347.1296 |
| qfs_loss                | 85.46307  |
| qs_abs_difference       | 144       |
| qs_difference           | 144       |
| qs_mean                 | 314.31995 |
| time_elapsed            | 13003     |
| total timesteps         | 139062    |
| train_time              | 3639      |
| update_time             | 8957      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 660       |
| eval_abs_qs_difference  | 233.25717 |
| eval_discount_q         | 112       |
| eval_ep_rewmean         | 174       |
| eval_eplenmean          | 87.1      |
| eval_qs                 | 305.5172  |
| eval_qs_difference      | 233       |
| eval_time_elapsed       | 1         |
| total timesteps         | 140001    |
---------------------------------------
---------------------------------------
| act_time                | 88        |
| current_lr              | 0.0003    |
| discount_q              | 0.0332    |
| env_time                | 223       |
| ep_rewmean              | 887       |
| episodes                | 1768      |
| eplenmean               | 262       |
| fps                     | 10        |
| mean 100 episode reward | 887       |
| n_updates               | 230600    |
| q_grad_norm             | 4035.3962 |
| qfs_loss                | 117.19077 |
| qs_abs_difference       | 21.3      |
| qs_difference           | 20.9      |
| qs_mean                 | 287.073   |
| time_elapsed            | 13177     |
| total timesteps         | 140216    |
| train_time              | 3703      |
| update_time             | 9064      |
---------------------------------------
---------------------------------------
| act_time                | 88        |
| current_lr              | 0.0003    |
| discount_q              | 1.45      |
| env_time                | 224       |
| ep_rewmean              | 885       |
| episodes                | 1772      |
| eplenmean               | 261       |
| fps                     | 10        |
| mean 100 episode reward | 885       |
| n_updates               | 232200    |
| q_grad_norm             | 3074.9014 |
| qfs_loss                | 60.779537 |
| qs_abs_difference       | 23.5      |
| qs_difference           | 21.5      |
| qs_mean                 | 293.95816 |
| time_elapsed            | 13292     |
| total timesteps         | 141011    |
| train_time              | 3747      |
| update_time             | 9133      |
---------------------------------------
---------------------------------------
| act_time                | 89        |
| current_lr              | 0.0003    |
| discount_q              | 0.0336    |
| env_time                | 226       |
| ep_rewmean              | 887       |
| episodes                | 1776      |
| eplenmean               | 261       |
| fps                     | 10        |
| mean 100 episode reward | 887       |
| n_updates               | 234400    |
| q_grad_norm             | 3177.6284 |
| qfs_loss                | 75.37622  |
| qs_abs_difference       | 63.4      |
| qs_difference           | 63.3      |
| qs_mean                 | 308.94077 |
| time_elapsed            | 13453     |
| total timesteps         | 142166    |
| train_time              | 3808      |
| update_time             | 9230      |
---------------------------------------
---------------------------------------
| act_time                | 90        |
| current_lr              | 0.0003    |
| discount_q              | 0.0195    |
| env_time                | 228       |
| ep_rewmean              | 898       |
| episodes                | 1780      |
| eplenmean               | 263       |
| fps                     | 10        |
| mean 100 episode reward | 898       |
| n_updates               | 237200    |
| q_grad_norm             | 3207.8523 |
| qfs_loss                | 74.41995  |
| qs_abs_difference       | 14.8      |
| qs_difference           | -5.96     |
| qs_mean                 | 312.05334 |
| time_elapsed            | 13572     |
| total timesteps         | 143501    |
| train_time              | 3847      |
| update_time             | 9307      |
---------------------------------------
---------------------------------------
| act_time                | 91        |
| current_lr              | 0.0003    |
| discount_q              | 0.0177    |
| env_time                | 229       |
| ep_rewmean              | 918       |
| episodes                | 1784      |
| eplenmean               | 268       |
| fps                     | 10        |
| mean 100 episode reward | 918       |
| n_updates               | 239600    |
| q_grad_norm             | 4230.5796 |
| qfs_loss                | 113.04035 |
| qs_abs_difference       | 47.6      |
| qs_difference           | 47.6      |
| qs_mean                 | 301.79095 |
| time_elapsed            | 13669     |
| total timesteps         | 144731    |
| train_time              | 3878      |
| update_time             | 9369      |
---------------------------------------
---------------------------------------
| act_time                | 91        |
| current_lr              | 0.0003    |
| discount_q              | 0.144     |
| env_time                | 231       |
| ep_rewmean              | 926       |
| episodes                | 1788      |
| eplenmean               | 270       |
| fps                     | 10        |
| mean 100 episode reward | 926       |
| n_updates               | 241600    |
| q_grad_norm             | 3352.8545 |
| qfs_loss                | 76.5362   |
| qs_abs_difference       | 26.7      |
| qs_difference           | 26.6      |
| qs_mean                 | 295.72922 |
| time_elapsed            | 13750     |
| total timesteps         | 145748    |
| train_time              | 3904      |
| update_time             | 9421      |
---------------------------------------
---------------------------------------
| act_time                | 92        |
| current_lr              | 0.0003    |
| discount_q              | 0.0753    |
| env_time                | 233       |
| ep_rewmean              | 905       |
| episodes                | 1792      |
| eplenmean               | 264       |
| fps                     | 10        |
| mean 100 episode reward | 905       |
| n_updates               | 243800    |
| q_grad_norm             | 3182.3718 |
| qfs_loss                | 72.917145 |
| qs_abs_difference       | 7.83      |
| qs_difference           | 0.682     |
| qs_mean                 | 305.50366 |
| time_elapsed            | 13838     |
| total timesteps         | 146885    |
| train_time              | 3933      |
| update_time             | 9477      |
---------------------------------------
---------------------------------------
| act_time                | 93        |
| current_lr              | 0.0003    |
| discount_q              | 0.0343    |
| env_time                | 235       |
| ep_rewmean              | 912       |
| episodes                | 1796      |
| eplenmean               | 266       |
| fps                     | 10        |
| mean 100 episode reward | 912       |
| n_updates               | 246600    |
| q_grad_norm             | 3932.9717 |
| qfs_loss                | 79.99898  |
| qs_abs_difference       | 21.6      |
| qs_difference           | 21.6      |
| qs_mean                 | 327.7617  |
| time_elapsed            | 13950     |
| total timesteps         | 148240    |
| train_time              | 3970      |
| update_time             | 9549      |
---------------------------------------
---------------------------------------
| act_time                | 94        |
| current_lr              | 0.0003    |
| discount_q              | 0.0324    |
| env_time                | 237       |
| ep_rewmean              | 924       |
| episodes                | 1800      |
| eplenmean               | 268       |
| fps                     | 10        |
| mean 100 episode reward | 924       |
| n_updates               | 249000    |
| q_grad_norm             | 2905.326  |
| qfs_loss                | 75.34634  |
| qs_abs_difference       | 34.9      |
| qs_difference           | 34.3      |
| qs_mean                 | 321.14233 |
| time_elapsed            | 14046     |
| total timesteps         | 149447    |
| train_time              | 4001      |
| update_time             | 9610      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 698       |
| eval_abs_qs_difference  | 25.108793 |
| eval_discount_q         | 258       |
| eval_ep_rewmean         | 1.03e+03  |
| eval_eplenmean          | 287       |
| eval_qs                 | 290.77405 |
| eval_qs_difference      | 20.3      |
| eval_time_elapsed       | 6         |
| total timesteps         | 150001    |
---------------------------------------
---------------------------------------
| act_time                | 95        |
| current_lr              | 0.0003    |
| discount_q              | 0.0135    |
| env_time                | 239       |
| ep_rewmean              | 948       |
| episodes                | 1804      |
| eplenmean               | 274       |
| fps                     | 10        |
| mean 100 episode reward | 948       |
| n_updates               | 251800    |
| q_grad_norm             | 3502.7295 |
| qfs_loss                | 76.1884   |
| qs_abs_difference       | 37.8      |
| qs_difference           | 37.8      |
| qs_mean                 | 336.65247 |
| time_elapsed            | 14163     |
| total timesteps         | 150810    |
| train_time              | 4038      |
| update_time             | 9681      |
---------------------------------------
---------------------------------------
| act_time                | 96        |
| current_lr              | 0.0003    |
| discount_q              | 0.0226    |
| env_time                | 241       |
| ep_rewmean              | 968       |
| episodes                | 1808      |
| eplenmean               | 278       |
| fps                     | 10        |
| mean 100 episode reward | 968       |
| n_updates               | 254200    |
| q_grad_norm             | 4187.804  |
| qfs_loss                | 99.17919  |
| qs_abs_difference       | 16.6      |
| qs_difference           | 11.2      |
| qs_mean                 | 309.52087 |
| time_elapsed            | 14259     |
| total timesteps         | 152046    |
| train_time              | 4069      |
| update_time             | 9742      |
---------------------------------------
---------------------------------------
| act_time                | 97        |
| current_lr              | 0.0003    |
| discount_q              | 0.0117    |
| env_time                | 243       |
| ep_rewmean              | 996       |
| episodes                | 1812      |
| eplenmean               | 284       |
| fps                     | 10        |
| mean 100 episode reward | 996       |
| n_updates               | 256800    |
| q_grad_norm             | 3301.0562 |
| qfs_loss                | 61.982975 |
| qs_abs_difference       | 14.4      |
| qs_difference           | 14        |
| qs_mean                 | 305.63464 |
| time_elapsed            | 14361     |
| total timesteps         | 153327    |
| train_time              | 4103      |
| update_time             | 9808      |
---------------------------------------
---------------------------------------
| act_time                | 98        |
| current_lr              | 0.0003    |
| discount_q              | 0.34      |
| env_time                | 244       |
| ep_rewmean              | 985       |
| episodes                | 1816      |
| eplenmean               | 279       |
| fps                     | 10        |
| mean 100 episode reward | 985       |
| n_updates               | 258600    |
| q_grad_norm             | 3065.3862 |
| qfs_loss                | 66.9491   |
| qs_abs_difference       | 38.5      |
| qs_difference           | 38.4      |
| qs_mean                 | 297.0031  |
| time_elapsed            | 14433     |
| total timesteps         | 154256    |
| train_time              | 4126      |
| update_time             | 9853      |
---------------------------------------
---------------------------------------
| act_time                | 98        |
| current_lr              | 0.0003    |
| discount_q              | 0.623     |
| env_time                | 246       |
| ep_rewmean              | 965       |
| episodes                | 1820      |
| eplenmean               | 272       |
| fps                     | 10        |
| mean 100 episode reward | 965       |
| n_updates               | 260400    |
| q_grad_norm             | 2909.0693 |
| qfs_loss                | 67.29067  |
| qs_abs_difference       | 18.3      |
| qs_difference           | 17.4      |
| qs_mean                 | 303.11774 |
| time_elapsed            | 14503     |
| total timesteps         | 155142    |
| train_time              | 4150      |
| update_time             | 9898      |
---------------------------------------
---------------------------------------
| act_time                | 99        |
| current_lr              | 0.0003    |
| discount_q              | 0.00956   |
| env_time                | 248       |
| ep_rewmean              | 970       |
| episodes                | 1824      |
| eplenmean               | 272       |
| fps                     | 10        |
| mean 100 episode reward | 970       |
| n_updates               | 263000    |
| q_grad_norm             | 4137.199  |
| qfs_loss                | 86.944244 |
| qs_abs_difference       | 45.2      |
| qs_difference           | 45.2      |
| qs_mean                 | 321.455   |
| time_elapsed            | 14605     |
| total timesteps         | 156444    |
| train_time              | 4184      |
| update_time             | 9962      |
---------------------------------------
---------------------------------------
| act_time                | 100       |
| current_lr              | 0.0003    |
| discount_q              | 0.171     |
| env_time                | 249       |
| ep_rewmean              | 946       |
| episodes                | 1828      |
| eplenmean               | 265       |
| fps                     | 10        |
| mean 100 episode reward | 946       |
| n_updates               | 265000    |
| q_grad_norm             | 2644.9734 |
| qfs_loss                | 58.68129  |
| qs_abs_difference       | 37.6      |
| qs_difference           | 36.1      |
| qs_mean                 | 307.38208 |
| time_elapsed            | 14684     |
| total timesteps         | 157455    |
| train_time              | 4210      |
| update_time             | 10012     |
---------------------------------------
---------------------------------------
| act_time                | 101       |
| current_lr              | 0.0003    |
| discount_q              | 0.029     |
| env_time                | 251       |
| ep_rewmean              | 961       |
| episodes                | 1832      |
| eplenmean               | 268       |
| fps                     | 10        |
| mean 100 episode reward | 961       |
| n_updates               | 267400    |
| q_grad_norm             | 3309.4563 |
| qfs_loss                | 84.74923  |
| qs_abs_difference       | 26.1      |
| qs_difference           | 25.6      |
| qs_mean                 | 311.13086 |
| time_elapsed            | 14778     |
| total timesteps         | 158654    |
| train_time              | 4241      |
| update_time             | 10072     |
---------------------------------------
---------------------------------------
| act_time                | 102       |
| current_lr              | 0.0003    |
| discount_q              | 0.0138    |
| env_time                | 253       |
| ep_rewmean              | 977       |
| episodes                | 1836      |
| eplenmean               | 271       |
| fps                     | 10        |
| mean 100 episode reward | 977       |
| n_updates               | 270000    |
| q_grad_norm             | 2417.7822 |
| qfs_loss                | 62.855175 |
| qs_abs_difference       | 25.4      |
| qs_difference           | 22.7      |
| qs_mean                 | 313.55618 |
| time_elapsed            | 14879     |
| total timesteps         | 159931    |
| train_time              | 4275      |
| update_time             | 10136     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 741       |
| eval_abs_qs_difference  | 30.851166 |
| eval_discount_q         | 271       |
| eval_ep_rewmean         | 1.16e+03  |
| eval_eplenmean          | 306       |
| eval_qs                 | 314.54108 |
| eval_qs_difference      | 22.3      |
| eval_time_elapsed       | 7         |
| total timesteps         | 160001    |
---------------------------------------
---------------------------------------
| act_time                | 103       |
| current_lr              | 0.0003    |
| discount_q              | 0.0154    |
| env_time                | 255       |
| ep_rewmean              | 994       |
| episodes                | 1840      |
| eplenmean               | 274       |
| fps                     | 10        |
| mean 100 episode reward | 994       |
| n_updates               | 272400    |
| q_grad_norm             | 3360.711  |
| qfs_loss                | 85.059105 |
| qs_abs_difference       | 57.5      |
| qs_difference           | 57.3      |
| qs_mean                 | 319.57007 |
| time_elapsed            | 14981     |
| total timesteps         | 161173    |
| train_time              | 4306      |
| update_time             | 10195     |
---------------------------------------
---------------------------------------
| act_time                | 104       |
| current_lr              | 0.0003    |
| discount_q              | 0.114     |
| env_time                | 257       |
| ep_rewmean              | 1e+03     |
| episodes                | 1844      |
| eplenmean               | 276       |
| fps                     | 10        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 274800    |
| q_grad_norm             | 3097.7273 |
| qfs_loss                | 60.40657  |
| qs_abs_difference       | 13.8      |
| qs_difference           | 11.7      |
| qs_mean                 | 326.0865  |
| time_elapsed            | 15074     |
| total timesteps         | 162338    |
| train_time              | 4337      |
| update_time             | 10255     |
---------------------------------------
---------------------------------------
| act_time                | 104       |
| current_lr              | 0.0003    |
| discount_q              | 0.0799    |
| env_time                | 258       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1848      |
| eplenmean               | 279       |
| fps                     | 10        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 276800    |
| q_grad_norm             | 2899.8066 |
| qfs_loss                | 57.235073 |
| qs_abs_difference       | 20.7      |
| qs_difference           | 20.5      |
| qs_mean                 | 291.34592 |
| time_elapsed            | 15152     |
| total timesteps         | 163377    |
| train_time              | 4364      |
| update_time             | 10303     |
---------------------------------------
---------------------------------------
| act_time                | 106       |
| current_lr              | 0.0003    |
| discount_q              | 0.00393   |
| env_time                | 261       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1852      |
| eplenmean               | 279       |
| fps                     | 10        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 279600    |
| q_grad_norm             | 2786.5984 |
| qfs_loss                | 68.58951  |
| qs_abs_difference       | 46.8      |
| qs_difference           | 46.2      |
| qs_mean                 | 303.83728 |
| time_elapsed            | 15260     |
| total timesteps         | 164738    |
| train_time              | 4400      |
| update_time             | 10372     |
---------------------------------------
---------------------------------------
| act_time                | 106       |
| current_lr              | 0.0003    |
| discount_q              | 0.145     |
| env_time                | 262       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1856      |
| eplenmean               | 279       |
| fps                     | 10        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 281600    |
| q_grad_norm             | 2484.6504 |
| qfs_loss                | 50.909664 |
| qs_abs_difference       | 54.3      |
| qs_difference           | 54.3      |
| qs_mean                 | 316.0236  |
| time_elapsed            | 15338     |
| total timesteps         | 165764    |
| train_time              | 4426      |
| update_time             | 10421     |
---------------------------------------
---------------------------------------
| act_time                | 107       |
| current_lr              | 0.0003    |
| discount_q              | 0.0482    |
| env_time                | 264       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 1860      |
| eplenmean               | 287       |
| fps                     | 10        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 283800    |
| q_grad_norm             | 2541.8708 |
| qfs_loss                | 48.41141  |
| qs_abs_difference       | 26.9      |
| qs_difference           | 26.8      |
| qs_mean                 | 300.92935 |
| time_elapsed            | 15423     |
| total timesteps         | 166867    |
| train_time              | 4455      |
| update_time             | 10475     |
---------------------------------------
---------------------------------------
| act_time                | 108       |
| current_lr              | 0.0003    |
| discount_q              | 0.0576    |
| env_time                | 266       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 1864      |
| eplenmean               | 289       |
| fps                     | 10        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 286200    |
| q_grad_norm             | 2369.985  |
| qfs_loss                | 46.15983  |
| qs_abs_difference       | 32.1      |
| qs_difference           | 31.8      |
| qs_mean                 | 321.51282 |
| time_elapsed            | 15515     |
| total timesteps         | 168011    |
| train_time              | 4486      |
| update_time             | 10533     |
---------------------------------------
---------------------------------------
| act_time                | 108       |
| current_lr              | 0.0003    |
| discount_q              | 6.4       |
| env_time                | 266       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1868      |
| eplenmean               | 283       |
| fps                     | 10        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 287000    |
| q_grad_norm             | 2878.847  |
| qfs_loss                | 62.8268   |
| qs_abs_difference       | 210       |
| qs_difference           | 210       |
| qs_mean                 | 351.93274 |
| time_elapsed            | 15546     |
| total timesteps         | 168475    |
| train_time              | 4497      |
| update_time             | 10552     |
---------------------------------------
--------------------------------------
| act_time                | 109      |
| current_lr              | 0.0003   |
| discount_q              | 0.0182   |
| env_time                | 268      |
| ep_rewmean              | 1.06e+03 |
| episodes                | 1872     |
| eplenmean               | 287      |
| fps                     | 10       |
| mean 100 episode reward | 1.06e+03 |
| n_updates               | 289600   |
| q_grad_norm             | 3398.903 |
| qfs_loss                | 85.68652 |
| qs_abs_difference       | 22.4     |
| qs_difference           | 18.3     |
| qs_mean                 | 308.9045 |
| time_elapsed            | 15646    |
| total timesteps         | 169720   |
| train_time              | 4531     |
| update_time             | 10615    |
--------------------------------------
---------------------------------------
| eval mean 100 episod... | 733       |
| eval_abs_qs_difference  | 174.17912 |
| eval_discount_q         | 183       |
| eval_ep_rewmean         | 445       |
| eval_eplenmean          | 153       |
| eval_qs                 | 322.93002 |
| eval_qs_difference      | 173       |
| eval_time_elapsed       | 3         |
| total timesteps         | 170001    |
---------------------------------------
---------------------------------------
| act_time                | 110       |
| current_lr              | 0.0003    |
| discount_q              | 0.0373    |
| env_time                | 270       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1876      |
| eplenmean               | 287       |
| fps                     | 10        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 292000    |
| q_grad_norm             | 2389.2114 |
| qfs_loss                | 56.803436 |
| qs_abs_difference       | 20.7      |
| qs_difference           | 20.1      |
| qs_mean                 | 322.23355 |
| time_elapsed            | 15742     |
| total timesteps         | 170913    |
| train_time              | 4562      |
| update_time             | 10673     |
---------------------------------------
---------------------------------------
| act_time                | 111       |
| current_lr              | 0.0003    |
| discount_q              | 1.15      |
| env_time                | 271       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1880      |
| eplenmean               | 282       |
| fps                     | 10        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 293600    |
| q_grad_norm             | 2747.1182 |
| qfs_loss                | 70.96854  |
| qs_abs_difference       | 28        |
| qs_difference           | 26.8      |
| qs_mean                 | 312.5577  |
| time_elapsed            | 15804     |
| total timesteps         | 171733    |
| train_time              | 4583      |
| update_time             | 10711     |
---------------------------------------
---------------------------------------
| act_time                | 112       |
| current_lr              | 0.0003    |
| discount_q              | 0.043     |
| env_time                | 273       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1884      |
| eplenmean               | 281       |
| fps                     | 10        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 295800    |
| q_grad_norm             | 2500.7637 |
| qfs_loss                | 60.610252 |
| qs_abs_difference       | 22.3      |
| qs_difference           | 16.7      |
| qs_mean                 | 291.3599  |
| time_elapsed            | 15888     |
| total timesteps         | 172838    |
| train_time              | 4611      |
| update_time             | 10764     |
---------------------------------------
---------------------------------------
| act_time                | 112       |
| current_lr              | 0.0003    |
| discount_q              | 0.153     |
| env_time                | 275       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1888      |
| eplenmean               | 280       |
| fps                     | 10        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 297600    |
| q_grad_norm             | 3243.5388 |
| qfs_loss                | 69.59742  |
| qs_abs_difference       | 77.2      |
| qs_difference           | 76.9      |
| qs_mean                 | 287.58926 |
| time_elapsed            | 15957     |
| total timesteps         | 173759    |
| train_time              | 4635      |
| update_time             | 10807     |
---------------------------------------
---------------------------------------
| act_time                | 113       |
| current_lr              | 0.0003    |
| discount_q              | 0.0517    |
| env_time                | 276       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1892      |
| eplenmean               | 278       |
| fps                     | 10        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 299400    |
| q_grad_norm             | 2352.0918 |
| qfs_loss                | 57.05521  |
| qs_abs_difference       | 243       |
| qs_difference           | 243       |
| qs_mean                 | 346.0968  |
| time_elapsed            | 16026     |
| total timesteps         | 174646    |
| train_time              | 4658      |
| update_time             | 10850     |
---------------------------------------
---------------------------------------
| act_time                | 114       |
| current_lr              | 0.0003    |
| discount_q              | 0.205     |
| env_time                | 277       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1896      |
| eplenmean               | 274       |
| fps                     | 10        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 301400    |
| q_grad_norm             | 2853.3997 |
| qfs_loss                | 59.707394 |
| qs_abs_difference       | 103       |
| qs_difference           | 103       |
| qs_mean                 | 345.88593 |
| time_elapsed            | 16103     |
| total timesteps         | 175631    |
| train_time              | 4684      |
| update_time             | 10898     |
---------------------------------------
---------------------------------------
| act_time                | 114       |
| current_lr              | 0.0003    |
| discount_q              | 0.141     |
| env_time                | 279       |
| ep_rewmean              | 1e+03     |
| episodes                | 1900      |
| eplenmean               | 271       |
| fps                     | 10        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 303200    |
| q_grad_norm             | 3055.1162 |
| qfs_loss                | 73.5664   |
| qs_abs_difference       | 72.8      |
| qs_difference           | 71.7      |
| qs_mean                 | 286.90994 |
| time_elapsed            | 16172     |
| total timesteps         | 176550    |
| train_time              | 4708      |
| update_time             | 10941     |
---------------------------------------
---------------------------------------
| act_time                | 115       |
| current_lr              | 0.0003    |
| discount_q              | 1.72      |
| env_time                | 280       |
| ep_rewmean              | 967       |
| episodes                | 1904      |
| eplenmean               | 263       |
| fps                     | 10        |
| mean 100 episode reward | 967       |
| n_updates               | 304200    |
| q_grad_norm             | 2909.6296 |
| qfs_loss                | 72.13922  |
| qs_abs_difference       | 245       |
| qs_difference           | 245       |
| qs_mean                 | 348.6711  |
| time_elapsed            | 16210     |
| total timesteps         | 177091    |
| train_time              | 4721      |
| update_time             | 10965     |
---------------------------------------
---------------------------------------
| act_time                | 115       |
| current_lr              | 0.0003    |
| discount_q              | 0.207     |
| env_time                | 281       |
| ep_rewmean              | 946       |
| episodes                | 1908      |
| eplenmean               | 258       |
| fps                     | 10        |
| mean 100 episode reward | 946       |
| n_updates               | 305800    |
| q_grad_norm             | 3615.7068 |
| qfs_loss                | 91.07185  |
| qs_abs_difference       | 244       |
| qs_difference           | 244       |
| qs_mean                 | 348.30774 |
| time_elapsed            | 16271     |
| total timesteps         | 177840    |
| train_time              | 4742      |
| update_time             | 11003     |
---------------------------------------
---------------------------------------
| act_time                | 116       |
| current_lr              | 0.0003    |
| discount_q              | 0.864     |
| env_time                | 282       |
| ep_rewmean              | 916       |
| episodes                | 1912      |
| eplenmean               | 251       |
| fps                     | 10        |
| mean 100 episode reward | 916       |
| n_updates               | 307000    |
| q_grad_norm             | 4298.2173 |
| qfs_loss                | 98.091354 |
| qs_abs_difference       | 245       |
| qs_difference           | 245       |
| qs_mean                 | 351.14047 |
| time_elapsed            | 16317     |
| total timesteps         | 178452    |
| train_time              | 4757      |
| update_time             | 11032     |
---------------------------------------
---------------------------------------
| act_time                | 116       |
| current_lr              | 0.0003    |
| discount_q              | 0.209     |
| env_time                | 283       |
| ep_rewmean              | 918       |
| episodes                | 1916      |
| eplenmean               | 251       |
| fps                     | 10        |
| mean 100 episode reward | 918       |
| n_updates               | 308800    |
| q_grad_norm             | 3326.6104 |
| qfs_loss                | 87.42031  |
| qs_abs_difference       | 22.2      |
| qs_difference           | 14        |
| qs_mean                 | 286.11465 |
| time_elapsed            | 16386     |
| total timesteps         | 179393    |
| train_time              | 4781      |
| update_time             | 11075     |
---------------------------------------
---------------------------------------
| act_time                | 117       |
| current_lr              | 0.0003    |
| discount_q              | 103       |
| env_time                | 284       |
| ep_rewmean              | 894       |
| episodes                | 1920      |
| eplenmean               | 246       |
| fps                     | 10        |
| mean 100 episode reward | 894       |
| n_updates               | 309600    |
| q_grad_norm             | 2891.5747 |
| qfs_loss                | 59.77101  |
| qs_abs_difference       | 50.1      |
| qs_difference           | 50.1      |
| qs_mean                 | 311.35797 |
| time_elapsed            | 16417     |
| total timesteps         | 179710    |
| train_time              | 4791      |
| update_time             | 11094     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 718       |
| eval_abs_qs_difference  | 115.35847 |
| eval_discount_q         | 207       |
| eval_ep_rewmean         | 551       |
| eval_eplenmean          | 166       |
| eval_qs                 | 297.40833 |
| eval_qs_difference      | 112       |
| eval_time_elapsed       | 3         |
| total timesteps         | 180001    |
---------------------------------------
---------------------------------------
| act_time                | 117       |
| current_lr              | 0.0003    |
| discount_q              | 0.103     |
| env_time                | 285       |
| ep_rewmean              | 883       |
| episodes                | 1924      |
| eplenmean               | 243       |
| fps                     | 10        |
| mean 100 episode reward | 883       |
| n_updates               | 311400    |
| q_grad_norm             | 3164.769  |
| qfs_loss                | 82.017784 |
| qs_abs_difference       | 40.1      |
| qs_difference           | 34.4      |
| qs_mean                 | 285.95328 |
| time_elapsed            | 16490     |
| total timesteps         | 180699    |
| train_time              | 4815      |
| update_time             | 11137     |
---------------------------------------
---------------------------------------
| act_time                | 118       |
| current_lr              | 0.0003    |
| discount_q              | 0.0803    |
| env_time                | 286       |
| ep_rewmean              | 872       |
| episodes                | 1928      |
| eplenmean               | 239       |
| fps                     | 10        |
| mean 100 episode reward | 872       |
| n_updates               | 312800    |
| q_grad_norm             | 3017.185  |
| qfs_loss                | 77.390045 |
| qs_abs_difference       | 277       |
| qs_difference           | 277       |
| qs_mean                 | 309.15994 |
| time_elapsed            | 16543     |
| total timesteps         | 181384    |
| train_time              | 4833      |
| update_time             | 11171     |
---------------------------------------
---------------------------------------
| act_time                | 118       |
| current_lr              | 0.0003    |
| discount_q              | 7.04      |
| env_time                | 287       |
| ep_rewmean              | 838       |
| episodes                | 1932      |
| eplenmean               | 232       |
| fps                     | 10        |
| mean 100 episode reward | 838       |
| n_updates               | 313800    |
| q_grad_norm             | 3624.2163 |
| qfs_loss                | 89.94897  |
| qs_abs_difference       | 163       |
| qs_difference           | 163       |
| qs_mean                 | 276.01886 |
| time_elapsed            | 16581     |
| total timesteps         | 181832    |
| train_time              | 4846      |
| update_time             | 11195     |
---------------------------------------
--------------------------------------
| act_time                | 119      |
| current_lr              | 0.0003   |
| discount_q              | 0.575    |
| env_time                | 288      |
| ep_rewmean              | 805      |
| episodes                | 1936     |
| eplenmean               | 224      |
| fps                     | 10       |
| mean 100 episode reward | 805      |
| n_updates               | 314800   |
| q_grad_norm             | 2742.526 |
| qfs_loss                | 85.08474 |
| qs_abs_difference       | 278      |
| qs_difference           | 278      |
| qs_mean                 | 313.3354 |
| time_elapsed            | 16620    |
| total timesteps         | 182336   |
| train_time              | 4860     |
| update_time             | 11218    |
--------------------------------------
---------------------------------------
| act_time                | 119       |
| current_lr              | 0.0003    |
| discount_q              | 42.1      |
| env_time                | 288       |
| ep_rewmean              | 763       |
| episodes                | 1940      |
| eplenmean               | 214       |
| fps                     | 10        |
| mean 100 episode reward | 763       |
| n_updates               | 315200    |
| q_grad_norm             | 3318.0862 |
| qfs_loss                | 78.41339  |
| qs_abs_difference       | 150       |
| qs_difference           | 149       |
| qs_mean                 | 256.56577 |
| time_elapsed            | 16635     |
| total timesteps         | 182570    |
| train_time              | 4865      |
| update_time             | 11228     |
---------------------------------------
---------------------------------------
| act_time                | 119       |
| current_lr              | 0.0003    |
| discount_q              | 36.5      |
| env_time                | 289       |
| ep_rewmean              | 738       |
| episodes                | 1944      |
| eplenmean               | 208       |
| fps                     | 10        |
| mean 100 episode reward | 738       |
| n_updates               | 316400    |
| q_grad_norm             | 3334.723  |
| qfs_loss                | 88.7204   |
| qs_abs_difference       | 53.4      |
| qs_difference           | 53.4      |
| qs_mean                 | 343.52725 |
| time_elapsed            | 16681     |
| total timesteps         | 183106    |
| train_time              | 4881      |
| update_time             | 11257     |
---------------------------------------
----------------------------------------
| act_time                | 120        |
| current_lr              | 0.0003     |
| discount_q              | 0.262      |
| env_time                | 290        |
| ep_rewmean              | 720        |
| episodes                | 1948       |
| eplenmean               | 204        |
| fps                     | 10         |
| mean 100 episode reward | 720        |
| n_updates               | 317600     |
| q_grad_norm             | 4259.717   |
| qfs_loss                | 108.729706 |
| qs_abs_difference       | 220        |
| qs_difference           | 220        |
| qs_mean                 | 278.3499   |
| time_elapsed            | 16727      |
| total timesteps         | 183777     |
| train_time              | 4896       |
| update_time             | 11285      |
----------------------------------------
---------------------------------------
| act_time                | 120       |
| current_lr              | 0.0003    |
| discount_q              | 0.0922    |
| env_time                | 292       |
| ep_rewmean              | 712       |
| episodes                | 1952      |
| eplenmean               | 201       |
| fps                     | 10        |
| mean 100 episode reward | 712       |
| n_updates               | 319800    |
| q_grad_norm             | 2945.6143 |
| qfs_loss                | 72.2244   |
| qs_abs_difference       | 45.5      |
| qs_difference           | 44.2      |
| qs_mean                 | 308.43112 |
| time_elapsed            | 16811     |
| total timesteps         | 184849    |
| train_time              | 4925      |
| update_time             | 11338     |
---------------------------------------
---------------------------------------
| act_time                | 121       |
| current_lr              | 0.0003    |
| discount_q              | 0.158     |
| env_time                | 293       |
| ep_rewmean              | 715       |
| episodes                | 1956      |
| eplenmean               | 201       |
| fps                     | 11        |
| mean 100 episode reward | 715       |
| n_updates               | 321800    |
| q_grad_norm             | 3469.58   |
| qfs_loss                | 88.00763  |
| qs_abs_difference       | 21.8      |
| qs_difference           | 19        |
| qs_mean                 | 304.40222 |
| time_elapsed            | 16889     |
| total timesteps         | 185836    |
| train_time              | 4951      |
| update_time             | 11387     |
---------------------------------------
---------------------------------------
| act_time                | 122       |
| current_lr              | 0.0003    |
| discount_q              | 0.071     |
| env_time                | 295       |
| ep_rewmean              | 715       |
| episodes                | 1960      |
| eplenmean               | 201       |
| fps                     | 11        |
| mean 100 episode reward | 715       |
| n_updates               | 324000    |
| q_grad_norm             | 3311.4656 |
| qfs_loss                | 71.34662  |
| qs_abs_difference       | 22        |
| qs_difference           | 21.9      |
| qs_mean                 | 321.71597 |
| time_elapsed            | 16976     |
| total timesteps         | 186940    |
| train_time              | 4980      |
| update_time             | 11441     |
---------------------------------------
---------------------------------------
| act_time                | 123       |
| current_lr              | 0.0003    |
| discount_q              | 0.0658    |
| env_time                | 297       |
| ep_rewmean              | 712       |
| episodes                | 1964      |
| eplenmean               | 200       |
| fps                     | 11        |
| mean 100 episode reward | 712       |
| n_updates               | 326000    |
| q_grad_norm             | 3717.644  |
| qfs_loss                | 91.95598  |
| qs_abs_difference       | 33.7      |
| qs_difference           | 32.3      |
| qs_mean                 | 305.49448 |
| time_elapsed            | 17054     |
| total timesteps         | 187994    |
| train_time              | 5007      |
| update_time             | 11490     |
---------------------------------------
---------------------------------------
| act_time                | 123       |
| current_lr              | 0.0003    |
| discount_q              | 0.778     |
| env_time                | 298       |
| ep_rewmean              | 726       |
| episodes                | 1968      |
| eplenmean               | 203       |
| fps                     | 11        |
| mean 100 episode reward | 726       |
| n_updates               | 327600    |
| q_grad_norm             | 3040.4922 |
| qfs_loss                | 64.87337  |
| qs_abs_difference       | 57        |
| qs_difference           | 56.6      |
| qs_mean                 | 299.2229  |
| time_elapsed            | 17117     |
| total timesteps         | 188788    |
| train_time              | 5028      |
| update_time             | 11530     |
---------------------------------------
---------------------------------------
| act_time                | 124       |
| current_lr              | 0.0003    |
| discount_q              | 0.161     |
| env_time                | 299       |
| ep_rewmean              | 721       |
| episodes                | 1972      |
| eplenmean               | 201       |
| fps                     | 11        |
| mean 100 episode reward | 721       |
| n_updates               | 329800    |
| q_grad_norm             | 3961.2075 |
| qfs_loss                | 85.09605  |
| qs_abs_difference       | 34.4      |
| qs_difference           | 33.9      |
| qs_mean                 | 318.9534  |
| time_elapsed            | 17203     |
| total timesteps         | 189805    |
| train_time              | 5057      |
| update_time             | 11584     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 698       |
| eval_abs_qs_difference  | 56.669125 |
| eval_discount_q         | 250       |
| eval_ep_rewmean         | 831       |
| eval_eplenmean          | 215       |
| eval_qs                 | 304.80994 |
| eval_qs_difference      | 50.9      |
| eval_time_elapsed       | 5         |
| total timesteps         | 190001    |
---------------------------------------
---------------------------------------
| act_time                | 125       |
| current_lr              | 0.0003    |
| discount_q              | 0.0859    |
| env_time                | 301       |
| ep_rewmean              | 718       |
| episodes                | 1976      |
| eplenmean               | 200       |
| fps                     | 11        |
| mean 100 episode reward | 718       |
| n_updates               | 331800    |
| q_grad_norm             | 3829.205  |
| qfs_loss                | 78.03063  |
| qs_abs_difference       | 17.3      |
| qs_difference           | 16.9      |
| qs_mean                 | 327.74408 |
| time_elapsed            | 17287     |
| total timesteps         | 190895    |
| train_time              | 5084      |
| update_time             | 11634     |
---------------------------------------
---------------------------------------
| act_time                | 126       |
| current_lr              | 0.0003    |
| discount_q              | 0.0826    |
| env_time                | 303       |
| ep_rewmean              | 733       |
| episodes                | 1980      |
| eplenmean               | 203       |
| fps                     | 11        |
| mean 100 episode reward | 733       |
| n_updates               | 334200    |
| q_grad_norm             | 3698.7646 |
| qfs_loss                | 79.06509  |
| qs_abs_difference       | 27        |
| qs_difference           | 24.4      |
| qs_mean                 | 329.14502 |
| time_elapsed            | 17382     |
| total timesteps         | 192080    |
| train_time              | 5116      |
| update_time             | 11693     |
---------------------------------------
---------------------------------------
| act_time                | 127       |
| current_lr              | 0.0003    |
| discount_q              | 0.604     |
| env_time                | 305       |
| ep_rewmean              | 730       |
| episodes                | 1984      |
| eplenmean               | 203       |
| fps                     | 11        |
| mean 100 episode reward | 730       |
| n_updates               | 336200    |
| q_grad_norm             | 2552.0981 |
| qfs_loss                | 53.96946  |
| qs_abs_difference       | 18.2      |
| qs_difference           | 16.7      |
| qs_mean                 | 338.14862 |
| time_elapsed            | 17460     |
| total timesteps         | 193093    |
| train_time              | 5142      |
| update_time             | 11743     |
---------------------------------------
---------------------------------------
| act_time                | 128       |
| current_lr              | 0.0003    |
| discount_q              | 0.0389    |
| env_time                | 307       |
| ep_rewmean              | 743       |
| episodes                | 1988      |
| eplenmean               | 205       |
| fps                     | 11        |
| mean 100 episode reward | 743       |
| n_updates               | 338600    |
| q_grad_norm             | 2898.3113 |
| qfs_loss                | 56.50534  |
| qs_abs_difference       | 30.1      |
| qs_difference           | 29.4      |
| qs_mean                 | 325.71478 |
| time_elapsed            | 17554     |
| total timesteps         | 194266    |
| train_time              | 5174      |
| update_time             | 11802     |
---------------------------------------
---------------------------------------
| act_time                | 128       |
| current_lr              | 0.0003    |
| discount_q              | 0.0424    |
| env_time                | 308       |
| ep_rewmean              | 752       |
| episodes                | 1992      |
| eplenmean               | 207       |
| fps                     | 11        |
| mean 100 episode reward | 752       |
| n_updates               | 340800    |
| q_grad_norm             | 3257.377  |
| qfs_loss                | 64.375755 |
| qs_abs_difference       | 19.3      |
| qs_difference           | 11.6      |
| qs_mean                 | 300.2194  |
| time_elapsed            | 17641     |
| total timesteps         | 195381    |
| train_time              | 5203      |
| update_time             | 11856     |
---------------------------------------
---------------------------------------
| act_time                | 129       |
| current_lr              | 0.0003    |
| discount_q              | 0.271     |
| env_time                | 310       |
| ep_rewmean              | 754       |
| episodes                | 1996      |
| eplenmean               | 207       |
| fps                     | 11        |
| mean 100 episode reward | 754       |
| n_updates               | 342800    |
| q_grad_norm             | 3921.694  |
| qfs_loss                | 77.86627  |
| qs_abs_difference       | 16.1      |
| qs_difference           | -7.56     |
| qs_mean                 | 301.76328 |
| time_elapsed            | 17719     |
| total timesteps         | 196351    |
| train_time              | 5229      |
| update_time             | 11906     |
---------------------------------------
--------------------------------------
| act_time                | 130      |
| current_lr              | 0.0003   |
| discount_q              | 0.164    |
| env_time                | 311      |
| ep_rewmean              | 757      |
| episodes                | 2000     |
| eplenmean               | 208      |
| fps                     | 11       |
| mean 100 episode reward | 757      |
| n_updates               | 344800   |
| q_grad_norm             | 3550.952 |
| qfs_loss                | 70.21924 |
| qs_abs_difference       | 70.7     |
| qs_difference           | 70.6     |
| qs_mean                 | 323.3136 |
| time_elapsed            | 17797    |
| total timesteps         | 197323   |
| train_time              | 5256     |
| update_time             | 11954    |
--------------------------------------
--------------------------------------
| act_time                | 131      |
| current_lr              | 0.0003   |
| discount_q              | 0.0821   |
| env_time                | 313      |
| ep_rewmean              | 785      |
| episodes                | 2004     |
| eplenmean               | 213      |
| fps                     | 11       |
| mean 100 episode reward | 785      |
| n_updates               | 347000   |
| q_grad_norm             | 3233.114 |
| qfs_loss                | 69.52425 |
| qs_abs_difference       | 18.4     |
| qs_difference           | 14.8     |
| qs_mean                 | 316.6359 |
| time_elapsed            | 17881    |
| total timesteps         | 198427   |
| train_time              | 5284     |
| update_time             | 12007    |
--------------------------------------
---------------------------------------
| act_time                | 132       |
| current_lr              | 0.0003    |
| discount_q              | 0.031     |
| env_time                | 315       |
| ep_rewmean              | 807       |
| episodes                | 2008      |
| eplenmean               | 218       |
| fps                     | 11        |
| mean 100 episode reward | 807       |
| n_updates               | 349400    |
| q_grad_norm             | 2741.1318 |
| qfs_loss                | 57.65369  |
| qs_abs_difference       | 14        |
| qs_difference           | 13.6      |
| qs_mean                 | 323.44983 |
| time_elapsed            | 17972     |
| total timesteps         | 199626    |
| train_time              | 5316      |
| update_time             | 12064     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 721       |
| eval_abs_qs_difference  | 10.976467 |
| eval_discount_q         | 275       |
| eval_ep_rewmean         | 1.21e+03  |
| eval_eplenmean          | 299       |
| eval_qs                 | 313.97095 |
| eval_qs_difference      | 2.43      |
| eval_time_elapsed       | 7         |
| total timesteps         | 200001    |
---------------------------------------
---------------------------------------
| act_time                | 132       |
| current_lr              | 0.0003    |
| discount_q              | 0.011     |
| env_time                | 316       |
| ep_rewmean              | 818       |
| episodes                | 2012      |
| eplenmean               | 220       |
| fps                     | 11        |
| mean 100 episode reward | 818       |
| n_updates               | 351000    |
| q_grad_norm             | 3083.3872 |
| qfs_loss                | 60.801685 |
| qs_abs_difference       | 281       |
| qs_difference           | 281       |
| qs_mean                 | 300.4825  |
| time_elapsed            | 18041     |
| total timesteps         | 200434    |
| train_time              | 5337      |
| update_time             | 12102     |
---------------------------------------
---------------------------------------
| act_time                | 132       |
| current_lr              | 0.0003    |
| discount_q              | 0.956     |
| env_time                | 317       |
| ep_rewmean              | 793       |
| episodes                | 2016      |
| eplenmean               | 213       |
| fps                     | 11        |
| mean 100 episode reward | 792       |
| n_updates               | 351600    |
| q_grad_norm             | 3778.4822 |
| qfs_loss                | 81.61476  |
| qs_abs_difference       | 283       |
| qs_difference           | 283       |
| qs_mean                 | 293.3728  |
| time_elapsed            | 18064     |
| total timesteps         | 200732    |
| train_time              | 5345      |
| update_time             | 12116     |
---------------------------------------
---------------------------------------
| act_time                | 132       |
| current_lr              | 0.0003    |
| discount_q              | 9.63      |
| env_time                | 317       |
| ep_rewmean              | 783       |
| episodes                | 2020      |
| eplenmean               | 211       |
| fps                     | 11        |
| mean 100 episode reward | 783       |
| n_updates               | 351600    |
| qs_abs_difference       | 283       |
| qs_difference           | 283       |
| qs_mean                 | 292.35504 |
| time_elapsed            | 18064     |
| total timesteps         | 200792    |
| train_time              | 5345      |
| update_time             | 12116     |
---------------------------------------
---------------------------------------
| act_time                | 133       |
| current_lr              | 0.0003    |
| discount_q              | 0.13      |
| env_time                | 318       |
| ep_rewmean              | 783       |
| episodes                | 2024      |
| eplenmean               | 211       |
| fps                     | 11        |
| mean 100 episode reward | 783       |
| n_updates               | 353600    |
| q_grad_norm             | 2904.0984 |
| qfs_loss                | 55.62777  |
| qs_abs_difference       | 12.3      |
| qs_difference           | 4.77      |
| qs_mean                 | 291.44498 |
| time_elapsed            | 18141     |
| total timesteps         | 201791    |
| train_time              | 5371      |
| update_time             | 12164     |
---------------------------------------
---------------------------------------
| act_time                | 134       |
| current_lr              | 0.0003    |
| discount_q              | 0.0922    |
| env_time                | 320       |
| ep_rewmean              | 801       |
| episodes                | 2028      |
| eplenmean               | 215       |
| fps                     | 11        |
| mean 100 episode reward | 801       |
| n_updates               | 355800    |
| q_grad_norm             | 3663.7156 |
| qfs_loss                | 84.809425 |
| qs_abs_difference       | 24.4      |
| qs_difference           | 24.2      |
| qs_mean                 | 305.56088 |
| time_elapsed            | 18225     |
| total timesteps         | 202836    |
| train_time              | 5400      |
| update_time             | 12217     |
---------------------------------------
---------------------------------------
| act_time                | 135       |
| current_lr              | 0.0003    |
| discount_q              | 0.674     |
| env_time                | 321       |
| ep_rewmean              | 817       |
| episodes                | 2032      |
| eplenmean               | 218       |
| fps                     | 11        |
| mean 100 episode reward | 817       |
| n_updates               | 357400    |
| q_grad_norm             | 3498.7998 |
| qfs_loss                | 72.83987  |
| qs_abs_difference       | 26.7      |
| qs_difference           | 23.7      |
| qs_mean                 | 275.5733  |
| time_elapsed            | 18287     |
| total timesteps         | 203635    |
| train_time              | 5421      |
| update_time             | 12256     |
---------------------------------------
--------------------------------------
| act_time                | 135      |
| current_lr              | 0.0003   |
| discount_q              | 1.16     |
| env_time                | 322      |
| ep_rewmean              | 829      |
| episodes                | 2036     |
| eplenmean               | 221      |
| fps                     | 11       |
| mean 100 episode reward | 829      |
| n_updates               | 358800   |
| q_grad_norm             | 3171.758 |
| qfs_loss                | 69.12251 |
| qs_abs_difference       | 31.2     |
| qs_difference           | 30.3     |
| qs_mean                 | 284.9791 |
| time_elapsed            | 18340    |
| total timesteps         | 204389   |
| train_time              | 5439     |
| update_time             | 12289    |
--------------------------------------
---------------------------------------
| act_time                | 136       |
| current_lr              | 0.0003    |
| discount_q              | 0.0785    |
| env_time                | 324       |
| ep_rewmean              | 861       |
| episodes                | 2040      |
| eplenmean               | 228       |
| fps                     | 11        |
| mean 100 episode reward | 861       |
| n_updates               | 360800    |
| q_grad_norm             | 3599.8147 |
| qfs_loss                | 67.38275  |
| qs_abs_difference       | 60        |
| qs_difference           | 60        |
| qs_mean                 | 281.1282  |
| time_elapsed            | 18417     |
| total timesteps         | 205378    |
| train_time              | 5465      |
| update_time             | 12337     |
---------------------------------------
---------------------------------------
| act_time                | 137       |
| current_lr              | 0.0003    |
| discount_q              | 0.0354    |
| env_time                | 325       |
| ep_rewmean              | 877       |
| episodes                | 2044      |
| eplenmean               | 232       |
| fps                     | 11        |
| mean 100 episode reward | 877       |
| n_updates               | 362600    |
| q_grad_norm             | 2696.85   |
| qfs_loss                | 55.045044 |
| qs_abs_difference       | 255       |
| qs_difference           | 255       |
| qs_mean                 | 338.46774 |
| time_elapsed            | 18486     |
| total timesteps         | 206282    |
| train_time              | 5488      |
| update_time             | 12380     |
---------------------------------------
---------------------------------------
| act_time                | 137       |
| current_lr              | 0.0003    |
| discount_q              | 0.202     |
| env_time                | 327       |
| ep_rewmean              | 894       |
| episodes                | 2048      |
| eplenmean               | 235       |
| fps                     | 11        |
| mean 100 episode reward | 894       |
| n_updates               | 364600    |
| q_grad_norm             | 3262.7822 |
| qfs_loss                | 70.41252  |
| qs_abs_difference       | 18.3      |
| qs_difference           | -12.4     |
| qs_mean                 | 296.83582 |
| time_elapsed            | 18563     |
| total timesteps         | 207266    |
| train_time              | 5514      |
| update_time             | 12428     |
---------------------------------------
---------------------------------------
| act_time                | 138       |
| current_lr              | 0.0003    |
| discount_q              | 0.0569    |
| env_time                | 328       |
| ep_rewmean              | 894       |
| episodes                | 2052      |
| eplenmean               | 234       |
| fps                     | 11        |
| mean 100 episode reward | 894       |
| n_updates               | 366600    |
| q_grad_norm             | 3191.6116 |
| qfs_loss                | 61.67674  |
| qs_abs_difference       | 28.2      |
| qs_difference           | 18.6      |
| qs_mean                 | 258.6595  |
| time_elapsed            | 18640     |
| total timesteps         | 208295    |
| train_time              | 5540      |
| update_time             | 12477     |
---------------------------------------
---------------------------------------
| act_time                | 139       |
| current_lr              | 0.0003    |
| discount_q              | 0.502     |
| env_time                | 330       |
| ep_rewmean              | 889       |
| episodes                | 2056      |
| eplenmean               | 234       |
| fps                     | 11        |
| mean 100 episode reward | 889       |
| n_updates               | 368600    |
| q_grad_norm             | 2805.8584 |
| qfs_loss                | 62.920673 |
| qs_abs_difference       | 13.4      |
| qs_difference           | 4.22      |
| qs_mean                 | 311.774   |
| time_elapsed            | 18724     |
| total timesteps         | 209213    |
| train_time              | 5567      |
| update_time             | 12532     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 728       |
| eval_abs_qs_difference  | 16.460327 |
| eval_discount_q         | 273       |
| eval_ep_rewmean         | 1.08e+03  |
| eval_eplenmean          | 269       |
| eval_qs                 | 307.09332 |
| eval_qs_difference      | 7.6       |
| eval_time_elapsed       | 6         |
| total timesteps         | 210001    |
---------------------------------------
---------------------------------------
| act_time                | 139       |
| current_lr              | 0.0003    |
| discount_q              | 0.316     |
| env_time                | 331       |
| ep_rewmean              | 879       |
| episodes                | 2060      |
| eplenmean               | 231       |
| fps                     | 11        |
| mean 100 episode reward | 879       |
| n_updates               | 370200    |
| q_grad_norm             | 3236.5857 |
| qfs_loss                | 76.16673  |
| qs_abs_difference       | 35.4      |
| qs_difference           | 33.6      |
| qs_mean                 | 273.76416 |
| time_elapsed            | 18799     |
| total timesteps         | 210077    |
| train_time              | 5587      |
| update_time             | 12579     |
---------------------------------------
---------------------------------------
| act_time                | 140       |
| current_lr              | 0.0003    |
| discount_q              | 0.069     |
| env_time                | 332       |
| ep_rewmean              | 874       |
| episodes                | 2064      |
| eplenmean               | 230       |
| fps                     | 11        |
| mean 100 episode reward | 874       |
| n_updates               | 372200    |
| q_grad_norm             | 3015.179  |
| qfs_loss                | 54.407852 |
| qs_abs_difference       | 168       |
| qs_difference           | 168       |
| qs_mean                 | 321.5429  |
| time_elapsed            | 18881     |
| total timesteps         | 211005    |
| train_time              | 5610      |
| update_time             | 12635     |
---------------------------------------
---------------------------------------
| act_time                | 141       |
| current_lr              | 0.0003    |
| discount_q              | 0.223     |
| env_time                | 334       |
| ep_rewmean              | 883       |
| episodes                | 2068      |
| eplenmean               | 232       |
| fps                     | 11        |
| mean 100 episode reward | 883       |
| n_updates               | 374000    |
| q_grad_norm             | 3339.8325 |
| qfs_loss                | 69.956474 |
| qs_abs_difference       | 16.1      |
| qs_difference           | 0.594     |
| qs_mean                 | 288.14026 |
| time_elapsed            | 18954     |
| total timesteps         | 211938    |
| train_time              | 5629      |
| update_time             | 12686     |
---------------------------------------
---------------------------------------
| act_time                | 142       |
| current_lr              | 0.0003    |
| discount_q              | 0.495     |
| env_time                | 335       |
| ep_rewmean              | 876       |
| episodes                | 2072      |
| eplenmean               | 230       |
| fps                     | 11        |
| mean 100 episode reward | 876       |
| n_updates               | 375600    |
| q_grad_norm             | 2845.378  |
| qfs_loss                | 60.854053 |
| qs_abs_difference       | 17.3      |
| qs_difference           | 13.2      |
| qs_mean                 | 290.25793 |
| time_elapsed            | 19017     |
| total timesteps         | 212796    |
| train_time              | 5647      |
| update_time             | 12730     |
---------------------------------------
---------------------------------------
| act_time                | 142       |
| current_lr              | 0.0003    |
| discount_q              | 0.159     |
| env_time                | 336       |
| ep_rewmean              | 871       |
| episodes                | 2076      |
| eplenmean               | 229       |
| fps                     | 11        |
| mean 100 episode reward | 871       |
| n_updates               | 377800    |
| q_grad_norm             | 4087.7017 |
| qfs_loss                | 91.12462  |
| qs_abs_difference       | 18.6      |
| qs_difference           | 16.7      |
| qs_mean                 | 322.0094  |
| time_elapsed            | 19103     |
| total timesteps         | 213834    |
| train_time              | 5670      |
| update_time             | 12790     |
---------------------------------------
---------------------------------------
| act_time                | 143       |
| current_lr              | 0.0003    |
| discount_q              | 0.357     |
| env_time                | 337       |
| ep_rewmean              | 862       |
| episodes                | 2080      |
| eplenmean               | 227       |
| fps                     | 11        |
| mean 100 episode reward | 862       |
| n_updates               | 379600    |
| q_grad_norm             | 3189.2888 |
| qfs_loss                | 61.95461  |
| qs_abs_difference       | 13.3      |
| qs_difference           | 12.6      |
| qs_mean                 | 322.42462 |
| time_elapsed            | 19174     |
| total timesteps         | 214794    |
| train_time              | 5689      |
| update_time             | 12840     |
---------------------------------------
---------------------------------------
| act_time                | 144       |
| current_lr              | 0.0003    |
| discount_q              | 0.0322    |
| env_time                | 339       |
| ep_rewmean              | 870       |
| episodes                | 2084      |
| eplenmean               | 229       |
| fps                     | 11        |
| mean 100 episode reward | 870       |
| n_updates               | 382000    |
| q_grad_norm             | 2847.1416 |
| qfs_loss                | 51.03917  |
| qs_abs_difference       | 12.1      |
| qs_difference           | -9.72     |
| qs_mean                 | 306.8502  |
| time_elapsed            | 19265     |
| total timesteps         | 215955    |
| train_time              | 5714      |
| update_time             | 12903     |
---------------------------------------
---------------------------------------
| act_time                | 145       |
| current_lr              | 0.0003    |
| discount_q              | 0.0135    |
| env_time                | 340       |
| ep_rewmean              | 866       |
| episodes                | 2088      |
| eplenmean               | 228       |
| fps                     | 11        |
| mean 100 episode reward | 866       |
| n_updates               | 384200    |
| q_grad_norm             | 3411.3743 |
| qfs_loss                | 62.35463  |
| qs_abs_difference       | 181       |
| qs_difference           | 181       |
| qs_mean                 | 353.99878 |
| time_elapsed            | 19348     |
| total timesteps         | 217065    |
| train_time              | 5737      |
| update_time             | 12960     |
---------------------------------------
---------------------------------------
| act_time                | 145       |
| current_lr              | 0.0003    |
| discount_q              | 0.177     |
| env_time                | 342       |
| ep_rewmean              | 860       |
| episodes                | 2092      |
| eplenmean               | 227       |
| fps                     | 11        |
| mean 100 episode reward | 860       |
| n_updates               | 386200    |
| q_grad_norm             | 2812.1262 |
| qfs_loss                | 45.492813 |
| qs_abs_difference       | 37.3      |
| qs_difference           | 37.1      |
| qs_mean                 | 319.8524  |
| time_elapsed            | 19421     |
| total timesteps         | 218055    |
| train_time              | 5757      |
| update_time             | 13011     |
---------------------------------------
---------------------------------------
| act_time                | 146       |
| current_lr              | 0.0003    |
| discount_q              | 0.23      |
| env_time                | 343       |
| ep_rewmean              | 857       |
| episodes                | 2096      |
| eplenmean               | 226       |
| fps                     | 11        |
| mean 100 episode reward | 857       |
| n_updates               | 388000    |
| q_grad_norm             | 3514.3772 |
| qfs_loss                | 75.41617  |
| qs_abs_difference       | 89.6      |
| qs_difference           | 89.6      |
| qs_mean                 | 309.49872 |
| time_elapsed            | 19485     |
| total timesteps         | 218942    |
| train_time              | 5775      |
| update_time             | 13055     |
---------------------------------------
---------------------------------------
| act_time                | 147       |
| current_lr              | 0.0003    |
| discount_q              | 0.141     |
| env_time                | 345       |
| ep_rewmean              | 861       |
| episodes                | 2100      |
| eplenmean               | 226       |
| fps                     | 11        |
| mean 100 episode reward | 861       |
| n_updates               | 390000    |
| q_grad_norm             | 3557.679  |
| qfs_loss                | 60.36848  |
| qs_abs_difference       | 14.5      |
| qs_difference           | -13.5     |
| qs_mean                 | 293.60556 |
| time_elapsed            | 19592     |
| total timesteps         | 219940    |
| train_time              | 5808      |
| update_time             | 13125     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 806       |
| eval_abs_qs_difference  | 49.08092  |
| eval_discount_q         | 254       |
| eval_ep_rewmean         | 965       |
| eval_eplenmean          | 263       |
| eval_qs                 | 306.30673 |
| eval_qs_difference      | 46.5      |
| eval_time_elapsed       | 7         |
| total timesteps         | 220001    |
---------------------------------------
---------------------------------------
| act_time                | 148       |
| current_lr              | 0.0003    |
| discount_q              | 0.0282    |
| env_time                | 347       |
| ep_rewmean              | 864       |
| episodes                | 2104      |
| eplenmean               | 227       |
| fps                     | 11        |
| mean 100 episode reward | 864       |
| n_updates               | 392400    |
| q_grad_norm             | 2762.7834 |
| qfs_loss                | 51.969658 |
| qs_abs_difference       | 10.6      |
| qs_difference           | 8.43      |
| qs_mean                 | 330.80927 |
| time_elapsed            | 19779     |
| total timesteps         | 221156    |
| train_time              | 5867      |
| update_time             | 13240     |
---------------------------------------
--------------------------------------
| act_time                | 149      |
| current_lr              | 0.0003   |
| discount_q              | 0.193    |
| env_time                | 349      |
| ep_rewmean              | 851      |
| episodes                | 2108     |
| eplenmean               | 225      |
| fps                     | 11       |
| mean 100 episode reward | 851      |
| n_updates               | 394200   |
| q_grad_norm             | 2730.712 |
| qfs_loss                | 47.07392 |
| qs_abs_difference       | 16.5     |
| qs_difference           | 12.1     |
| qs_mean                 | 281.6426 |
| time_elapsed            | 19869    |
| total timesteps         | 222083   |
| train_time              | 5896     |
| update_time             | 13299    |
--------------------------------------
---------------------------------------
| act_time                | 150       |
| current_lr              | 0.0003    |
| discount_q              | 35.5      |
| env_time                | 349       |
| ep_rewmean              | 838       |
| episodes                | 2112      |
| eplenmean               | 221       |
| fps                     | 11        |
| mean 100 episode reward | 838       |
| n_updates               | 395200    |
| q_grad_norm             | 3207.8022 |
| qfs_loss                | 63.830723 |
| qs_abs_difference       | 60.5      |
| qs_difference           | 59.7      |
| qs_mean                 | 324.78848 |
| time_elapsed            | 19901     |
| total timesteps         | 222582    |
| train_time              | 5905      |
| update_time             | 13321     |
---------------------------------------
---------------------------------------
| act_time                | 151       |
| current_lr              | 0.0003    |
| discount_q              | 0.0206    |
| env_time                | 351       |
| ep_rewmean              | 880       |
| episodes                | 2116      |
| eplenmean               | 232       |
| fps                     | 11        |
| mean 100 episode reward | 880       |
| n_updates               | 398000    |
| q_grad_norm             | 2874.4695 |
| qfs_loss                | 51.973927 |
| qs_abs_difference       | 17.2      |
| qs_difference           | 12.9      |
| qs_mean                 | 337.50104 |
| time_elapsed            | 19993     |
| total timesteps         | 223941    |
| train_time              | 5933      |
| update_time             | 13383     |
---------------------------------------
---------------------------------------
| act_time                | 151       |
| current_lr              | 0.0003    |
| discount_q              | 0.0361    |
| env_time                | 353       |
| ep_rewmean              | 923       |
| episodes                | 2120      |
| eplenmean               | 243       |
| fps                     | 11        |
| mean 100 episode reward | 923       |
| n_updates               | 400200    |
| q_grad_norm             | 3984.9097 |
| qfs_loss                | 66.94278  |
| qs_abs_difference       | 27.1      |
| qs_difference           | 24.6      |
| qs_mean                 | 306.24713 |
| time_elapsed            | 20066     |
| total timesteps         | 225074    |
| train_time              | 5954      |
| update_time             | 13431     |
---------------------------------------
---------------------------------------
| act_time                | 152       |
| current_lr              | 0.0003    |
| discount_q              | 0.0219    |
| env_time                | 354       |
| ep_rewmean              | 931       |
| episodes                | 2124      |
| eplenmean               | 245       |
| fps                     | 11        |
| mean 100 episode reward | 931       |
| n_updates               | 402600    |
| q_grad_norm             | 3546.243  |
| qfs_loss                | 68.1986   |
| qs_abs_difference       | 20.8      |
| qs_difference           | 19.6      |
| qs_mean                 | 307.52145 |
| time_elapsed            | 20145     |
| total timesteps         | 226260    |
| train_time              | 5977      |
| update_time             | 13485     |
---------------------------------------
---------------------------------------
| act_time                | 153       |
| current_lr              | 0.0003    |
| discount_q              | 0.206     |
| env_time                | 355       |
| ep_rewmean              | 933       |
| episodes                | 2128      |
| eplenmean               | 246       |
| fps                     | 11        |
| mean 100 episode reward | 933       |
| n_updates               | 404800    |
| q_grad_norm             | 3682.147  |
| qfs_loss                | 74.08863  |
| qs_abs_difference       | 20.9      |
| qs_difference           | 20.3      |
| qs_mean                 | 350.58633 |
| time_elapsed            | 20217     |
| total timesteps         | 227391    |
| train_time              | 5998      |
| update_time             | 13533     |
---------------------------------------
---------------------------------------
| act_time                | 153       |
| current_lr              | 0.0003    |
| discount_q              | 0.0634    |
| env_time                | 357       |
| ep_rewmean              | 947       |
| episodes                | 2132      |
| eplenmean               | 248       |
| fps                     | 11        |
| mean 100 episode reward | 947       |
| n_updates               | 407000    |
| q_grad_norm             | 2730.5715 |
| qfs_loss                | 48.26027  |
| qs_abs_difference       | 40.6      |
| qs_difference           | 39.5      |
| qs_mean                 | 318.04846 |
| time_elapsed            | 20290     |
| total timesteps         | 228457    |
| train_time              | 6020      |
| update_time             | 13582     |
---------------------------------------
---------------------------------------
| act_time                | 154       |
| current_lr              | 0.0003    |
| discount_q              | 0.0874    |
| env_time                | 358       |
| ep_rewmean              | 965       |
| episodes                | 2136      |
| eplenmean               | 251       |
| fps                     | 11        |
| mean 100 episode reward | 965       |
| n_updates               | 409200    |
| q_grad_norm             | 3124.8538 |
| qfs_loss                | 57.59781  |
| qs_abs_difference       | 31.7      |
| qs_difference           | 31.3      |
| qs_mean                 | 324.33224 |
| time_elapsed            | 20362     |
| total timesteps         | 229529    |
| train_time              | 6041      |
| update_time             | 13631     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 913       |
| eval_abs_qs_difference  | 15.472406 |
| eval_discount_q         | 286       |
| eval_ep_rewmean         | 1.09e+03  |
| eval_eplenmean          | 263       |
| eval_qs                 | 318.9187  |
| eval_qs_difference      | 11.1      |
| eval_time_elapsed       | 5         |
| total timesteps         | 230001    |
---------------------------------------
---------------------------------------
| act_time                | 155       |
| current_lr              | 0.0003    |
| discount_q              | 0.0418    |
| env_time                | 359       |
| ep_rewmean              | 973       |
| episodes                | 2140      |
| eplenmean               | 253       |
| fps                     | 11        |
| mean 100 episode reward | 973       |
| n_updates               | 411400    |
| q_grad_norm             | 2837.1987 |
| qfs_loss                | 49.324493 |
| qs_abs_difference       | 13        |
| qs_difference           | 10.2      |
| qs_mean                 | 310.50696 |
| time_elapsed            | 20440     |
| total timesteps         | 230644    |
| train_time              | 6062      |
| update_time             | 13680     |
---------------------------------------
---------------------------------------
| act_time                | 155       |
| current_lr              | 0.0003    |
| discount_q              | 0.116     |
| env_time                | 361       |
| ep_rewmean              | 979       |
| episodes                | 2144      |
| eplenmean               | 253       |
| fps                     | 11        |
| mean 100 episode reward | 979       |
| n_updates               | 413400    |
| q_grad_norm             | 3248.4731 |
| qfs_loss                | 52.082535 |
| qs_abs_difference       | 54.7      |
| qs_difference           | 54.4      |
| qs_mean                 | 319.4703  |
| time_elapsed            | 20507     |
| total timesteps         | 231628    |
| train_time              | 6082      |
| update_time             | 13725     |
---------------------------------------
---------------------------------------
| act_time                | 156       |
| current_lr              | 0.0003    |
| discount_q              | 0.0046    |
| env_time                | 362       |
| ep_rewmean              | 972       |
| episodes                | 2148      |
| eplenmean               | 251       |
| fps                     | 11        |
| mean 100 episode reward | 972       |
| n_updates               | 414800    |
| q_grad_norm             | 3184.7693 |
| qfs_loss                | 56.160633 |
| qs_abs_difference       | 299       |
| qs_difference           | 299       |
| qs_mean                 | 304.32263 |
| time_elapsed            | 20555     |
| total timesteps         | 232398    |
| train_time              | 6096      |
| update_time             | 13757     |
---------------------------------------
---------------------------------------
| act_time                | 157       |
| current_lr              | 0.0003    |
| discount_q              | 0.0575    |
| env_time                | 363       |
| ep_rewmean              | 977       |
| episodes                | 2152      |
| eplenmean               | 252       |
| fps                     | 11        |
| mean 100 episode reward | 977       |
| n_updates               | 417000    |
| q_grad_norm             | 3264.61   |
| qfs_loss                | 51.64055  |
| qs_abs_difference       | 13.5      |
| qs_difference           | 11.3      |
| qs_mean                 | 311.26285 |
| time_elapsed            | 20630     |
| total timesteps         | 233483    |
| train_time              | 6118      |
| update_time             | 13808     |
---------------------------------------
---------------------------------------
| act_time                | 157       |
| current_lr              | 0.0003    |
| discount_q              | 0.115     |
| env_time                | 364       |
| ep_rewmean              | 984       |
| episodes                | 2156      |
| eplenmean               | 253       |
| fps                     | 11        |
| mean 100 episode reward | 984       |
| n_updates               | 419000    |
| q_grad_norm             | 2806.526  |
| qfs_loss                | 50.78162  |
| qs_abs_difference       | 25.4      |
| qs_difference           | 25.1      |
| qs_mean                 | 312.23672 |
| time_elapsed            | 20699     |
| total timesteps         | 234496    |
| train_time              | 6138      |
| update_time             | 13854     |
---------------------------------------
---------------------------------------
| act_time                | 158       |
| current_lr              | 0.0003    |
| discount_q              | 0.179     |
| env_time                | 366       |
| ep_rewmean              | 992       |
| episodes                | 2160      |
| eplenmean               | 254       |
| fps                     | 11        |
| mean 100 episode reward | 992       |
| n_updates               | 421000    |
| q_grad_norm             | 2601.3928 |
| qfs_loss                | 38.643406 |
| qs_abs_difference       | 23.2      |
| qs_difference           | 20.2      |
| qs_mean                 | 318.93515 |
| time_elapsed            | 20770     |
| total timesteps         | 235498    |
| train_time              | 6161      |
| update_time             | 13901     |
---------------------------------------
---------------------------------------
| act_time                | 159       |
| current_lr              | 0.0003    |
| discount_q              | 0.162     |
| env_time                | 368       |
| ep_rewmean              | 998       |
| episodes                | 2164      |
| eplenmean               | 255       |
| fps                     | 11        |
| mean 100 episode reward | 998       |
| n_updates               | 423200    |
| q_grad_norm             | 2748.0012 |
| qfs_loss                | 45.33875  |
| qs_abs_difference       | 36.7      |
| qs_difference           | 35.7      |
| qs_mean                 | 326.95206 |
| time_elapsed            | 20917     |
| total timesteps         | 236501    |
| train_time              | 6211      |
| update_time             | 13994     |
---------------------------------------
---------------------------------------
| act_time                | 160       |
| current_lr              | 0.0003    |
| discount_q              | 0.0824    |
| env_time                | 369       |
| ep_rewmean              | 997       |
| episodes                | 2168      |
| eplenmean               | 255       |
| fps                     | 11        |
| mean 100 episode reward | 997       |
| n_updates               | 425000    |
| q_grad_norm             | 2471.6926 |
| qfs_loss                | 40.459896 |
| qs_abs_difference       | 192       |
| qs_difference           | 192       |
| qs_mean                 | 382.52478 |
| time_elapsed            | 21015     |
| total timesteps         | 237463    |
| train_time              | 6242      |
| update_time             | 14058     |
---------------------------------------
---------------------------------------
| act_time                | 161       |
| current_lr              | 0.0003    |
| discount_q              | 0.295     |
| env_time                | 371       |
| ep_rewmean              | 1e+03     |
| episodes                | 2172      |
| eplenmean               | 256       |
| fps                     | 11        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 427000    |
| q_grad_norm             | 2460.9856 |
| qfs_loss                | 36.893204 |
| qs_abs_difference       | 24.3      |
| qs_difference           | 24        |
| qs_mean                 | 339.23093 |
| time_elapsed            | 21083     |
| total timesteps         | 238438    |
| train_time              | 6262      |
| update_time             | 14104     |
---------------------------------------
---------------------------------------
| act_time                | 161       |
| current_lr              | 0.0003    |
| discount_q              | 0.202     |
| env_time                | 372       |
| ep_rewmean              | 1e+03     |
| episodes                | 2176      |
| eplenmean               | 256       |
| fps                     | 11        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 429000    |
| q_grad_norm             | 3445.7068 |
| qfs_loss                | 71.86327  |
| qs_abs_difference       | 17.9      |
| qs_difference           | 17.4      |
| qs_mean                 | 340.83862 |
| time_elapsed            | 21150     |
| total timesteps         | 239465    |
| train_time              | 6282      |
| update_time             | 14148     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 922       |
| eval_abs_qs_difference  | 23.73936  |
| eval_discount_q         | 274       |
| eval_ep_rewmean         | 950       |
| eval_eplenmean          | 236       |
| eval_qs                 | 304.88153 |
| eval_qs_difference      | 17.4      |
| eval_time_elapsed       | 6         |
| total timesteps         | 240001    |
---------------------------------------
---------------------------------------
| act_time                | 162       |
| current_lr              | 0.0003    |
| discount_q              | 0.183     |
| env_time                | 374       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2180      |
| eplenmean               | 256       |
| fps                     | 11        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 431000    |
| q_grad_norm             | 3020.2236 |
| qfs_loss                | 49.35985  |
| qs_abs_difference       | 31.7      |
| qs_difference           | 30.4      |
| qs_mean                 | 302.23416 |
| time_elapsed            | 21280     |
| total timesteps         | 240411    |
| train_time              | 6325      |
| update_time             | 14225     |
---------------------------------------
---------------------------------------
| act_time                | 163       |
| current_lr              | 0.0003    |
| discount_q              | 0.216     |
| env_time                | 376       |
| ep_rewmean              | 1e+03     |
| episodes                | 2184      |
| eplenmean               | 255       |
| fps                     | 11        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 433000    |
| q_grad_norm             | 2975.4138 |
| qfs_loss                | 58.366344 |
| qs_abs_difference       | 20.7      |
| qs_difference           | 20.4      |
| qs_mean                 | 326.7357  |
| time_elapsed            | 21402     |
| total timesteps         | 241409    |
| train_time              | 6365      |
| update_time             | 14304     |
---------------------------------------
---------------------------------------
| act_time                | 164       |
| current_lr              | 0.0003    |
| discount_q              | 0.245     |
| env_time                | 377       |
| ep_rewmean              | 997       |
| episodes                | 2188      |
| eplenmean               | 254       |
| fps                     | 11        |
| mean 100 episode reward | 997       |
| n_updates               | 435000    |
| q_grad_norm             | 3076.8157 |
| qfs_loss                | 47.356033 |
| qs_abs_difference       | 17.4      |
| qs_difference           | 16.3      |
| qs_mean                 | 339.04633 |
| time_elapsed            | 21470     |
| total timesteps         | 242430    |
| train_time              | 6385      |
| update_time             | 14350     |
---------------------------------------
---------------------------------------
| act_time                | 165       |
| current_lr              | 0.0003    |
| discount_q              | 0.0796    |
| env_time                | 378       |
| ep_rewmean              | 998       |
| episodes                | 2192      |
| eplenmean               | 254       |
| fps                     | 11        |
| mean 100 episode reward | 998       |
| n_updates               | 437000    |
| q_grad_norm             | 2748.885  |
| qfs_loss                | 64.960304 |
| qs_abs_difference       | 95.3      |
| qs_difference           | 95.3      |
| qs_mean                 | 320.3995  |
| time_elapsed            | 21538     |
| total timesteps         | 243418    |
| train_time              | 6405      |
| update_time             | 14395     |
---------------------------------------
---------------------------------------
| act_time                | 165       |
| current_lr              | 0.0003    |
| discount_q              | 0.272     |
| env_time                | 380       |
| ep_rewmean              | 1e+03     |
| episodes                | 2196      |
| eplenmean               | 254       |
| fps                     | 11        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 438800    |
| q_grad_norm             | 3106.6038 |
| qfs_loss                | 64.27362  |
| qs_abs_difference       | 65.3      |
| qs_difference           | 64.9      |
| qs_mean                 | 364.85803 |
| time_elapsed            | 21599     |
| total timesteps         | 244388    |
| train_time              | 6423      |
| update_time             | 14437     |
---------------------------------------
---------------------------------------
| act_time                | 166       |
| current_lr              | 0.0003    |
| discount_q              | 0.0583    |
| env_time                | 381       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2200      |
| eplenmean               | 256       |
| fps                     | 11        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 441200    |
| q_grad_norm             | 3405.029  |
| qfs_loss                | 70.908775 |
| qs_abs_difference       | 16.1      |
| qs_difference           | 15.8      |
| qs_mean                 | 329.04776 |
| time_elapsed            | 21681     |
| total timesteps         | 245512    |
| train_time              | 6447      |
| update_time             | 14491     |
---------------------------------------
---------------------------------------
| act_time                | 167       |
| current_lr              | 0.0003    |
| discount_q              | 0.0873    |
| env_time                | 382       |
| ep_rewmean              | 990       |
| episodes                | 2204      |
| eplenmean               | 251       |
| fps                     | 11        |
| mean 100 episode reward | 990       |
| n_updates               | 442600    |
| q_grad_norm             | 2588.2173 |
| qfs_loss                | 38.291107 |
| qs_abs_difference       | 279       |
| qs_difference           | 279       |
| qs_mean                 | 333.1334  |
| time_elapsed            | 21728     |
| total timesteps         | 246255    |
| train_time              | 6461      |
| update_time             | 14523     |
---------------------------------------
---------------------------------------
| act_time                | 167       |
| current_lr              | 0.0003    |
| discount_q              | 0.0914    |
| env_time                | 383       |
| ep_rewmean              | 996       |
| episodes                | 2208      |
| eplenmean               | 253       |
| fps                     | 11        |
| mean 100 episode reward | 996       |
| n_updates               | 444800    |
| q_grad_norm             | 3202.2258 |
| qfs_loss                | 61.42944  |
| qs_abs_difference       | 13.8      |
| qs_difference           | 12.4      |
| qs_mean                 | 322.50916 |
| time_elapsed            | 21803     |
| total timesteps         | 247337    |
| train_time              | 6483      |
| update_time             | 14573     |
---------------------------------------
---------------------------------------
| act_time                | 168       |
| current_lr              | 0.0003    |
| discount_q              | 0.0611    |
| env_time                | 385       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2212      |
| eplenmean               | 259       |
| fps                     | 11        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 447000    |
| q_grad_norm             | 2623.1035 |
| qfs_loss                | 40.833485 |
| qs_abs_difference       | 25.7      |
| qs_difference           | 25.7      |
| qs_mean                 | 333.28082 |
| time_elapsed            | 21878     |
| total timesteps         | 248451    |
| train_time              | 6506      |
| update_time             | 14624     |
---------------------------------------
---------------------------------------
| act_time                | 169       |
| current_lr              | 0.0003    |
| discount_q              | 0.0279    |
| env_time                | 386       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2216      |
| eplenmean               | 257       |
| fps                     | 11        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 449400    |
| q_grad_norm             | 2766.9675 |
| qfs_loss                | 43.747227 |
| qs_abs_difference       | 24        |
| qs_difference           | 23.9      |
| qs_mean                 | 324.81815 |
| time_elapsed            | 21960     |
| total timesteps         | 249636    |
| train_time              | 6530      |
| update_time             | 14679     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 898       |
| eval_abs_qs_difference  | 84.77654  |
| eval_discount_q         | 223       |
| eval_ep_rewmean         | 948       |
| eval_eplenmean          | 230       |
| eval_qs                 | 327.69516 |
| eval_qs_difference      | 79.7      |
| eval_time_elapsed       | 4         |
| total timesteps         | 250001    |
---------------------------------------
---------------------------------------
| act_time                | 170       |
| current_lr              | 0.0003    |
| discount_q              | 0.0477    |
| env_time                | 388       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2220      |
| eplenmean               | 256       |
| fps                     | 11        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 451600    |
| q_grad_norm             | 3574.8445 |
| qfs_loss                | 61.49506  |
| qs_abs_difference       | 27.5      |
| qs_difference           | 27.5      |
| qs_mean                 | 302.52106 |
| time_elapsed            | 22039     |
| total timesteps         | 250716    |
| train_time              | 6552      |
| update_time             | 14729     |
---------------------------------------
---------------------------------------
| act_time                | 170       |
| current_lr              | 0.0003    |
| discount_q              | 0.0299    |
| env_time                | 389       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2224      |
| eplenmean               | 257       |
| fps                     | 11        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 454000    |
| q_grad_norm             | 2762.3057 |
| qfs_loss                | 40.354683 |
| qs_abs_difference       | 17        |
| qs_difference           | 16        |
| qs_mean                 | 328.99417 |
| time_elapsed            | 22122     |
| total timesteps         | 251978    |
| train_time              | 6576      |
| update_time             | 14785     |
---------------------------------------
---------------------------------------
| act_time                | 171       |
| current_lr              | 0.0003    |
| discount_q              | 0.817     |
| env_time                | 391       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2228      |
| eplenmean               | 254       |
| fps                     | 11        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 455800    |
| q_grad_norm             | 2853.8914 |
| qfs_loss                | 43.819138 |
| qs_abs_difference       | 8.31      |
| qs_difference           | 4.77      |
| qs_mean                 | 319.5523  |
| time_elapsed            | 22183     |
| total timesteps         | 252832    |
| train_time              | 6594      |
| update_time             | 14826     |
---------------------------------------
---------------------------------------
| act_time                | 172       |
| current_lr              | 0.0003    |
| discount_q              | 0.1       |
| env_time                | 392       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2232      |
| eplenmean               | 255       |
| fps                     | 11        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 458000    |
| q_grad_norm             | 2675.1165 |
| qfs_loss                | 41.29813  |
| qs_abs_difference       | 15        |
| qs_difference           | 10.3      |
| qs_mean                 | 322.7663  |
| time_elapsed            | 22257     |
| total timesteps         | 253911    |
| train_time              | 6616      |
| update_time             | 14876     |
---------------------------------------
---------------------------------------
| act_time                | 172       |
| current_lr              | 0.0003    |
| discount_q              | 0.188     |
| env_time                | 393       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2236      |
| eplenmean               | 254       |
| fps                     | 11        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 460000    |
| q_grad_norm             | 2598.9797 |
| qfs_loss                | 39.651485 |
| qs_abs_difference       | 36.3      |
| qs_difference           | 35.6      |
| qs_mean                 | 334.06873 |
| time_elapsed            | 22325     |
| total timesteps         | 254927    |
| train_time              | 6636      |
| update_time             | 14921     |
---------------------------------------
---------------------------------------
| act_time                | 173       |
| current_lr              | 0.0003    |
| discount_q              | 0.0745    |
| env_time                | 395       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2240      |
| eplenmean               | 254       |
| fps                     | 11        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 462200    |
| q_grad_norm             | 2761.0227 |
| qfs_loss                | 53.38491  |
| qs_abs_difference       | 16.1      |
| qs_difference           | 15.9      |
| qs_mean                 | 326.43893 |
| time_elapsed            | 22400     |
| total timesteps         | 256030    |
| train_time              | 6658      |
| update_time             | 14971     |
---------------------------------------
---------------------------------------
| act_time                | 174       |
| current_lr              | 0.0003    |
| discount_q              | 0.0571    |
| env_time                | 396       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2244      |
| eplenmean               | 255       |
| fps                     | 11        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 464400    |
| q_grad_norm             | 2704.4602 |
| qfs_loss                | 42.343975 |
| qs_abs_difference       | 22.4      |
| qs_difference           | 20.9      |
| qs_mean                 | 300.90894 |
| time_elapsed            | 22474     |
| total timesteps         | 257116    |
| train_time              | 6680      |
| update_time             | 15021     |
---------------------------------------
---------------------------------------
| act_time                | 175       |
| current_lr              | 0.0003    |
| discount_q              | 0.0367    |
| env_time                | 397       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2248      |
| eplenmean               | 259       |
| fps                     | 11        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 466600    |
| q_grad_norm             | 1999.256  |
| qfs_loss                | 32.087723 |
| qs_abs_difference       | 21.2      |
| qs_difference           | 19.9      |
| qs_mean                 | 309.68518 |
| time_elapsed            | 22549     |
| total timesteps         | 258253    |
| train_time              | 6702      |
| update_time             | 15071     |
---------------------------------------
---------------------------------------
| act_time                | 175       |
| current_lr              | 0.0003    |
| discount_q              | 0.0415    |
| env_time                | 399       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2252      |
| eplenmean               | 257       |
| fps                     | 11        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 468400    |
| q_grad_norm             | 3225.7637 |
| qfs_loss                | 53.167778 |
| qs_abs_difference       | 94.1      |
| qs_difference           | 84.1      |
| qs_mean                 | 217.92892 |
| time_elapsed            | 22611     |
| total timesteps         | 259198    |
| train_time              | 6721      |
| update_time             | 15113     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 963       |
| eval_abs_qs_difference  | 16.587765 |
| eval_discount_q         | 285       |
| eval_ep_rewmean         | 1.11e+03  |
| eval_eplenmean          | 268       |
| eval_qs                 | 320.87976 |
| eval_qs_difference      | 12.3      |
| eval_time_elapsed       | 5         |
| total timesteps         | 260001    |
---------------------------------------
---------------------------------------
| act_time                | 176       |
| current_lr              | 0.0003    |
| discount_q              | 0.0271    |
| env_time                | 400       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2256      |
| eplenmean               | 259       |
| fps                     | 11        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 471000    |
| q_grad_norm             | 3865.5322 |
| qfs_loss                | 62.944305 |
| qs_abs_difference       | 6.62      |
| qs_difference           | 4.74      |
| qs_mean                 | 337.9354  |
| time_elapsed            | 22706     |
| total timesteps         | 260442    |
| train_time              | 6747      |
| update_time             | 15173     |
---------------------------------------
---------------------------------------
| act_time                | 177       |
| current_lr              | 0.0003    |
| discount_q              | 0.165     |
| env_time                | 402       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2260      |
| eplenmean               | 259       |
| fps                     | 11        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 473000    |
| q_grad_norm             | 3505.4421 |
| qfs_loss                | 64.10424  |
| qs_abs_difference       | 20.5      |
| qs_difference           | 20.2      |
| qs_mean                 | 314.9768  |
| time_elapsed            | 22774     |
| total timesteps         | 261439    |
| train_time              | 6767      |
| update_time             | 15218     |
---------------------------------------
---------------------------------------
| act_time                | 177       |
| current_lr              | 0.0003    |
| discount_q              | 0.0588    |
| env_time                | 403       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2264      |
| eplenmean               | 260       |
| fps                     | 11        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 475200    |
| q_grad_norm             | 2627.3022 |
| qfs_loss                | 42.32361  |
| qs_abs_difference       | 12.5      |
| qs_difference           | 8.71      |
| qs_mean                 | 317.68655 |
| time_elapsed            | 22849     |
| total timesteps         | 262547    |
| train_time              | 6790      |
| update_time             | 15269     |
---------------------------------------
---------------------------------------
| act_time                | 178       |
| current_lr              | 0.0003    |
| discount_q              | 0.0336    |
| env_time                | 405       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2268      |
| eplenmean               | 263       |
| fps                     | 11        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 477600    |
| q_grad_norm             | 2796.235  |
| qfs_loss                | 41.646645 |
| qs_abs_difference       | 9.26      |
| qs_difference           | 8.94      |
| qs_mean                 | 337.0275  |
| time_elapsed            | 22931     |
| total timesteps         | 263740    |
| train_time              | 6814      |
| update_time             | 15324     |
---------------------------------------
---------------------------------------
| act_time                | 179       |
| current_lr              | 0.0003    |
| discount_q              | 0.028     |
| env_time                | 406       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2272      |
| eplenmean               | 265       |
| fps                     | 11        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 480000    |
| q_grad_norm             | 3458.0935 |
| qfs_loss                | 62.646797 |
| qs_abs_difference       | 21.2      |
| qs_difference           | 21.2      |
| qs_mean                 | 330.318   |
| time_elapsed            | 23013     |
| total timesteps         | 264939    |
| train_time              | 6838      |
| update_time             | 15379     |
---------------------------------------
---------------------------------------
| act_time                | 180       |
| current_lr              | 0.0003    |
| discount_q              | 0.0212    |
| env_time                | 408       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2276      |
| eplenmean               | 268       |
| fps                     | 11        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 482600    |
| q_grad_norm             | 2276.7324 |
| qfs_loss                | 30.651396 |
| qs_abs_difference       | 6.07      |
| qs_difference           | 3.1       |
| qs_mean                 | 348.7274  |
| time_elapsed            | 23101     |
| total timesteps         | 266228    |
| train_time              | 6864      |
| update_time             | 15438     |
---------------------------------------
---------------------------------------
| act_time                | 181       |
| current_lr              | 0.0003    |
| discount_q              | 0.0226    |
| env_time                | 409       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2280      |
| eplenmean               | 269       |
| fps                     | 11        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 484800    |
| q_grad_norm             | 3077.5369 |
| qfs_loss                | 42.690765 |
| qs_abs_difference       | 190       |
| qs_difference           | 190       |
| qs_mean                 | 392.94318 |
| time_elapsed            | 23176     |
| total timesteps         | 267330    |
| train_time              | 6886      |
| update_time             | 15489     |
---------------------------------------
---------------------------------------
| act_time                | 181       |
| current_lr              | 0.0003    |
| discount_q              | 0.0337    |
| env_time                | 410       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2284      |
| eplenmean               | 265       |
| fps                     | 11        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 486000    |
| q_grad_norm             | 2612.0925 |
| qfs_loss                | 39.45895  |
| qs_abs_difference       | 286       |
| qs_difference           | 286       |
| qs_mean                 | 296.68845 |
| time_elapsed            | 23217     |
| total timesteps         | 267957    |
| train_time              | 6898      |
| update_time             | 15516     |
---------------------------------------
---------------------------------------
| act_time                | 182       |
| current_lr              | 0.0003    |
| discount_q              | 10        |
| env_time                | 411       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2288      |
| eplenmean               | 262       |
| fps                     | 11        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 487400    |
| q_grad_norm             | 2143.9536 |
| qfs_loss                | 28.354918 |
| qs_abs_difference       | 22.7      |
| qs_difference           | 22.3      |
| qs_mean                 | 344.92352 |
| time_elapsed            | 23265     |
| total timesteps         | 268601    |
| train_time              | 6912      |
| update_time             | 15548     |
---------------------------------------
---------------------------------------
| act_time                | 182       |
| current_lr              | 0.0003    |
| discount_q              | 0.491     |
| env_time                | 412       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2292      |
| eplenmean               | 261       |
| fps                     | 11        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 489000    |
| q_grad_norm             | 2984.2622 |
| qfs_loss                | 55.28386  |
| qs_abs_difference       | 16        |
| qs_difference           | 15.8      |
| qs_mean                 | 323.52963 |
| time_elapsed            | 23320     |
| total timesteps         | 269496    |
| train_time              | 6928      |
| update_time             | 15584     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.03e+03  |
| eval_abs_qs_difference  | 27.590462 |
| eval_discount_q         | 281       |
| eval_ep_rewmean         | 1.12e+03  |
| eval_eplenmean          | 273       |
| eval_qs                 | 328.08987 |
| eval_qs_difference      | 19.6      |
| eval_time_elapsed       | 6         |
| total timesteps         | 270001    |
---------------------------------------
---------------------------------------
| act_time                | 183       |
| current_lr              | 0.0003    |
| discount_q              | 0.0283    |
| env_time                | 414       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2296      |
| eplenmean               | 263       |
| fps                     | 11        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 491400    |
| q_grad_norm             | 3082.839  |
| qfs_loss                | 48.468884 |
| qs_abs_difference       | 12.4      |
| qs_difference           | 12.1      |
| qs_mean                 | 333.6838  |
| time_elapsed            | 23408     |
| total timesteps         | 270697    |
| train_time              | 6952      |
| update_time             | 15639     |
---------------------------------------
---------------------------------------
| act_time                | 184       |
| current_lr              | 0.0003    |
| discount_q              | 0.126     |
| env_time                | 415       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2300      |
| eplenmean               | 263       |
| fps                     | 11        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 493600    |
| q_grad_norm             | 2788.2998 |
| qfs_loss                | 41.31584  |
| qs_abs_difference       | 5.06      |
| qs_difference           | 1.14      |
| qs_mean                 | 333.66177 |
| time_elapsed            | 23483     |
| total timesteps         | 271763    |
| train_time              | 6974      |
| update_time             | 15690     |
---------------------------------------
---------------------------------------
| act_time                | 185       |
| current_lr              | 0.0003    |
| discount_q              | 0.0843    |
| env_time                | 417       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2304      |
| eplenmean               | 266       |
| fps                     | 11        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 495800    |
| q_grad_norm             | 3231.1357 |
| qfs_loss                | 52.375843 |
| qs_abs_difference       | 15.7      |
| qs_difference           | 11.3      |
| qs_mean                 | 336.7375  |
| time_elapsed            | 23558     |
| total timesteps         | 272893    |
| train_time              | 6997      |
| update_time             | 15740     |
---------------------------------------
---------------------------------------
| act_time                | 185       |
| current_lr              | 0.0003    |
| discount_q              | 0.514     |
| env_time                | 418       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2308      |
| eplenmean               | 264       |
| fps                     | 11        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 497600    |
| q_grad_norm             | 2916.2632 |
| qfs_loss                | 44.661514 |
| qs_abs_difference       | 16.3      |
| qs_difference           | 16.3      |
| qs_mean                 | 325.60672 |
| time_elapsed            | 23619     |
| total timesteps         | 273787    |
| train_time              | 7015      |
| update_time             | 15781     |
---------------------------------------
---------------------------------------
| act_time                | 186       |
| current_lr              | 0.0003    |
| discount_q              | 0.0759    |
| env_time                | 419       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2312      |
| eplenmean               | 264       |
| fps                     | 11        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 499800    |
| q_grad_norm             | 3030.518  |
| qfs_loss                | 49.640873 |
| qs_abs_difference       | 24.9      |
| qs_difference           | 24.1      |
| qs_mean                 | 310.7289  |
| time_elapsed            | 23694     |
| total timesteps         | 274863    |
| train_time              | 7037      |
| update_time             | 15832     |
---------------------------------------
---------------------------------------
| act_time                | 187       |
| current_lr              | 0.0003    |
| discount_q              | 0.0599    |
| env_time                | 421       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2316      |
| eplenmean               | 263       |
| fps                     | 11        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 502000    |
| q_grad_norm             | 3105.7515 |
| qfs_loss                | 49.191944 |
| qs_abs_difference       | 14.1      |
| qs_difference           | 13.3      |
| qs_mean                 | 319.43573 |
| time_elapsed            | 23769     |
| total timesteps         | 275962    |
| train_time              | 7059      |
| update_time             | 15882     |
---------------------------------------
---------------------------------------
| act_time                | 187       |
| current_lr              | 0.0003    |
| discount_q              | 0.036     |
| env_time                | 423       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2320      |
| eplenmean               | 265       |
| fps                     | 11        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 504400    |
| q_grad_norm             | 3050.9946 |
| qfs_loss                | 43.89989  |
| qs_abs_difference       | 27.3      |
| qs_difference           | 27        |
| qs_mean                 | 358.87915 |
| time_elapsed            | 23852     |
| total timesteps         | 277178    |
| train_time              | 7083      |
| update_time             | 15938     |
---------------------------------------
---------------------------------------
| act_time                | 188       |
| current_lr              | 0.0003    |
| discount_q              | 0.029     |
| env_time                | 424       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2324      |
| eplenmean               | 264       |
| fps                     | 11        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 506800    |
| q_grad_norm             | 2695.497  |
| qfs_loss                | 40.301422 |
| qs_abs_difference       | 76.3      |
| qs_difference           | 76.3      |
| qs_mean                 | 378.54803 |
| time_elapsed            | 23933     |
| total timesteps         | 278375    |
| train_time              | 7107      |
| update_time             | 15992     |
---------------------------------------
---------------------------------------
| act_time                | 189       |
| current_lr              | 0.0003    |
| discount_q              | 0.012     |
| env_time                | 426       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2328      |
| eplenmean               | 268       |
| fps                     | 11        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 509400    |
| q_grad_norm             | 3889.791  |
| qfs_loss                | 68.54212  |
| qs_abs_difference       | 33.9      |
| qs_difference           | 33.7      |
| qs_mean                 | 340.73523 |
| time_elapsed            | 24020     |
| total timesteps         | 279654    |
| train_time              | 7133      |
| update_time             | 16050     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.05e+03  |
| eval_abs_qs_difference  | 47.820175 |
| eval_discount_q         | 274       |
| eval_ep_rewmean         | 1.01e+03  |
| eval_eplenmean          | 256       |
| eval_qs                 | 331.842   |
| eval_qs_difference      | 44.6      |
| eval_time_elapsed       | 6         |
| total timesteps         | 280001    |
---------------------------------------
---------------------------------------
| act_time                | 190       |
| current_lr              | 0.0003    |
| discount_q              | 0.0476    |
| env_time                | 427       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2332      |
| eplenmean               | 269       |
| fps                     | 11        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 511800    |
| q_grad_norm             | 3008.051  |
| qfs_loss                | 43.72143  |
| qs_abs_difference       | 21.2      |
| qs_difference           | 20.5      |
| qs_mean                 | 338.88312 |
| time_elapsed            | 24106     |
| total timesteps         | 280830    |
| train_time              | 7157      |
| update_time             | 16104     |
---------------------------------------
---------------------------------------
| act_time                | 191       |
| current_lr              | 0.0003    |
| discount_q              | 0.0261    |
| env_time                | 429       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2336      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 514200    |
| q_grad_norm             | 2150.9426 |
| qfs_loss                | 30.008804 |
| qs_abs_difference       | 9.58      |
| qs_difference           | 8.72      |
| qs_mean                 | 342.8757  |
| time_elapsed            | 24187     |
| total timesteps         | 282066    |
| train_time              | 7181      |
| update_time             | 16158     |
---------------------------------------
---------------------------------------
| act_time                | 191       |
| current_lr              | 0.0003    |
| discount_q              | 0.0927    |
| env_time                | 430       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2340      |
| eplenmean               | 272       |
| fps                     | 11        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 516400    |
| q_grad_norm             | 3205.311  |
| qfs_loss                | 49.05681  |
| qs_abs_difference       | 9.49      |
| qs_difference           | -8.58     |
| qs_mean                 | 349.85245 |
| time_elapsed            | 24260     |
| total timesteps         | 283191    |
| train_time              | 7203      |
| update_time             | 16207     |
---------------------------------------
---------------------------------------
| act_time                | 192       |
| current_lr              | 0.0003    |
| discount_q              | 0.0478    |
| env_time                | 432       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 2344      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 518800    |
| q_grad_norm             | 3374.054  |
| qfs_loss                | 55.710796 |
| qs_abs_difference       | 21.5      |
| qs_difference           | 19.3      |
| qs_mean                 | 352.28445 |
| time_elapsed            | 24340     |
| total timesteps         | 284372    |
| train_time              | 7227      |
| update_time             | 16260     |
---------------------------------------
---------------------------------------
| act_time                | 193       |
| current_lr              | 0.0003    |
| discount_q              | 0.0477    |
| env_time                | 433       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 2348      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 521200    |
| q_grad_norm             | 2637.5256 |
| qfs_loss                | 38.60325  |
| qs_abs_difference       | 5.79      |
| qs_difference           | 3.94      |
| qs_mean                 | 345.10327 |
| time_elapsed            | 24420     |
| total timesteps         | 285550    |
| train_time              | 7251      |
| update_time             | 16313     |
---------------------------------------
---------------------------------------
| act_time                | 194       |
| current_lr              | 0.0003    |
| discount_q              | 0.0394    |
| env_time                | 435       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2352      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 523600    |
| q_grad_norm             | 3276.729  |
| qfs_loss                | 52.748043 |
| qs_abs_difference       | 6.13      |
| qs_difference           | -5.73     |
| qs_mean                 | 340.8799  |
| time_elapsed            | 24500     |
| total timesteps         | 286747    |
| train_time              | 7275      |
| update_time             | 16367     |
---------------------------------------
---------------------------------------
| act_time                | 195       |
| current_lr              | 0.0003    |
| discount_q              | 0.0886    |
| env_time                | 436       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 2356      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 525600    |
| q_grad_norm             | 2480.9666 |
| qfs_loss                | 36.362083 |
| qs_abs_difference       | 14.6      |
| qs_difference           | 14.2      |
| qs_mean                 | 317.09787 |
| time_elapsed            | 24567     |
| total timesteps         | 287788    |
| train_time              | 7295      |
| update_time             | 16411     |
---------------------------------------
---------------------------------------
| act_time                | 195       |
| current_lr              | 0.0003    |
| discount_q              | 0.0654    |
| env_time                | 438       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2360      |
| eplenmean               | 274       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 527800    |
| q_grad_norm             | 3040.765  |
| qfs_loss                | 41.21793  |
| qs_abs_difference       | 20.9      |
| qs_difference           | 20.5      |
| qs_mean                 | 327.17624 |
| time_elapsed            | 24641     |
| total timesteps         | 288884    |
| train_time              | 7317      |
| update_time             | 16461     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.06e+03  |
| eval_abs_qs_difference  | 49.603745 |
| eval_discount_q         | 290       |
| eval_ep_rewmean         | 1.23e+03  |
| eval_eplenmean          | 291       |
| eval_qs                 | 363.4173  |
| eval_qs_difference      | 43.6      |
| eval_time_elapsed       | 6         |
| total timesteps         | 290001    |
---------------------------------------
---------------------------------------
| act_time                | 196       |
| current_lr              | 0.0003    |
| discount_q              | 0.0494    |
| env_time                | 439       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2364      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 530200    |
| q_grad_norm             | 3015.6094 |
| qfs_loss                | 45.369385 |
| qs_abs_difference       | 4.81      |
| qs_difference           | -3.26     |
| qs_mean                 | 343.23807 |
| time_elapsed            | 24727     |
| total timesteps         | 290068    |
| train_time              | 7340      |
| update_time             | 16514     |
---------------------------------------
---------------------------------------
| act_time                | 197       |
| current_lr              | 0.0003    |
| discount_q              | 0.104     |
| env_time                | 441       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2368      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 532200    |
| q_grad_norm             | 2358.2659 |
| qfs_loss                | 36.60866  |
| qs_abs_difference       | 20.4      |
| qs_difference           | 19.4      |
| qs_mean                 | 298.77808 |
| time_elapsed            | 24794     |
| total timesteps         | 291067    |
| train_time              | 7360      |
| update_time             | 16558     |
---------------------------------------
---------------------------------------
| act_time                | 197       |
| current_lr              | 0.0003    |
| discount_q              | 0.284     |
| env_time                | 442       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 2372      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 534000    |
| q_grad_norm             | 2972.2458 |
| qfs_loss                | 53.11052  |
| qs_abs_difference       | 20.9      |
| qs_difference           | 20.6      |
| qs_mean                 | 313.9625  |
| time_elapsed            | 24854     |
| total timesteps         | 291993    |
| train_time              | 7378      |
| update_time             | 16599     |
---------------------------------------
---------------------------------------
| act_time                | 198       |
| current_lr              | 0.0003    |
| discount_q              | 0.0834    |
| env_time                | 443       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2376      |
| eplenmean               | 268       |
| fps                     | 11        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 536200    |
| q_grad_norm             | 3218.3965 |
| qfs_loss                | 50.028805 |
| qs_abs_difference       | 16.3      |
| qs_difference           | 14.5      |
| qs_mean                 | 323.1898  |
| time_elapsed            | 24927     |
| total timesteps         | 293071    |
| train_time              | 7401      |
| update_time             | 16647     |
---------------------------------------
---------------------------------------
| act_time                | 199       |
| current_lr              | 0.0003    |
| discount_q              | 0.121     |
| env_time                | 445       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2380      |
| eplenmean               | 267       |
| fps                     | 11        |
| mean 100 episode reward | 1.10e+03  |
| n_updates               | 538200    |
| q_grad_norm             | 3030.5771 |
| qfs_loss                | 48.75868  |
| qs_abs_difference       | 149       |
| qs_difference           | 149       |
| qs_mean                 | 393.23825 |
| time_elapsed            | 24994     |
| total timesteps         | 294041    |
| train_time              | 7421      |
| update_time             | 16692     |
---------------------------------------
---------------------------------------
| act_time                | 199       |
| current_lr              | 0.0003    |
| discount_q              | 0.141     |
| env_time                | 446       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 2384      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 540200    |
| q_grad_norm             | 2206.8684 |
| qfs_loss                | 29.875975 |
| qs_abs_difference       | 19.3      |
| qs_difference           | 18.1      |
| qs_mean                 | 327.41168 |
| time_elapsed            | 25061     |
| total timesteps         | 295065    |
| train_time              | 7440      |
| update_time             | 16737     |
---------------------------------------
---------------------------------------
| act_time                | 200       |
| current_lr              | 0.0003    |
| discount_q              | 0.16      |
| env_time                | 447       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2388      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 542200    |
| q_grad_norm             | 2936.8132 |
| qfs_loss                | 48.2755   |
| qs_abs_difference       | 5.71      |
| qs_difference           | 2.03      |
| qs_mean                 | 336.94345 |
| time_elapsed            | 25127     |
| total timesteps         | 296098    |
| train_time              | 7460      |
| update_time             | 16781     |
---------------------------------------
---------------------------------------
| act_time                | 201       |
| current_lr              | 0.0003    |
| discount_q              | 0.0437    |
| env_time                | 449       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2392      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 544600    |
| q_grad_norm             | 3427.9944 |
| qfs_loss                | 57.30334  |
| qs_abs_difference       | 32.2      |
| qs_difference           | 32.2      |
| qs_mean                 | 342.37057 |
| time_elapsed            | 25207     |
| total timesteps         | 297232    |
| train_time              | 7484      |
| update_time             | 16834     |
---------------------------------------
---------------------------------------
| act_time                | 202       |
| current_lr              | 0.0003    |
| discount_q              | 0.427     |
| env_time                | 450       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2396      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 546400    |
| q_grad_norm             | 3252.725  |
| qfs_loss                | 56.335915 |
| qs_abs_difference       | 14.5      |
| qs_difference           | 5.4       |
| qs_mean                 | 337.33267 |
| time_elapsed            | 25268     |
| total timesteps         | 298179    |
| train_time              | 7502      |
| update_time             | 16875     |
---------------------------------------
---------------------------------------
| act_time                | 202       |
| current_lr              | 0.0003    |
| discount_q              | 0.0457    |
| env_time                | 451       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2400      |
| eplenmean               | 276       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 548800    |
| q_grad_norm             | 1847.7596 |
| qfs_loss                | 35.64788  |
| qs_abs_difference       | 6.28      |
| qs_difference           | -4.3      |
| qs_mean                 | 332.63266 |
| time_elapsed            | 25349     |
| total timesteps         | 299331    |
| train_time              | 7526      |
| update_time             | 16929     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.05e+03  |
| eval_abs_qs_difference  | 45.190536 |
| eval_discount_q         | 280       |
| eval_ep_rewmean         | 1.02e+03  |
| eval_eplenmean          | 250       |
| eval_qs                 | 329.69827 |
| eval_qs_difference      | 39.9      |
| eval_time_elapsed       | 5         |
| total timesteps         | 300001    |
---------------------------------------
---------------------------------------
| act_time                | 203       |
| current_lr              | 0.0003    |
| discount_q              | 0.08      |
| env_time                | 453       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2404      |
| eplenmean               | 276       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 551000    |
| q_grad_norm             | 3823.7856 |
| qfs_loss                | 62.637413 |
| qs_abs_difference       | 21.3      |
| qs_difference           | 21.2      |
| qs_mean                 | 357.4029  |
| time_elapsed            | 25428     |
| total timesteps         | 300474    |
| train_time              | 7548      |
| update_time             | 16978     |
---------------------------------------
---------------------------------------
| act_time                | 204       |
| current_lr              | 0.0003    |
| discount_q              | 0.0928    |
| env_time                | 455       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2408      |
| eplenmean               | 278       |
| fps                     | 11        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 553400    |
| q_grad_norm             | 3488.8325 |
| qfs_loss                | 61.581875 |
| qs_abs_difference       | 7.11      |
| qs_difference           | 5.8       |
| qs_mean                 | 350.58804 |
| time_elapsed            | 25522     |
| total timesteps         | 301614    |
| train_time              | 7578      |
| update_time             | 17040     |
---------------------------------------
---------------------------------------
| act_time                | 205       |
| current_lr              | 0.0003    |
| discount_q              | 0.368     |
| env_time                | 456       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2412      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 555200    |
| q_grad_norm             | 2994.8623 |
| qfs_loss                | 53.880356 |
| qs_abs_difference       | 39.5      |
| qs_difference           | 39.3      |
| qs_mean                 | 340.1043  |
| time_elapsed            | 25607     |
| total timesteps         | 302535    |
| train_time              | 7605      |
| update_time             | 17095     |
---------------------------------------
---------------------------------------
| act_time                | 206       |
| current_lr              | 0.0003    |
| discount_q              | 0.0467    |
| env_time                | 458       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2416      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 557400    |
| q_grad_norm             | 3470.7578 |
| qfs_loss                | 65.82741  |
| qs_abs_difference       | 16.9      |
| qs_difference           | 15.5      |
| qs_mean                 | 308.9258  |
| time_elapsed            | 25712     |
| total timesteps         | 303645    |
| train_time              | 7639      |
| update_time             | 17163     |
---------------------------------------
--------------------------------------
| act_time                | 207      |
| current_lr              | 0.0003   |
| discount_q              | 0.0405   |
| env_time                | 459      |
| ep_rewmean              | 1.16e+03 |
| episodes                | 2420     |
| eplenmean               | 276      |
| fps                     | 11       |
| mean 100 episode reward | 1.16e+03 |
| n_updates               | 559800   |
| q_grad_norm             | 2493.795 |
| qfs_loss                | 36.92102 |
| qs_abs_difference       | 46.5     |
| qs_difference           | 45.7     |
| qs_mean                 | 345.5806 |
| time_elapsed            | 25825    |
| total timesteps         | 304803   |
| train_time              | 7675     |
| update_time             | 17237    |
--------------------------------------
---------------------------------------
| act_time                | 208       |
| current_lr              | 0.0003    |
| discount_q              | 0.018     |
| env_time                | 462       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2424      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 562200    |
| q_grad_norm             | 2583.3599 |
| qfs_loss                | 28.783463 |
| qs_abs_difference       | 18.4      |
| qs_difference           | 17.9      |
| qs_mean                 | 346.10422 |
| time_elapsed            | 25961     |
| total timesteps         | 306070    |
| train_time              | 7722      |
| update_time             | 17323     |
---------------------------------------
---------------------------------------
| act_time                | 209       |
| current_lr              | 0.0003    |
| discount_q              | 0.166     |
| env_time                | 464       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2428      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 564400    |
| q_grad_norm             | 2282.0806 |
| qfs_loss                | 39.97203  |
| qs_abs_difference       | 8.03      |
| qs_difference           | -5.3      |
| qs_mean                 | 357.2234  |
| time_elapsed            | 26136     |
| total timesteps         | 307168    |
| train_time              | 7782      |
| update_time             | 17432     |
---------------------------------------
---------------------------------------
| act_time                | 211       |
| current_lr              | 0.0003    |
| discount_q              | 0.0383    |
| env_time                | 467       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2432      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 566800    |
| q_grad_norm             | 2876.7332 |
| qfs_loss                | 38.887283 |
| qs_abs_difference       | 10.5      |
| qs_difference           | 6.9       |
| qs_mean                 | 338.159   |
| time_elapsed            | 26328     |
| total timesteps         | 308346    |
| train_time              | 7850      |
| update_time             | 17551     |
---------------------------------------
---------------------------------------
| act_time                | 212       |
| current_lr              | 0.0003    |
| discount_q              | 0.0155    |
| env_time                | 470       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2436      |
| eplenmean               | 276       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 569400    |
| q_grad_norm             | 2415.2393 |
| qfs_loss                | 32.75139  |
| qs_abs_difference       | 20        |
| qs_difference           | 19.9      |
| qs_mean                 | 353.78552 |
| time_elapsed            | 26507     |
| total timesteps         | 309628    |
| train_time              | 7911      |
| update_time             | 17665     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.05e+03  |
| eval_abs_qs_difference  | 61.146816 |
| eval_discount_q         | 268       |
| eval_ep_rewmean         | 979       |
| eval_eplenmean          | 254       |
| eval_qs                 | 339.7737  |
| eval_qs_difference      | 59        |
| eval_time_elapsed       | 5         |
| total timesteps         | 310001    |
---------------------------------------
---------------------------------------
| act_time                | 213       |
| current_lr              | 0.0003    |
| discount_q              | 0.0383    |
| env_time                | 471       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2440      |
| eplenmean               | 276       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 571600    |
| q_grad_norm             | 3301.596  |
| qfs_loss                | 54.93984  |
| qs_abs_difference       | 44.4      |
| qs_difference           | 44.2      |
| qs_mean                 | 339.04468 |
| time_elapsed            | 26616     |
| total timesteps         | 310770    |
| train_time              | 7944      |
| update_time             | 17732     |
---------------------------------------
---------------------------------------
| act_time                | 214       |
| current_lr              | 0.0003    |
| discount_q              | 0.0792    |
| env_time                | 473       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2444      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 573800    |
| q_grad_norm             | 1706.8085 |
| qfs_loss                | 25.651243 |
| qs_abs_difference       | 22.3      |
| qs_difference           | 20.2      |
| qs_mean                 | 341.4631  |
| time_elapsed            | 26721     |
| total timesteps         | 311874    |
| train_time              | 7977      |
| update_time             | 17801     |
---------------------------------------
---------------------------------------
| act_time                | 215       |
| current_lr              | 0.0003    |
| discount_q              | 0.00886   |
| env_time                | 475       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2448      |
| eplenmean               | 276       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 576400    |
| q_grad_norm             | 2233.6743 |
| qfs_loss                | 30.681093 |
| qs_abs_difference       | 86.6      |
| qs_difference           | 86.6      |
| qs_mean                 | 383.24356 |
| time_elapsed            | 26844     |
| total timesteps         | 313189    |
| train_time              | 8016      |
| update_time             | 17881     |
---------------------------------------
---------------------------------------
| act_time                | 216       |
| current_lr              | 0.0003    |
| discount_q              | 0.0646    |
| env_time                | 477       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2452      |
| eplenmean               | 276       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 578800    |
| q_grad_norm             | 2760.0212 |
| qfs_loss                | 39.73613  |
| qs_abs_difference       | 10.1      |
| qs_difference           | 8.11      |
| qs_mean                 | 350.65762 |
| time_elapsed            | 26957     |
| total timesteps         | 314362    |
| train_time              | 8054      |
| update_time             | 17954     |
---------------------------------------
---------------------------------------
| act_time                | 217       |
| current_lr              | 0.0003    |
| discount_q              | 0.0631    |
| env_time                | 479       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2456      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 581200    |
| q_grad_norm             | 2469.3096 |
| qfs_loss                | 33.75     |
| qs_abs_difference       | 27.7      |
| qs_difference           | 26.9      |
| qs_mean                 | 354.17413 |
| time_elapsed            | 27072     |
| total timesteps         | 315508    |
| train_time              | 8091      |
| update_time             | 18029     |
---------------------------------------
---------------------------------------
| act_time                | 218       |
| current_lr              | 0.0003    |
| discount_q              | 0.0833    |
| env_time                | 480       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2460      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 583400    |
| q_grad_norm             | 2699.6074 |
| qfs_loss                | 40.336422 |
| qs_abs_difference       | 9.89      |
| qs_difference           | 8.76      |
| qs_mean                 | 333.75427 |
| time_elapsed            | 27166     |
| total timesteps         | 316610    |
| train_time              | 8120      |
| update_time             | 18090     |
---------------------------------------
---------------------------------------
| act_time                | 219       |
| current_lr              | 0.0003    |
| discount_q              | 0.063     |
| env_time                | 482       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2464      |
| eplenmean               | 276       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 585600    |
| q_grad_norm             | 2790.6118 |
| qfs_loss                | 43.757694 |
| qs_abs_difference       | 24.5      |
| qs_difference           | 23.4      |
| qs_mean                 | 327.50485 |
| time_elapsed            | 27262     |
| total timesteps         | 317706    |
| train_time              | 8150      |
| update_time             | 18153     |
---------------------------------------
---------------------------------------
| act_time                | 220       |
| current_lr              | 0.0003    |
| discount_q              | 0.0983    |
| env_time                | 483       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2468      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 587600    |
| q_grad_norm             | 2064.1191 |
| qfs_loss                | 30.588041 |
| qs_abs_difference       | 26.9      |
| qs_difference           | 26.9      |
| qs_mean                 | 321.99597 |
| time_elapsed            | 27349     |
| total timesteps         | 318736    |
| train_time              | 8177      |
| update_time             | 18211     |
---------------------------------------
---------------------------------------
| act_time                | 221       |
| current_lr              | 0.0003    |
| discount_q              | 0.113     |
| env_time                | 485       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2472      |
| eplenmean               | 278       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 589800    |
| q_grad_norm             | 2143.874  |
| qfs_loss                | 29.530651 |
| qs_abs_difference       | 13.3      |
| qs_difference           | 12.6      |
| qs_mean                 | 346.28915 |
| time_elapsed            | 27446     |
| total timesteps         | 319832    |
| train_time              | 8208      |
| update_time             | 18274     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.07e+03  |
| eval_abs_qs_difference  | 25.266884 |
| eval_discount_q         | 287       |
| eval_ep_rewmean         | 1.23e+03  |
| eval_eplenmean          | 295       |
| eval_qs                 | 343.51642 |
| eval_qs_difference      | 21.4      |
| eval_time_elapsed       | 6         |
| total timesteps         | 320001    |
---------------------------------------
---------------------------------------
| act_time                | 222       |
| current_lr              | 0.0003    |
| discount_q              | 0.107     |
| env_time                | 487       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2476      |
| eplenmean               | 278       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 592000    |
| q_grad_norm             | 2246.2234 |
| qfs_loss                | 28.747011 |
| qs_abs_difference       | 13.2      |
| qs_difference           | 12.7      |
| qs_mean                 | 345.2528  |
| time_elapsed            | 27548     |
| total timesteps         | 320913    |
| train_time              | 8238      |
| update_time             | 18336     |
---------------------------------------
---------------------------------------
| act_time                | 222       |
| current_lr              | 0.0003    |
| discount_q              | 0.105     |
| env_time                | 488       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2480      |
| eplenmean               | 279       |
| fps                     | 11        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 594000    |
| q_grad_norm             | 3657.8547 |
| qfs_loss                | 62.976513 |
| qs_abs_difference       | 30.1      |
| qs_difference           | 30.1      |
| qs_mean                 | 321.24872 |
| time_elapsed            | 27630     |
| total timesteps         | 321923    |
| train_time              | 8263      |
| update_time             | 18391     |
---------------------------------------
---------------------------------------
| act_time                | 223       |
| current_lr              | 0.0003    |
| discount_q              | 0.365     |
| env_time                | 489       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2484      |
| eplenmean               | 278       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 595800    |
| q_grad_norm             | 2608.6426 |
| qfs_loss                | 39.12593  |
| qs_abs_difference       | 26        |
| qs_difference           | 26        |
| qs_mean                 | 331.93695 |
| time_elapsed            | 27693     |
| total timesteps         | 322842    |
| train_time              | 8282      |
| update_time             | 18433     |
---------------------------------------
---------------------------------------
| act_time                | 224       |
| current_lr              | 0.0003    |
| discount_q              | 0.166     |
| env_time                | 490       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2488      |
| eplenmean               | 278       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 597800    |
| q_grad_norm             | 3752.6743 |
| qfs_loss                | 66.48783  |
| qs_abs_difference       | 17.5      |
| qs_difference           | 17.2      |
| qs_mean                 | 334.96317 |
| time_elapsed            | 27764     |
| total timesteps         | 323857    |
| train_time              | 8304      |
| update_time             | 18480     |
---------------------------------------
---------------------------------------
| act_time                | 224       |
| current_lr              | 0.0003    |
| discount_q              | 0.0461    |
| env_time                | 492       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2492      |
| eplenmean               | 278       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 600000    |
| q_grad_norm             | 2901.6853 |
| qfs_loss                | 47.17426  |
| qs_abs_difference       | 25.4      |
| qs_difference           | 20.7      |
| qs_mean                 | 322.38797 |
| time_elapsed            | 27866     |
| total timesteps         | 324985    |
| train_time              | 8338      |
| update_time             | 18546     |
---------------------------------------
---------------------------------------
| act_time                | 226       |
| current_lr              | 0.0003    |
| discount_q              | 0.0742    |
| env_time                | 494       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2496      |
| eplenmean               | 279       |
| fps                     | 11        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 602200    |
| q_grad_norm             | 2347.0457 |
| qfs_loss                | 38.203785 |
| qs_abs_difference       | 11.4      |
| qs_difference           | 8.11      |
| qs_mean                 | 329.49603 |
| time_elapsed            | 28031     |
| total timesteps         | 326084    |
| train_time              | 8395      |
| update_time             | 18649     |
---------------------------------------
---------------------------------------
| act_time                | 227       |
| current_lr              | 0.0003    |
| discount_q              | 0.0802    |
| env_time                | 496       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2500      |
| eplenmean               | 278       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 604400    |
| q_grad_norm             | 2677.2297 |
| qfs_loss                | 34.37457  |
| qs_abs_difference       | 25.6      |
| qs_difference           | 25.4      |
| qs_mean                 | 303.86606 |
| time_elapsed            | 28195     |
| total timesteps         | 327107    |
| train_time              | 8452      |
| update_time             | 18752     |
---------------------------------------
---------------------------------------
| act_time                | 228       |
| current_lr              | 0.0003    |
| discount_q              | 0.0408    |
| env_time                | 498       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2504      |
| eplenmean               | 278       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 606600    |
| q_grad_norm             | 2243.6606 |
| qfs_loss                | 29.627634 |
| qs_abs_difference       | 5.33      |
| qs_difference           | -2.4      |
| qs_mean                 | 343.2128  |
| time_elapsed            | 28321     |
| total timesteps         | 328289    |
| train_time              | 8493      |
| update_time             | 18833     |
---------------------------------------
---------------------------------------
| act_time                | 229       |
| current_lr              | 0.0003    |
| discount_q              | 0.0243    |
| env_time                | 499       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2508      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 607800    |
| q_grad_norm             | 2312.4915 |
| qfs_loss                | 31.113064 |
| qs_abs_difference       | 305       |
| qs_difference           | 305       |
| qs_mean                 | 309.9132  |
| time_elapsed            | 28368     |
| total timesteps         | 328892    |
| train_time              | 8508      |
| update_time             | 18864     |
---------------------------------------
---------------------------------------
| act_time                | 229       |
| current_lr              | 0.0003    |
| discount_q              | 0.406     |
| env_time                | 500       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2512      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 609800    |
| q_grad_norm             | 2463.5312 |
| qfs_loss                | 37.441048 |
| qs_abs_difference       | 8.13      |
| qs_difference           | -5.02     |
| qs_mean                 | 320.60782 |
| time_elapsed            | 28434     |
| total timesteps         | 329808    |
| train_time              | 8528      |
| update_time             | 18908     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.12e+03  |
| eval_abs_qs_difference  | 15.696586 |
| eval_discount_q         | 310       |
| eval_ep_rewmean         | 1.48e+03  |
| eval_eplenmean          | 323       |
| eval_qs                 | 347.87366 |
| eval_qs_difference      | -15       |
| eval_time_elapsed       | 6         |
| total timesteps         | 330001    |
---------------------------------------
---------------------------------------
| act_time                | 230       |
| current_lr              | 0.0003    |
| discount_q              | 0.0247    |
| env_time                | 502       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2516      |
| eplenmean               | 274       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 612200    |
| q_grad_norm             | 2840.6292 |
| qfs_loss                | 44.851055 |
| qs_abs_difference       | 8.24      |
| qs_difference           | -1.8      |
| qs_mean                 | 345.63608 |
| time_elapsed            | 28522     |
| total timesteps         | 331046    |
| train_time              | 8552      |
| update_time             | 18962     |
---------------------------------------
---------------------------------------
| act_time                | 231       |
| current_lr              | 0.0003    |
| discount_q              | 0.0474    |
| env_time                | 504       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2520      |
| eplenmean               | 274       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 614600    |
| q_grad_norm             | 1938.7395 |
| qfs_loss                | 30.704756 |
| qs_abs_difference       | 19.2      |
| qs_difference           | 19.1      |
| qs_mean                 | 361.4943  |
| time_elapsed            | 28619     |
| total timesteps         | 332225    |
| train_time              | 8583      |
| update_time             | 19025     |
---------------------------------------
---------------------------------------
| act_time                | 232       |
| current_lr              | 0.0003    |
| discount_q              | 0.0197    |
| env_time                | 506       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2524      |
| eplenmean               | 274       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 617200    |
| q_grad_norm             | 2178.986  |
| qfs_loss                | 28.510715 |
| qs_abs_difference       | 11.1      |
| qs_difference           | 7.66      |
| qs_mean                 | 355.651   |
| time_elapsed            | 28784     |
| total timesteps         | 333518    |
| train_time              | 8639      |
| update_time             | 19130     |
---------------------------------------
---------------------------------------
| act_time                | 233       |
| current_lr              | 0.0003    |
| discount_q              | 0.0627    |
| env_time                | 508       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2528      |
| eplenmean               | 274       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 619200    |
| q_grad_norm             | 3308.316  |
| qfs_loss                | 58.33859  |
| qs_abs_difference       | 157       |
| qs_difference           | 157       |
| qs_mean                 | 405.94757 |
| time_elapsed            | 28871     |
| total timesteps         | 334575    |
| train_time              | 8666      |
| update_time             | 19188     |
---------------------------------------
---------------------------------------
| act_time                | 234       |
| current_lr              | 0.0003    |
| discount_q              | 0.13      |
| env_time                | 509       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2532      |
| eplenmean               | 272       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 621200    |
| q_grad_norm             | 2789.728  |
| qfs_loss                | 39.93708  |
| qs_abs_difference       | 13.3      |
| qs_difference           | 11.1      |
| qs_mean                 | 325.41852 |
| time_elapsed            | 28938     |
| total timesteps         | 335595    |
| train_time              | 8686      |
| update_time             | 19232     |
---------------------------------------
---------------------------------------
| act_time                | 235       |
| current_lr              | 0.0003    |
| discount_q              | 0.0909    |
| env_time                | 511       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2536      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 623600    |
| q_grad_norm             | 2558.3938 |
| qfs_loss                | 36.861988 |
| qs_abs_difference       | 6.48      |
| qs_difference           | 3.6       |
| qs_mean                 | 348.60602 |
| time_elapsed            | 29016     |
| total timesteps         | 336718    |
| train_time              | 8710      |
| update_time             | 19284     |
---------------------------------------
---------------------------------------
| act_time                | 235       |
| current_lr              | 0.0003    |
| discount_q              | 0.0716    |
| env_time                | 512       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2540      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 625800    |
| q_grad_norm             | 2684.7295 |
| qfs_loss                | 45.324707 |
| qs_abs_difference       | 4.12      |
| qs_difference           | -3.14     |
| qs_mean                 | 345.9595  |
| time_elapsed            | 29089     |
| total timesteps         | 337853    |
| train_time              | 8731      |
| update_time             | 19332     |
---------------------------------------
---------------------------------------
| act_time                | 236       |
| current_lr              | 0.0003    |
| discount_q              | 0.0755    |
| env_time                | 514       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2544      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 628200    |
| q_grad_norm             | 2063.293  |
| qfs_loss                | 31.527576 |
| qs_abs_difference       | 5.94      |
| qs_difference           | -4.69     |
| qs_mean                 | 361.98508 |
| time_elapsed            | 29169     |
| total timesteps         | 339014    |
| train_time              | 8755      |
| update_time             | 19385     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.15e+03  |
| eval_abs_qs_difference  | 63.299618 |
| eval_discount_q         | 289       |
| eval_ep_rewmean         | 1.2e+03   |
| eval_eplenmean          | 281       |
| eval_qs                 | 371.90402 |
| eval_qs_difference      | 56        |
| eval_time_elapsed       | 6         |
| total timesteps         | 340001    |
---------------------------------------
---------------------------------------
| act_time                | 237       |
| current_lr              | 0.0003    |
| discount_q              | 0.0688    |
| env_time                | 515       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 2548      |
| eplenmean               | 269       |
| fps                     | 11        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 630200    |
| q_grad_norm             | 3369.7754 |
| qfs_loss                | 51.464634 |
| qs_abs_difference       | 159       |
| qs_difference           | 159       |
| qs_mean                 | 406.4363  |
| time_elapsed            | 29241     |
| total timesteps         | 340041    |
| train_time              | 8775      |
| update_time             | 19429     |
---------------------------------------
---------------------------------------
| act_time                | 238       |
| current_lr              | 0.0003    |
| discount_q              | 0.0733    |
| env_time                | 516       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2552      |
| eplenmean               | 268       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 632400    |
| q_grad_norm             | 2705.1526 |
| qfs_loss                | 42.21188  |
| qs_abs_difference       | 5         |
| qs_difference           | 2.95      |
| qs_mean                 | 347.11646 |
| time_elapsed            | 29314     |
| total timesteps         | 341170    |
| train_time              | 8798      |
| update_time             | 19477     |
---------------------------------------
---------------------------------------
| act_time                | 238       |
| current_lr              | 0.0003    |
| discount_q              | 0.0167    |
| env_time                | 518       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2556      |
| eplenmean               | 268       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 634800    |
| q_grad_norm             | 2957.808  |
| qfs_loss                | 38.459396 |
| qs_abs_difference       | 154       |
| qs_difference           | 154       |
| qs_mean                 | 371.75952 |
| time_elapsed            | 29392     |
| total timesteps         | 342300    |
| train_time              | 8821      |
| update_time             | 19529     |
---------------------------------------
---------------------------------------
| act_time                | 239       |
| current_lr              | 0.0003    |
| discount_q              | 0.0957    |
| env_time                | 519       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2560      |
| eplenmean               | 268       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 637000    |
| q_grad_norm             | 1940.8317 |
| qfs_loss                | 24.103254 |
| qs_abs_difference       | 3         |
| qs_difference           | -2.06     |
| qs_mean                 | 349.8302  |
| time_elapsed            | 29465     |
| total timesteps         | 343410    |
| train_time              | 8843      |
| update_time             | 19577     |
---------------------------------------
---------------------------------------
| act_time                | 240       |
| current_lr              | 0.0003    |
| discount_q              | 0.0594    |
| env_time                | 521       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2564      |
| eplenmean               | 269       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 639200    |
| q_grad_norm             | 2872.691  |
| qfs_loss                | 43.642235 |
| qs_abs_difference       | 19.4      |
| qs_difference           | 19.3      |
| qs_mean                 | 360.21875 |
| time_elapsed            | 29538     |
| total timesteps         | 344570    |
| train_time              | 8865      |
| update_time             | 19625     |
---------------------------------------
---------------------------------------
| act_time                | 241       |
| current_lr              | 0.0003    |
| discount_q              | 0.0544    |
| env_time                | 523       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2568      |
| eplenmean               | 269       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 641400    |
| q_grad_norm             | 2329.684  |
| qfs_loss                | 32.12973  |
| qs_abs_difference       | 31        |
| qs_difference           | 29.7      |
| qs_mean                 | 310.90634 |
| time_elapsed            | 29626     |
| total timesteps         | 345629    |
| train_time              | 8894      |
| update_time             | 19683     |
---------------------------------------
---------------------------------------
| act_time                | 242       |
| current_lr              | 0.0003    |
| discount_q              | 0.0833    |
| env_time                | 524       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2572      |
| eplenmean               | 269       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 643600    |
| q_grad_norm             | 2533.836  |
| qfs_loss                | 35.054726 |
| qs_abs_difference       | 5.07      |
| qs_difference           | 0.688     |
| qs_mean                 | 355.58286 |
| time_elapsed            | 29743     |
| total timesteps         | 346755    |
| train_time              | 8931      |
| update_time             | 19758     |
---------------------------------------
---------------------------------------
| act_time                | 243       |
| current_lr              | 0.0003    |
| discount_q              | 0.0818    |
| env_time                | 526       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2576      |
| eplenmean               | 270       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 645800    |
| q_grad_norm             | 2236.4539 |
| qfs_loss                | 28.582508 |
| qs_abs_difference       | 15.2      |
| qs_difference           | 14.8      |
| qs_mean                 | 362.79483 |
| time_elapsed            | 29862     |
| total timesteps         | 347878    |
| train_time              | 8970      |
| update_time             | 19835     |
---------------------------------------
---------------------------------------
| act_time                | 244       |
| current_lr              | 0.0003    |
| discount_q              | 0.0413    |
| env_time                | 528       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2580      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 648000    |
| q_grad_norm             | 2846.7278 |
| qfs_loss                | 40.607006 |
| qs_abs_difference       | 25.1      |
| qs_difference           | 24        |
| qs_mean                 | 318.10223 |
| time_elapsed            | 29982     |
| total timesteps         | 348991    |
| train_time              | 9009      |
| update_time             | 19913     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.16e+03  |
| eval_abs_qs_difference  | 17.565195 |
| eval_discount_q         | 298       |
| eval_ep_rewmean         | 1.21e+03  |
| eval_eplenmean          | 274       |
| eval_qs                 | 336.74023 |
| eval_qs_difference      | 4.4       |
| eval_time_elapsed       | 6         |
| total timesteps         | 350001    |
---------------------------------------
---------------------------------------
| act_time                | 245       |
| current_lr              | 0.0003    |
| discount_q              | 0.0384    |
| env_time                | 530       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2584      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 650400    |
| q_grad_norm             | 2996.9524 |
| qfs_loss                | 41.043278 |
| qs_abs_difference       | 30        |
| qs_difference           | 29.8      |
| qs_mean                 | 351.62048 |
| time_elapsed            | 30119     |
| total timesteps         | 350153    |
| train_time              | 9052      |
| update_time             | 19996     |
---------------------------------------
---------------------------------------
| act_time                | 246       |
| current_lr              | 0.0003    |
| discount_q              | 0.0366    |
| env_time                | 532       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2588      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 652600    |
| q_grad_norm             | 2094.2585 |
| qfs_loss                | 25.988161 |
| qs_abs_difference       | 201       |
| qs_difference           | 201       |
| qs_mean                 | 407.58044 |
| time_elapsed            | 30237     |
| total timesteps         | 351201    |
| train_time              | 9089      |
| update_time             | 20073     |
---------------------------------------
---------------------------------------
| act_time                | 247       |
| current_lr              | 0.0003    |
| discount_q              | 0.013     |
| env_time                | 534       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2592      |
| eplenmean               | 274       |
| fps                     | 11        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 654800    |
| q_grad_norm             | 2608.0583 |
| qfs_loss                | 37.879177 |
| qs_abs_difference       | 208       |
| qs_difference           | 208       |
| qs_mean                 | 410.87457 |
| time_elapsed            | 30343     |
| total timesteps         | 352353    |
| train_time              | 9123      |
| update_time             | 20141     |
---------------------------------------
---------------------------------------
| act_time                | 248       |
| current_lr              | 0.0003    |
| discount_q              | 0.00863   |
| env_time                | 536       |
| ep_rewmean              | 1.19e+03  |
| episodes                | 2596      |
| eplenmean               | 276       |
| fps                     | 11        |
| mean 100 episode reward | 1.19e+03  |
| n_updates               | 657400    |
| q_grad_norm             | 2840.9575 |
| qfs_loss                | 41.67754  |
| qs_abs_difference       | 11.7      |
| qs_difference           | 6.28      |
| qs_mean                 | 333.74557 |
| time_elapsed            | 30458     |
| total timesteps         | 353657    |
| train_time              | 9159      |
| update_time             | 20216     |
---------------------------------------
---------------------------------------
| act_time                | 249       |
| current_lr              | 0.0003    |
| discount_q              | 0.000727  |
| env_time                | 538       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2600      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 659200    |
| q_grad_norm             | 3114.3564 |
| qfs_loss                | 40.8175   |
| qs_abs_difference       | 300       |
| qs_difference           | 300       |
| qs_mean                 | 303.45853 |
| time_elapsed            | 30537     |
| total timesteps         | 354580    |
| train_time              | 9185      |
| update_time             | 20267     |
---------------------------------------
---------------------------------------
| act_time                | 250       |
| current_lr              | 0.0003    |
| discount_q              | 2.18      |
| env_time                | 539       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2604      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 661000    |
| q_grad_norm             | 2346.5215 |
| qfs_loss                | 37.0363   |
| qs_abs_difference       | 14.7      |
| qs_difference           | 14.3      |
| qs_mean                 | 357.95126 |
| time_elapsed            | 30615     |
| total timesteps         | 355406    |
| train_time              | 9211      |
| update_time             | 20317     |
---------------------------------------
---------------------------------------
| act_time                | 251       |
| current_lr              | 0.0003    |
| discount_q              | 0.0253    |
| env_time                | 541       |
| ep_rewmean              | 1.19e+03  |
| episodes                | 2608      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.19e+03  |
| n_updates               | 663400    |
| q_grad_norm             | 2782.3274 |
| qfs_loss                | 38.16668  |
| qs_abs_difference       | 17.4      |
| qs_difference           | 17.2      |
| qs_mean                 | 348.81985 |
| time_elapsed            | 30718     |
| total timesteps         | 356639    |
| train_time              | 9246      |
| update_time             | 20381     |
---------------------------------------
---------------------------------------
| act_time                | 252       |
| current_lr              | 0.0003    |
| discount_q              | 0.0759    |
| env_time                | 543       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2612      |
| eplenmean               | 280       |
| fps                     | 11        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 665800    |
| q_grad_norm             | 2571.5728 |
| qfs_loss                | 35.262516 |
| qs_abs_difference       | 8.3       |
| qs_difference           | 8.14      |
| qs_mean                 | 367.10266 |
| time_elapsed            | 30823     |
| total timesteps         | 357806    |
| train_time              | 9280      |
| update_time             | 20449     |
---------------------------------------
---------------------------------------
| act_time                | 252       |
| current_lr              | 0.0003    |
| discount_q              | 0.748     |
| env_time                | 543       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2616      |
| eplenmean               | 270       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 666200    |
| q_grad_norm             | 2257.4204 |
| qfs_loss                | 32.089375 |
| qs_abs_difference       | 319       |
| qs_difference           | 319       |
| qs_mean                 | 324.49298 |
| time_elapsed            | 30841     |
| total timesteps         | 358068    |
| train_time              | 9287      |
| update_time             | 20460     |
---------------------------------------
---------------------------------------
| act_time                | 253       |
| current_lr              | 0.0003    |
| discount_q              | 0.147     |
| env_time                | 545       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2620      |
| eplenmean               | 269       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 668400    |
| q_grad_norm             | 2444.1091 |
| qfs_loss                | 41.9926   |
| qs_abs_difference       | 7.07      |
| qs_difference           | 5.82      |
| qs_mean                 | 365.01425 |
| time_elapsed            | 30937     |
| total timesteps         | 359158    |
| train_time              | 9321      |
| update_time             | 20519     |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 1.21e+03 |
| eval_abs_qs_difference  | 9.989753 |
| eval_discount_q         | 304      |
| eval_ep_rewmean         | 1.6e+03  |
| eval_eplenmean          | 353      |
| eval_qs                 | 362.1365 |
| eval_qs_difference      | -6.01    |
| eval_time_elapsed       | 6        |
| total timesteps         | 360001   |
--------------------------------------
---------------------------------------
| act_time                | 254       |
| current_lr              | 0.0003    |
| discount_q              | 0.0294    |
| env_time                | 547       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2624      |
| eplenmean               | 268       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 670600    |
| q_grad_norm             | 3059.8926 |
| qfs_loss                | 40.181564 |
| qs_abs_difference       | 163       |
| qs_difference           | 163       |
| qs_mean                 | 414.8989  |
| time_elapsed            | 31037     |
| total timesteps         | 360292    |
| train_time              | 9350      |
| update_time             | 20580     |
---------------------------------------
---------------------------------------
| act_time                | 255       |
| current_lr              | 0.0003    |
| discount_q              | 0.132     |
| env_time                | 548       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2628      |
| eplenmean               | 267       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 672800    |
| q_grad_norm             | 3066.1006 |
| qfs_loss                | 44.313377 |
| qs_abs_difference       | 134       |
| qs_difference           | 134       |
| qs_mean                 | 412.72366 |
| time_elapsed            | 31123     |
| total timesteps         | 361306    |
| train_time              | 9377      |
| update_time             | 20637     |
---------------------------------------
--------------------------------------
| act_time                | 255      |
| current_lr              | 0.0003   |
| discount_q              | 0.189    |
| env_time                | 549      |
| ep_rewmean              | 1.15e+03 |
| episodes                | 2632     |
| eplenmean               | 267      |
| fps                     | 11       |
| mean 100 episode reward | 1.15e+03 |
| n_updates               | 674600   |
| q_grad_norm             | 2901.613 |
| qfs_loss                | 44.43568 |
| qs_abs_difference       | 49.7     |
| qs_difference           | 49.6     |
| qs_mean                 | 351.0258 |
| time_elapsed            | 31193    |
| total timesteps         | 362287   |
| train_time              | 9398     |
| update_time             | 20683    |
--------------------------------------
---------------------------------------
| act_time                | 256       |
| current_lr              | 0.0003    |
| discount_q              | 0.0781    |
| env_time                | 551       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2636      |
| eplenmean               | 267       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 676800    |
| q_grad_norm             | 3775.0793 |
| qfs_loss                | 55.27782  |
| qs_abs_difference       | 15.8      |
| qs_difference           | 15.1      |
| qs_mean                 | 335.4167  |
| time_elapsed            | 31278     |
| total timesteps         | 363374    |
| train_time              | 9425      |
| update_time             | 20739     |
---------------------------------------
---------------------------------------
| act_time                | 257       |
| current_lr              | 0.0003    |
| discount_q              | 0.0423    |
| env_time                | 552       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2640      |
| eplenmean               | 266       |
| fps                     | 11        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 679000    |
| q_grad_norm             | 3045.7446 |
| qfs_loss                | 43.48682  |
| qs_abs_difference       | 132       |
| qs_difference           | 132       |
| qs_mean                 | 414.155   |
| time_elapsed            | 31365     |
| total timesteps         | 364499    |
| train_time              | 9452      |
| update_time             | 20796     |
---------------------------------------
---------------------------------------
| act_time                | 258       |
| current_lr              | 0.0003    |
| discount_q              | 0.0387    |
| env_time                | 554       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2644      |
| eplenmean               | 267       |
| fps                     | 11        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 681600    |
| q_grad_norm             | 4271.2495 |
| qfs_loss                | 64.92669  |
| qs_abs_difference       | 8         |
| qs_difference           | 6.97      |
| qs_mean                 | 365.08228 |
| time_elapsed            | 31466     |
| total timesteps         | 365712    |
| train_time              | 9483      |
| update_time             | 20864     |
---------------------------------------
---------------------------------------
| act_time                | 258       |
| current_lr              | 0.0003    |
| discount_q              | 0.0195    |
| env_time                | 555       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2648      |
| eplenmean               | 269       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 684000    |
| q_grad_norm             | 3150.959  |
| qfs_loss                | 40.75467  |
| qs_abs_difference       | 18.5      |
| qs_difference           | 18.5      |
| qs_mean                 | 365.03854 |
| time_elapsed            | 31561     |
| total timesteps         | 366974    |
| train_time              | 9512      |
| update_time             | 20926     |
---------------------------------------
---------------------------------------
| act_time                | 259       |
| current_lr              | 0.0003    |
| discount_q              | 0.0347    |
| env_time                | 557       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2652      |
| eplenmean               | 271       |
| fps                     | 11        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 686600    |
| q_grad_norm             | 3457.989  |
| qfs_loss                | 55.281197 |
| qs_abs_difference       | 12.5      |
| qs_difference           | 10.9      |
| qs_mean                 | 368.22513 |
| time_elapsed            | 31662     |
| total timesteps         | 368234    |
| train_time              | 9544      |
| update_time             | 20993     |
---------------------------------------
---------------------------------------
| act_time                | 260       |
| current_lr              | 0.0003    |
| discount_q              | 0.0112    |
| env_time                | 559       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2656      |
| eplenmean               | 273       |
| fps                     | 11        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 689200    |
| q_grad_norm             | 4042.4795 |
| qfs_loss                | 61.69597  |
| qs_abs_difference       | 21.2      |
| qs_difference           | 20.4      |
| qs_mean                 | 358.2448  |
| time_elapsed            | 31764     |
| total timesteps         | 369551    |
| train_time              | 9576      |
| update_time             | 21059     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.27e+03  |
| eval_abs_qs_difference  | 12.967816 |
| eval_discount_q         | 304       |
| eval_ep_rewmean         | 1.51e+03  |
| eval_eplenmean          | 341       |
| eval_qs                 | 358.91022 |
| eval_qs_difference      | 3.41      |
| eval_time_elapsed       | 6         |
| total timesteps         | 370001    |
---------------------------------------
---------------------------------------
| act_time                | 261       |
| current_lr              | 0.0003    |
| discount_q              | 0.00751   |
| env_time                | 560       |
| ep_rewmean              | 1.19e+03  |
| episodes                | 2660      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.19e+03  |
| n_updates               | 692000    |
| q_grad_norm             | 4200.9883 |
| qfs_loss                | 59.12501  |
| qs_abs_difference       | 37.5      |
| qs_difference           | 37.4      |
| qs_mean                 | 367.23734 |
| time_elapsed            | 31880     |
| total timesteps         | 370914    |
| train_time              | 9610      |
| update_time             | 21132     |
---------------------------------------
---------------------------------------
| act_time                | 262       |
| current_lr              | 0.0003    |
| discount_q              | 0.0405    |
| env_time                | 562       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2664      |
| eplenmean               | 275       |
| fps                     | 11        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 694200    |
| q_grad_norm             | 3568.0125 |
| qfs_loss                | 52.587894 |
| qs_abs_difference       | 32.7      |
| qs_difference           | 31.5      |
| qs_mean                 | 352.76413 |
| time_elapsed            | 31966     |
| total timesteps         | 372088    |
| train_time              | 9637      |
| update_time             | 21188     |
---------------------------------------
---------------------------------------
| act_time                | 263       |
| current_lr              | 0.0003    |
| discount_q              | 0.0218    |
| env_time                | 564       |
| ep_rewmean              | 1.19e+03  |
| episodes                | 2668      |
| eplenmean               | 277       |
| fps                     | 11        |
| mean 100 episode reward | 1.19e+03  |
| n_updates               | 696800    |
| q_grad_norm             | 4226.175  |
| qfs_loss                | 54.138527 |
| qs_abs_difference       | 13.8      |
| qs_difference           | 13.4      |
| qs_mean                 | 356.46976 |
| time_elapsed            | 32068     |
| total timesteps         | 373342    |
| train_time              | 9669      |
| update_time             | 21255     |
---------------------------------------
---------------------------------------
| act_time                | 264       |
| current_lr              | 0.0003    |
| discount_q              | 0.0118    |
| env_time                | 565       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2672      |
| eplenmean               | 279       |
| fps                     | 11        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 699400    |
| q_grad_norm             | 3969.11   |
| qfs_loss                | 56.092995 |
| qs_abs_difference       | 11.7      |
| qs_difference           | 11.1      |
| qs_mean                 | 368.16614 |
| time_elapsed            | 32171     |
| total timesteps         | 374683    |
| train_time              | 9701      |
| update_time             | 21323     |
---------------------------------------
---------------------------------------
| act_time                | 264       |
| current_lr              | 0.0003    |
| discount_q              | 0.0163    |
| env_time                | 567       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2676      |
| eplenmean               | 281       |
| fps                     | 11        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 702000    |
| q_grad_norm             | 4493.762  |
| qfs_loss                | 76.48769  |
| qs_abs_difference       | 14.5      |
| qs_difference           | 11.5      |
| qs_mean                 | 348.25305 |
| time_elapsed            | 32272     |
| total timesteps         | 375942    |
| train_time              | 9733      |
| update_time             | 21390     |
---------------------------------------
---------------------------------------
| act_time                | 265       |
| current_lr              | 0.0003    |
| discount_q              | 0.0126    |
| env_time                | 569       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 2680      |
| eplenmean               | 283       |
| fps                     | 11        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 704600    |
| q_grad_norm             | 3865.0088 |
| qfs_loss                | 59.27153  |
| qs_abs_difference       | 11.1      |
| qs_difference           | 9.23      |
| qs_mean                 | 364.01074 |
| time_elapsed            | 32375     |
| total timesteps         | 377288    |
| train_time              | 9765      |
| update_time             | 21457     |
---------------------------------------
---------------------------------------
| act_time                | 266       |
| current_lr              | 0.0003    |
| discount_q              | 0.265     |
| env_time                | 570       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2684      |
| eplenmean               | 281       |
| fps                     | 11        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 706600    |
| q_grad_norm             | 2852.6196 |
| qfs_loss                | 32.708355 |
| qs_abs_difference       | 6.04      |
| qs_difference           | 4.17      |
| qs_mean                 | 355.12888 |
| time_elapsed            | 32454     |
| total timesteps         | 378288    |
| train_time              | 9790      |
| update_time             | 21509     |
---------------------------------------
---------------------------------------
| act_time                | 267       |
| current_lr              | 0.0003    |
| discount_q              | 0.0349    |
| env_time                | 571       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2688      |
| eplenmean               | 282       |
| fps                     | 11        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 709000    |
| q_grad_norm             | 2680.1853 |
| qfs_loss                | 31.129654 |
| qs_abs_difference       | 33.3      |
| qs_difference           | 29.2      |
| qs_mean                 | 323.4665  |
| time_elapsed            | 32546     |
| total timesteps         | 379424    |
| train_time              | 9818      |
| update_time             | 21570     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.27e+03  |
| eval_abs_qs_difference  | 24.849041 |
| eval_discount_q         | 286       |
| eval_ep_rewmean         | 1.16e+03  |
| eval_eplenmean          | 277       |
| eval_qs                 | 325.56137 |
| eval_qs_difference      | 9.36      |
| eval_time_elapsed       | 5         |
| total timesteps         | 380001    |
---------------------------------------
---------------------------------------
| act_time                | 267       |
| current_lr              | 0.0003    |
| discount_q              | 0.0499    |
| env_time                | 573       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 2692      |
| eplenmean               | 283       |
| fps                     | 11        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 711400    |
| q_grad_norm             | 2603.4602 |
| qfs_loss                | 37.801    |
| qs_abs_difference       | 23        |
| qs_difference           | 22.4      |
| qs_mean                 | 372.80222 |
| time_elapsed            | 32645     |
| total timesteps         | 380697    |
| train_time              | 9847      |
| update_time             | 21632     |
---------------------------------------
---------------------------------------
| act_time                | 268       |
| current_lr              | 0.0003    |
| discount_q              | 0.174     |
| env_time                | 574       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2696      |
| eplenmean               | 281       |
| fps                     | 11        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 713600    |
| q_grad_norm             | 3564.4712 |
| qfs_loss                | 44.38888  |
| qs_abs_difference       | 4.04      |
| qs_difference           | 0.955     |
| qs_mean                 | 364.4768  |
| time_elapsed            | 32731     |
| total timesteps         | 381770    |
| train_time              | 9874      |
| update_time             | 21688     |
---------------------------------------
---------------------------------------
| act_time                | 269       |
| current_lr              | 0.0003    |
| discount_q              | 0.0315    |
| env_time                | 576       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 2700      |
| eplenmean               | 284       |
| fps                     | 11        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 716000    |
| q_grad_norm             | 3560.2078 |
| qfs_loss                | 59.59264  |
| qs_abs_difference       | 22.8      |
| qs_difference           | 22.6      |
| qs_mean                 | 340.35974 |
| time_elapsed            | 32825     |
| total timesteps         | 382945    |
| train_time              | 9904      |
| update_time             | 21751     |
---------------------------------------
---------------------------------------
| act_time                | 270       |
| current_lr              | 0.0003    |
| discount_q              | 0.00861   |
| env_time                | 577       |
| ep_rewmean              | 1.23e+03  |
| episodes                | 2704      |
| eplenmean               | 287       |
| fps                     | 11        |
| mean 100 episode reward | 1.23e+03  |
| n_updates               | 718200    |
| q_grad_norm             | 3330.5068 |
| qfs_loss                | 47.5127   |
| qs_abs_difference       | 253       |
| qs_difference           | 253       |
| qs_mean                 | 398.1107  |
| time_elapsed            | 32911     |
| total timesteps         | 384066    |
| train_time              | 9930      |
| update_time             | 21807     |
---------------------------------------
---------------------------------------
| act_time                | 271       |
| current_lr              | 0.0003    |
| discount_q              | 0.039     |
| env_time                | 579       |
| ep_rewmean              | 1.23e+03  |
| episodes                | 2708      |
| eplenmean               | 286       |
| fps                     | 11        |
| mean 100 episode reward | 1.23e+03  |
| n_updates               | 720600    |
| q_grad_norm             | 3911.7207 |
| qfs_loss                | 60.622738 |
| qs_abs_difference       | 8.89      |
| qs_difference           | 6         |
| qs_mean                 | 360.8338  |
| time_elapsed            | 33005     |
| total timesteps         | 385270    |
| train_time              | 9960      |
| update_time             | 21868     |
---------------------------------------
---------------------------------------
| act_time                | 271       |
| current_lr              | 0.0003    |
| discount_q              | 0.0925    |
| env_time                | 580       |
| ep_rewmean              | 1.23e+03  |
| episodes                | 2712      |
| eplenmean               | 286       |
| fps                     | 11        |
| mean 100 episode reward | 1.23e+03  |
| n_updates               | 722800    |
| q_grad_norm             | 4286.5034 |
| qfs_loss                | 49.871895 |
| qs_abs_difference       | 18.8      |
| qs_difference           | 18.2      |
| qs_mean                 | 352.83752 |
| time_elapsed            | 33090     |
| total timesteps         | 386365    |
| train_time              | 9987      |
| update_time             | 21925     |
---------------------------------------
---------------------------------------
| act_time                | 272       |
| current_lr              | 0.0003    |
| discount_q              | 0.209     |
| env_time                | 582       |
| ep_rewmean              | 1.26e+03  |
| episodes                | 2716      |
| eplenmean               | 293       |
| fps                     | 11        |
| mean 100 episode reward | 1.26e+03  |
| n_updates               | 724800    |
| q_grad_norm             | 3437.5378 |
| qfs_loss                | 38.734062 |
| qs_abs_difference       | 9.76      |
| qs_difference           | 1.4       |
| qs_mean                 | 349.3382  |
| time_elapsed            | 33169     |
| total timesteps         | 387395    |
| train_time              | 10011     |
| update_time             | 21976     |
---------------------------------------
---------------------------------------
| act_time                | 273       |
| current_lr              | 0.0003    |
| discount_q              | 0.0254    |
| env_time                | 583       |
| ep_rewmean              | 1.27e+03  |
| episodes                | 2720      |
| eplenmean               | 295       |
| fps                     | 11        |
| mean 100 episode reward | 1.27e+03  |
| n_updates               | 727400    |
| q_grad_norm             | 3803.7156 |
| qfs_loss                | 46.268013 |
| qs_abs_difference       | 5.15      |
| qs_difference           | 2.66      |
| qs_mean                 | 351.4723  |
| time_elapsed            | 33269     |
| total timesteps         | 388619    |
| train_time              | 10043     |
| update_time             | 22043     |
---------------------------------------
---------------------------------------
| act_time                | 273       |
| current_lr              | 0.0003    |
| discount_q              | 0.148     |
| env_time                | 584       |
| ep_rewmean              | 1.26e+03  |
| episodes                | 2724      |
| eplenmean               | 293       |
| fps                     | 11        |
| mean 100 episode reward | 1.26e+03  |
| n_updates               | 729400    |
| q_grad_norm             | 3126.3643 |
| qfs_loss                | 35.31367  |
| qs_abs_difference       | 30.3      |
| qs_difference           | 26.9      |
| qs_mean                 | 310.95462 |
| time_elapsed            | 33348     |
| total timesteps         | 389600    |
| train_time              | 10067     |
| update_time             | 22095     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.28e+03  |
| eval_abs_qs_difference  | 17.351524 |
| eval_discount_q         | 298       |
| eval_ep_rewmean         | 1.19e+03  |
| eval_eplenmean          | 272       |
| eval_qs                 | 338.43387 |
| eval_qs_difference      | 11.6      |
| eval_time_elapsed       | 5         |
| total timesteps         | 390001    |
---------------------------------------
---------------------------------------
| act_time                | 274       |
| current_lr              | 0.0003    |
| discount_q              | 0.134     |
| env_time                | 586       |
| ep_rewmean              | 1.27e+03  |
| episodes                | 2728      |
| eplenmean               | 294       |
| fps                     | 11        |
| mean 100 episode reward | 1.27e+03  |
| n_updates               | 731400    |
| q_grad_norm             | 3331.2732 |
| qfs_loss                | 36.715145 |
| qs_abs_difference       | 7.97      |
| qs_difference           | 6.89      |
| qs_mean                 | 360.00687 |
| time_elapsed            | 33432     |
| total timesteps         | 390681    |
| train_time              | 10091     |
| update_time             | 22147     |
---------------------------------------
---------------------------------------
| act_time                | 275       |
| current_lr              | 0.0003    |
| discount_q              | 0.0655    |
| env_time                | 587       |
| ep_rewmean              | 1.28e+03  |
| episodes                | 2732      |
| eplenmean               | 295       |
| fps                     | 11        |
| mean 100 episode reward | 1.28e+03  |
| n_updates               | 733800    |
| q_grad_norm             | 2733.6052 |
| qfs_loss                | 32.391605 |
| qs_abs_difference       | 4.04      |
| qs_difference           | 1.53      |
| qs_mean                 | 357.50607 |
| time_elapsed            | 33524     |
| total timesteps         | 391829    |
| train_time              | 10120     |
| update_time             | 22208     |
---------------------------------------
---------------------------------------
| act_time                | 276       |
| current_lr              | 0.0003    |
| discount_q              | 0.0283    |
| env_time                | 589       |
| ep_rewmean              | 1.29e+03  |
| episodes                | 2736      |
| eplenmean               | 297       |
| fps                     | 11        |
| mean 100 episode reward | 1.29e+03  |
| n_updates               | 736200    |
| q_grad_norm             | 3260.845  |
| qfs_loss                | 42.85107  |
| qs_abs_difference       | 14.4      |
| qs_difference           | 11.4      |
| qs_mean                 | 355.41534 |
| time_elapsed            | 33614     |
| total timesteps         | 393047    |
| train_time              | 10148     |
| update_time             | 22267     |
---------------------------------------
---------------------------------------
| act_time                | 276       |
| current_lr              | 0.0003    |
| discount_q              | 0.0488    |
| env_time                | 590       |
| ep_rewmean              | 1.29e+03  |
| episodes                | 2740      |
| eplenmean               | 297       |
| fps                     | 11        |
| mean 100 episode reward | 1.29e+03  |
| n_updates               | 738400    |
| q_grad_norm             | 4388.1587 |
| qfs_loss                | 53.859337 |
| qs_abs_difference       | 16.4      |
| qs_difference           | 13        |
| qs_mean                 | 331.01044 |
| time_elapsed            | 33698     |
| total timesteps         | 394169    |
| train_time              | 10174     |
| update_time             | 22322     |
---------------------------------------
---------------------------------------
| act_time                | 277       |
| current_lr              | 0.0003    |
| discount_q              | 0.0637    |
| env_time                | 592       |
| ep_rewmean              | 1.28e+03  |
| episodes                | 2744      |
| eplenmean               | 296       |
| fps                     | 11        |
| mean 100 episode reward | 1.28e+03  |
| n_updates               | 740600    |
| q_grad_norm             | 5602.541  |
| qfs_loss                | 73.623955 |
| qs_abs_difference       | 24.4      |
| qs_difference           | 22.6      |
| qs_mean                 | 348.7813  |
| time_elapsed            | 33781     |
| total timesteps         | 395280    |
| train_time              | 10200     |
| update_time             | 22377     |
---------------------------------------
---------------------------------------
| act_time                | 278       |
| current_lr              | 0.0003    |
| discount_q              | 0.0838    |
| env_time                | 593       |
| ep_rewmean              | 1.28e+03  |
| episodes                | 2748      |
| eplenmean               | 294       |
| fps                     | 11        |
| mean 100 episode reward | 1.28e+03  |
| n_updates               | 742800    |
| q_grad_norm             | 3213.2563 |
| qfs_loss                | 35.824066 |
| qs_abs_difference       | 7.55      |
| qs_difference           | -6.43     |
| qs_mean                 | 350.47    |
| time_elapsed            | 33865     |
| total timesteps         | 396397    |
| train_time              | 10226     |
| update_time             | 22432     |
---------------------------------------
--------------------------------------
| act_time                | 279      |
| current_lr              | 0.0003   |
| discount_q              | 0.077    |
| env_time                | 594      |
| ep_rewmean              | 1.27e+03 |
| episodes                | 2752     |
| eplenmean               | 293      |
| fps                     | 11       |
| mean 100 episode reward | 1.27e+03 |
| n_updates               | 745000   |
| q_grad_norm             | 4045.782 |
| qfs_loss                | 54.97363 |
| qs_abs_difference       | 22.7     |
| qs_difference           | 21.8     |
| qs_mean                 | 348.5421 |
| time_elapsed            | 33948    |
| total timesteps         | 397491   |
| train_time              | 10252    |
| update_time             | 22487    |
--------------------------------------
---------------------------------------
| act_time                | 279       |
| current_lr              | 0.0003    |
| discount_q              | 0.0838    |
| env_time                | 596       |
| ep_rewmean              | 1.26e+03  |
| episodes                | 2756      |
| eplenmean               | 290       |
| fps                     | 11        |
| mean 100 episode reward | 1.26e+03  |
| n_updates               | 747200    |
| q_grad_norm             | 3549.3562 |
| qfs_loss                | 43.225143 |
| qs_abs_difference       | 10.2      |
| qs_difference           | 7.5       |
| qs_mean                 | 337.28613 |
| time_elapsed            | 34031     |
| total timesteps         | 398573    |
| train_time              | 10278     |
| update_time             | 22542     |
---------------------------------------
---------------------------------------
| act_time                | 280       |
| current_lr              | 0.0003    |
| discount_q              | 0.0668    |
| env_time                | 597       |
| ep_rewmean              | 1.25e+03  |
| episodes                | 2760      |
| eplenmean               | 287       |
| fps                     | 11        |
| mean 100 episode reward | 1.25e+03  |
| n_updates               | 749400    |
| q_grad_norm             | 3633.238  |
| qfs_loss                | 48.556896 |
| qs_abs_difference       | 18.4      |
| qs_difference           | 13.3      |
| qs_mean                 | 313.79257 |
| time_elapsed            | 34115     |
| total timesteps         | 399635    |
| train_time              | 10304     |
| update_time             | 22597     |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 1.32e+03 |
| eval_abs_qs_difference  | 45.37227 |
| eval_discount_q         | 288      |
| eval_ep_rewmean         | 1.41e+03 |
| eval_eplenmean          | 316      |
| eval_qs                 | 367.5817 |
| eval_qs_difference      | 35.8     |
| eval_time_elapsed       | 5        |
| total timesteps         | 400001   |
--------------------------------------
total runtime: 34156.82078766823s
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 2, 'comment': 'hopper_gem+tbp_2', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_2
max_step:  1000
Box(-inf, inf, (11,), float64) Box(-1.0, 1.0, (3,), float32)
max_step:  1000
seed=2, logdir=./log_gem/mujoco/gem+tbp/hopper_gem+tbp_2
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/run/train.py:30: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-05-05 08:58:07.270871: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-05-05 08:58:07.304438: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz
2022-05-05 08:58:07.305018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e475217960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-05-05 08:58:07.305060: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:98: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/policies.py:283: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:138: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:203: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:226: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:251: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:261: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:264: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

GEM Agent Here
TD3 Update Memory Many Agent here
here (?, 1)
model building finished
----------------------------------------
| eval mean 100 episod... | 0.6        |
| eval_abs_qs_difference  | 0.6570774  |
| eval_discount_q         | 0.857      |
| eval_ep_rewmean         | 0.66       |
| eval_eplenmean          | 11         |
| eval_qs                 | -1.7786884 |
| eval_qs_difference      | -0.0655    |
| eval_time_elapsed       | 0          |
| total timesteps         | 1          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.09        |
| env_time                | 0           |
| ep_rewmean              | 19.9        |
| episodes                | 4           |
| eplenmean               | 25.5        |
| fps                     | 67          |
| mean 100 episode reward | 19.9        |
| n_updates               | 0           |
| qs_abs_difference       | 7.09        |
| qs_difference           | -7.09       |
| qs_mean                 | -0.33948937 |
| time_elapsed            | 1           |
| total timesteps         | 102         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.91        |
| env_time                | 0           |
| ep_rewmean              | 16.7        |
| episodes                | 8           |
| eplenmean               | 24.1        |
| fps                     | 113         |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.27        |
| qs_difference           | -1.59       |
| qs_mean                 | -0.19599035 |
| time_elapsed            | 1           |
| total timesteps         | 193         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 19.7        |
| env_time                | 0           |
| ep_rewmean              | 17.1        |
| episodes                | 12          |
| eplenmean               | 23.5        |
| fps                     | 149         |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 17.5        |
| qs_difference           | -17.5       |
| qs_mean                 | -0.08957527 |
| time_elapsed            | 1           |
| total timesteps         | 282         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 1.7         |
| env_time                | 0           |
| ep_rewmean              | 22.4        |
| episodes                | 16          |
| eplenmean               | 25.1        |
| fps                     | 184         |
| mean 100 episode reward | 22.4        |
| n_updates               | 0           |
| qs_abs_difference       | 2.4         |
| qs_difference           | -2.4        |
| qs_mean                 | -0.22117904 |
| time_elapsed            | 2           |
| total timesteps         | 402         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.98        |
| env_time                | 0           |
| ep_rewmean              | 20.9        |
| episodes                | 20          |
| eplenmean               | 23.6        |
| fps                     | 205         |
| mean 100 episode reward | 20.9        |
| n_updates               | 0           |
| qs_abs_difference       | 7.93        |
| qs_difference           | -7.93       |
| qs_mean                 | 0.027118333 |
| time_elapsed            | 2           |
| total timesteps         | 472         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.54        |
| env_time                | 1           |
| ep_rewmean              | 19.3        |
| episodes                | 24          |
| eplenmean               | 22.2        |
| fps                     | 215         |
| mean 100 episode reward | 19.3        |
| n_updates               | 0           |
| qs_abs_difference       | 3.16        |
| qs_difference           | -3.06       |
| qs_mean                 | -0.06632346 |
| time_elapsed            | 2           |
| total timesteps         | 533         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 2.81       |
| env_time                | 1          |
| ep_rewmean              | 19.9       |
| episodes                | 28         |
| eplenmean               | 23.8       |
| fps                     | 239        |
| mean 100 episode reward | 19.9       |
| n_updates               | 0          |
| qs_abs_difference       | 4.33       |
| qs_difference           | -4.33      |
| qs_mean                 | 0.13351348 |
| time_elapsed            | 2          |
| total timesteps         | 665        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.78       |
| env_time                | 1          |
| ep_rewmean              | 20.1       |
| episodes                | 32         |
| eplenmean               | 24.7       |
| fps                     | 252        |
| mean 100 episode reward | 20.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.91       |
| qs_difference           | -5.91      |
| qs_mean                 | -0.2239483 |
| time_elapsed            | 3          |
| total timesteps         | 789        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 9.11        |
| env_time                | 1           |
| ep_rewmean              | 18.9        |
| episodes                | 36          |
| eplenmean               | 23.5        |
| fps                     | 255         |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 4.48        |
| qs_difference           | -4.26       |
| qs_mean                 | -0.15032373 |
| time_elapsed            | 3           |
| total timesteps         | 847         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.63       |
| env_time                | 1          |
| ep_rewmean              | 18.5       |
| episodes                | 40         |
| eplenmean               | 23.3       |
| fps                     | 260        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.68       |
| qs_difference           | -3.68      |
| qs_mean                 | 0.16867211 |
| time_elapsed            | 3          |
| total timesteps         | 931        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.23       |
| env_time                | 1          |
| ep_rewmean              | 18.2       |
| episodes                | 44         |
| eplenmean               | 23.2       |
| fps                     | 264        |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 7.41       |
| qs_difference           | -7.41      |
| qs_mean                 | -0.4508137 |
| time_elapsed            | 3          |
| total timesteps         | 1019       |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.57       |
| env_time                | 1          |
| ep_rewmean              | 18.5       |
| episodes                | 48         |
| eplenmean               | 23         |
| fps                     | 265        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.86       |
| qs_difference           | -3.82      |
| qs_mean                 | 0.06769688 |
| time_elapsed            | 4          |
| total timesteps         | 1104       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 6.94         |
| env_time                | 1            |
| ep_rewmean              | 19.2         |
| episodes                | 52           |
| eplenmean               | 23.2         |
| fps                     | 269          |
| mean 100 episode reward | 19.2         |
| n_updates               | 0            |
| qs_abs_difference       | 9.65         |
| qs_difference           | -9.65        |
| qs_mean                 | 0.0019248091 |
| time_elapsed            | 4            |
| total timesteps         | 1209         |
| train_time              | 0            |
| update_time             | 1            |
------------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 8.21         |
| env_time                | 1            |
| ep_rewmean              | 19           |
| episodes                | 56           |
| eplenmean               | 23           |
| fps                     | 277          |
| mean 100 episode reward | 19           |
| n_updates               | 0            |
| qs_abs_difference       | 8.17         |
| qs_difference           | -8.17        |
| qs_mean                 | -0.053583708 |
| time_elapsed            | 4            |
| total timesteps         | 1287         |
| train_time              | 0            |
| update_time             | 1            |
------------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.02        |
| env_time                | 2           |
| ep_rewmean              | 18.8        |
| episodes                | 60          |
| eplenmean               | 22.9        |
| fps                     | 276         |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.45        |
| qs_difference           | -5.45       |
| qs_mean                 | -0.12921941 |
| time_elapsed            | 4           |
| total timesteps         | 1371        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 18.5        |
| env_time                | 2           |
| ep_rewmean              | 19          |
| episodes                | 64          |
| eplenmean               | 23          |
| fps                     | 277         |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 19.9        |
| qs_difference           | -19.9       |
| qs_mean                 | -0.24439304 |
| time_elapsed            | 5           |
| total timesteps         | 1474        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 10.2       |
| env_time                | 2          |
| ep_rewmean              | 20.1       |
| episodes                | 68         |
| eplenmean               | 23.5       |
| fps                     | 281        |
| mean 100 episode reward | 20.1       |
| n_updates               | 0          |
| qs_abs_difference       | 13.8       |
| qs_difference           | -13.8      |
| qs_mean                 | -0.4631601 |
| time_elapsed            | 5          |
| total timesteps         | 1599       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 10.5        |
| env_time                | 2           |
| ep_rewmean              | 19.7        |
| episodes                | 72          |
| eplenmean               | 23.1        |
| fps                     | 279         |
| mean 100 episode reward | 19.7        |
| n_updates               | 0           |
| qs_abs_difference       | 8.77        |
| qs_difference           | -8.77       |
| qs_mean                 | -0.36475757 |
| time_elapsed            | 5           |
| total timesteps         | 1665        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.01       |
| env_time                | 2          |
| ep_rewmean              | 19.5       |
| episodes                | 76         |
| eplenmean               | 22.8       |
| fps                     | 275        |
| mean 100 episode reward | 19.5       |
| n_updates               | 0          |
| qs_abs_difference       | 2.54       |
| qs_difference           | -2.23      |
| qs_mean                 | 0.10099222 |
| time_elapsed            | 6          |
| total timesteps         | 1732       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 12.1        |
| env_time                | 2           |
| ep_rewmean              | 20.1        |
| episodes                | 80          |
| eplenmean               | 23          |
| fps                     | 274         |
| mean 100 episode reward | 20.1        |
| n_updates               | 0           |
| qs_abs_difference       | 16.1        |
| qs_difference           | -16.1       |
| qs_mean                 | -0.31523436 |
| time_elapsed            | 6           |
| total timesteps         | 1843        |
| train_time              | 0           |
| update_time             | 2           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.83        |
| env_time                | 2           |
| ep_rewmean              | 20          |
| episodes                | 84          |
| eplenmean               | 23.1        |
| fps                     | 272         |
| mean 100 episode reward | 20          |
| n_updates               | 0           |
| qs_abs_difference       | 6.05        |
| qs_difference           | -6.05       |
| qs_mean                 | -0.39183426 |
| time_elapsed            | 7           |
| total timesteps         | 1938        |
| train_time              | 0           |
| update_time             | 2           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.89       |
| env_time                | 2          |
| ep_rewmean              | 19.8       |
| episodes                | 88         |
| eplenmean               | 22.9       |
| fps                     | 268        |
| mean 100 episode reward | 19.8       |
| n_updates               | 0          |
| qs_abs_difference       | 5.7        |
| qs_difference           | -5.7       |
| qs_mean                 | -0.1063331 |
| time_elapsed            | 7          |
| total timesteps         | 2016       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 9.36        |
| env_time                | 2           |
| ep_rewmean              | 19.7        |
| episodes                | 92          |
| eplenmean               | 23          |
| fps                     | 264         |
| mean 100 episode reward | 19.7        |
| n_updates               | 0           |
| qs_abs_difference       | 10.6        |
| qs_difference           | -10.6       |
| qs_mean                 | -0.08354911 |
| time_elapsed            | 7           |
| total timesteps         | 2112        |
| train_time              | 0           |
| update_time             | 3           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.18       |
| env_time                | 3          |
| ep_rewmean              | 19.6       |
| episodes                | 96         |
| eplenmean               | 22.9       |
| fps                     | 270        |
| mean 100 episode reward | 19.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.51       |
| qs_difference           | -4.51      |
| qs_mean                 | 0.18727502 |
| time_elapsed            | 8          |
| total timesteps         | 2196       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.1         |
| env_time                | 3           |
| ep_rewmean              | 19.5        |
| episodes                | 100         |
| eplenmean               | 22.7        |
| fps                     | 266         |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 4.41        |
| qs_difference           | -4.41       |
| qs_mean                 | -0.34069213 |
| time_elapsed            | 8           |
| total timesteps         | 2274        |
| train_time              | 0           |
| update_time             | 3           |
-----------------------------------------
--------------------------------------
| act_time                | 0        |
| current_lr              | 0.0003   |
| discount_q              | 6.94     |
| env_time                | 3        |
| ep_rewmean              | 19.3     |
| episodes                | 104      |
| eplenmean               | 22.5     |
| fps                     | 262      |
| mean 100 episode reward | 19.3     |
| n_updates               | 0        |
| qs_abs_difference       | 7.27     |
| qs_difference           | -7.27    |
| qs_mean                 | 0.064669 |
| time_elapsed            | 8        |
| total timesteps         | 2356     |
| train_time              | 0        |
| update_time             | 3        |
--------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.91       |
| env_time                | 3          |
| ep_rewmean              | 19.2       |
| episodes                | 108        |
| eplenmean               | 22.3       |
| fps                     | 258        |
| mean 100 episode reward | 19.2       |
| n_updates               | 0          |
| qs_abs_difference       | 3.04       |
| qs_difference           | -2.9       |
| qs_mean                 | -0.0440803 |
| time_elapsed            | 9          |
| total timesteps         | 2424       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 19.4       |
| env_time                | 3          |
| ep_rewmean              | 19.3       |
| episodes                | 112        |
| eplenmean               | 22.6       |
| fps                     | 255        |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 14.3       |
| qs_difference           | -13.3      |
| qs_mean                 | -0.1590139 |
| time_elapsed            | 9          |
| total timesteps         | 2543       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 11.7        |
| env_time                | 3           |
| ep_rewmean              | 18.3        |
| episodes                | 116         |
| eplenmean               | 22.2        |
| fps                     | 252         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 7.84        |
| qs_difference           | -7.84       |
| qs_mean                 | -0.13553943 |
| time_elapsed            | 10          |
| total timesteps         | 2618        |
| train_time              | 0           |
| update_time             | 4           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.52        |
| env_time                | 3           |
| ep_rewmean              | 18.4        |
| episodes                | 120         |
| eplenmean               | 22.4        |
| fps                     | 248         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 10.2        |
| qs_difference           | -10.2       |
| qs_mean                 | -0.38211232 |
| time_elapsed            | 10          |
| total timesteps         | 2709        |
| train_time              | 0           |
| update_time             | 5           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.25       |
| env_time                | 3          |
| ep_rewmean              | 18.5       |
| episodes                | 124        |
| eplenmean               | 22.5       |
| fps                     | 252        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.64       |
| qs_difference           | -3.55      |
| qs_mean                 | 0.09050716 |
| time_elapsed            | 11         |
| total timesteps         | 2782       |
| train_time              | 0          |
| update_time             | 5          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.55        |
| env_time                | 3           |
| ep_rewmean              | 18.5        |
| episodes                | 128         |
| eplenmean               | 22.1        |
| fps                     | 249         |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 6.62        |
| qs_difference           | -6.62       |
| qs_mean                 | -0.34182692 |
| time_elapsed            | 11          |
| total timesteps         | 2870        |
| train_time              | 0           |
| update_time             | 5           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 17.7        |
| env_time                | 4           |
| ep_rewmean              | 18.3        |
| episodes                | 132         |
| eplenmean               | 21.6        |
| fps                     | 244         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 18.1        |
| qs_difference           | -18.1       |
| qs_mean                 | -0.29515108 |
| time_elapsed            | 12          |
| total timesteps         | 2948        |
| train_time              | 0           |
| update_time             | 5           |
-----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 4.18      |
| env_time                | 4         |
| ep_rewmean              | 18.7      |
| episodes                | 136       |
| eplenmean               | 22        |
| fps                     | 241       |
| mean 100 episode reward | 18.7      |
| n_updates               | 0         |
| qs_abs_difference       | 4.49      |
| qs_difference           | -4.46     |
| qs_mean                 | 0.1399925 |
| time_elapsed            | 12        |
| total timesteps         | 3046      |
| train_time              | 0         |
| update_time             | 6         |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 14.8        |
| env_time                | 4           |
| ep_rewmean              | 18.7        |
| episodes                | 140         |
| eplenmean               | 21.9        |
| fps                     | 237         |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 10.6        |
| qs_difference           | -10.6       |
| qs_mean                 | -0.38743198 |
| time_elapsed            | 13          |
| total timesteps         | 3117        |
| train_time              | 0           |
| update_time             | 6           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.37       |
| env_time                | 4          |
| ep_rewmean              | 18.6       |
| episodes                | 144        |
| eplenmean               | 22         |
| fps                     | 234        |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 3.65       |
| qs_difference           | -3.61      |
| qs_mean                 | -0.2214175 |
| time_elapsed            | 13         |
| total timesteps         | 3220       |
| train_time              | 0          |
| update_time             | 6          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 28.4        |
| env_time                | 4           |
| ep_rewmean              | 19.2        |
| episodes                | 148         |
| eplenmean               | 22.4        |
| fps                     | 232         |
| mean 100 episode reward | 19.2        |
| n_updates               | 0           |
| qs_abs_difference       | 40.6        |
| qs_difference           | -40.6       |
| qs_mean                 | -0.09823956 |
| time_elapsed            | 14          |
| total timesteps         | 3345        |
| train_time              | 0           |
| update_time             | 7           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.76        |
| env_time                | 4           |
| ep_rewmean              | 18.6        |
| episodes                | 152         |
| eplenmean               | 22.1        |
| fps                     | 228         |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 4.2         |
| qs_difference           | -4.2        |
| qs_mean                 | 0.020914944 |
| time_elapsed            | 14          |
| total timesteps         | 3416        |
| train_time              | 0           |
| update_time             | 7           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.33        |
| env_time                | 4           |
| ep_rewmean              | 19          |
| episodes                | 156         |
| eplenmean               | 22.4        |
| fps                     | 227         |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 4.55        |
| qs_difference           | -4.55       |
| qs_mean                 | -0.15779735 |
| time_elapsed            | 15          |
| total timesteps         | 3530        |
| train_time              | 0           |
| update_time             | 8           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.49       |
| env_time                | 4          |
| ep_rewmean              | 19.1       |
| episodes                | 160        |
| eplenmean               | 22.3       |
| fps                     | 223        |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.12       |
| qs_difference           | -5.12      |
| qs_mean                 | 0.06499911 |
| time_elapsed            | 16         |
| total timesteps         | 3601       |
| train_time              | 0          |
| update_time             | 8          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.88        |
| env_time                | 4           |
| ep_rewmean              | 18.9        |
| episodes                | 164         |
| eplenmean               | 22.3        |
| fps                     | 220         |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 9.28        |
| qs_difference           | -9.28       |
| qs_mean                 | -0.37367287 |
| time_elapsed            | 16          |
| total timesteps         | 3703        |
| train_time              | 0           |
| update_time             | 9           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.93       |
| env_time                | 5          |
| ep_rewmean              | 18.1       |
| episodes                | 168        |
| eplenmean               | 21.9       |
| fps                     | 223        |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 7.03       |
| qs_difference           | -7.03      |
| qs_mean                 | -0.4057915 |
| time_elapsed            | 16         |
| total timesteps         | 3788       |
| train_time              | 0          |
| update_time             | 9          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.39        |
| env_time                | 5           |
| ep_rewmean              | 18.3        |
| episodes                | 172         |
| eplenmean               | 22          |
| fps                     | 219         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 4.38        |
| qs_difference           | -4.38       |
| qs_mean                 | -0.25508732 |
| time_elapsed            | 17          |
| total timesteps         | 3864        |
| train_time              | 0           |
| update_time             | 9           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.37        |
| env_time                | 5           |
| ep_rewmean              | 18.3        |
| episodes                | 176         |
| eplenmean               | 22.1        |
| fps                     | 216         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 5.39        |
| qs_difference           | -5.38       |
| qs_mean                 | -0.08927164 |
| time_elapsed            | 18          |
| total timesteps         | 3940        |
| train_time              | 0           |
| update_time             | 10          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 24.8        |
| env_time                | 5           |
| ep_rewmean              | 17.9        |
| episodes                | 180         |
| eplenmean               | 21.9        |
| fps                     | 212         |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 24.2        |
| qs_difference           | -24.2       |
| qs_mean                 | -0.23514676 |
| time_elapsed            | 18          |
| total timesteps         | 4030        |
| train_time              | 0           |
| update_time             | 10          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.44        |
| env_time                | 5           |
| ep_rewmean              | 17.7        |
| episodes                | 184         |
| eplenmean               | 21.6        |
| fps                     | 215         |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.63        |
| qs_difference           | -3.63       |
| qs_mean                 | -0.58304924 |
| time_elapsed            | 19          |
| total timesteps         | 4095        |
| train_time              | 0           |
| update_time             | 10          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 9.97        |
| env_time                | 5           |
| ep_rewmean              | 17.6        |
| episodes                | 188         |
| eplenmean               | 21.6        |
| fps                     | 211         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 5.83        |
| qs_difference           | -5.8        |
| qs_mean                 | -0.29669896 |
| time_elapsed            | 19          |
| total timesteps         | 4171        |
| train_time              | 0           |
| update_time             | 11          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 14.7        |
| env_time                | 5           |
| ep_rewmean              | 17.6        |
| episodes                | 192         |
| eplenmean               | 21.4        |
| fps                     | 208         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 16.1        |
| qs_difference           | -16.1       |
| qs_mean                 | -0.12871304 |
| time_elapsed            | 20          |
| total timesteps         | 4253        |
| train_time              | 0           |
| update_time             | 11          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.25        |
| env_time                | 5           |
| ep_rewmean              | 17.5        |
| episodes                | 196         |
| eplenmean               | 21.4        |
| fps                     | 205         |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 6.93        |
| qs_difference           | -6.93       |
| qs_mean                 | -0.29895213 |
| time_elapsed            | 21          |
| total timesteps         | 4333        |
| train_time              | 0           |
| update_time             | 12          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.06        |
| env_time                | 5           |
| ep_rewmean              | 17.5        |
| episodes                | 200         |
| eplenmean               | 21.3        |
| fps                     | 202         |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 5.73        |
| qs_difference           | -5.73       |
| qs_mean                 | -0.05743943 |
| time_elapsed            | 21          |
| total timesteps         | 4401        |
| train_time              | 0           |
| update_time             | 12          |
-----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 6.91      |
| env_time                | 5         |
| ep_rewmean              | 17.5      |
| episodes                | 204       |
| eplenmean               | 21.2      |
| fps                     | 204       |
| mean 100 episode reward | 17.5      |
| n_updates               | 0         |
| qs_abs_difference       | 6.52      |
| qs_difference           | -6.52     |
| qs_mean                 | 0.1509078 |
| time_elapsed            | 21        |
| total timesteps         | 4481      |
| train_time              | 0         |
| update_time             | 12        |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 9.65        |
| env_time                | 6           |
| ep_rewmean              | 17.6        |
| episodes                | 208         |
| eplenmean               | 21.3        |
| fps                     | 201         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 9.13        |
| qs_difference           | -9.13       |
| qs_mean                 | -0.11935742 |
| time_elapsed            | 22          |
| total timesteps         | 4554        |
| train_time              | 0           |
| update_time             | 13          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6           |
| env_time                | 6           |
| ep_rewmean              | 17.5        |
| episodes                | 212         |
| eplenmean               | 21.1        |
| fps                     | 199         |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 5.13        |
| qs_difference           | -5.13       |
| qs_mean                 | -0.09275267 |
| time_elapsed            | 23          |
| total timesteps         | 4651        |
| train_time              | 0           |
| update_time             | 13          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.01        |
| env_time                | 6           |
| ep_rewmean              | 17.7        |
| episodes                | 216         |
| eplenmean               | 21.3        |
| fps                     | 197         |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.45        |
| qs_difference           | -3.45       |
| qs_mean                 | -0.34155905 |
| time_elapsed            | 24          |
| total timesteps         | 4747        |
| train_time              | 0           |
| update_time             | 14          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.36        |
| env_time                | 6           |
| ep_rewmean              | 17.4        |
| episodes                | 220         |
| eplenmean               | 21          |
| fps                     | 194         |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.82        |
| qs_difference           | -3.82       |
| qs_mean                 | -0.34117705 |
| time_elapsed            | 24          |
| total timesteps         | 4807        |
| train_time              | 0           |
| update_time             | 15          |
-----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 3.94         |
| env_time                | 6            |
| ep_rewmean              | 17.9         |
| episodes                | 224          |
| eplenmean               | 21.5         |
| fps                     | 192          |
| mean 100 episode reward | 17.9         |
| n_updates               | 0            |
| qs_abs_difference       | 4.35         |
| qs_difference           | -3.73        |
| qs_mean                 | -0.026333366 |
| time_elapsed            | 25           |
| total timesteps         | 4932         |
| train_time              | 0            |
| update_time             | 15           |
------------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 10.2       |
| env_time                | 6          |
| ep_rewmean              | 17.7       |
| episodes                | 228        |
| eplenmean               | 21.4       |
| fps                     | 190        |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 8.81       |
| qs_difference           | -8.81      |
| qs_mean                 | -0.4252545 |
| time_elapsed            | 26         |
| total timesteps         | 5008       |
| train_time              | 0          |
| update_time             | 16         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.72        |
| env_time                | 6           |
| ep_rewmean              | 17.4        |
| episodes                | 232         |
| eplenmean               | 21.4        |
| fps                     | 192         |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 8.55        |
| qs_difference           | -8.55       |
| qs_mean                 | -0.08795197 |
| time_elapsed            | 26          |
| total timesteps         | 5091        |
| train_time              | 0           |
| update_time             | 16          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.59        |
| env_time                | 6           |
| ep_rewmean              | 17          |
| episodes                | 236         |
| eplenmean               | 21          |
| fps                     | 188         |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 6.65        |
| qs_difference           | -6.65       |
| qs_mean                 | -0.18932799 |
| time_elapsed            | 27          |
| total timesteps         | 5144        |
| train_time              | 0           |
| update_time             | 17          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.85       |
| env_time                | 6          |
| ep_rewmean              | 17         |
| episodes                | 240        |
| eplenmean               | 21.1       |
| fps                     | 186        |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 4.29       |
| qs_difference           | -4.29      |
| qs_mean                 | 0.26506898 |
| time_elapsed            | 28         |
| total timesteps         | 5226       |
| train_time              | 0          |
| update_time             | 17         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.22        |
| env_time                | 6           |
| ep_rewmean              | 17.1        |
| episodes                | 244         |
| eplenmean               | 21.3        |
| fps                     | 185         |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 1.97        |
| qs_difference           | -1.48       |
| qs_mean                 | -0.41278598 |
| time_elapsed            | 28          |
| total timesteps         | 5347        |
| train_time              | 0           |
| update_time             | 18          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.67        |
| env_time                | 7           |
| ep_rewmean              | 16.8        |
| episodes                | 248         |
| eplenmean               | 21.1        |
| fps                     | 183         |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 11.9        |
| qs_difference           | -11.9       |
| qs_mean                 | -0.24153154 |
| time_elapsed            | 29          |
| total timesteps         | 5450        |
| train_time              | 0           |
| update_time             | 19          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.41        |
| env_time                | 7           |
| ep_rewmean              | 16.8        |
| episodes                | 252         |
| eplenmean               | 21.1        |
| fps                     | 180         |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 2.42        |
| qs_difference           | -2.37       |
| qs_mean                 | -0.29579288 |
| time_elapsed            | 30          |
| total timesteps         | 5531        |
| train_time              | 0           |
| update_time             | 19          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 9.19        |
| env_time                | 7           |
| ep_rewmean              | 16.3        |
| episodes                | 256         |
| eplenmean               | 20.6        |
| fps                     | 182         |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 7.73        |
| qs_difference           | -7.73       |
| qs_mean                 | -0.46833587 |
| time_elapsed            | 30          |
| total timesteps         | 5595        |
| train_time              | 0           |
| update_time             | 19          |
-----------------------------------------
-------------------------------------------
| act_time                | 0             |
| current_lr              | 0.0003        |
| discount_q              | 8.33          |
| env_time                | 7             |
| ep_rewmean              | 16            |
| episodes                | 260           |
| eplenmean               | 20.7          |
| fps                     | 179           |
| mean 100 episode reward | 16            |
| n_updates               | 0             |
| qs_abs_difference       | 6.75          |
| qs_difference           | -6.75         |
| qs_mean                 | 0.00032447986 |
| time_elapsed            | 31            |
| total timesteps         | 5667          |
| train_time              | 0             |
| update_time             | 20            |
-------------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 35.6         |
| env_time                | 7            |
| ep_rewmean              | 16.4         |
| episodes                | 264          |
| eplenmean               | 20.5         |
| fps                     | 177          |
| mean 100 episode reward | 16.4         |
| n_updates               | 0            |
| qs_abs_difference       | 32.1         |
| qs_difference           | -32.1        |
| qs_mean                 | -0.121763036 |
| time_elapsed            | 32           |
| total timesteps         | 5757         |
| train_time              | 0            |
| update_time             | 21           |
------------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.47       |
| env_time                | 7          |
| ep_rewmean              | 17.2       |
| episodes                | 268        |
| eplenmean               | 20.9       |
| fps                     | 176        |
| mean 100 episode reward | 17.2       |
| n_updates               | 0          |
| qs_abs_difference       | 5.17       |
| qs_difference           | -5.17      |
| qs_mean                 | 0.06391745 |
| time_elapsed            | 33         |
| total timesteps         | 5874       |
| train_time              | 0          |
| update_time             | 21         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.46       |
| env_time                | 7          |
| ep_rewmean              | 17         |
| episodes                | 272        |
| eplenmean               | 20.8       |
| fps                     | 173        |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 3.94       |
| qs_difference           | -3.94      |
| qs_mean                 | -0.4567163 |
| time_elapsed            | 34         |
| total timesteps         | 5945       |
| train_time              | 0          |
| update_time             | 22         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.49        |
| env_time                | 7           |
| ep_rewmean              | 17.1        |
| episodes                | 276         |
| eplenmean               | 21          |
| fps                     | 171         |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 2.59        |
| qs_difference           | -2.58       |
| qs_mean                 | -0.06590151 |
| time_elapsed            | 35          |
| total timesteps         | 6036        |
| train_time              | 0           |
| update_time             | 23          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.78        |
| env_time                | 7           |
| ep_rewmean              | 16.7        |
| episodes                | 280         |
| eplenmean               | 21          |
| fps                     | 169         |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.8         |
| qs_difference           | -3.8        |
| qs_mean                 | -0.02041771 |
| time_elapsed            | 36          |
| total timesteps         | 6126        |
| train_time              | 0           |
| update_time             | 24          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 9.04        |
| env_time                | 8           |
| ep_rewmean              | 17          |
| episodes                | 284         |
| eplenmean               | 21.4        |
| fps                     | 168         |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 12.9        |
| qs_difference           | -12.9       |
| qs_mean                 | 0.033640943 |
| time_elapsed            | 37          |
| total timesteps         | 6232        |
| train_time              | 0           |
| update_time             | 24          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 30.8        |
| env_time                | 8           |
| ep_rewmean              | 17.6        |
| episodes                | 288         |
| eplenmean               | 21.8        |
| fps                     | 166         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 27          |
| qs_difference           | -27         |
| qs_mean                 | -0.22086313 |
| time_elapsed            | 38          |
| total timesteps         | 6347        |
| train_time              | 0           |
| update_time             | 25          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.67        |
| env_time                | 8           |
| ep_rewmean              | 17.8        |
| episodes                | 292         |
| eplenmean               | 21.9        |
| fps                     | 164         |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.47        |
| qs_difference           | -5.47       |
| qs_mean                 | -0.39466256 |
| time_elapsed            | 39          |
| total timesteps         | 6447        |
| train_time              | 0           |
| update_time             | 26          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.32       |
| env_time                | 8          |
| ep_rewmean              | 17.9       |
| episodes                | 296        |
| eplenmean               | 22         |
| fps                     | 162        |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 3.88       |
| qs_difference           | -3.88      |
| qs_mean                 | -0.3914919 |
| time_elapsed            | 40         |
| total timesteps         | 6532       |
| train_time              | 0          |
| update_time             | 27         |
----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 9.03         |
| env_time                | 8            |
| ep_rewmean              | 18.1         |
| episodes                | 300          |
| eplenmean               | 22.3         |
| fps                     | 161          |
| mean 100 episode reward | 18.1         |
| n_updates               | 0            |
| qs_abs_difference       | 5.57         |
| qs_difference           | -5.56        |
| qs_mean                 | -0.068586774 |
| time_elapsed            | 41           |
| total timesteps         | 6628         |
| train_time              | 0            |
| update_time             | 28           |
------------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 5.5          |
| env_time                | 8            |
| ep_rewmean              | 18.4         |
| episodes                | 304          |
| eplenmean               | 22.7         |
| fps                     | 160          |
| mean 100 episode reward | 18.4         |
| n_updates               | 0            |
| qs_abs_difference       | 7.82         |
| qs_difference           | -7.82        |
| qs_mean                 | -0.059633676 |
| time_elapsed            | 42           |
| total timesteps         | 6749         |
| train_time              | 0            |
| update_time             | 29           |
------------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.26       |
| env_time                | 8          |
| ep_rewmean              | 18.6       |
| episodes                | 308        |
| eplenmean               | 22.9       |
| fps                     | 158        |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.34       |
| qs_difference           | -4.34      |
| qs_mean                 | 0.06272191 |
| time_elapsed            | 43         |
| total timesteps         | 6846       |
| train_time              | 0          |
| update_time             | 29         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.07        |
| env_time                | 9           |
| ep_rewmean              | 18.8        |
| episodes                | 312         |
| eplenmean               | 23.1        |
| fps                     | 157         |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.92        |
| qs_difference           | -5.92       |
| qs_mean                 | -0.30182856 |
| time_elapsed            | 44          |
| total timesteps         | 6966        |
| train_time              | 0           |
| update_time             | 30          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.33        |
| env_time                | 9           |
| ep_rewmean              | 18.6        |
| episodes                | 316         |
| eplenmean               | 23.1        |
| fps                     | 155         |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 6           |
| qs_difference           | -6          |
| qs_mean                 | -0.37232536 |
| time_elapsed            | 45          |
| total timesteps         | 7054        |
| train_time              | 0           |
| update_time             | 31          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.53        |
| env_time                | 9           |
| ep_rewmean              | 18.7        |
| episodes                | 320         |
| eplenmean               | 23.1        |
| fps                     | 153         |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 6.23        |
| qs_difference           | -6.23       |
| qs_mean                 | 0.013552775 |
| time_elapsed            | 46          |
| total timesteps         | 7116        |
| train_time              | 0           |
| update_time             | 32          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.62       |
| env_time                | 9          |
| ep_rewmean              | 18         |
| episodes                | 324        |
| eplenmean               | 22.6       |
| fps                     | 154        |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 4.41       |
| qs_difference           | -4.41      |
| qs_mean                 | -0.4419674 |
| time_elapsed            | 46         |
| total timesteps         | 7189       |
| train_time              | 0          |
| update_time             | 32         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.69        |
| env_time                | 9           |
| ep_rewmean              | 18.2        |
| episodes                | 328         |
| eplenmean               | 22.7        |
| fps                     | 152         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 7.33        |
| qs_difference           | -7.33       |
| qs_mean                 | -0.08035355 |
| time_elapsed            | 47          |
| total timesteps         | 7279        |
| train_time              | 0           |
| update_time             | 33          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.72       |
| env_time                | 9          |
| ep_rewmean              | 18.3       |
| episodes                | 332        |
| eplenmean               | 22.6       |
| fps                     | 151        |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 7.13       |
| qs_difference           | -7.13      |
| qs_mean                 | 0.15378568 |
| time_elapsed            | 48         |
| total timesteps         | 7346       |
| train_time              | 0          |
| update_time             | 34         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.72        |
| env_time                | 9           |
| ep_rewmean              | 18.4        |
| episodes                | 336         |
| eplenmean               | 22.7        |
| fps                     | 149         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.23        |
| qs_difference           | -3.23       |
| qs_mean                 | -0.12688816 |
| time_elapsed            | 49          |
| total timesteps         | 7412        |
| train_time              | 0           |
| update_time             | 35          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 24.3       |
| env_time                | 9          |
| ep_rewmean              | 19.1       |
| episodes                | 340        |
| eplenmean               | 23.2       |
| fps                     | 148        |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 25.8       |
| qs_difference           | -25.8      |
| qs_mean                 | -0.2247346 |
| time_elapsed            | 50         |
| total timesteps         | 7545       |
| train_time              | 0          |
| update_time             | 36         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.93      |
| env_time                | 9         |
| ep_rewmean              | 18.9      |
| episodes                | 344       |
| eplenmean               | 22.6      |
| fps                     | 146       |
| mean 100 episode reward | 18.9      |
| n_updates               | 0         |
| qs_abs_difference       | 3.61      |
| qs_difference           | -3.6      |
| qs_mean                 | -0.203301 |
| time_elapsed            | 51        |
| total timesteps         | 7612      |
| train_time              | 0         |
| update_time             | 37        |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.73        |
| env_time                | 9           |
| ep_rewmean              | 18.3        |
| episodes                | 348         |
| eplenmean               | 22.4        |
| fps                     | 147         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 5.03        |
| qs_difference           | -4.97       |
| qs_mean                 | -0.42468023 |
| time_elapsed            | 52          |
| total timesteps         | 7686        |
| train_time              | 0           |
| update_time             | 37          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.09        |
| env_time                | 9           |
| ep_rewmean              | 18.2        |
| episodes                | 352         |
| eplenmean               | 22.2        |
| fps                     | 145         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 4.65        |
| qs_difference           | -4.65       |
| qs_mean                 | -0.11381814 |
| time_elapsed            | 53          |
| total timesteps         | 7751        |
| train_time              | 0           |
| update_time             | 38          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.91        |
| env_time                | 10          |
| ep_rewmean              | 18.2        |
| episodes                | 356         |
| eplenmean               | 22.5        |
| fps                     | 144         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 2.01        |
| qs_difference           | -1.5        |
| qs_mean                 | -0.31441504 |
| time_elapsed            | 54          |
| total timesteps         | 7845        |
| train_time              | 0           |
| update_time             | 39          |
-----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 8.35      |
| env_time                | 10        |
| ep_rewmean              | 18.9      |
| episodes                | 360       |
| eplenmean               | 22.8      |
| fps                     | 143       |
| mean 100 episode reward | 18.9      |
| n_updates               | 0         |
| qs_abs_difference       | 8.66      |
| qs_difference           | -8.66     |
| qs_mean                 | -0.260558 |
| time_elapsed            | 55        |
| total timesteps         | 7948      |
| train_time              | 0         |
| update_time             | 40        |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.15        |
| env_time                | 10          |
| ep_rewmean              | 18.4        |
| episodes                | 364         |
| eplenmean               | 22.6        |
| fps                     | 141         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 4.55        |
| qs_difference           | -4.46       |
| qs_mean                 | -0.10086013 |
| time_elapsed            | 56          |
| total timesteps         | 8022        |
| train_time              | 0           |
| update_time             | 41          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 12.2       |
| env_time                | 10         |
| ep_rewmean              | 17.5       |
| episodes                | 368        |
| eplenmean               | 22.4       |
| fps                     | 140        |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 11.7       |
| qs_difference           | -11.7      |
| qs_mean                 | -0.0611319 |
| time_elapsed            | 57         |
| total timesteps         | 8119       |
| train_time              | 0          |
| update_time             | 42         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.13       |
| env_time                | 10         |
| ep_rewmean              | 17.4       |
| episodes                | 372        |
| eplenmean               | 22.4       |
| fps                     | 141        |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 4.84       |
| qs_difference           | -4.84      |
| qs_mean                 | -0.3259982 |
| time_elapsed            | 57         |
| total timesteps         | 8190       |
| train_time              | 0          |
| update_time             | 42         |
----------------------------------------
-------------------------------------------
| act_time                | 0             |
| current_lr              | 0.0003        |
| discount_q              | 11.2          |
| env_time                | 10            |
| ep_rewmean              | 17.5          |
| episodes                | 376           |
| eplenmean               | 22.6          |
| fps                     | 140           |
| mean 100 episode reward | 17.5          |
| n_updates               | 0             |
| qs_abs_difference       | 11.9          |
| qs_difference           | -11.9         |
| qs_mean                 | -0.0144619495 |
| time_elapsed            | 59            |
| total timesteps         | 8296          |
| train_time              | 0             |
| update_time             | 43            |
-------------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 15.8       |
| env_time                | 10         |
| ep_rewmean              | 17.7       |
| episodes                | 380        |
| eplenmean               | 22.8       |
| fps                     | 136        |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 17.1       |
| qs_difference           | -17.1      |
| qs_mean                 | -0.4516812 |
| time_elapsed            | 61         |
| total timesteps         | 8409       |
| train_time              | 0          |
| update_time             | 45         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 13.9        |
| env_time                | 10          |
| ep_rewmean              | 18.3        |
| episodes                | 384         |
| eplenmean               | 23          |
| fps                     | 135         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 20.2        |
| qs_difference           | -20.2       |
| qs_mean                 | -0.25245684 |
| time_elapsed            | 62          |
| total timesteps         | 8530        |
| train_time              | 0           |
| update_time             | 46          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.07        |
| env_time                | 11          |
| ep_rewmean              | 17.9        |
| episodes                | 388         |
| eplenmean               | 22.7        |
| fps                     | 134         |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 4.46        |
| qs_difference           | -4.46       |
| qs_mean                 | -0.32320783 |
| time_elapsed            | 64          |
| total timesteps         | 8614        |
| train_time              | 0           |
| update_time             | 47          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.22       |
| env_time                | 11         |
| ep_rewmean              | 17.4       |
| episodes                | 392        |
| eplenmean               | 22.4       |
| fps                     | 135        |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 3.27       |
| qs_difference           | -3.27      |
| qs_mean                 | -0.6001424 |
| time_elapsed            | 64         |
| total timesteps         | 8686       |
| train_time              | 0          |
| update_time             | 47         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.83        |
| env_time                | 11          |
| ep_rewmean              | 17.3        |
| episodes                | 396         |
| eplenmean               | 22.4        |
| fps                     | 134         |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 7.68        |
| qs_difference           | -7.68       |
| qs_mean                 | 0.077968836 |
| time_elapsed            | 65          |
| total timesteps         | 8775        |
| train_time              | 0           |
| update_time             | 48          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 2.77       |
| env_time                | 11         |
| ep_rewmean              | 17.2       |
| episodes                | 400        |
| eplenmean               | 22.2       |
| fps                     | 132        |
| mean 100 episode reward | 17.2       |
| n_updates               | 0          |
| qs_abs_difference       | 2.12       |
| qs_difference           | -1.95      |
| qs_mean                 | -0.2577357 |
| time_elapsed            | 66         |
| total timesteps         | 8853       |
| train_time              | 0          |
| update_time             | 49         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 7.69      |
| env_time                | 11        |
| ep_rewmean              | 16.7      |
| episodes                | 404       |
| eplenmean               | 21.6      |
| fps                     | 131       |
| mean 100 episode reward | 16.7      |
| n_updates               | 0         |
| qs_abs_difference       | 5.43      |
| qs_difference           | -5.43     |
| qs_mean                 | -0.426599 |
| time_elapsed            | 67        |
| total timesteps         | 8913      |
| train_time              | 0         |
| update_time             | 51        |
---------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 14.8      |
| env_time                | 11        |
| ep_rewmean              | 16.6      |
| episodes                | 408       |
| eplenmean               | 21.5      |
| fps                     | 132       |
| mean 100 episode reward | 16.6      |
| n_updates               | 0         |
| qs_abs_difference       | 15.3      |
| qs_difference           | -15.3     |
| qs_mean                 | -0.360274 |
| time_elapsed            | 68        |
| total timesteps         | 8994      |
| train_time              | 0         |
| update_time             | 51        |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.26        |
| env_time                | 11          |
| ep_rewmean              | 16.4        |
| episodes                | 412         |
| eplenmean               | 21.2        |
| fps                     | 130         |
| mean 100 episode reward | 16.4        |
| n_updates               | 0           |
| qs_abs_difference       | 6.11        |
| qs_difference           | -6.11       |
| qs_mean                 | -0.32640356 |
| time_elapsed            | 69          |
| total timesteps         | 9082        |
| train_time              | 0           |
| update_time             | 52          |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 14.9         |
| env_time                | 11           |
| ep_rewmean              | 16.5         |
| episodes                | 416          |
| eplenmean               | 21.2         |
| fps                     | 129          |
| mean 100 episode reward | 16.5         |
| n_updates               | 0            |
| qs_abs_difference       | 12.7         |
| qs_difference           | -12.7        |
| qs_mean                 | -0.007825769 |
| time_elapsed            | 70           |
| total timesteps         | 9172         |
| train_time              | 0            |
| update_time             | 53           |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.95        |
| env_time                | 11          |
| ep_rewmean              | 16.5        |
| episodes                | 420         |
| eplenmean               | 21.4        |
| fps                     | 128         |
| mean 100 episode reward | 16.5        |
| n_updates               | 0           |
| qs_abs_difference       | 5.88        |
| qs_difference           | -5.88       |
| qs_mean                 | -0.43512222 |
| time_elapsed            | 71          |
| total timesteps         | 9252        |
| train_time              | 0           |
| update_time             | 54          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.03       |
| env_time                | 11         |
| ep_rewmean              | 16.6       |
| episodes                | 424        |
| eplenmean               | 21.4       |
| fps                     | 127        |
| mean 100 episode reward | 16.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.49       |
| qs_difference           | -5.49      |
| qs_mean                 | 0.07368947 |
| time_elapsed            | 73         |
| total timesteps         | 9329       |
| train_time              | 0          |
| update_time             | 55         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.83        |
| env_time                | 12          |
| ep_rewmean              | 16.7        |
| episodes                | 428         |
| eplenmean               | 21.9        |
| fps                     | 126         |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 13.4        |
| qs_difference           | -13.4       |
| qs_mean                 | -0.39099944 |
| time_elapsed            | 74          |
| total timesteps         | 9468        |
| train_time              | 0           |
| update_time             | 56          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 13.6        |
| env_time                | 12          |
| ep_rewmean              | 16.9        |
| episodes                | 432         |
| eplenmean               | 22.1        |
| fps                     | 125         |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 13.8        |
| qs_difference           | -13.8       |
| qs_mean                 | -0.12954608 |
| time_elapsed            | 76          |
| total timesteps         | 9557        |
| train_time              | 0           |
| update_time             | 58          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 18.9        |
| env_time                | 12          |
| ep_rewmean              | 17.2        |
| episodes                | 436         |
| eplenmean               | 22.4        |
| fps                     | 124         |
| mean 100 episode reward | 17.2        |
| n_updates               | 0           |
| qs_abs_difference       | 19.7        |
| qs_difference           | -19.7       |
| qs_mean                 | -0.36238447 |
| time_elapsed            | 77          |
| total timesteps         | 9648        |
| train_time              | 0           |
| update_time             | 59          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.52       |
| env_time                | 12         |
| ep_rewmean              | 16.5       |
| episodes                | 440        |
| eplenmean               | 21.6       |
| fps                     | 123        |
| mean 100 episode reward | 16.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.78       |
| qs_difference           | -4.78      |
| qs_mean                 | -0.2759652 |
| time_elapsed            | 78         |
| total timesteps         | 9704       |
| train_time              | 0          |
| update_time             | 60         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 3.62      |
| env_time                | 12        |
| ep_rewmean              | 16.9      |
| episodes                | 444       |
| eplenmean               | 21.7      |
| fps                     | 123       |
| mean 100 episode reward | 16.9      |
| n_updates               | 0         |
| qs_abs_difference       | 3.7       |
| qs_difference           | -3.7      |
| qs_mean                 | 0.1447385 |
| time_elapsed            | 78        |
| total timesteps         | 9781      |
| train_time              | 0         |
| update_time             | 60        |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.6         |
| env_time                | 12          |
| ep_rewmean              | 17.1        |
| episodes                | 448         |
| eplenmean               | 21.8        |
| fps                     | 122         |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 2.48        |
| qs_difference           | -2.38       |
| qs_mean                 | -0.39102834 |
| time_elapsed            | 80          |
| total timesteps         | 9865        |
| train_time              | 0           |
| update_time             | 61          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.91        |
| env_time                | 12          |
| ep_rewmean              | 17.6        |
| episodes                | 452         |
| eplenmean               | 22.3        |
| fps                     | 121         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 8.12        |
| qs_difference           | -8.12       |
| qs_mean                 | -0.24747714 |
| time_elapsed            | 81          |
| total timesteps         | 9977        |
| train_time              | 0           |
| update_time             | 62          |
-----------------------------------------
----------------------------------------
| eval mean 100 episod... | 0.7        |
| eval_abs_qs_difference  | 0.64878845 |
| eval_discount_q         | 0.854      |
| eval_ep_rewmean         | 0.658      |
| eval_eplenmean          | 11         |
| eval_qs                 | -1.7813576 |
| eval_qs_difference      | -0.0759    |
| eval_time_elapsed       | 0          |
| total timesteps         | 10001      |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 10.8        |
| env_time                | 12          |
| ep_rewmean              | 17.7        |
| episodes                | 456         |
| eplenmean               | 22.1        |
| fps                     | 120         |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 9.41        |
| qs_difference           | -9.41       |
| qs_mean                 | -0.05512608 |
| time_elapsed            | 83          |
| total timesteps         | 10058       |
| train_time              | 0           |
| update_time             | 64          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 31.9        |
| env_time                | 13          |
| ep_rewmean              | 19.4        |
| episodes                | 460         |
| eplenmean               | 23.4        |
| fps                     | 118         |
| mean 100 episode reward | 19.4        |
| n_updates               | 0           |
| qs_abs_difference       | 59.2        |
| qs_difference           | -59.2       |
| qs_mean                 | -0.30781537 |
| time_elapsed            | 86          |
| total timesteps         | 10286       |
| train_time              | 0           |
| update_time             | 66          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.18        |
| env_time                | 13          |
| ep_rewmean              | 19.3        |
| episodes                | 464         |
| eplenmean               | 23.3        |
| fps                     | 117         |
| mean 100 episode reward | 19.3        |
| n_updates               | 0           |
| qs_abs_difference       | 4.64        |
| qs_difference           | -4.64       |
| qs_mean                 | -0.18961383 |
| time_elapsed            | 87          |
| total timesteps         | 10355       |
| train_time              | 0           |
| update_time             | 68          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 10.5       |
| env_time                | 13         |
| ep_rewmean              | 19.4       |
| episodes                | 468        |
| eplenmean               | 23.2       |
| fps                     | 116        |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 8.65       |
| qs_difference           | -8.65      |
| qs_mean                 | -0.2778589 |
| time_elapsed            | 89         |
| total timesteps         | 10440      |
| train_time              | 0          |
| update_time             | 69         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 9.79        |
| env_time                | 13          |
| ep_rewmean              | 19.6        |
| episodes                | 472         |
| eplenmean               | 23.5        |
| fps                     | 116         |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 9.5         |
| qs_difference           | -9.5        |
| qs_mean                 | -0.21822685 |
| time_elapsed            | 90          |
| total timesteps         | 10538       |
| train_time              | 0           |
| update_time             | 70          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.46        |
| env_time                | 13          |
| ep_rewmean              | 19.6        |
| episodes                | 476         |
| eplenmean               | 23.3        |
| fps                     | 115         |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 5.05        |
| qs_difference           | -5.05       |
| qs_mean                 | -0.08159851 |
| time_elapsed            | 92          |
| total timesteps         | 10630       |
| train_time              | 0           |
| update_time             | 72          |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 14.5         |
| env_time                | 13           |
| ep_rewmean              | 19.3         |
| episodes                | 480          |
| eplenmean               | 23           |
| fps                     | 114          |
| mean 100 episode reward | 19.3         |
| n_updates               | 0            |
| qs_abs_difference       | 12           |
| qs_difference           | -12          |
| qs_mean                 | -0.012845524 |
| time_elapsed            | 93           |
| total timesteps         | 10709        |
| train_time              | 0            |
| update_time             | 73           |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 3.53       |
| env_time                | 13         |
| ep_rewmean              | 18.6       |
| episodes                | 484        |
| eplenmean               | 22.5       |
| fps                     | 114        |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 2.98       |
| qs_difference           | -2.98      |
| qs_mean                 | -0.4320784 |
| time_elapsed            | 93         |
| total timesteps         | 10776      |
| train_time              | 0          |
| update_time             | 73         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.79        |
| env_time                | 13          |
| ep_rewmean              | 18.5        |
| episodes                | 488         |
| eplenmean               | 22.3        |
| fps                     | 113         |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 6.04        |
| qs_difference           | -6.04       |
| qs_mean                 | 0.024697643 |
| time_elapsed            | 95          |
| total timesteps         | 10841       |
| train_time              | 0           |
| update_time             | 74          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.42        |
| env_time                | 14          |
| ep_rewmean              | 18.5        |
| episodes                | 492         |
| eplenmean               | 22.2        |
| fps                     | 112         |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 3.55        |
| qs_difference           | -3.55       |
| qs_mean                 | 0.029843397 |
| time_elapsed            | 96          |
| total timesteps         | 10903       |
| train_time              | 0           |
| update_time             | 76          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 11          |
| env_time                | 14          |
| ep_rewmean              | 18.3        |
| episodes                | 496         |
| eplenmean               | 22          |
| fps                     | 112         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 10          |
| qs_difference           | -10         |
| qs_mean                 | -0.24516335 |
| time_elapsed            | 97          |
| total timesteps         | 10971       |
| train_time              | 0           |
| update_time             | 76          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.61        |
| env_time                | 14          |
| ep_rewmean              | 18.4        |
| episodes                | 500         |
| eplenmean               | 22          |
| fps                     | 112         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 8.26        |
| qs_difference           | -8.26       |
| qs_mean                 | -0.14449367 |
| time_elapsed            | 98          |
| total timesteps         | 11049       |
| train_time              | 0           |
| update_time             | 77          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 12.1        |
| env_time                | 14          |
| ep_rewmean              | 18.6        |
| episodes                | 504         |
| eplenmean               | 22.1        |
| fps                     | 111         |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 11.8        |
| qs_difference           | -11.8       |
| qs_mean                 | -0.44509217 |
| time_elapsed            | 100         |
| total timesteps         | 11126       |
| train_time              | 0           |
| update_time             | 78          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.35        |
| env_time                | 14          |
| ep_rewmean              | 18.7        |
| episodes                | 508         |
| eplenmean               | 22.4        |
| fps                     | 110         |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 5.11        |
| qs_difference           | -5.11       |
| qs_mean                 | -0.31819767 |
| time_elapsed            | 101         |
| total timesteps         | 11238       |
| train_time              | 0           |
| update_time             | 80          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.1        |
| env_time                | 14         |
| ep_rewmean              | 18.3       |
| episodes                | 512        |
| eplenmean               | 22.1       |
| fps                     | 110        |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.34       |
| qs_difference           | -4.33      |
| qs_mean                 | 0.15278767 |
| time_elapsed            | 101        |
| total timesteps         | 11296      |
| train_time              | 0          |
| update_time             | 80         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 12.2        |
| env_time                | 14          |
| ep_rewmean              | 18.4        |
| episodes                | 516         |
| eplenmean               | 22          |
| fps                     | 109         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 11.5        |
| qs_difference           | -11.5       |
| qs_mean                 | -0.11227142 |
| time_elapsed            | 103         |
| total timesteps         | 11372       |
| train_time              | 0           |
| update_time             | 81          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.56        |
| env_time                | 14          |
| ep_rewmean              | 18.9        |
| episodes                | 520         |
| eplenmean               | 22.2        |
| fps                     | 109         |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 5.99        |
| qs_difference           | -5.99       |
| qs_mean                 | -0.38767946 |
| time_elapsed            | 105         |
| total timesteps         | 11471       |
| train_time              | 0           |
| update_time             | 83          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.57        |
| env_time                | 14          |
| ep_rewmean              | 19.1        |
| episodes                | 524         |
| eplenmean               | 22.2        |
| fps                     | 108         |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 4.82        |
| qs_difference           | -4.82       |
| qs_mean                 | 0.012865156 |
| time_elapsed            | 106         |
| total timesteps         | 11554       |
| train_time              | 0           |
| update_time             | 84          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.7         |
| env_time                | 14          |
| ep_rewmean              | 18.7        |
| episodes                | 528         |
| eplenmean               | 21.5        |
| fps                     | 107         |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.41        |
| qs_difference           | -3.41       |
| qs_mean                 | -0.15622327 |
| time_elapsed            | 108         |
| total timesteps         | 11619       |
| train_time              | 0           |
| update_time             | 86          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.21        |
| env_time                | 15          |
| ep_rewmean              | 18.5        |
| episodes                | 532         |
| eplenmean               | 21.5        |
| fps                     | 106         |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 5.63        |
| qs_difference           | -5.63       |
| qs_mean                 | -0.18823725 |
| time_elapsed            | 109         |
| total timesteps         | 11710       |
| train_time              | 0           |
| update_time             | 87          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.05        |
| env_time                | 15          |
| ep_rewmean              | 18.2        |
| episodes                | 536         |
| eplenmean               | 21.2        |
| fps                     | 107         |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 2.63        |
| qs_difference           | -2.63       |
| qs_mean                 | -0.04539627 |
| time_elapsed            | 109         |
| total timesteps         | 11772       |
| train_time              | 0           |
| update_time             | 87          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.01        |
| env_time                | 15          |
| ep_rewmean              | 18.3        |
| episodes                | 540         |
| eplenmean               | 21.4        |
| fps                     | 106         |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 2.71        |
| qs_difference           | 1.29        |
| qs_mean                 | -0.26747015 |
| time_elapsed            | 111         |
| total timesteps         | 11847       |
| train_time              | 0           |
| update_time             | 89          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.23       |
| env_time                | 15         |
| ep_rewmean              | 17.7       |
| episodes                | 544        |
| eplenmean               | 21.3       |
| fps                     | 105        |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 4.5        |
| qs_difference           | -4.5       |
| qs_mean                 | 0.09916879 |
| time_elapsed            | 113        |
| total timesteps         | 11909      |
| train_time              | 0          |
| update_time             | 90         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.14        |
| env_time                | 15          |
| ep_rewmean              | 17.7        |
| episodes                | 548         |
| eplenmean               | 21.2        |
| fps                     | 105         |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 5.78        |
| qs_difference           | -5.78       |
| qs_mean                 | 0.028116545 |
| time_elapsed            | 113         |
| total timesteps         | 11985       |
| train_time              | 0           |
| update_time             | 90          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.09        |
| env_time                | 15          |
| ep_rewmean              | 17.5        |
| episodes                | 552         |
| eplenmean               | 20.9        |
| fps                     | 104         |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 4.19        |
| qs_difference           | -4.19       |
| qs_mean                 | 0.033296928 |
| time_elapsed            | 114         |
| total timesteps         | 12064       |
| train_time              | 0           |
| update_time             | 92          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.81        |
| env_time                | 15          |
| ep_rewmean              | 17.4        |
| episodes                | 556         |
| eplenmean               | 20.9        |
| fps                     | 104         |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 4.98        |
| qs_difference           | -4.86       |
| qs_mean                 | 0.044110864 |
| time_elapsed            | 116         |
| total timesteps         | 12146       |
| train_time              | 0           |
| update_time             | 93          |
-----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 4.44      |
| env_time                | 15        |
| ep_rewmean              | 15        |
| episodes                | 560       |
| eplenmean               | 19.5      |
| fps                     | 103       |
| mean 100 episode reward | 15        |
| n_updates               | 0         |
| qs_abs_difference       | 3.62      |
| qs_difference           | -3.62     |
| qs_mean                 | -0.290927 |
| time_elapsed            | 118       |
| total timesteps         | 12236     |
| train_time              | 0         |
| update_time             | 95        |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.07        |
| env_time                | 15          |
| ep_rewmean              | 16.3        |
| episodes                | 564         |
| eplenmean               | 20.2        |
| fps                     | 102         |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 9.33        |
| qs_difference           | -9.33       |
| qs_mean                 | -0.40450925 |
| time_elapsed            | 120         |
| total timesteps         | 12374       |
| train_time              | 0           |
| update_time             | 96          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.54        |
| env_time                | 15          |
| ep_rewmean              | 16.5        |
| episodes                | 568         |
| eplenmean               | 20.1        |
| fps                     | 102         |
| mean 100 episode reward | 16.5        |
| n_updates               | 0           |
| qs_abs_difference       | 3.59        |
| qs_difference           | -3.58       |
| qs_mean                 | -0.26006204 |
| time_elapsed            | 121         |
| total timesteps         | 12455       |
| train_time              | 0           |
| update_time             | 98          |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 6.95         |
| env_time                | 16           |
| ep_rewmean              | 16.4         |
| episodes                | 572          |
| eplenmean               | 19.9         |
| fps                     | 101          |
| mean 100 episode reward | 16.4         |
| n_updates               | 0            |
| qs_abs_difference       | 5.48         |
| qs_difference           | -5.48        |
| qs_mean                 | -0.076222226 |
| time_elapsed            | 123          |
| total timesteps         | 12532        |
| train_time              | 0            |
| update_time             | 99           |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.73       |
| env_time                | 16         |
| ep_rewmean              | 15.9       |
| episodes                | 576        |
| eplenmean               | 19.6       |
| fps                     | 101        |
| mean 100 episode reward | 15.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.4        |
| qs_difference           | -5.4       |
| qs_mean                 | 0.07453453 |
| time_elapsed            | 123        |
| total timesteps         | 12595      |
| train_time              | 0          |
| update_time             | 99         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 3.38      |
| env_time                | 16        |
| ep_rewmean              | 16.1      |
| episodes                | 580       |
| eplenmean               | 19.8      |
| fps                     | 101       |
| mean 100 episode reward | 16.1      |
| n_updates               | 0         |
| qs_abs_difference       | 3.78      |
| qs_difference           | -3.78     |
| qs_mean                 | 0.1033303 |
| time_elapsed            | 125       |
| total timesteps         | 12693     |
| train_time              | 0         |
| update_time             | 101       |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 13.3        |
| env_time                | 16          |
| ep_rewmean              | 16.2        |
| episodes                | 584         |
| eplenmean               | 20.1        |
| fps                     | 100         |
| mean 100 episode reward | 16.2        |
| n_updates               | 0           |
| qs_abs_difference       | 12          |
| qs_difference           | -12         |
| qs_mean                 | -0.13530631 |
| time_elapsed            | 127         |
| total timesteps         | 12783       |
| train_time              | 0           |
| update_time             | 103         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.74        |
| env_time                | 16          |
| ep_rewmean              | 16          |
| episodes                | 588         |
| eplenmean               | 20.1        |
| fps                     | 99          |
| mean 100 episode reward | 16          |
| n_updates               | 0           |
| qs_abs_difference       | 3.85        |
| qs_difference           | -3.84       |
| qs_mean                 | -0.23042186 |
| time_elapsed            | 128         |
| total timesteps         | 12846       |
| train_time              | 0           |
| update_time             | 104         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.1        |
| env_time                | 16         |
| ep_rewmean              | 15.9       |
| episodes                | 592        |
| eplenmean               | 20.3       |
| fps                     | 98         |
| mean 100 episode reward | 15.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.94       |
| qs_difference           | -5.94      |
| qs_mean                 | -0.4645002 |
| time_elapsed            | 130        |
| total timesteps         | 12937      |
| train_time              | 0          |
| update_time             | 106        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 11.3        |
| env_time                | 16          |
| ep_rewmean              | 16          |
| episodes                | 596         |
| eplenmean               | 20.5        |
| fps                     | 98          |
| mean 100 episode reward | 16          |
| n_updates               | 0           |
| qs_abs_difference       | 6.29        |
| qs_difference           | -6.06       |
| qs_mean                 | -0.31915578 |
| time_elapsed            | 132         |
| total timesteps         | 13019       |
| train_time              | 0           |
| update_time             | 108         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.45        |
| env_time                | 16          |
| ep_rewmean              | 16          |
| episodes                | 600         |
| eplenmean               | 20.4        |
| fps                     | 98          |
| mean 100 episode reward | 16          |
| n_updates               | 0           |
| qs_abs_difference       | 6.2         |
| qs_difference           | -6.2        |
| qs_mean                 | -0.12029869 |
| time_elapsed            | 132         |
| total timesteps         | 13090       |
| train_time              | 0           |
| update_time             | 108         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.75       |
| env_time                | 16         |
| ep_rewmean              | 15.9       |
| episodes                | 604        |
| eplenmean               | 20.6       |
| fps                     | 97         |
| mean 100 episode reward | 15.9       |
| n_updates               | 0          |
| qs_abs_difference       | 6.7        |
| qs_difference           | -6.7       |
| qs_mean                 | 0.07232481 |
| time_elapsed            | 134        |
| total timesteps         | 13181      |
| train_time              | 0          |
| update_time             | 109        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 27          |
| env_time                | 16          |
| ep_rewmean              | 16.3        |
| episodes                | 608         |
| eplenmean               | 20.6        |
| fps                     | 97          |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 34.1        |
| qs_difference           | -34.1       |
| qs_mean                 | -0.38924405 |
| time_elapsed            | 136         |
| total timesteps         | 13297       |
| train_time              | 0           |
| update_time             | 111         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 14.2         |
| env_time                | 17           |
| ep_rewmean              | 16.5         |
| episodes                | 612          |
| eplenmean               | 20.8         |
| fps                     | 96           |
| mean 100 episode reward | 16.5         |
| n_updates               | 0            |
| qs_abs_difference       | 12.1         |
| qs_difference           | -12.1        |
| qs_mean                 | 0.0034096346 |
| time_elapsed            | 138          |
| total timesteps         | 13375        |
| train_time              | 0            |
| update_time             | 113          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 13.5        |
| env_time                | 17          |
| ep_rewmean              | 16.3        |
| episodes                | 616         |
| eplenmean               | 20.9        |
| fps                     | 95          |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 14.1        |
| qs_difference           | -14.1       |
| qs_mean                 | -0.42408535 |
| time_elapsed            | 140         |
| total timesteps         | 13460       |
| train_time              | 0           |
| update_time             | 114         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.13        |
| env_time                | 17          |
| ep_rewmean              | 15.8        |
| episodes                | 620         |
| eplenmean               | 20.6        |
| fps                     | 95          |
| mean 100 episode reward | 15.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.01        |
| qs_difference           | -5.01       |
| qs_mean                 | 0.026086792 |
| time_elapsed            | 142         |
| total timesteps         | 13530       |
| train_time              | 0           |
| update_time             | 116         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.71        |
| env_time                | 17          |
| ep_rewmean              | 15.9        |
| episodes                | 624         |
| eplenmean               | 20.9        |
| fps                     | 94          |
| mean 100 episode reward | 15.9        |
| n_updates               | 0           |
| qs_abs_difference       | 6.27        |
| qs_difference           | -6.27       |
| qs_mean                 | -0.43651208 |
| time_elapsed            | 144         |
| total timesteps         | 13639       |
| train_time              | 0           |
| update_time             | 118         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.97        |
| env_time                | 17          |
| ep_rewmean              | 16          |
| episodes                | 628         |
| eplenmean               | 21.2        |
| fps                     | 94          |
| mean 100 episode reward | 16          |
| n_updates               | 0           |
| qs_abs_difference       | 3.65        |
| qs_difference           | -3.28       |
| qs_mean                 | -0.06532965 |
| time_elapsed            | 146         |
| total timesteps         | 13738       |
| train_time              | 0           |
| update_time             | 120         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 12.3        |
| env_time                | 17          |
| ep_rewmean              | 15.9        |
| episodes                | 632         |
| eplenmean               | 21          |
| fps                     | 93          |
| mean 100 episode reward | 15.9        |
| n_updates               | 0           |
| qs_abs_difference       | 11          |
| qs_difference           | -11         |
| qs_mean                 | -0.28991702 |
| time_elapsed            | 147         |
| total timesteps         | 13814       |
| train_time              | 0           |
| update_time             | 122         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 8.91         |
| env_time                | 17           |
| ep_rewmean              | 16.2         |
| episodes                | 636          |
| eplenmean               | 21.6         |
| fps                     | 92           |
| mean 100 episode reward | 16.2         |
| n_updates               | 0            |
| qs_abs_difference       | 13.8         |
| qs_difference           | -13.8        |
| qs_mean                 | -0.014503062 |
| time_elapsed            | 149          |
| total timesteps         | 13931        |
| train_time              | 0            |
| update_time             | 123          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 9.97        |
| env_time                | 17          |
| ep_rewmean              | 16.6        |
| episodes                | 640         |
| eplenmean               | 21.7        |
| fps                     | 92          |
| mean 100 episode reward | 16.6        |
| n_updates               | 0           |
| qs_abs_difference       | 10.7        |
| qs_difference           | -10.7       |
| qs_mean                 | -0.07855661 |
| time_elapsed            | 151         |
| total timesteps         | 14018       |
| train_time              | 0           |
| update_time             | 125         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.53        |
| env_time                | 17          |
| ep_rewmean              | 16.8        |
| episodes                | 644         |
| eplenmean               | 21.8        |
| fps                     | 92          |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 3.1         |
| qs_difference           | -3.1        |
| qs_mean                 | -0.06317897 |
| time_elapsed            | 151         |
| total timesteps         | 14087       |
| train_time              | 0           |
| update_time             | 125         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 4.49         |
| env_time                | 18           |
| ep_rewmean              | 16.6         |
| episodes                | 648          |
| eplenmean               | 21.7         |
| fps                     | 92           |
| mean 100 episode reward | 16.6         |
| n_updates               | 0            |
| qs_abs_difference       | 4.6          |
| qs_difference           | -4.6         |
| qs_mean                 | -0.112330265 |
| time_elapsed            | 153          |
| total timesteps         | 14159        |
| train_time              | 0            |
| update_time             | 127          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.86        |
| env_time                | 18          |
| ep_rewmean              | 16.5        |
| episodes                | 652         |
| eplenmean               | 21.8        |
| fps                     | 91          |
| mean 100 episode reward | 16.5        |
| n_updates               | 0           |
| qs_abs_difference       | 3.78        |
| qs_difference           | -3.78       |
| qs_mean                 | -0.21874958 |
| time_elapsed            | 155         |
| total timesteps         | 14248       |
| train_time              | 0           |
| update_time             | 129         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.44        |
| env_time                | 18          |
| ep_rewmean              | 16.7        |
| episodes                | 656         |
| eplenmean               | 22          |
| fps                     | 90          |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 6.71        |
| qs_difference           | -6.71       |
| qs_mean                 | -0.24185297 |
| time_elapsed            | 157         |
| total timesteps         | 14342       |
| train_time              | 0           |
| update_time             | 130         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 15.4       |
| env_time                | 18         |
| ep_rewmean              | 16.6       |
| episodes                | 660        |
| eplenmean               | 21.7       |
| fps                     | 90         |
| mean 100 episode reward | 16.6       |
| n_updates               | 0          |
| qs_abs_difference       | 12.2       |
| qs_difference           | -12.2      |
| qs_mean                 | 0.07247795 |
| time_elapsed            | 159        |
| total timesteps         | 14410      |
| train_time              | 0          |
| update_time             | 132        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.68        |
| env_time                | 18          |
| ep_rewmean              | 15.5        |
| episodes                | 664         |
| eplenmean               | 21.1        |
| fps                     | 90          |
| mean 100 episode reward | 15.5        |
| n_updates               | 0           |
| qs_abs_difference       | 4.77        |
| qs_difference           | -4.77       |
| qs_mean                 | -0.28037608 |
| time_elapsed            | 159         |
| total timesteps         | 14485       |
| train_time              | 0           |
| update_time             | 132         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 20          |
| env_time                | 18          |
| ep_rewmean              | 15.7        |
| episodes                | 668         |
| eplenmean               | 21.5        |
| fps                     | 89          |
| mean 100 episode reward | 15.7        |
| n_updates               | 0           |
| qs_abs_difference       | 25.3        |
| qs_difference           | -25.3       |
| qs_mean                 | -0.23936681 |
| time_elapsed            | 163         |
| total timesteps         | 14609       |
| train_time              | 0           |
| update_time             | 136         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.19        |
| env_time                | 18          |
| ep_rewmean              | 15.7        |
| episodes                | 672         |
| eplenmean               | 21.5        |
| fps                     | 89          |
| mean 100 episode reward | 15.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.13        |
| qs_difference           | -2.51       |
| qs_mean                 | -0.12126163 |
| time_elapsed            | 163         |
| total timesteps         | 14685       |
| train_time              | 0           |
| update_time             | 136         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 14.8       |
| env_time                | 18         |
| ep_rewmean              | 16.1       |
| episodes                | 676        |
| eplenmean               | 21.8       |
| fps                     | 88         |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 16         |
| qs_difference           | -16        |
| qs_mean                 | -0.3580338 |
| time_elapsed            | 166        |
| total timesteps         | 14776      |
| train_time              | 0          |
| update_time             | 138        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.99        |
| env_time                | 18          |
| ep_rewmean              | 16          |
| episodes                | 680         |
| eplenmean               | 21.7        |
| fps                     | 88          |
| mean 100 episode reward | 16          |
| n_updates               | 0           |
| qs_abs_difference       | 9           |
| qs_difference           | -9          |
| qs_mean                 | 0.038003203 |
| time_elapsed            | 168         |
| total timesteps         | 14862       |
| train_time              | 0           |
| update_time             | 140         |
-----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 2.9       |
| env_time                | 19        |
| ep_rewmean              | 16.5      |
| episodes                | 684       |
| eplenmean               | 21.9      |
| fps                     | 87        |
| mean 100 episode reward | 16.5      |
| n_updates               | 0         |
| qs_abs_difference       | 3.28      |
| qs_difference           | -3.28     |
| qs_mean                 | -0.602385 |
| time_elapsed            | 170       |
| total timesteps         | 14971     |
| train_time              | 0         |
| update_time             | 142       |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.16        |
| env_time                | 19          |
| ep_rewmean              | 16.5        |
| episodes                | 688         |
| eplenmean               | 22          |
| fps                     | 87          |
| mean 100 episode reward | 16.5        |
| n_updates               | 0           |
| qs_abs_difference       | 4.96        |
| qs_difference           | -4.96       |
| qs_mean                 | -0.33934286 |
| time_elapsed            | 172         |
| total timesteps         | 15047       |
| train_time              | 0           |
| update_time             | 144         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 12.3        |
| env_time                | 19          |
| ep_rewmean              | 16.8        |
| episodes                | 692         |
| eplenmean               | 22.1        |
| fps                     | 86          |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 9.75        |
| qs_difference           | -9.7        |
| qs_mean                 | -0.07028916 |
| time_elapsed            | 174         |
| total timesteps         | 15145       |
| train_time              | 0           |
| update_time             | 146         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 2.44       |
| env_time                | 19         |
| ep_rewmean              | 17.7       |
| episodes                | 696        |
| eplenmean               | 22.4       |
| fps                     | 86         |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 2.48       |
| qs_difference           | -2.36      |
| qs_mean                 | -0.2534879 |
| time_elapsed            | 176        |
| total timesteps         | 15260      |
| train_time              | 0          |
| update_time             | 148        |
----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 13.2         |
| env_time                | 19           |
| ep_rewmean              | 18           |
| episodes                | 700          |
| eplenmean               | 22.6         |
| fps                     | 85           |
| mean 100 episode reward | 18           |
| n_updates               | 0            |
| qs_abs_difference       | 12           |
| qs_difference           | -12          |
| qs_mean                 | -0.009694565 |
| time_elapsed            | 178          |
| total timesteps         | 15355        |
| train_time              | 0            |
| update_time             | 149          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.35        |
| env_time                | 19          |
| ep_rewmean              | 18.2        |
| episodes                | 704         |
| eplenmean               | 22.6        |
| fps                     | 85          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 3.69        |
| qs_difference           | -3.69       |
| qs_mean                 | -0.16302454 |
| time_elapsed            | 180         |
| total timesteps         | 15446       |
| train_time              | 0           |
| update_time             | 151         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 10.7        |
| env_time                | 19          |
| ep_rewmean              | 17.6        |
| episodes                | 708         |
| eplenmean               | 22.2        |
| fps                     | 84          |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 9.83        |
| qs_difference           | -9.83       |
| qs_mean                 | -0.14804842 |
| time_elapsed            | 182         |
| total timesteps         | 15516       |
| train_time              | 0           |
| update_time             | 153         |
-----------------------------------------
--------------------------------------
| act_time                | 1        |
| current_lr              | 0.0003   |
| discount_q              | 6.92     |
| env_time                | 19       |
| ep_rewmean              | 17.7     |
| episodes                | 712      |
| eplenmean               | 22.2     |
| fps                     | 85       |
| mean 100 episode reward | 17.7     |
| n_updates               | 0        |
| qs_abs_difference       | 6.19     |
| qs_difference           | -6.19    |
| qs_mean                 | 0.087282 |
| time_elapsed            | 182      |
| total timesteps         | 15592    |
| train_time              | 0        |
| update_time             | 153      |
--------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.29        |
| env_time                | 19          |
| ep_rewmean              | 17.7        |
| episodes                | 716         |
| eplenmean               | 22.3        |
| fps                     | 84          |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 5.07        |
| qs_difference           | -5.07       |
| qs_mean                 | -0.32730702 |
| time_elapsed            | 185         |
| total timesteps         | 15690       |
| train_time              | 0           |
| update_time             | 155         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 2.54        |
| env_time                | 20          |
| ep_rewmean              | 19.2        |
| episodes                | 720         |
| eplenmean               | 22.9        |
| fps                     | 83          |
| mean 100 episode reward | 19.2        |
| n_updates               | 0           |
| qs_abs_difference       | 3.04        |
| qs_difference           | -3.01       |
| qs_mean                 | -0.48507547 |
| time_elapsed            | 189         |
| total timesteps         | 15822       |
| train_time              | 0           |
| update_time             | 159         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 13.5        |
| env_time                | 20          |
| ep_rewmean              | 18.9        |
| episodes                | 724         |
| eplenmean               | 22.8        |
| fps                     | 83          |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 7.67        |
| qs_difference           | -7.54       |
| qs_mean                 | -0.14155896 |
| time_elapsed            | 191         |
| total timesteps         | 15917       |
| train_time              | 0           |
| update_time             | 161         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.52        |
| env_time                | 20          |
| ep_rewmean              | 19.1        |
| episodes                | 728         |
| eplenmean               | 22.7        |
| fps                     | 82          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 4.15        |
| qs_difference           | -4.15       |
| qs_mean                 | -0.09984572 |
| time_elapsed            | 193         |
| total timesteps         | 16005       |
| train_time              | 0           |
| update_time             | 163         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 6.38         |
| env_time                | 20           |
| ep_rewmean              | 19.1         |
| episodes                | 732          |
| eplenmean               | 22.7         |
| fps                     | 83           |
| mean 100 episode reward | 19.1         |
| n_updates               | 0            |
| qs_abs_difference       | 7.46         |
| qs_difference           | -7.46        |
| qs_mean                 | -0.096605584 |
| time_elapsed            | 193          |
| total timesteps         | 16088        |
| train_time              | 0            |
| update_time             | 163          |
------------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 5.42         |
| env_time                | 20           |
| ep_rewmean              | 18.8         |
| episodes                | 736          |
| eplenmean               | 22.4         |
| fps                     | 82           |
| mean 100 episode reward | 18.8         |
| n_updates               | 0            |
| qs_abs_difference       | 4.74         |
| qs_difference           | -4.73        |
| qs_mean                 | -0.086042374 |
| time_elapsed            | 195          |
| total timesteps         | 16166        |
| train_time              | 0            |
| update_time             | 165          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.67        |
| env_time                | 20          |
| ep_rewmean              | 19          |
| episodes                | 740         |
| eplenmean               | 22.4        |
| fps                     | 82          |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 9.82        |
| qs_difference           | -9.82       |
| qs_mean                 | 0.026756661 |
| time_elapsed            | 198         |
| total timesteps         | 16263       |
| train_time              | 0           |
| update_time             | 167         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 7.57         |
| env_time                | 20           |
| ep_rewmean              | 18.9         |
| episodes                | 744          |
| eplenmean               | 22.4         |
| fps                     | 81           |
| mean 100 episode reward | 18.9         |
| n_updates               | 0            |
| qs_abs_difference       | 3.78         |
| qs_difference           | -3.35        |
| qs_mean                 | -0.011136942 |
| time_elapsed            | 200          |
| total timesteps         | 16332        |
| train_time              | 0            |
| update_time             | 170          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.39        |
| env_time                | 20          |
| ep_rewmean              | 19.1        |
| episodes                | 748         |
| eplenmean               | 22.5        |
| fps                     | 81          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 7.64        |
| qs_difference           | -7.64       |
| qs_mean                 | -0.19407566 |
| time_elapsed            | 202         |
| total timesteps         | 16409       |
| train_time              | 0           |
| update_time             | 172         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.13       |
| env_time                | 20         |
| ep_rewmean              | 19.1       |
| episodes                | 752        |
| eplenmean               | 22.5       |
| fps                     | 81         |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.95       |
| qs_difference           | -5.95      |
| qs_mean                 | 0.08288816 |
| time_elapsed            | 202        |
| total timesteps         | 16498      |
| train_time              | 0          |
| update_time             | 172        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.37        |
| env_time                | 20          |
| ep_rewmean              | 19.1        |
| episodes                | 756         |
| eplenmean               | 22.4        |
| fps                     | 80          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 4.46        |
| qs_difference           | -4.46       |
| qs_mean                 | 0.026278533 |
| time_elapsed            | 204         |
| total timesteps         | 16578       |
| train_time              | 0           |
| update_time             | 174         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.77        |
| env_time                | 21          |
| ep_rewmean              | 19.1        |
| episodes                | 760         |
| eplenmean               | 22.4        |
| fps                     | 80          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 3.72        |
| qs_difference           | -3.72       |
| qs_mean                 | -0.39235407 |
| time_elapsed            | 207         |
| total timesteps         | 16646       |
| train_time              | 0           |
| update_time             | 176         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 29.1        |
| env_time                | 21          |
| ep_rewmean              | 19.6        |
| episodes                | 764         |
| eplenmean               | 22.7        |
| fps                     | 79          |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 27.1        |
| qs_difference           | -27.1       |
| qs_mean                 | -0.28497058 |
| time_elapsed            | 209         |
| total timesteps         | 16755       |
| train_time              | 0           |
| update_time             | 178         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 13.9         |
| env_time                | 21           |
| ep_rewmean              | 19.3         |
| episodes                | 768          |
| eplenmean               | 22.4         |
| fps                     | 79           |
| mean 100 episode reward | 19.3         |
| n_updates               | 0            |
| qs_abs_difference       | 9.19         |
| qs_difference           | -9.17        |
| qs_mean                 | -0.056257833 |
| time_elapsed            | 211          |
| total timesteps         | 16844        |
| train_time              | 0            |
| update_time             | 180          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.9         |
| env_time                | 21          |
| ep_rewmean              | 19.1        |
| episodes                | 772         |
| eplenmean               | 22.3        |
| fps                     | 78          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 4.28        |
| qs_difference           | -4.26       |
| qs_mean                 | 0.081356056 |
| time_elapsed            | 214         |
| total timesteps         | 16911       |
| train_time              | 0           |
| update_time             | 182         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 2.29        |
| env_time                | 21          |
| ep_rewmean              | 19          |
| episodes                | 776         |
| eplenmean               | 22.2        |
| fps                     | 79          |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 2.01        |
| qs_difference           | 0.755       |
| qs_mean                 | -0.31526387 |
| time_elapsed            | 214         |
| total timesteps         | 16993       |
| train_time              | 0           |
| update_time             | 182         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.52        |
| env_time                | 21          |
| ep_rewmean              | 18.9        |
| episodes                | 780         |
| eplenmean               | 22.2        |
| fps                     | 78          |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 3.54        |
| qs_difference           | -1.36       |
| qs_mean                 | -0.15506743 |
| time_elapsed            | 216         |
| total timesteps         | 17084       |
| train_time              | 0           |
| update_time             | 185         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 11.4        |
| env_time                | 21          |
| ep_rewmean              | 18.2        |
| episodes                | 784         |
| eplenmean               | 21.9        |
| fps                     | 78          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 11.3        |
| qs_difference           | -11.3       |
| qs_mean                 | -0.03550758 |
| time_elapsed            | 219         |
| total timesteps         | 17156       |
| train_time              | 0           |
| update_time             | 187         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 9.5         |
| env_time                | 21          |
| ep_rewmean              | 18.5        |
| episodes                | 788         |
| eplenmean               | 22          |
| fps                     | 77          |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 8.95        |
| qs_difference           | -8.95       |
| qs_mean                 | 0.027142907 |
| time_elapsed            | 221         |
| total timesteps         | 17249       |
| train_time              | 0           |
| update_time             | 189         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.3         |
| env_time                | 21          |
| ep_rewmean              | 18.3        |
| episodes                | 792         |
| eplenmean               | 21.8        |
| fps                     | 77          |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 5.26        |
| qs_difference           | -5.24       |
| qs_mean                 | 0.035010148 |
| time_elapsed            | 223         |
| total timesteps         | 17322       |
| train_time              | 0           |
| update_time             | 191         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 8.42         |
| env_time                | 22           |
| ep_rewmean              | 17.6         |
| episodes                | 796          |
| eplenmean               | 21.6         |
| fps                     | 77           |
| mean 100 episode reward | 17.6         |
| n_updates               | 0            |
| qs_abs_difference       | 7.93         |
| qs_difference           | -7.93        |
| qs_mean                 | -0.039451215 |
| time_elapsed            | 226          |
| total timesteps         | 17417        |
| train_time              | 0            |
| update_time             | 193          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.24        |
| env_time                | 22          |
| ep_rewmean              | 17.1        |
| episodes                | 800         |
| eplenmean               | 21.3        |
| fps                     | 77          |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 2.87        |
| qs_difference           | -2.87       |
| qs_mean                 | -0.18381351 |
| time_elapsed            | 226         |
| total timesteps         | 17485       |
| train_time              | 0           |
| update_time             | 193         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 5.72         |
| env_time                | 22           |
| ep_rewmean              | 17           |
| episodes                | 804          |
| eplenmean               | 21.3         |
| fps                     | 76           |
| mean 100 episode reward | 17           |
| n_updates               | 0            |
| qs_abs_difference       | 4.06         |
| qs_difference           | -3.37        |
| qs_mean                 | -0.022765182 |
| time_elapsed            | 228          |
| total timesteps         | 17577        |
| train_time              | 0            |
| update_time             | 196          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.96        |
| env_time                | 22          |
| ep_rewmean              | 17.4        |
| episodes                | 808         |
| eplenmean               | 21.9        |
| fps                     | 75          |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 8.14        |
| qs_difference           | -8.14       |
| qs_mean                 | -0.49317414 |
| time_elapsed            | 233         |
| total timesteps         | 17705       |
| train_time              | 0           |
| update_time             | 200         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.56        |
| env_time                | 22          |
| ep_rewmean              | 17.2        |
| episodes                | 812         |
| eplenmean               | 21.7        |
| fps                     | 76          |
| mean 100 episode reward | 17.2        |
| n_updates               | 0           |
| qs_abs_difference       | 5.53        |
| qs_difference           | -5.53       |
| qs_mean                 | -0.09713687 |
| time_elapsed            | 233         |
| total timesteps         | 17766       |
| train_time              | 0           |
| update_time             | 200         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 16.3        |
| env_time                | 22          |
| ep_rewmean              | 17.5        |
| episodes                | 816         |
| eplenmean               | 21.7        |
| fps                     | 75          |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 17.6        |
| qs_difference           | -17.6       |
| qs_mean                 | -0.20835164 |
| time_elapsed            | 235         |
| total timesteps         | 17858       |
| train_time              | 0           |
| update_time             | 202         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.24       |
| env_time                | 22         |
| ep_rewmean              | 16.2       |
| episodes                | 820        |
| eplenmean               | 21.2       |
| fps                     | 75         |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 6.4        |
| qs_difference           | -6.36      |
| qs_mean                 | 0.07657491 |
| time_elapsed            | 238        |
| total timesteps         | 17947      |
| train_time              | 0          |
| update_time             | 205        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 25.3        |
| env_time                | 22          |
| ep_rewmean              | 16.7        |
| episodes                | 824         |
| eplenmean               | 21.4        |
| fps                     | 74          |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 18.4        |
| qs_difference           | -18.4       |
| qs_mean                 | -0.15823038 |
| time_elapsed            | 240         |
| total timesteps         | 18053       |
| train_time              | 0           |
| update_time             | 207         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.02        |
| env_time                | 22          |
| ep_rewmean              | 16.4        |
| episodes                | 828         |
| eplenmean               | 21.4        |
| fps                     | 74          |
| mean 100 episode reward | 16.4        |
| n_updates               | 0           |
| qs_abs_difference       | 2.98        |
| qs_difference           | -2.98       |
| qs_mean                 | -0.18599877 |
| time_elapsed            | 243         |
| total timesteps         | 18142       |
| train_time              | 0           |
| update_time             | 209         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.54       |
| env_time                | 23         |
| ep_rewmean              | 16.7       |
| episodes                | 832        |
| eplenmean               | 21.5       |
| fps                     | 74         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 6.96       |
| qs_difference           | -6.96      |
| qs_mean                 | -0.3991105 |
| time_elapsed            | 245        |
| total timesteps         | 18238      |
| train_time              | 0          |
| update_time             | 212        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.75        |
| env_time                | 23          |
| ep_rewmean              | 16.9        |
| episodes                | 836         |
| eplenmean               | 22          |
| fps                     | 73          |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 3.13        |
| qs_difference           | -2.75       |
| qs_mean                 | -0.35123792 |
| time_elapsed            | 248         |
| total timesteps         | 18363       |
| train_time              | 0           |
| update_time             | 214         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.96        |
| env_time                | 23          |
| ep_rewmean              | 16.8        |
| episodes                | 840         |
| eplenmean               | 22.1        |
| fps                     | 73          |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 9.23        |
| qs_difference           | -9.23       |
| qs_mean                 | -0.14340872 |
| time_elapsed            | 250         |
| total timesteps         | 18468       |
| train_time              | 0           |
| update_time             | 216         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 5.06         |
| env_time                | 23           |
| ep_rewmean              | 16.7         |
| episodes                | 844          |
| eplenmean               | 21.9         |
| fps                     | 73           |
| mean 100 episode reward | 16.7         |
| n_updates               | 0            |
| qs_abs_difference       | 3.8          |
| qs_difference           | -3.8         |
| qs_mean                 | -0.121225975 |
| time_elapsed            | 253          |
| total timesteps         | 18518        |
| train_time              | 0            |
| update_time             | 219          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.34        |
| env_time                | 23          |
| ep_rewmean              | 16.5        |
| episodes                | 848         |
| eplenmean               | 21.7        |
| fps                     | 73          |
| mean 100 episode reward | 16.5        |
| n_updates               | 0           |
| qs_abs_difference       | 5.04        |
| qs_difference           | -5.04       |
| qs_mean                 | 0.014344713 |
| time_elapsed            | 253         |
| total timesteps         | 18576       |
| train_time              | 0           |
| update_time             | 219         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.31        |
| env_time                | 23          |
| ep_rewmean              | 16.2        |
| episodes                | 852         |
| eplenmean               | 21.3        |
| fps                     | 72          |
| mean 100 episode reward | 16.2        |
| n_updates               | 0           |
| qs_abs_difference       | 4.27        |
| qs_difference           | -4.27       |
| qs_mean                 | -0.42806295 |
| time_elapsed            | 255         |
| total timesteps         | 18632       |
| train_time              | 0           |
| update_time             | 221         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.4        |
| env_time                | 23         |
| ep_rewmean              | 16.1       |
| episodes                | 856        |
| eplenmean               | 21.3       |
| fps                     | 72         |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 6.13       |
| qs_difference           | -6.13      |
| qs_mean                 | -0.2892393 |
| time_elapsed            | 258        |
| total timesteps         | 18712      |
| train_time              | 0          |
| update_time             | 223        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.73        |
| env_time                | 23          |
| ep_rewmean              | 16.2        |
| episodes                | 860         |
| eplenmean               | 21.4        |
| fps                     | 72          |
| mean 100 episode reward | 16.2        |
| n_updates               | 0           |
| qs_abs_difference       | 6.31        |
| qs_difference           | -6.31       |
| qs_mean                 | -0.14339928 |
| time_elapsed            | 258         |
| total timesteps         | 18791       |
| train_time              | 0           |
| update_time             | 223         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 2.85        |
| env_time                | 23          |
| ep_rewmean              | 16.2        |
| episodes                | 864         |
| eplenmean               | 21.7        |
| fps                     | 71          |
| mean 100 episode reward | 16.2        |
| n_updates               | 0           |
| qs_abs_difference       | 4.4         |
| qs_difference           | -4.4        |
| qs_mean                 | -0.41904345 |
| time_elapsed            | 263         |
| total timesteps         | 18925       |
| train_time              | 0           |
| update_time             | 228         |
-----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 4.54      |
| env_time                | 23        |
| ep_rewmean              | 16.1      |
| episodes                | 868       |
| eplenmean               | 21.4      |
| fps                     | 71        |
| mean 100 episode reward | 16.1      |
| n_updates               | 0         |
| qs_abs_difference       | 2.72      |
| qs_difference           | -2.62     |
| qs_mean                 | 0.3060092 |
| time_elapsed            | 263       |
| total timesteps         | 18980     |
| train_time              | 0         |
| update_time             | 228       |
---------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 5.39         |
| env_time                | 24           |
| ep_rewmean              | 16.2         |
| episodes                | 872          |
| eplenmean               | 21.4         |
| fps                     | 71           |
| mean 100 episode reward | 16.2         |
| n_updates               | 0            |
| qs_abs_difference       | 4.11         |
| qs_difference           | -4.11        |
| qs_mean                 | -0.072665416 |
| time_elapsed            | 266          |
| total timesteps         | 19052        |
| train_time              | 0            |
| update_time             | 231          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 7.13        |
| env_time                | 24          |
| ep_rewmean              | 16          |
| episodes                | 876         |
| eplenmean               | 21.4        |
| fps                     | 71          |
| mean 100 episode reward | 16          |
| n_updates               | 0           |
| qs_abs_difference       | 7.37        |
| qs_difference           | -7.37       |
| qs_mean                 | -0.00272367 |
| time_elapsed            | 268         |
| total timesteps         | 19129       |
| train_time              | 0           |
| update_time             | 233         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.16       |
| env_time                | 24         |
| ep_rewmean              | 16.1       |
| episodes                | 880        |
| eplenmean               | 21.2       |
| fps                     | 70         |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 6.64       |
| qs_difference           | -6.64      |
| qs_mean                 | 0.22521782 |
| time_elapsed            | 271        |
| total timesteps         | 19201      |
| train_time              | 0          |
| update_time             | 236        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.74       |
| env_time                | 24         |
| ep_rewmean              | 16.2       |
| episodes                | 884        |
| eplenmean               | 21.2       |
| fps                     | 71         |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 3.65       |
| qs_difference           | -2.92      |
| qs_mean                 | 0.03129771 |
| time_elapsed            | 271        |
| total timesteps         | 19281      |
| train_time              | 0          |
| update_time             | 236        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 2.43        |
| env_time                | 24          |
| ep_rewmean              | 17.9        |
| episodes                | 888         |
| eplenmean               | 21.7        |
| fps                     | 70          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 4.77        |
| qs_difference           | -4.77       |
| qs_mean                 | -0.30483648 |
| time_elapsed            | 276         |
| total timesteps         | 19418       |
| train_time              | 0           |
| update_time             | 240         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.05        |
| env_time                | 24          |
| ep_rewmean              | 17.8        |
| episodes                | 892         |
| eplenmean               | 21.6        |
| fps                     | 70          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 2.23        |
| qs_difference           | -2.22       |
| qs_mean                 | 0.048586935 |
| time_elapsed            | 276         |
| total timesteps         | 19486       |
| train_time              | 0           |
| update_time             | 240         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.12        |
| env_time                | 24          |
| ep_rewmean              | 17.7        |
| episodes                | 896         |
| eplenmean               | 21.6        |
| fps                     | 70          |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 6.63        |
| qs_difference           | -6.63       |
| qs_mean                 | -0.18649772 |
| time_elapsed            | 279         |
| total timesteps         | 19582       |
| train_time              | 0           |
| update_time             | 243         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 27.6         |
| env_time                | 24           |
| ep_rewmean              | 18.6         |
| episodes                | 900          |
| eplenmean               | 22.2         |
| fps                     | 69           |
| mean 100 episode reward | 18.6         |
| n_updates               | 0            |
| qs_abs_difference       | 35.8         |
| qs_difference           | -35.8        |
| qs_mean                 | -0.008872945 |
| time_elapsed            | 284          |
| total timesteps         | 19705        |
| train_time              | 0            |
| update_time             | 248          |
------------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 6.58         |
| env_time                | 24           |
| ep_rewmean              | 18.4         |
| episodes                | 904          |
| eplenmean               | 22           |
| fps                     | 69           |
| mean 100 episode reward | 18.4         |
| n_updates               | 0            |
| qs_abs_difference       | 3.77         |
| qs_difference           | -3.66        |
| qs_mean                 | -0.041365493 |
| time_elapsed            | 284          |
| total timesteps         | 19776        |
| train_time              | 0            |
| update_time             | 248          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 7.94        |
| env_time                | 25          |
| ep_rewmean              | 18          |
| episodes                | 908         |
| eplenmean               | 21.5        |
| fps                     | 69          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 8.35        |
| qs_difference           | -8.35       |
| qs_mean                 | -0.07888595 |
| time_elapsed            | 287         |
| total timesteps         | 19857       |
| train_time              | 0           |
| update_time             | 250         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 6.53         |
| env_time                | 25           |
| ep_rewmean              | 18.3         |
| episodes                | 912          |
| eplenmean               | 21.8         |
| fps                     | 68           |
| mean 100 episode reward | 18.3         |
| n_updates               | 0            |
| qs_abs_difference       | 6.79         |
| qs_difference           | -6.79        |
| qs_mean                 | -0.060435895 |
| time_elapsed            | 290          |
| total timesteps         | 19944        |
| train_time              | 0            |
| update_time             | 253          |
------------------------------------------
----------------------------------------
| eval mean 100 episod... | 0.6        |
| eval_abs_qs_difference  | 0.65191704 |
| eval_discount_q         | 0.793      |
| eval_ep_rewmean         | 0.593      |
| eval_eplenmean          | 11         |
| eval_qs                 | -1.7823691 |
| eval_qs_difference      | -0.0379    |
| eval_time_elapsed       | 0          |
| total timesteps         | 20001      |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 8.82       |
| env_time                | 25         |
| ep_rewmean              | 17.9       |
| episodes                | 916        |
| eplenmean               | 21.6       |
| fps                     | 68         |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 7.75       |
| qs_difference           | -7.75      |
| qs_mean                 | -0.3862542 |
| time_elapsed            | 293        |
| total timesteps         | 20022      |
| train_time              | 0          |
| update_time             | 256        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.75        |
| env_time                | 25          |
| ep_rewmean              | 18.2        |
| episodes                | 920         |
| eplenmean               | 22.1        |
| fps                     | 68          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 7.4         |
| qs_difference           | -7.4        |
| qs_mean                 | -0.05847412 |
| time_elapsed            | 295         |
| total timesteps         | 20156       |
| train_time              | 0           |
| update_time             | 258         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 9.25        |
| env_time                | 25          |
| ep_rewmean              | 18.2        |
| episodes                | 924         |
| eplenmean               | 22.1        |
| fps                     | 67          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 11.7        |
| qs_difference           | -11.7       |
| qs_mean                 | -0.47486866 |
| time_elapsed            | 298         |
| total timesteps         | 20264       |
| train_time              | 0           |
| update_time             | 261         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 2.72        |
| env_time                | 25          |
| ep_rewmean              | 18.2        |
| episodes                | 928         |
| eplenmean               | 21.9        |
| fps                     | 67          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 2.17        |
| qs_difference           | -2.14       |
| qs_mean                 | -0.48221698 |
| time_elapsed            | 301         |
| total timesteps         | 20327       |
| train_time              | 0           |
| update_time             | 263         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 10           |
| env_time                | 25           |
| ep_rewmean              | 17.8         |
| episodes                | 932          |
| eplenmean               | 21.6         |
| fps                     | 67           |
| mean 100 episode reward | 17.8         |
| n_updates               | 0            |
| qs_abs_difference       | 8.21         |
| qs_difference           | -8.21        |
| qs_mean                 | -0.118250094 |
| time_elapsed            | 304          |
| total timesteps         | 20402        |
| train_time              | 0            |
| update_time             | 266          |
------------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 8.05         |
| env_time                | 25           |
| ep_rewmean              | 17.6         |
| episodes                | 936          |
| eplenmean               | 21.2         |
| fps                     | 67           |
| mean 100 episode reward | 17.6         |
| n_updates               | 0            |
| qs_abs_difference       | 8.42         |
| qs_difference           | -8.42        |
| qs_mean                 | -0.070495725 |
| time_elapsed            | 304          |
| total timesteps         | 20487        |
| train_time              | 0            |
| update_time             | 266          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 8.27        |
| env_time                | 25          |
| ep_rewmean              | 17.2        |
| episodes                | 940         |
| eplenmean               | 20.9        |
| fps                     | 66          |
| mean 100 episode reward | 17.2        |
| n_updates               | 0           |
| qs_abs_difference       | 8.67        |
| qs_difference           | -8.67       |
| qs_mean                 | -0.28349662 |
| time_elapsed            | 306         |
| total timesteps         | 20563       |
| train_time              | 0           |
| update_time             | 268         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.73        |
| env_time                | 25          |
| ep_rewmean              | 17.4        |
| episodes                | 944         |
| eplenmean               | 21.2        |
| fps                     | 66          |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 4.12        |
| qs_difference           | -4.12       |
| qs_mean                 | -0.36497957 |
| time_elapsed            | 309         |
| total timesteps         | 20634       |
| train_time              | 0           |
| update_time             | 271         |
-----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 4.93      |
| env_time                | 26        |
| ep_rewmean              | 18        |
| episodes                | 948       |
| eplenmean               | 21.7      |
| fps                     | 66        |
| mean 100 episode reward | 18        |
| n_updates               | 0         |
| qs_abs_difference       | 6.42      |
| qs_difference           | -6.42     |
| qs_mean                 | -0.252568 |
| time_elapsed            | 312       |
| total timesteps         | 20743     |
| train_time              | 0         |
| update_time             | 274       |
---------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.11        |
| env_time                | 26          |
| ep_rewmean              | 18          |
| episodes                | 952         |
| eplenmean               | 21.7        |
| fps                     | 65          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 2.67        |
| qs_difference           | -2.67       |
| qs_mean                 | -0.27574366 |
| time_elapsed            | 315         |
| total timesteps         | 20804       |
| train_time              | 0           |
| update_time             | 276         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 10.3        |
| env_time                | 26          |
| ep_rewmean              | 18          |
| episodes                | 956         |
| eplenmean               | 21.6        |
| fps                     | 66          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 6.96        |
| qs_difference           | -6.95       |
| qs_mean                 | -0.13408013 |
| time_elapsed            | 315         |
| total timesteps         | 20873       |
| train_time              | 0           |
| update_time             | 276         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 7.04        |
| env_time                | 26          |
| ep_rewmean              | 17.9        |
| episodes                | 960         |
| eplenmean               | 21.6        |
| fps                     | 65          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 5.91        |
| qs_difference           | -5.91       |
| qs_mean                 | -0.16824546 |
| time_elapsed            | 318         |
| total timesteps         | 20948       |
| train_time              | 0           |
| update_time             | 279         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.64        |
| env_time                | 26          |
| ep_rewmean              | 17.3        |
| episodes                | 964         |
| eplenmean               | 20.8        |
| fps                     | 65          |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 4.63        |
| qs_difference           | -4.63       |
| qs_mean                 | -0.37479764 |
| time_elapsed            | 321         |
| total timesteps         | 21005       |
| train_time              | 0           |
| update_time             | 282         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 10.3       |
| env_time                | 26         |
| ep_rewmean              | 17.3       |
| episodes                | 968        |
| eplenmean               | 20.9       |
| fps                     | 65         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 9.07       |
| qs_difference           | -9.07      |
| qs_mean                 | -0.4166898 |
| time_elapsed            | 321        |
| total timesteps         | 21072      |
| train_time              | 0          |
| update_time             | 282        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.83        |
| env_time                | 26          |
| ep_rewmean              | 17.3        |
| episodes                | 972         |
| eplenmean               | 20.9        |
| fps                     | 65          |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 2.77        |
| qs_difference           | -2.26       |
| qs_mean                 | 0.011890702 |
| time_elapsed            | 324         |
| total timesteps         | 21138       |
| train_time              | 0           |
| update_time             | 284         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 14.8        |
| env_time                | 26          |
| ep_rewmean              | 19.1        |
| episodes                | 976         |
| eplenmean               | 22          |
| fps                     | 64          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 36.2        |
| qs_difference           | -36.2       |
| qs_mean                 | -0.18260393 |
| time_elapsed            | 329         |
| total timesteps         | 21326       |
| train_time              | 0           |
| update_time             | 290         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.12       |
| env_time                | 26         |
| ep_rewmean              | 18.9       |
| episodes                | 980        |
| eplenmean               | 21.7       |
| fps                     | 64         |
| mean 100 episode reward | 18.9       |
| n_updates               | 0          |
| qs_abs_difference       | 2.46       |
| qs_difference           | -2.46      |
| qs_mean                 | -0.1453675 |
| time_elapsed            | 329        |
| total timesteps         | 21373      |
| train_time              | 0          |
| update_time             | 290        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 8.19        |
| env_time                | 27          |
| ep_rewmean              | 19.2        |
| episodes                | 984         |
| eplenmean               | 21.9        |
| fps                     | 64          |
| mean 100 episode reward | 19.2        |
| n_updates               | 0           |
| qs_abs_difference       | 9.88        |
| qs_difference           | -9.88       |
| qs_mean                 | 0.018960766 |
| time_elapsed            | 332         |
| total timesteps         | 21468       |
| train_time              | 0           |
| update_time             | 293         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 8.55       |
| env_time                | 27         |
| ep_rewmean              | 17.3       |
| episodes                | 988        |
| eplenmean               | 21.2       |
| fps                     | 64         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 7.32       |
| qs_difference           | -7.32      |
| qs_mean                 | -0.3825648 |
| time_elapsed            | 335        |
| total timesteps         | 21542      |
| train_time              | 0          |
| update_time             | 295        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.55        |
| env_time                | 27          |
| ep_rewmean              | 17.5        |
| episodes                | 992         |
| eplenmean               | 21.4        |
| fps                     | 63          |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 3.74        |
| qs_difference           | -3.74       |
| qs_mean                 | 0.111795925 |
| time_elapsed            | 338         |
| total timesteps         | 21630       |
| train_time              | 0           |
| update_time             | 298         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.61        |
| env_time                | 27          |
| ep_rewmean              | 17.4        |
| episodes                | 996         |
| eplenmean               | 21.3        |
| fps                     | 63          |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 4.86        |
| qs_difference           | -4.86       |
| qs_mean                 | -0.33055738 |
| time_elapsed            | 341         |
| total timesteps         | 21715       |
| train_time              | 0           |
| update_time             | 301         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.05       |
| env_time                | 27         |
| ep_rewmean              | 17.5       |
| episodes                | 1000       |
| eplenmean               | 21.1       |
| fps                     | 63         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.34       |
| qs_difference           | -3.34      |
| qs_mean                 | 0.12415535 |
| time_elapsed            | 344        |
| total timesteps         | 21818      |
| train_time              | 0          |
| update_time             | 304        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.95        |
| env_time                | 27          |
| ep_rewmean              | 18.3        |
| episodes                | 1004        |
| eplenmean               | 21.5        |
| fps                     | 63          |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 2.84        |
| qs_difference           | -2.7        |
| qs_mean                 | -0.13888828 |
| time_elapsed            | 347         |
| total timesteps         | 21928       |
| train_time              | 0           |
| update_time             | 306         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 19          |
| env_time                | 27          |
| ep_rewmean              | 18.5        |
| episodes                | 1008        |
| eplenmean               | 21.7        |
| fps                     | 62          |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 15.3        |
| qs_difference           | -15.3       |
| qs_mean                 | -0.12542509 |
| time_elapsed            | 350         |
| total timesteps         | 22027       |
| train_time              | 0           |
| update_time             | 309         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 13.2        |
| env_time                | 27          |
| ep_rewmean              | 18.6        |
| episodes                | 1012        |
| eplenmean               | 21.8        |
| fps                     | 62          |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 14.8        |
| qs_difference           | -14.8       |
| qs_mean                 | -0.28838956 |
| time_elapsed            | 353         |
| total timesteps         | 22126       |
| train_time              | 0           |
| update_time             | 312         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.48        |
| env_time                | 28          |
| ep_rewmean              | 18.7        |
| episodes                | 1016        |
| eplenmean               | 21.9        |
| fps                     | 62          |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 4.95        |
| qs_difference           | -4.95       |
| qs_mean                 | -0.35238153 |
| time_elapsed            | 356         |
| total timesteps         | 22211       |
| train_time              | 0           |
| update_time             | 315         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 14.3         |
| env_time                | 28           |
| ep_rewmean              | 18.4         |
| episodes                | 1020         |
| eplenmean               | 21.4         |
| fps                     | 62           |
| mean 100 episode reward | 18.4         |
| n_updates               | 0            |
| qs_abs_difference       | 11.7         |
| qs_difference           | -11.7        |
| qs_mean                 | -0.050095953 |
| time_elapsed            | 359          |
| total timesteps         | 22300        |
| train_time              | 0            |
| update_time             | 318          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 2.46        |
| env_time                | 28          |
| ep_rewmean              | 18.2        |
| episodes                | 1024        |
| eplenmean               | 21.4        |
| fps                     | 61          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 3.22        |
| qs_difference           | -3.22       |
| qs_mean                 | -0.14869583 |
| time_elapsed            | 362         |
| total timesteps         | 22400       |
| train_time              | 0           |
| update_time             | 321         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 8.05        |
| env_time                | 28          |
| ep_rewmean              | 18.2        |
| episodes                | 1028        |
| eplenmean               | 21.6        |
| fps                     | 62          |
| mean 100 episode reward | 18.2        |
| n_updates               | 0           |
| qs_abs_difference       | 8.69        |
| qs_difference           | -8.69       |
| qs_mean                 | -0.18174273 |
| time_elapsed            | 362         |
| total timesteps         | 22484       |
| train_time              | 0           |
| update_time             | 321         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.95       |
| env_time                | 28         |
| ep_rewmean              | 18.2       |
| episodes                | 1032       |
| eplenmean               | 21.6       |
| fps                     | 61         |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 5.13       |
| qs_difference           | -5.11      |
| qs_mean                 | -0.1823558 |
| time_elapsed            | 365        |
| total timesteps         | 22561      |
| train_time              | 0          |
| update_time             | 323        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.53        |
| env_time                | 28          |
| ep_rewmean              | 19.5        |
| episodes                | 1036        |
| eplenmean               | 22.5        |
| fps                     | 61          |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 8.55        |
| qs_difference           | -8.18       |
| qs_mean                 | -0.21546543 |
| time_elapsed            | 371         |
| total timesteps         | 22741       |
| train_time              | 0           |
| update_time             | 329         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 10.8        |
| env_time                | 28          |
| ep_rewmean              | 20.9        |
| episodes                | 1040        |
| eplenmean               | 23.5        |
| fps                     | 60          |
| mean 100 episode reward | 20.9        |
| n_updates               | 0           |
| qs_abs_difference       | 21          |
| qs_difference           | -21         |
| qs_mean                 | -0.32439107 |
| time_elapsed            | 377         |
| total timesteps         | 22912       |
| train_time              | 0           |
| update_time             | 335         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.92       |
| env_time                | 28         |
| ep_rewmean              | 21.2       |
| episodes                | 1044       |
| eplenmean               | 23.8       |
| fps                     | 60         |
| mean 100 episode reward | 21.2       |
| n_updates               | 0          |
| qs_abs_difference       | 6.86       |
| qs_difference           | -6.86      |
| qs_mean                 | -0.2829806 |
| time_elapsed            | 380        |
| total timesteps         | 23015      |
| train_time              | 0          |
| update_time             | 338        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.69       |
| env_time                | 29         |
| ep_rewmean              | 20.5       |
| episodes                | 1048       |
| eplenmean               | 23.5       |
| fps                     | 60         |
| mean 100 episode reward | 20.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.57       |
| qs_difference           | -3.57      |
| qs_mean                 | -0.3742486 |
| time_elapsed            | 380        |
| total timesteps         | 23090      |
| train_time              | 0          |
| update_time             | 338        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 2.91       |
| env_time                | 29         |
| ep_rewmean              | 21.8       |
| episodes                | 1052       |
| eplenmean               | 24.4       |
| fps                     | 60         |
| mean 100 episode reward | 21.8       |
| n_updates               | 0          |
| qs_abs_difference       | 6.03       |
| qs_difference           | -6.03      |
| qs_mean                 | 0.08114483 |
| time_elapsed            | 387        |
| total timesteps         | 23244      |
| train_time              | 0          |
| update_time             | 344        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.42        |
| env_time                | 29          |
| ep_rewmean              | 22          |
| episodes                | 1056        |
| eplenmean               | 24.5        |
| fps                     | 59          |
| mean 100 episode reward | 22          |
| n_updates               | 0           |
| qs_abs_difference       | 5.96        |
| qs_difference           | -5.96       |
| qs_mean                 | -0.18363723 |
| time_elapsed            | 390         |
| total timesteps         | 23320       |
| train_time              | 0           |
| update_time             | 347         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.51        |
| env_time                | 29          |
| ep_rewmean              | 22.2        |
| episodes                | 1060        |
| eplenmean               | 24.7        |
| fps                     | 59          |
| mean 100 episode reward | 22.2        |
| n_updates               | 0           |
| qs_abs_difference       | 5.75        |
| qs_difference           | -5.75       |
| qs_mean                 | -0.16680095 |
| time_elapsed            | 393         |
| total timesteps         | 23418       |
| train_time              | 0           |
| update_time             | 350         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.09        |
| env_time                | 29          |
| ep_rewmean              | 22.7        |
| episodes                | 1064        |
| eplenmean               | 25.2        |
| fps                     | 59          |
| mean 100 episode reward | 22.7        |
| n_updates               | 0           |
| qs_abs_difference       | 7.29        |
| qs_difference           | -7.29       |
| qs_mean                 | -0.11944389 |
| time_elapsed            | 396         |
| total timesteps         | 23525       |
| train_time              | 0           |
| update_time             | 353         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 1.96        |
| env_time                | 29          |
| ep_rewmean              | 23.6        |
| episodes                | 1068        |
| eplenmean               | 25.7        |
| fps                     | 59          |
| mean 100 episode reward | 23.6        |
| n_updates               | 0           |
| qs_abs_difference       | 3.1         |
| qs_difference           | -3.1        |
| qs_mean                 | -0.11513117 |
| time_elapsed            | 399         |
| total timesteps         | 23645       |
| train_time              | 0           |
| update_time             | 356         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.13        |
| env_time                | 29          |
| ep_rewmean              | 23.7        |
| episodes                | 1072        |
| eplenmean               | 25.8        |
| fps                     | 58          |
| mean 100 episode reward | 23.7        |
| n_updates               | 0           |
| qs_abs_difference       | 5.4         |
| qs_difference           | -5.4        |
| qs_mean                 | 0.083319135 |
| time_elapsed            | 402         |
| total timesteps         | 23719       |
| train_time              | 0           |
| update_time             | 359         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.13        |
| env_time                | 29          |
| ep_rewmean              | 21.7        |
| episodes                | 1076        |
| eplenmean               | 24.6        |
| fps                     | 59          |
| mean 100 episode reward | 21.7        |
| n_updates               | 0           |
| qs_abs_difference       | 4.25        |
| qs_difference           | -4.24       |
| qs_mean                 | -0.30908012 |
| time_elapsed            | 402         |
| total timesteps         | 23785       |
| train_time              | 0           |
| update_time             | 359         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 14.9        |
| env_time                | 30          |
| ep_rewmean              | 22.2        |
| episodes                | 1080        |
| eplenmean               | 25.3        |
| fps                     | 58          |
| mean 100 episode reward | 22.2        |
| n_updates               | 0           |
| qs_abs_difference       | 18.9        |
| qs_difference           | -18.9       |
| qs_mean                 | -0.06013213 |
| time_elapsed            | 409         |
| total timesteps         | 23900       |
| train_time              | 0           |
| update_time             | 365         |
-----------------------------------------
-------------------------------------------
| act_time                | 2             |
| current_lr              | 0.0003        |
| discount_q              | 6.44          |
| env_time                | 30            |
| ep_rewmean              | 21.6          |
| episodes                | 1084          |
| eplenmean               | 24.9          |
| fps                     | 58            |
| mean 100 episode reward | 21.6          |
| n_updates               | 0             |
| qs_abs_difference       | 3.16          |
| qs_difference           | -2.5          |
| qs_mean                 | -0.0052324277 |
| time_elapsed            | 409           |
| total timesteps         | 23963         |
| train_time              | 0             |
| update_time             | 365           |
-------------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.35       |
| env_time                | 30         |
| ep_rewmean              | 21.8       |
| episodes                | 1088       |
| eplenmean               | 25.1       |
| fps                     | 58         |
| mean 100 episode reward | 21.8       |
| n_updates               | 0          |
| qs_abs_difference       | 6.39       |
| qs_difference           | -6.39      |
| qs_mean                 | -0.1238303 |
| time_elapsed            | 412        |
| total timesteps         | 24055      |
| train_time              | 0          |
| update_time             | 368        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.69       |
| env_time                | 30         |
| ep_rewmean              | 21.6       |
| episodes                | 1092       |
| eplenmean               | 24.8       |
| fps                     | 58         |
| mean 100 episode reward | 21.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.09       |
| qs_difference           | -5.09      |
| qs_mean                 | 0.14859937 |
| time_elapsed            | 415        |
| total timesteps         | 24109      |
| train_time              | 0          |
| update_time             | 371        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 7.02        |
| env_time                | 30          |
| ep_rewmean              | 21.6        |
| episodes                | 1096        |
| eplenmean               | 24.7        |
| fps                     | 58          |
| mean 100 episode reward | 21.6        |
| n_updates               | 0           |
| qs_abs_difference       | 6.37        |
| qs_difference           | -6.37       |
| qs_mean                 | 0.059268463 |
| time_elapsed            | 415         |
| total timesteps         | 24181       |
| train_time              | 0           |
| update_time             | 371         |
-----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 7.76      |
| env_time                | 30        |
| ep_rewmean              | 20.6      |
| episodes                | 1100      |
| eplenmean               | 24.1      |
| fps                     | 57        |
| mean 100 episode reward | 20.6      |
| n_updates               | 0         |
| qs_abs_difference       | 6.03      |
| qs_difference           | -6.03     |
| qs_mean                 | 0.0871572 |
| time_elapsed            | 419       |
| total timesteps         | 24231     |
| train_time              | 0         |
| update_time             | 374       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.06       |
| env_time                | 30         |
| ep_rewmean              | 19.8       |
| episodes                | 1104       |
| eplenmean               | 23.6       |
| fps                     | 57         |
| mean 100 episode reward | 19.8       |
| n_updates               | 0          |
| qs_abs_difference       | 5.82       |
| qs_difference           | -5.82      |
| qs_mean                 | 0.04730285 |
| time_elapsed            | 419        |
| total timesteps         | 24288      |
| train_time              | 0          |
| update_time             | 374        |
----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 5.73         |
| env_time                | 30           |
| ep_rewmean              | 19.7         |
| episodes                | 1108         |
| eplenmean               | 23.7         |
| fps                     | 57           |
| mean 100 episode reward | 19.7         |
| n_updates               | 0            |
| qs_abs_difference       | 3.62         |
| qs_difference           | -2.11        |
| qs_mean                 | -0.027356053 |
| time_elapsed            | 423          |
| total timesteps         | 24393        |
| train_time              | 0            |
| update_time             | 378          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 8.91        |
| env_time                | 30          |
| ep_rewmean              | 19.4        |
| episodes                | 1112        |
| eplenmean               | 23.5        |
| fps                     | 57          |
| mean 100 episode reward | 19.4        |
| n_updates               | 0           |
| qs_abs_difference       | 6.91        |
| qs_difference           | -6.91       |
| qs_mean                 | -0.21310395 |
| time_elapsed            | 427         |
| total timesteps         | 24476       |
| train_time              | 0           |
| update_time             | 382         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.9        |
| env_time                | 30         |
| ep_rewmean              | 19.4       |
| episodes                | 1116       |
| eplenmean               | 23.6       |
| fps                     | 56         |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 4.94       |
| qs_difference           | -4.94      |
| qs_mean                 | -0.4349446 |
| time_elapsed            | 432        |
| total timesteps         | 24572      |
| train_time              | 0          |
| update_time             | 386        |
----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 21.1         |
| env_time                | 31           |
| ep_rewmean              | 19.4         |
| episodes                | 1120         |
| eplenmean               | 23.6         |
| fps                     | 56           |
| mean 100 episode reward | 19.4         |
| n_updates               | 0            |
| qs_abs_difference       | 20.3         |
| qs_difference           | -20.3        |
| qs_mean                 | -0.040470395 |
| time_elapsed            | 436          |
| total timesteps         | 24655        |
| train_time              | 0            |
| update_time             | 390          |
------------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.71       |
| env_time                | 31         |
| ep_rewmean              | 19.3       |
| episodes                | 1124       |
| eplenmean               | 23.4       |
| fps                     | 56         |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 2.75       |
| qs_difference           | -2.69      |
| qs_mean                 | 0.07861686 |
| time_elapsed            | 440        |
| total timesteps         | 24745      |
| train_time              | 0          |
| update_time             | 395        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.56       |
| env_time                | 31         |
| ep_rewmean              | 19.2       |
| episodes                | 1128       |
| eplenmean               | 23.2       |
| fps                     | 55         |
| mean 100 episode reward | 19.2       |
| n_updates               | 0          |
| qs_abs_difference       | 4.99       |
| qs_difference           | -4.99      |
| qs_mean                 | 0.03537662 |
| time_elapsed            | 444        |
| total timesteps         | 24800      |
| train_time              | 0          |
| update_time             | 399        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 10.5        |
| env_time                | 31          |
| ep_rewmean              | 19.5        |
| episodes                | 1132        |
| eplenmean               | 23.4        |
| fps                     | 55          |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 10.2        |
| qs_difference           | -10.1       |
| qs_mean                 | -0.04622968 |
| time_elapsed            | 449         |
| total timesteps         | 24906       |
| train_time              | 0           |
| update_time             | 403         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 10           |
| env_time                | 31           |
| ep_rewmean              | 18.3         |
| episodes                | 1136         |
| eplenmean               | 22.5         |
| fps                     | 55           |
| mean 100 episode reward | 18.3         |
| n_updates               | 0            |
| qs_abs_difference       | 10.3         |
| qs_difference           | -10.3        |
| qs_mean                 | -0.047516868 |
| time_elapsed            | 449          |
| total timesteps         | 24989        |
| train_time              | 0            |
| update_time             | 403          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 16.4        |
| env_time                | 31          |
| ep_rewmean              | 18          |
| episodes                | 1140        |
| eplenmean               | 21.7        |
| fps                     | 54          |
| mean 100 episode reward | 18          |
| n_updates               | 200         |
| q_grad_norm             | 26.590857   |
| qfs_loss                | 91.745094   |
| qs_abs_difference       | 21.3        |
| qs_difference           | -21.3       |
| qs_mean                 | -0.12686045 |
| time_elapsed            | 459         |
| total timesteps         | 25085       |
| train_time              | 5           |
| update_time             | 407         |
-----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 17.5      |
| env_time                | 31        |
| ep_rewmean              | 18.7      |
| episodes                | 1144      |
| eplenmean               | 21.6      |
| fps                     | 54        |
| mean 100 episode reward | 18.7      |
| n_updates               | 400       |
| q_grad_norm             | 32.20679  |
| qfs_loss                | 79.93672  |
| qs_abs_difference       | 11.7      |
| qs_difference           | -7.75     |
| qs_mean                 | 13.505566 |
| time_elapsed            | 465       |
| total timesteps         | 25175     |
| train_time              | 7         |
| update_time             | 411       |
---------------------------------------
--------------------------------------
| act_time                | 3        |
| current_lr              | 0.0003   |
| discount_q              | 19.7     |
| env_time                | 32       |
| ep_rewmean              | 20.8     |
| episodes                | 1148     |
| eplenmean               | 22.3     |
| fps                     | 52       |
| mean 100 episode reward | 20.8     |
| n_updates               | 800      |
| q_grad_norm             | 66.22166 |
| qfs_loss                | 79.81845 |
| qs_abs_difference       | 19.5     |
| qs_difference           | -8.2     |
| qs_mean                 | 25.02448 |
| time_elapsed            | 479      |
| total timesteps         | 25318    |
| train_time              | 11       |
| update_time             | 420      |
--------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 16.3      |
| env_time                | 32        |
| ep_rewmean              | 22        |
| episodes                | 1152      |
| eplenmean               | 22.3      |
| fps                     | 52        |
| mean 100 episode reward | 22        |
| n_updates               | 1000      |
| q_grad_norm             | 87.60811  |
| qfs_loss                | 73.42598  |
| qs_abs_difference       | 14.3      |
| qs_difference           | 4.57      |
| qs_mean                 | 35.906963 |
| time_elapsed            | 485       |
| total timesteps         | 25470     |
| train_time              | 14        |
| update_time             | 424       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 24.2      |
| env_time                | 32        |
| ep_rewmean              | 24.6      |
| episodes                | 1156      |
| eplenmean               | 23.3      |
| fps                     | 51        |
| mean 100 episode reward | 24.6      |
| n_updates               | 1400      |
| q_grad_norm             | 146.08221 |
| qfs_loss                | 69.260574 |
| qs_abs_difference       | 22.5      |
| qs_difference           | 0.662     |
| qs_mean                 | 49.132126 |
| time_elapsed            | 499       |
| total timesteps         | 25653     |
| train_time              | 18        |
| update_time             | 432       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 6.74      |
| env_time                | 32        |
| ep_rewmean              | 30.3      |
| episodes                | 1160      |
| eplenmean               | 25.6      |
| fps                     | 49        |
| mean 100 episode reward | 30.3      |
| n_updates               | 2000      |
| q_grad_norm             | 315.69122 |
| qfs_loss                | 59.59474  |
| qs_abs_difference       | 23.9      |
| qs_difference           | 15.4      |
| qs_mean                 | 67.67431  |
| time_elapsed            | 519       |
| total timesteps         | 25977     |
| train_time              | 25        |
| update_time             | 445       |
---------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 8.86      |
| env_time                | 33        |
| ep_rewmean              | 36.1      |
| episodes                | 1164      |
| eplenmean               | 27.9      |
| fps                     | 48        |
| mean 100 episode reward | 36.1      |
| n_updates               | 2800      |
| q_grad_norm             | 515.5108  |
| qfs_loss                | 67.88268  |
| qs_abs_difference       | 24.7      |
| qs_difference           | 12.3      |
| qs_mean                 | 86.098465 |
| time_elapsed            | 546       |
| total timesteps         | 26316     |
| train_time              | 34        |
| update_time             | 462       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 8.1       |
| env_time                | 33        |
| ep_rewmean              | 41.7      |
| episodes                | 1168      |
| eplenmean               | 30.2      |
| fps                     | 46        |
| mean 100 episode reward | 41.7      |
| n_updates               | 3400      |
| q_grad_norm             | 663.8565  |
| qfs_loss                | 67.25509  |
| qs_abs_difference       | 33.7      |
| qs_difference           | 31.9      |
| qs_mean                 | 104.38321 |
| time_elapsed            | 567       |
| total timesteps         | 26666     |
| train_time              | 41        |
| update_time             | 476       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 7.7       |
| env_time                | 34        |
| ep_rewmean              | 48.1      |
| episodes                | 1172      |
| eplenmean               | 33        |
| fps                     | 45        |
| mean 100 episode reward | 48.1      |
| n_updates               | 4200      |
| q_grad_norm             | 858.4972  |
| qfs_loss                | 60.643993 |
| qs_abs_difference       | 44.8      |
| qs_difference           | 44.8      |
| qs_mean                 | 113.84943 |
| time_elapsed            | 594       |
| total timesteps         | 27016     |
| train_time              | 50        |
| update_time             | 493       |
---------------------------------------
----------------------------------------
| act_time                | 4          |
| current_lr              | 0.0003     |
| discount_q              | 8.4        |
| env_time                | 34         |
| ep_rewmean              | 54.6       |
| episodes                | 1176       |
| eplenmean               | 35.7       |
| fps                     | 44         |
| mean 100 episode reward | 54.6       |
| n_updates               | 4800       |
| q_grad_norm             | 1143.2007  |
| qfs_loss                | 62.09456   |
| qs_abs_difference       | 46.6       |
| qs_difference           | 46.6       |
| qs_mean                 | 120.982216 |
| time_elapsed            | 615        |
| total timesteps         | 27359      |
| train_time              | 56         |
| update_time             | 506        |
----------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 8.19      |
| env_time                | 35        |
| ep_rewmean              | 60.7      |
| episodes                | 1180      |
| eplenmean               | 38.1      |
| fps                     | 43        |
| mean 100 episode reward | 60.7      |
| n_updates               | 5600      |
| q_grad_norm             | 1226.8716 |
| qfs_loss                | 56.20881  |
| qs_abs_difference       | 48.6      |
| qs_difference           | 48.6      |
| qs_mean                 | 120.57009 |
| time_elapsed            | 643       |
| total timesteps         | 27707     |
| train_time              | 65        |
| update_time             | 524       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 5.52      |
| env_time                | 35        |
| ep_rewmean              | 66.5      |
| episodes                | 1184      |
| eplenmean               | 40.6      |
| fps                     | 42        |
| mean 100 episode reward | 66.5      |
| n_updates               | 6200      |
| q_grad_norm             | 1187.6826 |
| qfs_loss                | 62.504227 |
| qs_abs_difference       | 104       |
| qs_difference           | 104       |
| qs_mean                 | 148.78918 |
| time_elapsed            | 664       |
| total timesteps         | 28023     |
| train_time              | 72        |
| update_time             | 537       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 13.6      |
| env_time                | 36        |
| ep_rewmean              | 70        |
| episodes                | 1188      |
| eplenmean               | 42.1      |
| fps                     | 41        |
| mean 100 episode reward | 70        |
| n_updates               | 6600      |
| q_grad_norm             | 1523.1746 |
| qfs_loss                | 72.133095 |
| qs_abs_difference       | 104       |
| qs_difference           | 104       |
| qs_mean                 | 154.16867 |
| time_elapsed            | 678       |
| total timesteps         | 28269     |
| train_time              | 76        |
| update_time             | 546       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 11.5      |
| env_time                | 36        |
| ep_rewmean              | 75.5      |
| episodes                | 1192      |
| eplenmean               | 44.9      |
| fps                     | 40        |
| mean 100 episode reward | 75.5      |
| n_updates               | 7200      |
| q_grad_norm             | 2037.3387 |
| qfs_loss                | 100.02055 |
| qs_abs_difference       | 94.7      |
| qs_difference           | 94.7      |
| qs_mean                 | 159.85757 |
| time_elapsed            | 699       |
| total timesteps         | 28595     |
| train_time              | 83        |
| update_time             | 560       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 4.9       |
| env_time                | 37        |
| ep_rewmean              | 82.4      |
| episodes                | 1196      |
| eplenmean               | 48.2      |
| fps                     | 39        |
| mean 100 episode reward | 82.4      |
| n_updates               | 8200      |
| q_grad_norm             | 2362.7346 |
| qfs_loss                | 93.074326 |
| qs_abs_difference       | 96.9      |
| qs_difference           | 96.9      |
| qs_mean                 | 167.21555 |
| time_elapsed            | 734       |
| total timesteps         | 29000     |
| train_time              | 94        |
| update_time             | 583       |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 6.29      |
| env_time                | 37        |
| ep_rewmean              | 90.2      |
| episodes                | 1200      |
| eplenmean               | 51.5      |
| fps                     | 38        |
| mean 100 episode reward | 90.2      |
| n_updates               | 8800      |
| q_grad_norm             | 2426.2742 |
| qfs_loss                | 113.27948 |
| qs_abs_difference       | 85.3      |
| qs_difference           | 85.3      |
| qs_mean                 | 170.75069 |
| time_elapsed            | 756       |
| total timesteps         | 29384     |
| train_time              | 101       |
| update_time             | 597       |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 8.62      |
| env_time                | 38        |
| ep_rewmean              | 96.8      |
| episodes                | 1204      |
| eplenmean               | 54.4      |
| fps                     | 37        |
| mean 100 episode reward | 96.8      |
| n_updates               | 9600      |
| q_grad_norm             | 2402.7178 |
| qfs_loss                | 97.33851  |
| qs_abs_difference       | 95.6      |
| qs_difference           | 95.6      |
| qs_mean                 | 170.17082 |
| time_elapsed            | 784       |
| total timesteps         | 29727     |
| train_time              | 110       |
| update_time             | 615       |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 43.7      |
| eval_abs_qs_difference  | 100.68757 |
| eval_discount_q         | 116       |
| eval_ep_rewmean         | 185       |
| eval_eplenmean          | 94.2      |
| eval_qs                 | 175.30455 |
| eval_qs_difference      | 101       |
| eval_time_elapsed       | 2         |
| total timesteps         | 30001     |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 9.78      |
| env_time                | 38        |
| ep_rewmean              | 103       |
| episodes                | 1208      |
| eplenmean               | 56.8      |
| fps                     | 37        |
| mean 100 episode reward | 103       |
| n_updates               | 10200     |
| q_grad_norm             | 2769.327  |
| qfs_loss                | 112.02598 |
| qs_abs_difference       | 102       |
| qs_difference           | 102       |
| qs_mean                 | 176.96191 |
| time_elapsed            | 808       |
| total timesteps         | 30068     |
| train_time              | 117       |
| update_time             | 629       |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 5.23      |
| env_time                | 39        |
| ep_rewmean              | 113       |
| episodes                | 1212      |
| eplenmean               | 60.6      |
| fps                     | 36        |
| mean 100 episode reward | 113       |
| n_updates               | 11200     |
| q_grad_norm             | 3583.0688 |
| qfs_loss                | 110.56036 |
| qs_abs_difference       | 38.2      |
| qs_difference           | 25.2      |
| qs_mean                 | 149.70222 |
| time_elapsed            | 844       |
| total timesteps         | 30533     |
| train_time              | 128       |
| update_time             | 653       |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 7.34      |
| env_time                | 40        |
| ep_rewmean              | 122       |
| episodes                | 1216      |
| eplenmean               | 64        |
| fps                     | 35        |
| mean 100 episode reward | 122       |
| n_updates               | 12000     |
| q_grad_norm             | 3023.1853 |
| qfs_loss                | 89.49331  |
| qs_abs_difference       | 37.5      |
| qs_difference           | 32.8      |
| qs_mean                 | 153.2242  |
| time_elapsed            | 873       |
| total timesteps         | 30976     |
| train_time              | 137       |
| update_time             | 672       |
---------------------------------------
----------------------------------------
| act_time                | 7          |
| current_lr              | 0.0003     |
| discount_q              | 2.37       |
| env_time                | 41         |
| ep_rewmean              | 133        |
| episodes                | 1220       |
| eplenmean               | 68.5       |
| fps                     | 34         |
| mean 100 episode reward | 133        |
| n_updates               | 13200      |
| q_grad_norm             | 3852.3552  |
| qfs_loss                | 115.491974 |
| qs_abs_difference       | 47.6       |
| qs_difference           | 42.8       |
| qs_mean                 | 158.79909  |
| time_elapsed            | 917        |
| total timesteps         | 31509      |
| train_time              | 150        |
| update_time             | 701        |
----------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 1.72      |
| env_time                | 42        |
| ep_rewmean              | 150       |
| episodes                | 1224      |
| eplenmean               | 74.4      |
| fps                     | 33        |
| mean 100 episode reward | 150       |
| n_updates               | 14400     |
| q_grad_norm             | 4354.8433 |
| qfs_loss                | 127.52397 |
| qs_abs_difference       | 24.9      |
| qs_difference           | 8.19      |
| qs_mean                 | 172.71822 |
| time_elapsed            | 961       |
| total timesteps         | 32181     |
| train_time              | 164       |
| update_time             | 729       |
---------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 0.813     |
| env_time                | 43        |
| ep_rewmean              | 170       |
| episodes                | 1228      |
| eplenmean               | 82.3      |
| fps                     | 32        |
| mean 100 episode reward | 170       |
| n_updates               | 16200     |
| q_grad_norm             | 4583.576  |
| qfs_loss                | 131.38829 |
| qs_abs_difference       | 23.2      |
| qs_difference           | -16       |
| qs_mean                 | 188.2406  |
| time_elapsed            | 1027      |
| total timesteps         | 33031     |
| train_time              | 184       |
| update_time             | 773       |
---------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 0.0755    |
| env_time                | 45        |
| ep_rewmean              | 193       |
| episodes                | 1232      |
| eplenmean               | 90.7      |
| fps                     | 31        |
| mean 100 episode reward | 193       |
| n_updates               | 18000     |
| q_grad_norm             | 4975.023  |
| qfs_loss                | 145.17792 |
| qs_abs_difference       | 57.7      |
| qs_difference           | 56.4      |
| qs_mean                 | 203.39345 |
| time_elapsed            | 1093      |
| total timesteps         | 33973     |
| train_time              | 204       |
| update_time             | 816       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 5.63      |
| env_time                | 45        |
| ep_rewmean              | 203       |
| episodes                | 1236      |
| eplenmean               | 94.7      |
| fps                     | 30        |
| mean 100 episode reward | 203       |
| n_updates               | 19000     |
| q_grad_norm             | 5412.4355 |
| qfs_loss                | 171.3497  |
| qs_abs_difference       | 96.7      |
| qs_difference           | 96.7      |
| qs_mean                 | 229.67192 |
| time_elapsed            | 1130      |
| total timesteps         | 34463     |
| train_time              | 215       |
| update_time             | 841       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 5.42      |
| env_time                | 46        |
| ep_rewmean              | 213       |
| episodes                | 1240      |
| eplenmean               | 98.5      |
| fps                     | 29        |
| mean 100 episode reward | 213       |
| n_updates               | 20000     |
| q_grad_norm             | 6927.904  |
| qfs_loss                | 189.03685 |
| qs_abs_difference       | 84.4      |
| qs_difference           | 84.3      |
| qs_mean                 | 221.96498 |
| time_elapsed            | 1167      |
| total timesteps         | 34930     |
| train_time              | 226       |
| update_time             | 866       |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 3.15      |
| env_time                | 47        |
| ep_rewmean              | 225       |
| episodes                | 1244      |
| eplenmean               | 103       |
| fps                     | 29        |
| mean 100 episode reward | 225       |
| n_updates               | 21000     |
| q_grad_norm             | 6320.748  |
| qfs_loss                | 176.055   |
| qs_abs_difference       | 80.4      |
| qs_difference           | 80.4      |
| qs_mean                 | 222.85953 |
| time_elapsed            | 1205      |
| total timesteps         | 35457     |
| train_time              | 238       |
| update_time             | 891       |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 4.1       |
| env_time                | 47        |
| ep_rewmean              | 237       |
| episodes                | 1248      |
| eplenmean               | 106       |
| fps                     | 28        |
| mean 100 episode reward | 237       |
| n_updates               | 22000     |
| q_grad_norm             | 6940.2393 |
| qfs_loss                | 173.60715 |
| qs_abs_difference       | 76.7      |
| qs_difference           | 76.4      |
| qs_mean                 | 219.67865 |
| time_elapsed            | 1242      |
| total timesteps         | 35955     |
| train_time              | 249       |
| update_time             | 916       |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 5.37      |
| env_time                | 48        |
| ep_rewmean              | 244       |
| episodes                | 1252      |
| eplenmean               | 109       |
| fps                     | 28        |
| mean 100 episode reward | 244       |
| n_updates               | 22800     |
| q_grad_norm             | 7789.638  |
| qfs_loss                | 193.70984 |
| qs_abs_difference       | 167       |
| qs_difference           | 167       |
| qs_mean                 | 261.68787 |
| time_elapsed            | 1272      |
| total timesteps         | 36366     |
| train_time              | 258       |
| update_time             | 936       |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 5.62      |
| env_time                | 49        |
| ep_rewmean              | 251       |
| episodes                | 1256      |
| eplenmean               | 111       |
| fps                     | 28        |
| mean 100 episode reward | 250       |
| n_updates               | 23600     |
| q_grad_norm             | 7476.884  |
| qfs_loss                | 172.68904 |
| qs_abs_difference       | 167       |
| qs_difference           | 167       |
| qs_mean                 | 256.97433 |
| time_elapsed            | 1303      |
| total timesteps         | 36766     |
| train_time              | 267       |
| update_time             | 956       |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 7.6       |
| env_time                | 49        |
| ep_rewmean              | 253       |
| episodes                | 1260      |
| eplenmean               | 112       |
| fps                     | 27        |
| mean 100 episode reward | 252       |
| n_updates               | 24400     |
| q_grad_norm             | 7427.9736 |
| qfs_loss                | 155.7133  |
| qs_abs_difference       | 170       |
| qs_difference           | 170       |
| qs_mean                 | 257.26123 |
| time_elapsed            | 1334      |
| total timesteps         | 37132     |
| train_time              | 276       |
| update_time             | 977       |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 6.08      |
| env_time                | 50        |
| ep_rewmean              | 258       |
| episodes                | 1264      |
| eplenmean               | 113       |
| fps                     | 27        |
| mean 100 episode reward | 258       |
| n_updates               | 25200     |
| q_grad_norm             | 6316.286  |
| qfs_loss                | 136.18483 |
| qs_abs_difference       | 88.2      |
| qs_difference           | 88.2      |
| qs_mean                 | 221.31317 |
| time_elapsed            | 1364      |
| total timesteps         | 37589     |
| train_time              | 285       |
| update_time             | 997       |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 4.04      |
| env_time                | 51        |
| ep_rewmean              | 264       |
| episodes                | 1268      |
| eplenmean               | 114       |
| fps                     | 27        |
| mean 100 episode reward | 264       |
| n_updates               | 26200     |
| q_grad_norm             | 7889.3994 |
| qfs_loss                | 169.7571  |
| qs_abs_difference       | 86.6      |
| qs_difference           | 86.6      |
| qs_mean                 | 218.74876 |
| time_elapsed            | 1402      |
| total timesteps         | 38080     |
| train_time              | 296       |
| update_time             | 1023      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 0.226     |
| env_time                | 52        |
| ep_rewmean              | 273       |
| episodes                | 1272      |
| eplenmean               | 119       |
| fps                     | 26        |
| mean 100 episode reward | 273       |
| n_updates               | 27800     |
| q_grad_norm             | 8172.81   |
| qfs_loss                | 181.96548 |
| qs_abs_difference       | 82.3      |
| qs_difference           | 82.3      |
| qs_mean                 | 227.8644  |
| time_elapsed            | 1464      |
| total timesteps         | 38875     |
| train_time              | 314       |
| update_time             | 1065      |
---------------------------------------
---------------------------------------
| act_time                | 14        |
| current_lr              | 0.0003    |
| discount_q              | 2.99      |
| env_time                | 53        |
| ep_rewmean              | 281       |
| episodes                | 1276      |
| eplenmean               | 120       |
| fps                     | 26        |
| mean 100 episode reward | 281       |
| n_updates               | 29000     |
| q_grad_norm             | 6447.66   |
| qfs_loss                | 132.70872 |
| qs_abs_difference       | 122       |
| qs_difference           | 122       |
| qs_mean                 | 251.76915 |
| time_elapsed            | 1510      |
| total timesteps         | 39401     |
| train_time              | 327       |
| update_time             | 1096      |
---------------------------------------
--------------------------------------
| act_time                | 14       |
| current_lr              | 0.0003   |
| discount_q              | 3.17     |
| env_time                | 54       |
| ep_rewmean              | 291      |
| episodes                | 1280     |
| eplenmean               | 123      |
| fps                     | 25       |
| mean 100 episode reward | 291      |
| n_updates               | 30000    |
| q_grad_norm             | 7659.366 |
| qfs_loss                | 154.3113 |
| qs_abs_difference       | 56.3     |
| qs_difference           | 52.7     |
| qs_mean                 | 237.2221 |
| time_elapsed            | 1550     |
| total timesteps         | 39990    |
| train_time              | 338      |
| update_time             | 1123     |
--------------------------------------
---------------------------------------
| eval mean 100 episod... | 105       |
| eval_abs_qs_difference  | 91.728294 |
| eval_discount_q         | 177       |
| eval_ep_rewmean         | 362       |
| eval_eplenmean          | 130       |
| eval_qs                 | 234.31532 |
| eval_qs_difference      | 91.1      |
| eval_time_elapsed       | 2         |
| total timesteps         | 40001     |
---------------------------------------
---------------------------------------
| act_time                | 15        |
| current_lr              | 0.0003    |
| discount_q              | 2.24      |
| env_time                | 55        |
| ep_rewmean              | 302       |
| episodes                | 1284      |
| eplenmean               | 125       |
| fps                     | 25        |
| mean 100 episode reward | 302       |
| n_updates               | 31200     |
| q_grad_norm             | 7343.294  |
| qfs_loss                | 141.34117 |
| qs_abs_difference       | 101       |
| qs_difference           | 101       |
| qs_mean                 | 245.73888 |
| time_elapsed            | 1599      |
| total timesteps         | 40564     |
| train_time              | 352       |
| update_time             | 1154      |
---------------------------------------
---------------------------------------
| act_time                | 15        |
| current_lr              | 0.0003    |
| discount_q              | 2.25      |
| env_time                | 55        |
| ep_rewmean              | 311       |
| episodes                | 1288      |
| eplenmean               | 128       |
| fps                     | 25        |
| mean 100 episode reward | 311       |
| n_updates               | 32200     |
| q_grad_norm             | 6364.9624 |
| qfs_loss                | 142.364   |
| qs_abs_difference       | 154       |
| qs_difference           | 154       |
| qs_mean                 | 249.36858 |
| time_elapsed            | 1639      |
| total timesteps         | 41090     |
| train_time              | 363       |
| update_time             | 1181      |
---------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 1.59      |
| env_time                | 56        |
| ep_rewmean              | 320       |
| episodes                | 1292      |
| eplenmean               | 131       |
| fps                     | 24        |
| mean 100 episode reward | 320       |
| n_updates               | 33400     |
| q_grad_norm             | 7162.623  |
| qfs_loss                | 143.27928 |
| qs_abs_difference       | 127       |
| qs_difference           | 127       |
| qs_mean                 | 235.29652 |
| time_elapsed            | 1686      |
| total timesteps         | 41662     |
| train_time              | 376       |
| update_time             | 1214      |
---------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 2.46      |
| env_time                | 57        |
| ep_rewmean              | 325       |
| episodes                | 1296      |
| eplenmean               | 132       |
| fps                     | 24        |
| mean 100 episode reward | 325       |
| n_updates               | 34400     |
| q_grad_norm             | 6619.212  |
| qfs_loss                | 125.58185 |
| qs_abs_difference       | 116       |
| qs_difference           | 115       |
| qs_mean                 | 226.32077 |
| time_elapsed            | 1726      |
| total timesteps         | 42191     |
| train_time              | 388       |
| update_time             | 1241      |
---------------------------------------
----------------------------------------
| act_time                | 16         |
| current_lr              | 0.0003     |
| discount_q              | 4.29       |
| env_time                | 58         |
| ep_rewmean              | 328        |
| episodes                | 1300       |
| eplenmean               | 133        |
| fps                     | 24         |
| mean 100 episode reward | 328        |
| n_updates               | 35400      |
| q_grad_norm             | 6790.828   |
| qfs_loss                | 121.067276 |
| qs_abs_difference       | 112        |
| qs_difference           | 112        |
| qs_mean                 | 231.72061  |
| time_elapsed            | 1765       |
| total timesteps         | 42679      |
| train_time              | 399        |
| update_time             | 1268       |
----------------------------------------
---------------------------------------
| act_time                | 17        |
| current_lr              | 0.0003    |
| discount_q              | 4.02      |
| env_time                | 59        |
| ep_rewmean              | 333       |
| episodes                | 1304      |
| eplenmean               | 134       |
| fps                     | 23        |
| mean 100 episode reward | 333       |
| n_updates               | 36400     |
| q_grad_norm             | 7433.956  |
| qfs_loss                | 141.43874 |
| qs_abs_difference       | 132       |
| qs_difference           | 132       |
| qs_mean                 | 240.33286 |
| time_elapsed            | 1805      |
| total timesteps         | 43156     |
| train_time              | 410       |
| update_time             | 1295      |
---------------------------------------
---------------------------------------
| act_time                | 17        |
| current_lr              | 0.0003    |
| discount_q              | 0.77      |
| env_time                | 60        |
| ep_rewmean              | 344       |
| episodes                | 1308      |
| eplenmean               | 137       |
| fps                     | 23        |
| mean 100 episode reward | 344       |
| n_updates               | 37800     |
| q_grad_norm             | 7277.748  |
| qfs_loss                | 133.72972 |
| qs_abs_difference       | 137       |
| qs_difference           | 137       |
| qs_mean                 | 246.18765 |
| time_elapsed            | 1861      |
| total timesteps         | 43814     |
| train_time              | 426       |
| update_time             | 1334      |
---------------------------------------
----------------------------------------
| act_time                | 18         |
| current_lr              | 0.0003     |
| discount_q              | 0.634      |
| env_time                | 60         |
| ep_rewmean              | 351        |
| episodes                | 1312       |
| eplenmean               | 140        |
| fps                     | 23         |
| mean 100 episode reward | 351        |
| n_updates               | 39000      |
| q_grad_norm             | 6760.906   |
| qfs_loss                | 126.191124 |
| qs_abs_difference       | 131        |
| qs_difference           | 131        |
| qs_mean                 | 237.1673   |
| time_elapsed            | 1909       |
| total timesteps         | 44485      |
| train_time              | 439        |
| update_time             | 1367       |
----------------------------------------
---------------------------------------
| act_time                | 18        |
| current_lr              | 0.0003    |
| discount_q              | 0.839     |
| env_time                | 61        |
| ep_rewmean              | 357       |
| episodes                | 1316      |
| eplenmean               | 142       |
| fps                     | 22        |
| mean 100 episode reward | 357       |
| n_updates               | 40400     |
| q_grad_norm             | 5720.1777 |
| qfs_loss                | 112.08241 |
| qs_abs_difference       | 85.6      |
| qs_difference           | 85.6      |
| qs_mean                 | 208.03798 |
| time_elapsed            | 1966      |
| total timesteps         | 45126     |
| train_time              | 455       |
| update_time             | 1406      |
---------------------------------------
---------------------------------------
| act_time                | 19        |
| current_lr              | 0.0003    |
| discount_q              | 2.31      |
| env_time                | 62        |
| ep_rewmean              | 363       |
| episodes                | 1320      |
| eplenmean               | 143       |
| fps                     | 22        |
| mean 100 episode reward | 363       |
| n_updates               | 41600     |
| q_grad_norm             | 5943.044  |
| qfs_loss                | 122.38781 |
| qs_abs_difference       | 101       |
| qs_difference           | 101       |
| qs_mean                 | 250.65259 |
| time_elapsed            | 2014      |
| total timesteps         | 45793     |
| train_time              | 468       |
| update_time             | 1440      |
---------------------------------------
---------------------------------------
| act_time                | 19        |
| current_lr              | 0.0003    |
| discount_q              | 1.85      |
| env_time                | 63        |
| ep_rewmean              | 361       |
| episodes                | 1324      |
| eplenmean               | 142       |
| fps                     | 22        |
| mean 100 episode reward | 361       |
| n_updates               | 42800     |
| q_grad_norm             | 6533.017  |
| qfs_loss                | 124.19163 |
| qs_abs_difference       | 51.3      |
| qs_difference           | 49.7      |
| qs_mean                 | 203.05183 |
| time_elapsed            | 2063      |
| total timesteps         | 46386     |
| train_time              | 482       |
| update_time             | 1473      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 2.07      |
| env_time                | 64        |
| ep_rewmean              | 356       |
| episodes                | 1328      |
| eplenmean               | 139       |
| fps                     | 22        |
| mean 100 episode reward | 356       |
| n_updates               | 44000     |
| q_grad_norm             | 6003.0186 |
| qfs_loss                | 117.88089 |
| qs_abs_difference       | 76.4      |
| qs_difference           | 76.4      |
| qs_mean                 | 204.95181 |
| time_elapsed            | 2112      |
| total timesteps         | 46938     |
| train_time              | 495       |
| update_time             | 1507      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 1.72      |
| env_time                | 65        |
| ep_rewmean              | 346       |
| episodes                | 1332      |
| eplenmean               | 135       |
| fps                     | 21        |
| mean 100 episode reward | 346       |
| n_updates               | 45200     |
| q_grad_norm             | 6504.9624 |
| qfs_loss                | 118.82645 |
| qs_abs_difference       | 123       |
| qs_difference           | 123       |
| qs_mean                 | 230.2946  |
| time_elapsed            | 2162      |
| total timesteps         | 47513     |
| train_time              | 509       |
| update_time             | 1542      |
---------------------------------------
---------------------------------------
| act_time                | 21        |
| current_lr              | 0.0003    |
| discount_q              | 0.491     |
| env_time                | 66        |
| ep_rewmean              | 353       |
| episodes                | 1336      |
| eplenmean               | 138       |
| fps                     | 21        |
| mean 100 episode reward | 353       |
| n_updates               | 46600     |
| q_grad_norm             | 5045.4673 |
| qfs_loss                | 103.32573 |
| qs_abs_difference       | 125       |
| qs_difference           | 123       |
| qs_mean                 | 227.57901 |
| time_elapsed            | 2219      |
| total timesteps         | 48219     |
| train_time              | 524       |
| update_time             | 1582      |
---------------------------------------
---------------------------------------
| act_time                | 21        |
| current_lr              | 0.0003    |
| discount_q              | 0.504     |
| env_time                | 67        |
| ep_rewmean              | 361       |
| episodes                | 1340      |
| eplenmean               | 140       |
| fps                     | 21        |
| mean 100 episode reward | 361       |
| n_updates               | 48000     |
| q_grad_norm             | 6343.7383 |
| qfs_loss                | 130.40266 |
| qs_abs_difference       | 162       |
| qs_difference           | 162       |
| qs_mean                 | 274.95428 |
| time_elapsed            | 2278      |
| total timesteps         | 48935     |
| train_time              | 540       |
| update_time             | 1623      |
---------------------------------------
----------------------------------------
| act_time                | 22         |
| current_lr              | 0.0003     |
| discount_q              | 1.94       |
| env_time                | 68         |
| ep_rewmean              | 362        |
| episodes                | 1344       |
| eplenmean               | 141        |
| fps                     | 21         |
| mean 100 episode reward | 362        |
| n_updates               | 49200      |
| q_grad_norm             | 6158.6187  |
| qfs_loss                | 121.059074 |
| qs_abs_difference       | 83.5       |
| qs_difference           | 82.8       |
| qs_mean                 | 238.81813  |
| time_elapsed            | 2328       |
| total timesteps         | 49586      |
| train_time              | 553        |
| update_time             | 1658       |
----------------------------------------
--------------------------------------
| eval mean 100 episod... | 172      |
| eval_abs_qs_difference  | 51.61986 |
| eval_discount_q         | 191      |
| eval_ep_rewmean         | 517      |
| eval_eplenmean          | 192      |
| eval_qs                 | 221.8584 |
| eval_qs_difference      | 51       |
| eval_time_elapsed       | 4        |
| total timesteps         | 50001    |
--------------------------------------
---------------------------------------
| act_time                | 22        |
| current_lr              | 0.0003    |
| discount_q              | 0.0587    |
| env_time                | 69        |
| ep_rewmean              | 367       |
| episodes                | 1348      |
| eplenmean               | 143       |
| fps                     | 21        |
| mean 100 episode reward | 367       |
| n_updates               | 50600     |
| q_grad_norm             | 4626.601  |
| qfs_loss                | 81.772316 |
| qs_abs_difference       | 246       |
| qs_difference           | 246       |
| qs_mean                 | 268.92526 |
| time_elapsed            | 2391      |
| total timesteps         | 50252     |
| train_time              | 569       |
| update_time             | 1699      |
---------------------------------------
---------------------------------------
| act_time                | 23        |
| current_lr              | 0.0003    |
| discount_q              | 2.89      |
| env_time                | 70        |
| ep_rewmean              | 373       |
| episodes                | 1352      |
| eplenmean               | 145       |
| fps                     | 20        |
| mean 100 episode reward | 373       |
| n_updates               | 51800     |
| q_grad_norm             | 5239.198  |
| qfs_loss                | 103.96307 |
| qs_abs_difference       | 73.5      |
| qs_difference           | 72.4      |
| qs_mean                 | 241.9437  |
| time_elapsed            | 2441      |
| total timesteps         | 50866     |
| train_time              | 582       |
| update_time             | 1734      |
---------------------------------------
---------------------------------------
| act_time                | 23        |
| current_lr              | 0.0003    |
| discount_q              | 0.495     |
| env_time                | 71        |
| ep_rewmean              | 387       |
| episodes                | 1356      |
| eplenmean               | 149       |
| fps                     | 20        |
| mean 100 episode reward | 388       |
| n_updates               | 53400     |
| q_grad_norm             | 5130.416  |
| qfs_loss                | 98.137764 |
| qs_abs_difference       | 22.1      |
| qs_difference           | 18.4      |
| qs_mean                 | 232.98865 |
| time_elapsed            | 2508      |
| total timesteps         | 51683     |
| train_time              | 600       |
| update_time             | 1782      |
---------------------------------------
---------------------------------------
| act_time                | 24        |
| current_lr              | 0.0003    |
| discount_q              | 0.26      |
| env_time                | 73        |
| ep_rewmean              | 408       |
| episodes                | 1360      |
| eplenmean               | 155       |
| fps                     | 20        |
| mean 100 episode reward | 408       |
| n_updates               | 55400     |
| q_grad_norm             | 6339.674  |
| qfs_loss                | 134.35318 |
| qs_abs_difference       | 48.6      |
| qs_difference           | 47.8      |
| qs_mean                 | 250.73976 |
| time_elapsed            | 2593      |
| total timesteps         | 52663     |
| train_time              | 623       |
| update_time             | 1842      |
---------------------------------------
---------------------------------------
| act_time                | 25        |
| current_lr              | 0.0003    |
| discount_q              | 0.259     |
| env_time                | 74        |
| ep_rewmean              | 417       |
| episodes                | 1364      |
| eplenmean               | 159       |
| fps                     | 20        |
| mean 100 episode reward | 417       |
| n_updates               | 57200     |
| q_grad_norm             | 5336.2676 |
| qfs_loss                | 100.89058 |
| qs_abs_difference       | 161       |
| qs_difference           | 161       |
| qs_mean                 | 278.93045 |
| time_elapsed            | 2670      |
| total timesteps         | 53516     |
| train_time              | 643       |
| update_time             | 1896      |
---------------------------------------
---------------------------------------
| act_time                | 25        |
| current_lr              | 0.0003    |
| discount_q              | 0.373     |
| env_time                | 75        |
| ep_rewmean              | 422       |
| episodes                | 1368      |
| eplenmean               | 161       |
| fps                     | 19        |
| mean 100 episode reward | 422       |
| n_updates               | 58400     |
| q_grad_norm             | 6144.3735 |
| qfs_loss                | 116.30283 |
| qs_abs_difference       | 204       |
| qs_difference           | 204       |
| qs_mean                 | 287.29623 |
| time_elapsed            | 2722      |
| total timesteps         | 54195     |
| train_time              | 656       |
| update_time             | 1933      |
---------------------------------------
---------------------------------------
| act_time                | 26        |
| current_lr              | 0.0003    |
| discount_q              | 0.642     |
| env_time                | 76        |
| ep_rewmean              | 428       |
| episodes                | 1372      |
| eplenmean               | 161       |
| fps                     | 19        |
| mean 100 episode reward | 428       |
| n_updates               | 60000     |
| q_grad_norm             | 5765.197  |
| qfs_loss                | 114.39142 |
| qs_abs_difference       | 47.3      |
| qs_difference           | 47.3      |
| qs_mean                 | 244.74284 |
| time_elapsed            | 2791      |
| total timesteps         | 54973     |
| train_time              | 674       |
| update_time             | 1982      |
---------------------------------------
---------------------------------------
| act_time                | 27        |
| current_lr              | 0.0003    |
| discount_q              | 0.463     |
| env_time                | 77        |
| ep_rewmean              | 437       |
| episodes                | 1376      |
| eplenmean               | 164       |
| fps                     | 19        |
| mean 100 episode reward | 437       |
| n_updates               | 61600     |
| q_grad_norm             | 7020.949  |
| qfs_loss                | 135.04462 |
| qs_abs_difference       | 87.9      |
| qs_difference           | 87.7      |
| qs_mean                 | 270.10696 |
| time_elapsed            | 2860      |
| total timesteps         | 55785     |
| train_time              | 692       |
| update_time             | 2031      |
---------------------------------------
----------------------------------------
| act_time                | 27         |
| current_lr              | 0.0003     |
| discount_q              | 0.487      |
| env_time                | 79         |
| ep_rewmean              | 443        |
| episodes                | 1380       |
| eplenmean               | 166        |
| fps                     | 19         |
| mean 100 episode reward | 443        |
| n_updates               | 63200      |
| q_grad_norm             | 5897.332   |
| qfs_loss                | 120.401764 |
| qs_abs_difference       | 96.6       |
| qs_difference           | 96.2       |
| qs_mean                 | 276.17575  |
| time_elapsed            | 2929       |
| total timesteps         | 56591      |
| train_time              | 710        |
| update_time             | 2080       |
----------------------------------------
---------------------------------------
| act_time                | 28        |
| current_lr              | 0.0003    |
| discount_q              | 0.5       |
| env_time                | 80        |
| ep_rewmean              | 450       |
| episodes                | 1384      |
| eplenmean               | 168       |
| fps                     | 19        |
| mean 100 episode reward | 450       |
| n_updates               | 64800     |
| q_grad_norm             | 6006.8843 |
| qfs_loss                | 123.36929 |
| qs_abs_difference       | 89.2      |
| qs_difference           | 88.8      |
| qs_mean                 | 268.95203 |
| time_elapsed            | 2999      |
| total timesteps         | 57383     |
| train_time              | 728       |
| update_time             | 2130      |
---------------------------------------
--------------------------------------
| act_time                | 28       |
| current_lr              | 0.0003   |
| discount_q              | 0.294    |
| env_time                | 81       |
| ep_rewmean              | 450      |
| episodes                | 1388     |
| eplenmean               | 168      |
| fps                     | 18       |
| mean 100 episode reward | 450      |
| n_updates               | 66000    |
| q_grad_norm             | 5124.162 |
| qfs_loss                | 96.21182 |
| qs_abs_difference       | 257      |
| qs_difference           | 257      |
| qs_mean                 | 288.9082 |
| time_elapsed            | 3052     |
| total timesteps         | 57931    |
| train_time              | 741      |
| update_time             | 2168     |
--------------------------------------
---------------------------------------
| act_time                | 29        |
| current_lr              | 0.0003    |
| discount_q              | 1.08      |
| env_time                | 82        |
| ep_rewmean              | 456       |
| episodes                | 1392      |
| eplenmean               | 170       |
| fps                     | 18        |
| mean 100 episode reward | 456       |
| n_updates               | 67400     |
| q_grad_norm             | 6442.5015 |
| qfs_loss                | 127.44654 |
| qs_abs_difference       | 81.7      |
| qs_difference           | 81.2      |
| qs_mean                 | 269.86145 |
| time_elapsed            | 3113      |
| total timesteps         | 58664     |
| train_time              | 757       |
| update_time             | 2212      |
---------------------------------------
---------------------------------------
| act_time                | 30        |
| current_lr              | 0.0003    |
| discount_q              | 1.5       |
| env_time                | 83        |
| ep_rewmean              | 462       |
| episodes                | 1396      |
| eplenmean               | 171       |
| fps                     | 18        |
| mean 100 episode reward | 462       |
| n_updates               | 68800     |
| q_grad_norm             | 6291.3794 |
| qfs_loss                | 129.74765 |
| qs_abs_difference       | 96        |
| qs_difference           | 96        |
| qs_mean                 | 263.31952 |
| time_elapsed            | 3175      |
| total timesteps         | 59330     |
| train_time              | 773       |
| update_time             | 2257      |
---------------------------------------
---------------------------------------
| act_time                | 30        |
| current_lr              | 0.0003    |
| discount_q              | 2.46      |
| env_time                | 83        |
| ep_rewmean              | 461       |
| episodes                | 1400      |
| eplenmean               | 171       |
| fps                     | 18        |
| mean 100 episode reward | 461       |
| n_updates               | 69600     |
| q_grad_norm             | 5687.033  |
| qfs_loss                | 132.8716  |
| qs_abs_difference       | 236       |
| qs_difference           | 236       |
| qs_mean                 | 308.00153 |
| time_elapsed            | 3211      |
| total timesteps         | 59787     |
| train_time              | 782       |
| update_time             | 2282      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 224       |
| eval_abs_qs_difference  | 68.54349  |
| eval_discount_q         | 207       |
| eval_ep_rewmean         | 530       |
| eval_eplenmean          | 182       |
| eval_qs                 | 243.23851 |
| eval_qs_difference      | 63.9      |
| eval_time_elapsed       | 4         |
| total timesteps         | 60001     |
---------------------------------------
---------------------------------------
| act_time                | 30        |
| current_lr              | 0.0003    |
| discount_q              | 1.13      |
| env_time                | 84        |
| ep_rewmean              | 464       |
| episodes                | 1404      |
| eplenmean               | 172       |
| fps                     | 18        |
| mean 100 episode reward | 464       |
| n_updates               | 70800     |
| q_grad_norm             | 5650.4673 |
| qfs_loss                | 120.00618 |
| qs_abs_difference       | 226       |
| qs_difference           | 226       |
| qs_mean                 | 308.05478 |
| time_elapsed            | 3269      |
| total timesteps         | 60347     |
| train_time              | 795       |
| update_time             | 2320      |
---------------------------------------
---------------------------------------
| act_time                | 31        |
| current_lr              | 0.0003    |
| discount_q              | 0.565     |
| env_time                | 85        |
| ep_rewmean              | 469       |
| episodes                | 1408      |
| eplenmean               | 173       |
| fps                     | 18        |
| mean 100 episode reward | 469       |
| n_updates               | 72400     |
| q_grad_norm             | 6292.0894 |
| qfs_loss                | 137.1845  |
| qs_abs_difference       | 89.8      |
| qs_difference           | 89.7      |
| qs_mean                 | 272.35443 |
| time_elapsed            | 3341      |
| total timesteps         | 61143     |
| train_time              | 813       |
| update_time             | 2372      |
---------------------------------------
---------------------------------------
| act_time                | 31        |
| current_lr              | 0.0003    |
| discount_q              | 0.514     |
| env_time                | 86        |
| ep_rewmean              | 476       |
| episodes                | 1412      |
| eplenmean               | 175       |
| fps                     | 18        |
| mean 100 episode reward | 476       |
| n_updates               | 74000     |
| q_grad_norm             | 5931.085  |
| qfs_loss                | 111.15432 |
| qs_abs_difference       | 69        |
| qs_difference           | 69        |
| qs_mean                 | 268.65506 |
| time_elapsed            | 3413      |
| total timesteps         | 61949     |
| train_time              | 831       |
| update_time             | 2424      |
---------------------------------------
---------------------------------------
| act_time                | 32        |
| current_lr              | 0.0003    |
| discount_q              | 0.78      |
| env_time                | 88        |
| ep_rewmean              | 484       |
| episodes                | 1416      |
| eplenmean               | 177       |
| fps                     | 18        |
| mean 100 episode reward | 484       |
| n_updates               | 75600     |
| q_grad_norm             | 6211.514  |
| qfs_loss                | 126.47348 |
| qs_abs_difference       | 77        |
| qs_difference           | 76.4      |
| qs_mean                 | 287.79605 |
| time_elapsed            | 3485      |
| total timesteps         | 62785     |
| train_time              | 849       |
| update_time             | 2476      |
---------------------------------------
---------------------------------------
| act_time                | 33        |
| current_lr              | 0.0003    |
| discount_q              | 0.462     |
| env_time                | 89        |
| ep_rewmean              | 492       |
| episodes                | 1420      |
| eplenmean               | 178       |
| fps                     | 17        |
| mean 100 episode reward | 492       |
| n_updates               | 77400     |
| q_grad_norm             | 6103.601  |
| qfs_loss                | 127.47959 |
| qs_abs_difference       | 47.8      |
| qs_difference           | 45.9      |
| qs_mean                 | 255.61668 |
| time_elapsed            | 3566      |
| total timesteps         | 63611     |
| train_time              | 869       |
| update_time             | 2536      |
---------------------------------------
---------------------------------------
| act_time                | 33        |
| current_lr              | 0.0003    |
| discount_q              | 0.292     |
| env_time                | 90        |
| ep_rewmean              | 504       |
| episodes                | 1424      |
| eplenmean               | 181       |
| fps                     | 17        |
| mean 100 episode reward | 504       |
| n_updates               | 79000     |
| q_grad_norm             | 6702.54   |
| qfs_loss                | 139.04555 |
| qs_abs_difference       | 70.4      |
| qs_difference           | 70.4      |
| qs_mean                 | 275.2297  |
| time_elapsed            | 3640      |
| total timesteps         | 64499     |
| train_time              | 887       |
| update_time             | 2589      |
---------------------------------------
---------------------------------------
| act_time                | 34        |
| current_lr              | 0.0003    |
| discount_q              | 0.22      |
| env_time                | 91        |
| ep_rewmean              | 516       |
| episodes                | 1428      |
| eplenmean               | 185       |
| fps                     | 17        |
| mean 100 episode reward | 516       |
| n_updates               | 80800     |
| q_grad_norm             | 6953.725  |
| qfs_loss                | 135.02893 |
| qs_abs_difference       | 68.6      |
| qs_difference           | 68.6      |
| qs_mean                 | 272.02856 |
| time_elapsed            | 3722      |
| total timesteps         | 65397     |
| train_time              | 907       |
| update_time             | 2649      |
---------------------------------------
----------------------------------------
| act_time                | 35         |
| current_lr              | 0.0003     |
| discount_q              | 0.221      |
| env_time                | 93         |
| ep_rewmean              | 532        |
| episodes                | 1432       |
| eplenmean               | 188        |
| fps                     | 17         |
| mean 100 episode reward | 532        |
| n_updates               | 82800      |
| q_grad_norm             | 6123.009   |
| qfs_loss                | 126.648155 |
| qs_abs_difference       | 60.6       |
| qs_difference           | 60.6       |
| qs_mean                 | 279.74353  |
| time_elapsed            | 3814       |
| total timesteps         | 66326      |
| train_time              | 929        |
| update_time             | 2716       |
----------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 0.277     |
| env_time                | 94        |
| ep_rewmean              | 540       |
| episodes                | 1436      |
| eplenmean               | 190       |
| fps                     | 17        |
| mean 100 episode reward | 540       |
| n_updates               | 84600     |
| q_grad_norm             | 5953.717  |
| qfs_loss                | 115.03501 |
| qs_abs_difference       | 80.3      |
| qs_difference           | 79.3      |
| qs_mean                 | 276.90228 |
| time_elapsed            | 3898      |
| total timesteps         | 67207     |
| train_time              | 949       |
| update_time             | 2778      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 0.247     |
| env_time                | 96        |
| ep_rewmean              | 548       |
| episodes                | 1440      |
| eplenmean               | 192       |
| fps                     | 17        |
| mean 100 episode reward | 548       |
| n_updates               | 86400     |
| q_grad_norm             | 5633.436  |
| qfs_loss                | 99.321846 |
| qs_abs_difference       | 78.4      |
| qs_difference           | 77.5      |
| qs_mean                 | 276.3952  |
| time_elapsed            | 3982      |
| total timesteps         | 68122     |
| train_time              | 970       |
| update_time             | 2839      |
---------------------------------------
---------------------------------------
| act_time                | 37        |
| current_lr              | 0.0003    |
| discount_q              | 0.125     |
| env_time                | 97        |
| ep_rewmean              | 561       |
| episodes                | 1444      |
| eplenmean               | 195       |
| fps                     | 16        |
| mean 100 episode reward | 561       |
| n_updates               | 88200     |
| q_grad_norm             | 6648.5405 |
| qfs_loss                | 132.6785  |
| qs_abs_difference       | 72.8      |
| qs_difference           | 72.8      |
| qs_mean                 | 264.58792 |
| time_elapsed            | 4067      |
| total timesteps         | 69062     |
| train_time              | 990       |
| update_time             | 2901      |
---------------------------------------
---------------------------------------
| act_time                | 38        |
| current_lr              | 0.0003    |
| discount_q              | 0.618     |
| env_time                | 98        |
| ep_rewmean              | 567       |
| episodes                | 1448      |
| eplenmean               | 196       |
| fps                     | 16        |
| mean 100 episode reward | 567       |
| n_updates               | 89800     |
| q_grad_norm             | 5478.5254 |
| qfs_loss                | 102.50838 |
| qs_abs_difference       | 53        |
| qs_difference           | 53        |
| qs_mean                 | 258.6472  |
| time_elapsed            | 4142      |
| total timesteps         | 69853     |
| train_time              | 1008      |
| update_time             | 2956      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 280       |
| eval_abs_qs_difference  | 70.0655   |
| eval_discount_q         | 218       |
| eval_ep_rewmean         | 683       |
| eval_eplenmean          | 229       |
| eval_qs                 | 266.14798 |
| eval_qs_difference      | 62.4      |
| eval_time_elapsed       | 5         |
| total timesteps         | 70001     |
---------------------------------------
---------------------------------------
| act_time                | 38        |
| current_lr              | 0.0003    |
| discount_q              | 0.0639    |
| env_time                | 100       |
| ep_rewmean              | 578       |
| episodes                | 1452      |
| eplenmean               | 199       |
| fps                     | 16        |
| mean 100 episode reward | 578       |
| n_updates               | 91600     |
| q_grad_norm             | 5166.053  |
| qfs_loss                | 102.28288 |
| qs_abs_difference       | 198       |
| qs_difference           | 198       |
| qs_mean                 | 311.56625 |
| time_elapsed            | 4233      |
| total timesteps         | 70787     |
| train_time              | 1028      |
| update_time             | 3018      |
---------------------------------------
---------------------------------------
| act_time                | 39        |
| current_lr              | 0.0003    |
| discount_q              | 1.78      |
| env_time                | 101       |
| ep_rewmean              | 576       |
| episodes                | 1456      |
| eplenmean               | 198       |
| fps                     | 16        |
| mean 100 episode reward | 576       |
| n_updates               | 93200     |
| q_grad_norm             | 5208.3735 |
| qfs_loss                | 97.05975  |
| qs_abs_difference       | 51.4      |
| qs_difference           | 51.4      |
| qs_mean                 | 276.5932  |
| time_elapsed            | 4309      |
| total timesteps         | 71523     |
| train_time              | 1046      |
| update_time             | 3075      |
---------------------------------------
---------------------------------------
| act_time                | 40        |
| current_lr              | 0.0003    |
| discount_q              | 0.243     |
| env_time                | 102       |
| ep_rewmean              | 572       |
| episodes                | 1460      |
| eplenmean               | 197       |
| fps                     | 16        |
| mean 100 episode reward | 572       |
| n_updates               | 94800     |
| q_grad_norm             | 4796.583  |
| qfs_loss                | 109.24741 |
| qs_abs_difference       | 80.7      |
| qs_difference           | 80.5      |
| qs_mean                 | 235.71445 |
| time_elapsed            | 4384      |
| total timesteps         | 72341     |
| train_time              | 1063      |
| update_time             | 3130      |
---------------------------------------
----------------------------------------
| act_time                | 40         |
| current_lr              | 0.0003     |
| discount_q              | 1.6        |
| env_time                | 103        |
| ep_rewmean              | 560        |
| episodes                | 1464       |
| eplenmean               | 192        |
| fps                     | 16         |
| mean 100 episode reward | 560        |
| n_updates               | 95400      |
| q_grad_norm             | 5418.4243  |
| qfs_loss                | 109.144066 |
| qs_abs_difference       | 254        |
| qs_difference           | 254        |
| qs_mean                 | 279.8162   |
| time_elapsed            | 4412       |
| total timesteps         | 72698      |
| train_time              | 1069       |
| update_time             | 3151       |
----------------------------------------
---------------------------------------
| act_time                | 40        |
| current_lr              | 0.0003    |
| discount_q              | 57        |
| env_time                | 103       |
| ep_rewmean              | 551       |
| episodes                | 1468      |
| eplenmean               | 189       |
| fps                     | 16        |
| mean 100 episode reward | 551       |
| n_updates               | 96200     |
| q_grad_norm             | 5511.0444 |
| qfs_loss                | 108.09895 |
| qs_abs_difference       | 34.9      |
| qs_difference           | 33.9      |
| qs_mean                 | 257.99405 |
| time_elapsed            | 4449      |
| total timesteps         | 73051     |
| train_time              | 1078      |
| update_time             | 3179      |
---------------------------------------
---------------------------------------
| act_time                | 41        |
| current_lr              | 0.0003    |
| discount_q              | 0.456     |
| env_time                | 104       |
| ep_rewmean              | 555       |
| episodes                | 1472      |
| eplenmean               | 189       |
| fps                     | 16        |
| mean 100 episode reward | 555       |
| n_updates               | 97800     |
| q_grad_norm             | 5607.5317 |
| qfs_loss                | 100.12086 |
| qs_abs_difference       | 49        |
| qs_difference           | 47.3      |
| qs_mean                 | 251.2947  |
| time_elapsed            | 4525      |
| total timesteps         | 73857     |
| train_time              | 1095      |
| update_time             | 3236      |
---------------------------------------
----------------------------------------
| act_time                | 42         |
| current_lr              | 0.0003     |
| discount_q              | 0.287      |
| env_time                | 106        |
| ep_rewmean              | 563        |
| episodes                | 1476       |
| eplenmean               | 190        |
| fps                     | 16         |
| mean 100 episode reward | 563        |
| n_updates               | 99600      |
| q_grad_norm             | 5283.598   |
| qfs_loss                | 103.258896 |
| qs_abs_difference       | 33.4       |
| qs_difference           | 32.3       |
| qs_mean                 | 270.99722  |
| time_elapsed            | 4610       |
| total timesteps         | 74767      |
| train_time              | 1114       |
| update_time             | 3299       |
----------------------------------------
---------------------------------------
| act_time                | 42        |
| current_lr              | 0.0003    |
| discount_q              | 0.408     |
| env_time                | 107       |
| ep_rewmean              | 568       |
| episodes                | 1480      |
| eplenmean               | 190       |
| fps                     | 16        |
| mean 100 episode reward | 568       |
| n_updates               | 101400    |
| q_grad_norm             | 4913.2485 |
| qfs_loss                | 88.71173  |
| qs_abs_difference       | 27.6      |
| qs_difference           | 26        |
| qs_mean                 | 263.28555 |
| time_elapsed            | 4695      |
| total timesteps         | 75615     |
| train_time              | 1133      |
| update_time             | 3363      |
---------------------------------------
---------------------------------------
| act_time                | 43        |
| current_lr              | 0.0003    |
| discount_q              | 0.571     |
| env_time                | 108       |
| ep_rewmean              | 572       |
| episodes                | 1484      |
| eplenmean               | 191       |
| fps                     | 16        |
| mean 100 episode reward | 572       |
| n_updates               | 103000    |
| q_grad_norm             | 6017.0044 |
| qfs_loss                | 110.73871 |
| qs_abs_difference       | 48        |
| qs_difference           | 47.9      |
| qs_mean                 | 279.96582 |
| time_elapsed            | 4771      |
| total timesteps         | 76438     |
| train_time              | 1150      |
| update_time             | 3420      |
---------------------------------------
----------------------------------------
| act_time                | 43         |
| current_lr              | 0.0003     |
| discount_q              | 0.589      |
| env_time                | 109        |
| ep_rewmean              | 583        |
| episodes                | 1488       |
| eplenmean               | 193        |
| fps                     | 15         |
| mean 100 episode reward | 583        |
| n_updates               | 104600     |
| q_grad_norm             | 5848.2363  |
| qfs_loss                | 103.237976 |
| qs_abs_difference       | 85.8       |
| qs_difference           | 85.7       |
| qs_mean                 | 281.82913  |
| time_elapsed            | 4848       |
| total timesteps         | 77216      |
| train_time              | 1167       |
| update_time             | 3477       |
----------------------------------------
--------------------------------------
| act_time                | 44       |
| current_lr              | 0.0003   |
| discount_q              | 2.34     |
| env_time                | 110      |
| ep_rewmean              | 585      |
| episodes                | 1492     |
| eplenmean               | 193      |
| fps                     | 15       |
| mean 100 episode reward | 585      |
| n_updates               | 106000   |
| q_grad_norm             | 5418.744 |
| qfs_loss                | 99.98957 |
| qs_abs_difference       | 30.2     |
| qs_difference           | 22.6     |
| qs_mean                 | 276.1989 |
| time_elapsed            | 4915     |
| total timesteps         | 77952    |
| train_time              | 1182     |
| update_time             | 3528     |
--------------------------------------
--------------------------------------
| act_time                | 44       |
| current_lr              | 0.0003   |
| discount_q              | 0.427    |
| env_time                | 111      |
| ep_rewmean              | 583      |
| episodes                | 1496     |
| eplenmean               | 192      |
| fps                     | 15       |
| mean 100 episode reward | 584      |
| n_updates               | 107200   |
| q_grad_norm             | 4707.174 |
| qfs_loss                | 94.95602 |
| qs_abs_difference       | 257      |
| qs_difference           | 257      |
| qs_mean                 | 299.0741 |
| time_elapsed            | 4972     |
| total timesteps         | 78508    |
| train_time              | 1195     |
| update_time             | 3571     |
--------------------------------------
---------------------------------------
| act_time                | 45        |
| current_lr              | 0.0003    |
| discount_q              | 49.4      |
| env_time                | 111       |
| ep_rewmean              | 582       |
| episodes                | 1500      |
| eplenmean               | 191       |
| fps                     | 15        |
| mean 100 episode reward | 582       |
| n_updates               | 107800    |
| q_grad_norm             | 5414.1836 |
| qfs_loss                | 106.19163 |
| qs_abs_difference       | 47.1      |
| qs_difference           | 43.8      |
| qs_mean                 | 258.2267  |
| time_elapsed            | 5001      |
| total timesteps         | 78882     |
| train_time              | 1201      |
| update_time             | 3593      |
---------------------------------------
---------------------------------------
| act_time                | 45        |
| current_lr              | 0.0003    |
| discount_q              | 0.383     |
| env_time                | 113       |
| ep_rewmean              | 594       |
| episodes                | 1504      |
| eplenmean               | 194       |
| fps                     | 15        |
| mean 100 episode reward | 594       |
| n_updates               | 109600    |
| q_grad_norm             | 5297.0293 |
| qfs_loss                | 106.76251 |
| qs_abs_difference       | 56.1      |
| qs_difference           | 55.8      |
| qs_mean                 | 267.31137 |
| time_elapsed            | 5088      |
| total timesteps         | 79741     |
| train_time              | 1221      |
| update_time             | 3659      |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 304      |
| eval_abs_qs_difference  | 92.21202 |
| eval_discount_q         | 188      |
| eval_ep_rewmean         | 475      |
| eval_eplenmean          | 179      |
| eval_qs                 | 251.2455 |
| eval_qs_difference      | 90       |
| eval_time_elapsed       | 3        |
| total timesteps         | 80001    |
--------------------------------------
---------------------------------------
| act_time                | 46        |
| current_lr              | 0.0003    |
| discount_q              | 0.163     |
| env_time                | 114       |
| ep_rewmean              | 599       |
| episodes                | 1508      |
| eplenmean               | 195       |
| fps                     | 15        |
| mean 100 episode reward | 599       |
| n_updates               | 111400    |
| q_grad_norm             | 4633.084  |
| qfs_loss                | 102.64759 |
| qs_abs_difference       | 73.9      |
| qs_difference           | 73.9      |
| qs_mean                 | 250.03055 |
| time_elapsed            | 5180      |
| total timesteps         | 80625     |
| train_time              | 1240      |
| update_time             | 3725      |
---------------------------------------
---------------------------------------
| act_time                | 47        |
| current_lr              | 0.0003    |
| discount_q              | 0.644     |
| env_time                | 115       |
| ep_rewmean              | 595       |
| episodes                | 1512      |
| eplenmean               | 194       |
| fps                     | 15        |
| mean 100 episode reward | 595       |
| n_updates               | 112800    |
| q_grad_norm             | 5036.0083 |
| qfs_loss                | 93.38279  |
| qs_abs_difference       | 88        |
| qs_difference           | 87        |
| qs_mean                 | 230.75069 |
| time_elapsed            | 5248      |
| total timesteps         | 81340     |
| train_time              | 1255      |
| update_time             | 3777      |
---------------------------------------
---------------------------------------
| act_time                | 47        |
| current_lr              | 0.0003    |
| discount_q              | 1.09      |
| env_time                | 116       |
| ep_rewmean              | 592       |
| episodes                | 1516      |
| eplenmean               | 193       |
| fps                     | 15        |
| mean 100 episode reward | 592       |
| n_updates               | 114200    |
| q_grad_norm             | 4975.3433 |
| qfs_loss                | 98.51356  |
| qs_abs_difference       | 76        |
| qs_difference           | 75.8      |
| qs_mean                 | 283.39758 |
| time_elapsed            | 5317      |
| total timesteps         | 82076     |
| train_time              | 1269      |
| update_time             | 3829      |
---------------------------------------
---------------------------------------
| act_time                | 48        |
| current_lr              | 0.0003    |
| discount_q              | 0.564     |
| env_time                | 117       |
| ep_rewmean              | 594       |
| episodes                | 1520      |
| eplenmean               | 193       |
| fps                     | 15        |
| mean 100 episode reward | 594       |
| n_updates               | 115800    |
| q_grad_norm             | 4955.538  |
| qfs_loss                | 107.49286 |
| qs_abs_difference       | 28        |
| qs_difference           | 23.5      |
| qs_mean                 | 259.0322  |
| time_elapsed            | 5396      |
| total timesteps         | 82884     |
| train_time              | 1286      |
| update_time             | 3889      |
---------------------------------------
---------------------------------------
| act_time                | 48        |
| current_lr              | 0.0003    |
| discount_q              | 0.488     |
| env_time                | 118       |
| ep_rewmean              | 583       |
| episodes                | 1524      |
| eplenmean               | 189       |
| fps                     | 15        |
| mean 100 episode reward | 583       |
| n_updates               | 116800    |
| q_grad_norm             | 4931.937  |
| qfs_loss                | 103.52505 |
| qs_abs_difference       | 262       |
| qs_difference           | 262       |
| qs_mean                 | 291.30014 |
| time_elapsed            | 5445      |
| total timesteps         | 83374     |
| train_time              | 1297      |
| update_time             | 3926      |
---------------------------------------
---------------------------------------
| act_time                | 48        |
| current_lr              | 0.0003    |
| discount_q              | 18.1      |
| env_time                | 118       |
| ep_rewmean              | 557       |
| episodes                | 1528      |
| eplenmean               | 181       |
| fps                     | 15        |
| mean 100 episode reward | 557       |
| n_updates               | 117000    |
| q_grad_norm             | 4581.062  |
| qfs_loss                | 98.3764   |
| qs_abs_difference       | 262       |
| qs_difference           | 262       |
| qs_mean                 | 289.64368 |
| time_elapsed            | 5455      |
| total timesteps         | 83497     |
| train_time              | 1299      |
| update_time             | 3934      |
---------------------------------------
---------------------------------------
| act_time                | 49        |
| current_lr              | 0.0003    |
| discount_q              | 0.69      |
| env_time                | 119       |
| ep_rewmean              | 554       |
| episodes                | 1532      |
| eplenmean               | 180       |
| fps                     | 15        |
| mean 100 episode reward | 554       |
| n_updates               | 118800    |
| q_grad_norm             | 5049.412  |
| qfs_loss                | 113.92326 |
| qs_abs_difference       | 54        |
| qs_difference           | 52.9      |
| qs_mean                 | 290.876   |
| time_elapsed            | 5545      |
| total timesteps         | 84342     |
| train_time              | 1318      |
| update_time             | 4002      |
---------------------------------------
---------------------------------------
| act_time                | 49        |
| current_lr              | 0.0003    |
| discount_q              | 2.51      |
| env_time                | 120       |
| ep_rewmean              | 548       |
| episodes                | 1536      |
| eplenmean               | 178       |
| fps                     | 15        |
| mean 100 episode reward | 548       |
| n_updates               | 120200    |
| q_grad_norm             | 5992.085  |
| qfs_loss                | 146.76659 |
| qs_abs_difference       | 48.6      |
| qs_difference           | 45.9      |
| qs_mean                 | 267.09015 |
| time_elapsed            | 5615      |
| total timesteps         | 85023     |
| train_time              | 1333      |
| update_time             | 4056      |
---------------------------------------
--------------------------------------
| act_time                | 50       |
| current_lr              | 0.0003   |
| discount_q              | 0.517    |
| env_time                | 121      |
| ep_rewmean              | 547      |
| episodes                | 1540     |
| eplenmean               | 177      |
| fps                     | 15       |
| mean 100 episode reward | 547      |
| n_updates               | 121800   |
| q_grad_norm             | 4394.212 |
| qfs_loss                | 94.37134 |
| qs_abs_difference       | 73.2     |
| qs_difference           | 72.8     |
| qs_mean                 | 286.6009 |
| time_elapsed            | 5694     |
| total timesteps         | 85850    |
| train_time              | 1350     |
| update_time             | 4116     |
--------------------------------------
---------------------------------------
| act_time                | 51        |
| current_lr              | 0.0003    |
| discount_q              | 0.189     |
| env_time                | 123       |
| ep_rewmean              | 550       |
| episodes                | 1544      |
| eplenmean               | 177       |
| fps                     | 15        |
| mean 100 episode reward | 550       |
| n_updates               | 123600    |
| q_grad_norm             | 4707.122  |
| qfs_loss                | 94.393135 |
| qs_abs_difference       | 63.9      |
| qs_difference           | 63.7      |
| qs_mean                 | 285.62866 |
| time_elapsed            | 5784      |
| total timesteps         | 86797     |
| train_time              | 1369      |
| update_time             | 4185      |
---------------------------------------
---------------------------------------
| act_time                | 51        |
| current_lr              | 0.0003    |
| discount_q              | 0.424     |
| env_time                | 124       |
| ep_rewmean              | 553       |
| episodes                | 1548      |
| eplenmean               | 178       |
| fps                     | 14        |
| mean 100 episode reward | 553       |
| n_updates               | 125400    |
| q_grad_norm             | 4451.6104 |
| qfs_loss                | 85.68115  |
| qs_abs_difference       | 78.7      |
| qs_difference           | 78.3      |
| qs_mean                 | 288.09555 |
| time_elapsed            | 5875      |
| total timesteps         | 87650     |
| train_time              | 1388      |
| update_time             | 4254      |
---------------------------------------
----------------------------------------
| act_time                | 52         |
| current_lr              | 0.0003     |
| discount_q              | 0.339      |
| env_time                | 125        |
| ep_rewmean              | 557        |
| episodes                | 1552       |
| eplenmean               | 178        |
| fps                     | 14         |
| mean 100 episode reward | 557        |
| n_updates               | 127200     |
| q_grad_norm             | 5443.963   |
| qfs_loss                | 100.122025 |
| qs_abs_difference       | 34.8       |
| qs_difference           | 33.6       |
| qs_mean                 | 281.32605  |
| time_elapsed            | 5967       |
| total timesteps         | 88554      |
| train_time              | 1407       |
| update_time             | 4325       |
----------------------------------------
---------------------------------------
| act_time                | 53        |
| current_lr              | 0.0003    |
| discount_q              | 0.297     |
| env_time                | 126       |
| ep_rewmean              | 567       |
| episodes                | 1556      |
| eplenmean               | 180       |
| fps                     | 14        |
| mean 100 episode reward | 566       |
| n_updates               | 129000    |
| q_grad_norm             | 4865.8306 |
| qfs_loss                | 95.91946  |
| qs_abs_difference       | 21.3      |
| qs_difference           | 19.1      |
| qs_mean                 | 277.98862 |
| time_elapsed            | 6061      |
| total timesteps         | 89480     |
| train_time              | 1427      |
| update_time             | 4396      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 366       |
| eval_abs_qs_difference  | 64.18143  |
| eval_discount_q         | 227       |
| eval_ep_rewmean         | 633       |
| eval_eplenmean          | 196       |
| eval_qs                 | 269.54697 |
| eval_qs_difference      | 61.9      |
| eval_time_elapsed       | 4         |
| total timesteps         | 90001     |
---------------------------------------
---------------------------------------
| act_time                | 54        |
| current_lr              | 0.0003    |
| discount_q              | 0.185     |
| env_time                | 128       |
| ep_rewmean              | 574       |
| episodes                | 1560      |
| eplenmean               | 181       |
| fps                     | 14        |
| mean 100 episode reward | 574       |
| n_updates               | 131000    |
| q_grad_norm             | 5991.64   |
| qfs_loss                | 115.31251 |
| qs_abs_difference       | 57.1      |
| qs_difference           | 56.4      |
| qs_mean                 | 300.041   |
| time_elapsed            | 6170      |
| total timesteps         | 90472     |
| train_time              | 1450      |
| update_time             | 4476      |
---------------------------------------
---------------------------------------
| act_time                | 54        |
| current_lr              | 0.0003    |
| discount_q              | 0.206     |
| env_time                | 129       |
| ep_rewmean              | 600       |
| episodes                | 1564      |
| eplenmean               | 187       |
| fps                     | 14        |
| mean 100 episode reward | 600       |
| n_updates               | 133000    |
| q_grad_norm             | 4968.304  |
| qfs_loss                | 103.52633 |
| qs_abs_difference       | 20.3      |
| qs_difference           | 19        |
| qs_mean                 | 282.3616  |
| time_elapsed            | 6276      |
| total timesteps         | 91437     |
| train_time              | 1472      |
| update_time             | 4557      |
---------------------------------------
---------------------------------------
| act_time                | 55        |
| current_lr              | 0.0003    |
| discount_q              | 0.3       |
| env_time                | 131       |
| ep_rewmean              | 622       |
| episodes                | 1568      |
| eplenmean               | 193       |
| fps                     | 14        |
| mean 100 episode reward | 622       |
| n_updates               | 134800    |
| q_grad_norm             | 5422.0083 |
| qfs_loss                | 104.39889 |
| qs_abs_difference       | 43.1      |
| qs_difference           | 40.8      |
| qs_mean                 | 285.9443  |
| time_elapsed            | 6371      |
| total timesteps         | 92360     |
| train_time              | 1492      |
| update_time             | 4630      |
---------------------------------------
---------------------------------------
| act_time                | 56        |
| current_lr              | 0.0003    |
| discount_q              | 0.0259    |
| env_time                | 132       |
| ep_rewmean              | 639       |
| episodes                | 1572      |
| eplenmean               | 197       |
| fps                     | 14        |
| mean 100 episode reward | 639       |
| n_updates               | 137200    |
| q_grad_norm             | 5197.4785 |
| qfs_loss                | 114.75841 |
| qs_abs_difference       | 22.4      |
| qs_difference           | 21.3      |
| qs_mean                 | 301.35522 |
| time_elapsed            | 6499      |
| total timesteps         | 93599     |
| train_time              | 1519      |
| update_time             | 4728      |
---------------------------------------
---------------------------------------
| act_time                | 57        |
| current_lr              | 0.0003    |
| discount_q              | 0.0763    |
| env_time                | 134       |
| ep_rewmean              | 645       |
| episodes                | 1576      |
| eplenmean               | 199       |
| fps                     | 14        |
| mean 100 episode reward | 645       |
| n_updates               | 139400    |
| q_grad_norm             | 5399.2764 |
| qfs_loss                | 105.00359 |
| qs_abs_difference       | 68.2      |
| qs_difference           | 68.1      |
| qs_mean                 | 298.37643 |
| time_elapsed            | 6616      |
| total timesteps         | 94634     |
| train_time              | 1544      |
| update_time             | 4818      |
---------------------------------------
---------------------------------------
| act_time                | 58        |
| current_lr              | 0.0003    |
| discount_q              | 0.0228    |
| env_time                | 135       |
| ep_rewmean              | 658       |
| episodes                | 1580      |
| eplenmean               | 203       |
| fps                     | 14        |
| mean 100 episode reward | 658       |
| n_updates               | 141800    |
| q_grad_norm             | 5862.56   |
| qfs_loss                | 113.09267 |
| qs_abs_difference       | 37.1      |
| qs_difference           | 37        |
| qs_mean                 | 308.10913 |
| time_elapsed            | 6744      |
| total timesteps         | 95866     |
| train_time              | 1570      |
| update_time             | 4916      |
---------------------------------------
---------------------------------------
| act_time                | 59        |
| current_lr              | 0.0003    |
| discount_q              | 0.000224  |
| env_time                | 138       |
| ep_rewmean              | 682       |
| episodes                | 1584      |
| eplenmean               | 210       |
| fps                     | 14        |
| mean 100 episode reward | 682       |
| n_updates               | 145000    |
| q_grad_norm             | 5557.8125 |
| qfs_loss                | 121.61573 |
| qs_abs_difference       | 61.9      |
| qs_difference           | 61.9      |
| qs_mean                 | 278.17963 |
| time_elapsed            | 6917      |
| total timesteps         | 97448     |
| train_time              | 1606      |
| update_time             | 5050      |
---------------------------------------
---------------------------------------
| act_time                | 60        |
| current_lr              | 0.0003    |
| discount_q              | 2.28e-05  |
| env_time                | 141       |
| ep_rewmean              | 724       |
| episodes                | 1588      |
| eplenmean               | 222       |
| fps                     | 13        |
| mean 100 episode reward | 724       |
| n_updates               | 149000    |
| q_grad_norm             | 6184.6636 |
| qfs_loss                | 124.68217 |
| qs_abs_difference       | 34.9      |
| qs_difference           | 34.7      |
| qs_mean                 | 314.8718  |
| time_elapsed            | 7134      |
| total timesteps         | 99402     |
| train_time              | 1651      |
| update_time             | 5217      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 489       |
| eval_abs_qs_difference  | 22.244171 |
| eval_discount_q         | 264       |
| eval_ep_rewmean         | 1.16e+03  |
| eval_eplenmean          | 314       |
| eval_qs                 | 306.31262 |
| eval_qs_difference      | 19.1      |
| eval_time_elapsed       | 7         |
| total timesteps         | 100001    |
---------------------------------------
---------------------------------------
| act_time                | 62        |
| current_lr              | 0.0003    |
| discount_q              | 0.000147  |
| env_time                | 143       |
| ep_rewmean              | 764       |
| episodes                | 1592      |
| eplenmean               | 232       |
| fps                     | 13        |
| mean 100 episode reward | 764       |
| n_updates               | 152400    |
| q_grad_norm             | 6169.0796 |
| qfs_loss                | 135.70439 |
| qs_abs_difference       | 55.5      |
| qs_difference           | 55.5      |
| qs_mean                 | 321.254   |
| time_elapsed            | 7323      |
| total timesteps         | 101136    |
| train_time              | 1689      |
| update_time             | 5355      |
---------------------------------------
---------------------------------------
| act_time                | 63        |
| current_lr              | 0.0003    |
| discount_q              | 0.00923   |
| env_time                | 145       |
| ep_rewmean              | 793       |
| episodes                | 1596      |
| eplenmean               | 239       |
| fps                     | 13        |
| mean 100 episode reward | 793       |
| n_updates               | 155000    |
| q_grad_norm             | 4083.65   |
| qfs_loss                | 79.20984  |
| qs_abs_difference       | 30.7      |
| qs_difference           | 27.5      |
| qs_mean                 | 297.03488 |
| time_elapsed            | 7459      |
| total timesteps         | 102405    |
| train_time              | 1718      |
| update_time             | 5460      |
---------------------------------------
---------------------------------------
| act_time                | 64        |
| current_lr              | 0.0003    |
| discount_q              | 0.000263  |
| env_time                | 148       |
| ep_rewmean              | 844       |
| episodes                | 1600      |
| eplenmean               | 253       |
| fps                     | 13        |
| mean 100 episode reward | 844       |
| n_updates               | 158400    |
| q_grad_norm             | 5499.5356 |
| qfs_loss                | 99.15202  |
| qs_abs_difference       | 34.7      |
| qs_difference           | 33.7      |
| qs_mean                 | 315.09253 |
| time_elapsed            | 7635      |
| total timesteps         | 104137    |
| train_time              | 1756      |
| update_time             | 5593      |
---------------------------------------
---------------------------------------
| act_time                | 65        |
| current_lr              | 0.0003    |
| discount_q              | 0.0474    |
| env_time                | 149       |
| ep_rewmean              | 859       |
| episodes                | 1604      |
| eplenmean               | 256       |
| fps                     | 13        |
| mean 100 episode reward | 859       |
| n_updates               | 160800    |
| q_grad_norm             | 4611.864  |
| qfs_loss                | 109.44844 |
| qs_abs_difference       | 44.1      |
| qs_difference           | 44.1      |
| qs_mean                 | 322.73758 |
| time_elapsed            | 7757      |
| total timesteps         | 105352    |
| train_time              | 1782      |
| update_time             | 5685      |
---------------------------------------
---------------------------------------
| act_time                | 66        |
| current_lr              | 0.0003    |
| discount_q              | 0.0259    |
| env_time                | 151       |
| ep_rewmean              | 874       |
| episodes                | 1608      |
| eplenmean               | 259       |
| fps                     | 13        |
| mean 100 episode reward | 874       |
| n_updates               | 163200    |
| q_grad_norm             | 4496.226  |
| qfs_loss                | 103.13788 |
| qs_abs_difference       | 44.1      |
| qs_difference           | 42.7      |
| qs_mean                 | 313.22043 |
| time_elapsed            | 7877      |
| total timesteps         | 106565    |
| train_time              | 1809      |
| update_time             | 5775      |
---------------------------------------
---------------------------------------
| act_time                | 67        |
| current_lr              | 0.0003    |
| discount_q              | 0.0196    |
| env_time                | 153       |
| ep_rewmean              | 905       |
| episodes                | 1612      |
| eplenmean               | 267       |
| fps                     | 13        |
| mean 100 episode reward | 905       |
| n_updates               | 166200    |
| q_grad_norm             | 4818.6035 |
| qfs_loss                | 87.72319  |
| qs_abs_difference       | 35.5      |
| qs_difference           | 34.5      |
| qs_mean                 | 339.93402 |
| time_elapsed            | 8025      |
| total timesteps         | 108040    |
| train_time              | 1843      |
| update_time             | 5886      |
---------------------------------------
---------------------------------------
| act_time                | 68        |
| current_lr              | 0.0003    |
| discount_q              | 0.0411    |
| env_time                | 155       |
| ep_rewmean              | 929       |
| episodes                | 1616      |
| eplenmean               | 272       |
| fps                     | 13        |
| mean 100 episode reward | 929       |
| n_updates               | 168800    |
| q_grad_norm             | 3704.5469 |
| qfs_loss                | 73.14228  |
| qs_abs_difference       | 34.1      |
| qs_difference           | 34.1      |
| qs_mean                 | 329.55917 |
| time_elapsed            | 8151      |
| total timesteps         | 109311    |
| train_time              | 1872      |
| update_time             | 5980      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 601       |
| eval_abs_qs_difference  | 49.592896 |
| eval_discount_q         | 251       |
| eval_ep_rewmean         | 995       |
| eval_eplenmean          | 286       |
| eval_qs                 | 306.3433  |
| eval_qs_difference      | 46.9      |
| eval_time_elapsed       | 6         |
| total timesteps         | 110001    |
---------------------------------------
---------------------------------------
| act_time                | 69        |
| current_lr              | 0.0003    |
| discount_q              | 5.02e-05  |
| env_time                | 158       |
| ep_rewmean              | 965       |
| episodes                | 1620      |
| eplenmean               | 283       |
| fps                     | 13        |
| mean 100 episode reward | 966       |
| n_updates               | 172400    |
| q_grad_norm             | 4978.9893 |
| qfs_loss                | 109.25897 |
| qs_abs_difference       | 62.2      |
| qs_difference           | 62.2      |
| qs_mean                 | 319.5174  |
| time_elapsed            | 8328      |
| total timesteps         | 111138    |
| train_time              | 1912      |
| update_time             | 6106      |
---------------------------------------
---------------------------------------
| act_time                | 71        |
| current_lr              | 0.0003    |
| discount_q              | 0.000391  |
| env_time                | 161       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1624      |
| eplenmean               | 295       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 175800    |
| q_grad_norm             | 5447.5513 |
| qfs_loss                | 116.20206 |
| qs_abs_difference       | 31.1      |
| qs_difference           | 31.1      |
| qs_mean                 | 319.4679  |
| time_elapsed            | 8486      |
| total timesteps         | 112846    |
| train_time              | 1950      |
| update_time             | 6221      |
---------------------------------------
---------------------------------------
| act_time                | 72        |
| current_lr              | 0.0003    |
| discount_q              | 0.0289    |
| env_time                | 163       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 1628      |
| eplenmean               | 307       |
| fps                     | 13        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 178600    |
| q_grad_norm             | 4400.8086 |
| qfs_loss                | 87.154854 |
| qs_abs_difference       | 50        |
| qs_difference           | 49.7      |
| qs_mean                 | 337.7974  |
| time_elapsed            | 8619      |
| total timesteps         | 114235    |
| train_time              | 1982      |
| update_time             | 6318      |
---------------------------------------
---------------------------------------
| act_time                | 74        |
| current_lr              | 0.0003    |
| discount_q              | 0.000684  |
| env_time                | 166       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 1632      |
| eplenmean               | 320       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 182800    |
| q_grad_norm             | 4525.8975 |
| qfs_loss                | 88.41906  |
| qs_abs_difference       | 31.4      |
| qs_difference           | 31.2      |
| qs_mean                 | 350.39685 |
| time_elapsed            | 8806      |
| total timesteps         | 116304    |
| train_time              | 2029      |
| update_time             | 6453      |
---------------------------------------
---------------------------------------
| act_time                | 75        |
| current_lr              | 0.0003    |
| discount_q              | 0.00239   |
| env_time                | 168       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 1636      |
| eplenmean               | 326       |
| fps                     | 13        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 185400    |
| q_grad_norm             | 4063.5657 |
| qfs_loss                | 79.354675 |
| qs_abs_difference       | 80.4      |
| qs_difference           | 77.8      |
| qs_mean                 | 283.99814 |
| time_elapsed            | 8919      |
| total timesteps         | 117642    |
| train_time              | 2058      |
| update_time             | 6533      |
---------------------------------------
---------------------------------------
| act_time                | 76        |
| current_lr              | 0.0003    |
| discount_q              | 0.0454    |
| env_time                | 170       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1640      |
| eplenmean               | 329       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 187600    |
| q_grad_norm             | 4176.64   |
| qfs_loss                | 81.10728  |
| qs_abs_difference       | 74.5      |
| qs_difference           | 73.8      |
| qs_mean                 | 299.11786 |
| time_elapsed            | 9012      |
| total timesteps         | 118712    |
| train_time              | 2082      |
| update_time             | 6600      |
---------------------------------------
---------------------------------------
| act_time                | 76        |
| current_lr              | 0.0003    |
| discount_q              | 0.0491    |
| env_time                | 171       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 1644      |
| eplenmean               | 331       |
| fps                     | 13        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 190000    |
| q_grad_norm             | 5178.169  |
| qfs_loss                | 102.58841 |
| qs_abs_difference       | 30.5      |
| qs_difference           | 29.4      |
| qs_mean                 | 314.1533  |
| time_elapsed            | 9112      |
| total timesteps         | 119921    |
| train_time              | 2109      |
| update_time             | 6670      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 719       |
| eval_abs_qs_difference  | 28.282255 |
| eval_discount_q         | 259       |
| eval_ep_rewmean         | 1.26e+03  |
| eval_eplenmean          | 341       |
| eval_qs                 | 315.01648 |
| eval_qs_difference      | 23.9      |
| eval_time_elapsed       | 8         |
| total timesteps         | 120001    |
---------------------------------------
---------------------------------------
| act_time                | 77        |
| current_lr              | 0.0003    |
| discount_q              | 0.0803    |
| env_time                | 173       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 1648      |
| eplenmean               | 334       |
| fps                     | 13        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 192200    |
| q_grad_norm             | 4102.3833 |
| qfs_loss                | 71.30007  |
| qs_abs_difference       | 28.6      |
| qs_difference           | 28.1      |
| qs_mean                 | 307.89935 |
| time_elapsed            | 9212      |
| total timesteps         | 121043    |
| train_time              | 2134      |
| update_time             | 6733      |
---------------------------------------
---------------------------------------
| act_time                | 78        |
| current_lr              | 0.0003    |
| discount_q              | 0.081     |
| env_time                | 175       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 1652      |
| eplenmean               | 336       |
| fps                     | 13        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 194400    |
| q_grad_norm             | 3331.1826 |
| qfs_loss                | 62.24508  |
| qs_abs_difference       | 38.8      |
| qs_difference           | 37.8      |
| qs_mean                 | 308.45682 |
| time_elapsed            | 9301      |
| total timesteps         | 122142    |
| train_time              | 2159      |
| update_time             | 6795      |
---------------------------------------
----------------------------------------
| act_time                | 79         |
| current_lr              | 0.0003     |
| discount_q              | 0.0161     |
| env_time                | 176        |
| ep_rewmean              | 1.18e+03   |
| episodes                | 1656       |
| eplenmean               | 338        |
| fps                     | 13         |
| mean 100 episode reward | 1.18e+03   |
| n_updates               | 196800     |
| q_grad_norm             | 5792.159   |
| qfs_loss                | 121.864655 |
| qs_abs_difference       | 70.2       |
| qs_difference           | 70.1       |
| qs_mean                 | 290.17105  |
| time_elapsed            | 9397       |
| total timesteps         | 123307     |
| train_time              | 2186       |
| update_time             | 6861       |
----------------------------------------
---------------------------------------
| act_time                | 80        |
| current_lr              | 0.0003    |
| discount_q              | 0.11      |
| env_time                | 178       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 1660      |
| eplenmean               | 340       |
| fps                     | 13        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 199000    |
| q_grad_norm             | 3857.0674 |
| qfs_loss                | 85.14725  |
| qs_abs_difference       | 43.7      |
| qs_difference           | 43.7      |
| qs_mean                 | 333.98914 |
| time_elapsed            | 9483      |
| total timesteps         | 124475    |
| train_time              | 2210      |
| update_time             | 6920      |
---------------------------------------
---------------------------------------
| act_time                | 81        |
| current_lr              | 0.0003    |
| discount_q              | 0.0139    |
| env_time                | 180       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1664      |
| eplenmean               | 346       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 202200    |
| q_grad_norm             | 4206.2935 |
| qfs_loss                | 89.534355 |
| qs_abs_difference       | 49.1      |
| qs_difference           | 48.9      |
| qs_mean                 | 346.07663 |
| time_elapsed            | 9607      |
| total timesteps         | 126054    |
| train_time              | 2246      |
| update_time             | 7003      |
---------------------------------------
---------------------------------------
| act_time                | 82        |
| current_lr              | 0.0003    |
| discount_q              | 0.0337    |
| env_time                | 182       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 1668      |
| eplenmean               | 349       |
| fps                     | 13        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 204600    |
| q_grad_norm             | 3275.4128 |
| qfs_loss                | 74.03023  |
| qs_abs_difference       | 42.4      |
| qs_difference           | 42.3      |
| qs_mean                 | 311.3167  |
| time_elapsed            | 9698      |
| total timesteps         | 127219    |
| train_time              | 2273      |
| update_time             | 7065      |
---------------------------------------
---------------------------------------
| act_time                | 83        |
| current_lr              | 0.0003    |
| discount_q              | 0.00851   |
| env_time                | 184       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 1672      |
| eplenmean               | 351       |
| fps                     | 13        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 207400    |
| q_grad_norm             | 2551.5684 |
| qfs_loss                | 54.359554 |
| qs_abs_difference       | 36.8      |
| qs_difference           | 36.2      |
| qs_mean                 | 333.0361  |
| time_elapsed            | 9805      |
| total timesteps         | 128690    |
| train_time              | 2304      |
| update_time             | 7136      |
---------------------------------------
---------------------------------------
| act_time                | 84        |
| current_lr              | 0.0003    |
| discount_q              | 0.0398    |
| env_time                | 186       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 1676      |
| eplenmean               | 352       |
| fps                     | 13        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 209800    |
| q_grad_norm             | 4000.7693 |
| qfs_loss                | 81.200134 |
| qs_abs_difference       | 29.3      |
| qs_difference           | 28.9      |
| qs_mean                 | 300.5552  |
| time_elapsed            | 9895      |
| total timesteps         | 129830    |
| train_time              | 2331      |
| update_time             | 7196      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 824       |
| eval_abs_qs_difference  | 38.443573 |
| eval_discount_q         | 256       |
| eval_ep_rewmean         | 1.25e+03  |
| eval_eplenmean          | 351       |
| eval_qs                 | 314.04288 |
| eval_qs_difference      | 37.2      |
| eval_time_elapsed       | 8         |
| total timesteps         | 130001    |
---------------------------------------
---------------------------------------
| act_time                | 85        |
| current_lr              | 0.0003    |
| discount_q              | 0.0606    |
| env_time                | 188       |
| ep_rewmean              | 1.23e+03  |
| episodes                | 1680      |
| eplenmean               | 353       |
| fps                     | 13        |
| mean 100 episode reward | 1.23e+03  |
| n_updates               | 212400    |
| q_grad_norm             | 3458.7341 |
| qfs_loss                | 78.07679  |
| qs_abs_difference       | 47.7      |
| qs_difference           | 47.6      |
| qs_mean                 | 343.42056 |
| time_elapsed            | 10001     |
| total timesteps         | 131181    |
| train_time              | 2360      |
| update_time             | 7261      |
---------------------------------------
---------------------------------------
| act_time                | 87        |
| current_lr              | 0.0003    |
| discount_q              | 0.000639  |
| env_time                | 190       |
| ep_rewmean              | 1.23e+03  |
| episodes                | 1684      |
| eplenmean               | 353       |
| fps                     | 13        |
| mean 100 episode reward | 1.23e+03  |
| n_updates               | 215600    |
| q_grad_norm             | 3000.1907 |
| qfs_loss                | 57.51841  |
| qs_abs_difference       | 35.7      |
| qs_difference           | 35.7      |
| qs_mean                 | 304.25974 |
| time_elapsed            | 10120     |
| total timesteps         | 132730    |
| train_time              | 2396      |
| update_time             | 7341      |
---------------------------------------
---------------------------------------
| act_time                | 87        |
| current_lr              | 0.0003    |
| discount_q              | 0.096     |
| env_time                | 192       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1688      |
| eplenmean               | 343       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 217600    |
| q_grad_norm             | 3717.8538 |
| qfs_loss                | 66.66379  |
| qs_abs_difference       | 47.6      |
| qs_difference           | 46.4      |
| qs_mean                 | 290.9545  |
| time_elapsed            | 10195     |
| total timesteps         | 133732    |
| train_time              | 2418      |
| update_time             | 7391      |
---------------------------------------
---------------------------------------
| act_time                | 88        |
| current_lr              | 0.0003    |
| discount_q              | 0.0318    |
| env_time                | 194       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 1692      |
| eplenmean               | 337       |
| fps                     | 13        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 219800    |
| q_grad_norm             | 2445.6292 |
| qfs_loss                | 51.810688 |
| qs_abs_difference       | 29.7      |
| qs_difference           | 27.4      |
| qs_mean                 | 302.01132 |
| time_elapsed            | 10277     |
| total timesteps         | 134885    |
| train_time              | 2443      |
| update_time             | 7445      |
---------------------------------------
---------------------------------------
| act_time                | 89        |
| current_lr              | 0.0003    |
| discount_q              | 0.0539    |
| env_time                | 195       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 1696      |
| eplenmean               | 335       |
| fps                     | 13        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 222000    |
| q_grad_norm             | 3258.69   |
| qfs_loss                | 72.71036  |
| qs_abs_difference       | 64.3      |
| qs_difference           | 63.5      |
| qs_mean                 | 292.97778 |
| time_elapsed            | 10358     |
| total timesteps         | 135917    |
| train_time              | 2468      |
| update_time             | 7499      |
---------------------------------------
--------------------------------------
| act_time                | 90       |
| current_lr              | 0.0003   |
| discount_q              | 0.205    |
| env_time                | 197      |
| ep_rewmean              | 1.15e+03 |
| episodes                | 1700     |
| eplenmean               | 330      |
| fps                     | 13       |
| mean 100 episode reward | 1.15e+03 |
| n_updates               | 224400   |
| q_grad_norm             | 3413.955 |
| qfs_loss                | 66.69617 |
| qs_abs_difference       | 39       |
| qs_difference           | 38.9     |
| qs_mean                 | 340.1866 |
| time_elapsed            | 10447    |
| total timesteps         | 137114   |
| train_time              | 2495     |
| update_time             | 7558     |
--------------------------------------
---------------------------------------
| act_time                | 91        |
| current_lr              | 0.0003    |
| discount_q              | 0.706     |
| env_time                | 198       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1704      |
| eplenmean               | 327       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 226200    |
| q_grad_norm             | 3591.3862 |
| qfs_loss                | 80.96089  |
| qs_abs_difference       | 48.6      |
| qs_difference           | 48.2      |
| qs_mean                 | 333.78915 |
| time_elapsed            | 10513     |
| total timesteps         | 138095    |
| train_time              | 2515      |
| update_time             | 7601      |
---------------------------------------
---------------------------------------
| act_time                | 92        |
| current_lr              | 0.0003    |
| discount_q              | 0.003     |
| env_time                | 200       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 1708      |
| eplenmean               | 330       |
| fps                     | 13        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 229200    |
| q_grad_norm             | 2494.6638 |
| qfs_loss                | 53.601124 |
| qs_abs_difference       | 61.5      |
| qs_difference           | 61.3      |
| qs_mean                 | 323.24118 |
| time_elapsed            | 10623     |
| total timesteps         | 139539    |
| train_time              | 2548      |
| update_time             | 7674      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 979       |
| eval_abs_qs_difference  | 27.470264 |
| eval_discount_q         | 278       |
| eval_ep_rewmean         | 1.9e+03   |
| eval_eplenmean          | 515       |
| eval_qs                 | 328.3461  |
| eval_qs_difference      | 25.6      |
| eval_time_elapsed       | 13        |
| total timesteps         | 140001    |
---------------------------------------
---------------------------------------
| act_time                | 93        |
| current_lr              | 0.0003    |
| discount_q              | 0.000827  |
| env_time                | 203       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 1712      |
| eplenmean               | 329       |
| fps                     | 13        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 232000    |
| q_grad_norm             | 2593.9163 |
| qfs_loss                | 41.798985 |
| qs_abs_difference       | 43.5      |
| qs_difference           | 43.5      |
| qs_mean                 | 250.134   |
| time_elapsed            | 10739     |
| total timesteps         | 140953    |
| train_time              | 2580      |
| update_time             | 7742      |
---------------------------------------
---------------------------------------
| act_time                | 94        |
| current_lr              | 0.0003    |
| discount_q              | 0.155     |
| env_time                | 204       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1716      |
| eplenmean               | 327       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 234200    |
| q_grad_norm             | 3336.3694 |
| qfs_loss                | 94.658615 |
| qs_abs_difference       | 45.1      |
| qs_difference           | 45.1      |
| qs_mean                 | 322.47144 |
| time_elapsed            | 10819     |
| total timesteps         | 142029    |
| train_time              | 2604      |
| update_time             | 7795      |
---------------------------------------
---------------------------------------
| act_time                | 95        |
| current_lr              | 0.0003    |
| discount_q              | 0.00748   |
| env_time                | 206       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 1720      |
| eplenmean               | 322       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 236600    |
| q_grad_norm             | 3466.6855 |
| qfs_loss                | 71.443016 |
| qs_abs_difference       | 37.4      |
| qs_difference           | 33.6      |
| qs_mean                 | 280.60785 |
| time_elapsed            | 10907     |
| total timesteps         | 143290    |
| train_time              | 2631      |
| update_time             | 7852      |
---------------------------------------
---------------------------------------
| act_time                | 96        |
| current_lr              | 0.0003    |
| discount_q              | 0.0244    |
| env_time                | 208       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 1724      |
| eplenmean               | 316       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 239000    |
| q_grad_norm             | 2783.795  |
| qfs_loss                | 64.246346 |
| qs_abs_difference       | 156       |
| qs_difference           | 156       |
| qs_mean                 | 361.11734 |
| time_elapsed            | 10994     |
| total timesteps         | 144447    |
| train_time              | 2658      |
| update_time             | 7909      |
---------------------------------------
---------------------------------------
| act_time                | 97        |
| current_lr              | 0.0003    |
| discount_q              | 0.0221    |
| env_time                | 211       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 1728      |
| eplenmean               | 321       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 242800    |
| q_grad_norm             | 2591.3694 |
| qfs_loss                | 50.068012 |
| qs_abs_difference       | 62.6      |
| qs_difference           | 62.6      |
| qs_mean                 | 373.55057 |
| time_elapsed            | 11131     |
| total timesteps         | 146380    |
| train_time              | 2701      |
| update_time             | 7999      |
---------------------------------------
---------------------------------------
| act_time                | 98        |
| current_lr              | 0.0003    |
| discount_q              | 0.00187   |
| env_time                | 213       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 1732      |
| eplenmean               | 316       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 245800    |
| q_grad_norm             | 2809.1484 |
| qfs_loss                | 54.90459  |
| qs_abs_difference       | 36.8      |
| qs_difference           | 33.2      |
| qs_mean                 | 302.23154 |
| time_elapsed            | 11239     |
| total timesteps         | 147863    |
| train_time              | 2735      |
| update_time             | 8070      |
---------------------------------------
---------------------------------------
| act_time                | 99        |
| current_lr              | 0.0003    |
| discount_q              | 0.0536    |
| env_time                | 215       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 1736      |
| eplenmean               | 316       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 248600    |
| q_grad_norm             | 2754.877  |
| qfs_loss                | 56.45998  |
| qs_abs_difference       | 33.4      |
| qs_difference           | 32.5      |
| qs_mean                 | 338.12173 |
| time_elapsed            | 11340     |
| total timesteps         | 149239    |
| train_time              | 2766      |
| update_time             | 8135      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.2e+03   |
| eval_abs_qs_difference  | 80.44611  |
| eval_discount_q         | 263       |
| eval_ep_rewmean         | 2.62e+03  |
| eval_eplenmean          | 816       |
| eval_qs                 | 365.09006 |
| eval_qs_difference      | 80.2      |
| eval_time_elapsed       | 20        |
| total timesteps         | 150001    |
---------------------------------------
---------------------------------------
| act_time                | 100       |
| current_lr              | 0.0003    |
| discount_q              | 0.107     |
| env_time                | 217       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 1740      |
| eplenmean               | 318       |
| fps                     | 13        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 251200    |
| q_grad_norm             | 3083.9407 |
| qfs_loss                | 73.101395 |
| qs_abs_difference       | 54.7      |
| qs_difference           | 54.7      |
| qs_mean                 | 348.07584 |
| time_elapsed            | 11454     |
| total timesteps         | 150510    |
| train_time              | 2795      |
| update_time             | 8195      |
---------------------------------------
---------------------------------------
| act_time                | 102       |
| current_lr              | 0.0003    |
| discount_q              | 0.00754   |
| env_time                | 219       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 1744      |
| eplenmean               | 321       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 254000    |
| q_grad_norm             | 2645.6633 |
| qfs_loss                | 62.35121  |
| qs_abs_difference       | 55.4      |
| qs_difference           | 55.4      |
| qs_mean                 | 339.72565 |
| time_elapsed            | 11554     |
| total timesteps         | 151999    |
| train_time              | 2827      |
| update_time             | 8261      |
---------------------------------------
---------------------------------------
| act_time                | 102       |
| current_lr              | 0.0003    |
| discount_q              | 0.0508    |
| env_time                | 221       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 1748      |
| eplenmean               | 321       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 256400    |
| q_grad_norm             | 3041.6638 |
| qfs_loss                | 61.349155 |
| qs_abs_difference       | 43.1      |
| qs_difference           | 42.9      |
| qs_mean                 | 326.6412  |
| time_elapsed            | 11640     |
| total timesteps         | 153174    |
| train_time              | 2854      |
| update_time             | 8316      |
---------------------------------------
---------------------------------------
| act_time                | 103       |
| current_lr              | 0.0003    |
| discount_q              | 0.0979    |
| env_time                | 222       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 1752      |
| eplenmean               | 319       |
| fps                     | 13        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 258200    |
| q_grad_norm             | 2795.9082 |
| qfs_loss                | 59.240204 |
| qs_abs_difference       | 206       |
| qs_difference           | 206       |
| qs_mean                 | 347.61935 |
| time_elapsed            | 11704     |
| total timesteps         | 154060    |
| train_time              | 2874      |
| update_time             | 8358      |
---------------------------------------
---------------------------------------
| act_time                | 104       |
| current_lr              | 0.0003    |
| discount_q              | 0.0388    |
| env_time                | 224       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 1756      |
| eplenmean               | 319       |
| fps                     | 13        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 260600    |
| q_grad_norm             | 3254.7546 |
| qfs_loss                | 55.724678 |
| qs_abs_difference       | 49.4      |
| qs_difference           | 49.4      |
| qs_mean                 | 311.58466 |
| time_elapsed            | 11789     |
| total timesteps         | 155218    |
| train_time              | 2901      |
| update_time             | 8413      |
---------------------------------------
---------------------------------------
| act_time                | 105       |
| current_lr              | 0.0003    |
| discount_q              | 0.151     |
| env_time                | 225       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 1760      |
| eplenmean               | 315       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 262200    |
| q_grad_norm             | 2429.6763 |
| qfs_loss                | 43.146896 |
| qs_abs_difference       | 240       |
| qs_difference           | 240       |
| qs_mean                 | 342.47363 |
| time_elapsed            | 11846     |
| total timesteps         | 156003    |
| train_time              | 2919      |
| update_time             | 8450      |
---------------------------------------
---------------------------------------
| act_time                | 105       |
| current_lr              | 0.0003    |
| discount_q              | 9.6       |
| env_time                | 226       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1764      |
| eplenmean               | 306       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 263400    |
| q_grad_norm             | 2944.3818 |
| qfs_loss                | 56.148136 |
| qs_abs_difference       | 69.4      |
| qs_difference           | 69.4      |
| qs_mean                 | 345.66556 |
| time_elapsed            | 11889     |
| total timesteps         | 156684    |
| train_time              | 2932      |
| update_time             | 8478      |
---------------------------------------
---------------------------------------
| act_time                | 106       |
| current_lr              | 0.0003    |
| discount_q              | 0.174     |
| env_time                | 228       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1768      |
| eplenmean               | 305       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 265400    |
| q_grad_norm             | 3153.253  |
| qfs_loss                | 60.09145  |
| qs_abs_difference       | 40        |
| qs_difference           | 39.8      |
| qs_mean                 | 306.19885 |
| time_elapsed            | 11960     |
| total timesteps         | 157699    |
| train_time              | 2954      |
| update_time             | 8524      |
---------------------------------------
---------------------------------------
| act_time                | 107       |
| current_lr              | 0.0003    |
| discount_q              | 0.131     |
| env_time                | 229       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1772      |
| eplenmean               | 300       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 267400    |
| q_grad_norm             | 3318.4888 |
| qfs_loss                | 67.51739  |
| qs_abs_difference       | 59.2      |
| qs_difference           | 51.8      |
| qs_mean                 | 281.59998 |
| time_elapsed            | 12031     |
| total timesteps         | 158641    |
| train_time              | 2977      |
| update_time             | 8570      |
---------------------------------------
---------------------------------------
| act_time                | 108       |
| current_lr              | 0.0003    |
| discount_q              | 0.0599    |
| env_time                | 231       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1776      |
| eplenmean               | 299       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 269600    |
| q_grad_norm             | 3389.6863 |
| qfs_loss                | 62.60276  |
| qs_abs_difference       | 53.5      |
| qs_difference           | 53.1      |
| qs_mean                 | 311.63895 |
| time_elapsed            | 12108     |
| total timesteps         | 159751    |
| train_time              | 3001      |
| update_time             | 8620      |
---------------------------------------
----------------------------------------
| eval mean 100 episod... | 1.3e+03    |
| eval_abs_qs_difference  | 109.888435 |
| eval_discount_q         | 240        |
| eval_ep_rewmean         | 1.46e+03   |
| eval_eplenmean          | 469        |
| eval_qs                 | 358.44543  |
| eval_qs_difference      | 110        |
| eval_time_elapsed       | 12         |
| total timesteps         | 160001     |
----------------------------------------
---------------------------------------
| act_time                | 109       |
| current_lr              | 0.0003    |
| discount_q              | 0.0063    |
| env_time                | 233       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1780      |
| eplenmean               | 301       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 272600    |
| q_grad_norm             | 3533.622  |
| qfs_loss                | 69.87317  |
| qs_abs_difference       | 30.4      |
| qs_difference           | 28.3      |
| qs_mean                 | 323.23767 |
| time_elapsed            | 12227     |
| total timesteps         | 161273    |
| train_time              | 3035      |
| update_time             | 8689      |
---------------------------------------
---------------------------------------
| act_time                | 110       |
| current_lr              | 0.0003    |
| discount_q              | 0.00145   |
| env_time                | 235       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1784      |
| eplenmean               | 300       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 275600    |
| q_grad_norm             | 2880.0684 |
| qfs_loss                | 53.23865  |
| qs_abs_difference       | 27        |
| qs_difference           | 23.2      |
| qs_mean                 | 289.0653  |
| time_elapsed            | 12332     |
| total timesteps         | 162732    |
| train_time              | 3069      |
| update_time             | 8757      |
---------------------------------------
--------------------------------------
| act_time                | 111      |
| current_lr              | 0.0003   |
| discount_q              | 0.102    |
| env_time                | 236      |
| ep_rewmean              | 1.02e+03 |
| episodes                | 1788     |
| eplenmean               | 297      |
| fps                     | 13       |
| mean 100 episode reward | 1.02e+03 |
| n_updates               | 277000   |
| q_grad_norm             | 2352.386 |
| qfs_loss                | 44.46632 |
| qs_abs_difference       | 272      |
| qs_difference           | 272      |
| qs_mean                 | 316.6802 |
| time_elapsed            | 12381    |
| total timesteps         | 163441   |
| train_time              | 3084     |
| update_time             | 8788     |
--------------------------------------
---------------------------------------
| act_time                | 111       |
| current_lr              | 0.0003    |
| discount_q              | 0.337     |
| env_time                | 238       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1792      |
| eplenmean               | 296       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 279000    |
| q_grad_norm             | 4028.04   |
| qfs_loss                | 82.2892   |
| qs_abs_difference       | 51.9      |
| qs_difference           | 51.9      |
| qs_mean                 | 336.43008 |
| time_elapsed            | 12452     |
| total timesteps         | 164470    |
| train_time              | 3107      |
| update_time             | 8834      |
---------------------------------------
---------------------------------------
| act_time                | 112       |
| current_lr              | 0.0003    |
| discount_q              | 0.0284    |
| env_time                | 240       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1796      |
| eplenmean               | 297       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 281400    |
| q_grad_norm             | 2657.3245 |
| qfs_loss                | 57.95714  |
| qs_abs_difference       | 29.9      |
| qs_difference           | 29.6      |
| qs_mean                 | 287.70227 |
| time_elapsed            | 12536     |
| total timesteps         | 165610    |
| train_time              | 3134      |
| update_time             | 8888      |
---------------------------------------
---------------------------------------
| act_time                | 113       |
| current_lr              | 0.0003    |
| discount_q              | 0.00445   |
| env_time                | 242       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1800      |
| eplenmean               | 299       |
| fps                     | 13        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 284000    |
| q_grad_norm             | 3164.0076 |
| qfs_loss                | 62.805397 |
| qs_abs_difference       | 36.6      |
| qs_difference           | 36.6      |
| qs_mean                 | 304.36252 |
| time_elapsed            | 12627     |
| total timesteps         | 166990    |
| train_time              | 3163      |
| update_time             | 8946      |
---------------------------------------
---------------------------------------
| act_time                | 114       |
| current_lr              | 0.0003    |
| discount_q              | 0.738     |
| env_time                | 243       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1804      |
| eplenmean               | 297       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 285600    |
| q_grad_norm             | 3689.7085 |
| qfs_loss                | 71.972595 |
| qs_abs_difference       | 60        |
| qs_difference           | 60        |
| qs_mean                 | 282.18527 |
| time_elapsed            | 12683     |
| total timesteps         | 167767    |
| train_time              | 3181      |
| update_time             | 8983      |
---------------------------------------
---------------------------------------
| act_time                | 115       |
| current_lr              | 0.0003    |
| discount_q              | 0.113     |
| env_time                | 244       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1808      |
| eplenmean               | 292       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 287600    |
| q_grad_norm             | 1984.327  |
| qfs_loss                | 45.71307  |
| qs_abs_difference       | 49.8      |
| qs_difference           | 49.8      |
| qs_mean                 | 294.58286 |
| time_elapsed            | 12753     |
| total timesteps         | 168754    |
| train_time              | 3203      |
| update_time             | 9028      |
---------------------------------------
---------------------------------------
| act_time                | 115       |
| current_lr              | 0.0003    |
| discount_q              | 0.213     |
| env_time                | 245       |
| ep_rewmean              | 988       |
| episodes                | 1812      |
| eplenmean               | 287       |
| fps                     | 13        |
| mean 100 episode reward | 988       |
| n_updates               | 289400    |
| q_grad_norm             | 2758.3005 |
| qfs_loss                | 55.89391  |
| qs_abs_difference       | 176       |
| qs_difference           | 176       |
| qs_mean                 | 353.54666 |
| time_elapsed            | 12816     |
| total timesteps         | 169638    |
| train_time              | 3223      |
| update_time             | 9068      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.32e+03  |
| eval_abs_qs_difference  | 139.0588  |
| eval_discount_q         | 216       |
| eval_ep_rewmean         | 667       |
| eval_eplenmean          | 209       |
| eval_qs                 | 336.48398 |
| eval_qs_difference      | 138       |
| eval_time_elapsed       | 4         |
| total timesteps         | 170001    |
---------------------------------------
---------------------------------------
| act_time                | 116       |
| current_lr              | 0.0003    |
| discount_q              | 0.0202    |
| env_time                | 247       |
| ep_rewmean              | 995       |
| episodes                | 1816      |
| eplenmean               | 288       |
| fps                     | 13        |
| mean 100 episode reward | 994       |
| n_updates               | 291800    |
| q_grad_norm             | 3350.6362 |
| qfs_loss                | 73.44741  |
| qs_abs_difference       | 21.1      |
| qs_difference           | 19.2      |
| qs_mean                 | 295.1649  |
| time_elapsed            | 12906     |
| total timesteps         | 170847    |
| train_time              | 3251      |
| update_time             | 9123      |
---------------------------------------
---------------------------------------
| act_time                | 118       |
| current_lr              | 0.0003    |
| discount_q              | 0.0153    |
| env_time                | 250       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1820      |
| eplenmean               | 292       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 295000    |
| q_grad_norm             | 3968.272  |
| qfs_loss                | 94.323586 |
| qs_abs_difference       | 23.2      |
| qs_difference           | 22.6      |
| qs_mean                 | 339.03107 |
| time_elapsed            | 13018     |
| total timesteps         | 172481    |
| train_time              | 3287      |
| update_time             | 9195      |
---------------------------------------
---------------------------------------
| act_time                | 119       |
| current_lr              | 0.0003    |
| discount_q              | 5.73e-05  |
| env_time                | 251       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1824      |
| eplenmean               | 292       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 297400    |
| q_grad_norm             | 2298.4612 |
| qfs_loss                | 44.786285 |
| qs_abs_difference       | 289       |
| qs_difference           | 289       |
| qs_mean                 | 293.2667  |
| time_elapsed            | 13102     |
| total timesteps         | 173663    |
| train_time              | 3313      |
| update_time             | 9249      |
---------------------------------------
---------------------------------------
| act_time                | 119       |
| current_lr              | 0.0003    |
| discount_q              | 11.6      |
| env_time                | 252       |
| ep_rewmean              | 963       |
| episodes                | 1828      |
| eplenmean               | 278       |
| fps                     | 13        |
| mean 100 episode reward | 963       |
| n_updates               | 298600    |
| q_grad_norm             | 2785.0923 |
| qfs_loss                | 63.42119  |
| qs_abs_difference       | 47.1      |
| qs_difference           | 47        |
| qs_mean                 | 299.1566  |
| time_elapsed            | 13143     |
| total timesteps         | 174201    |
| train_time              | 3326      |
| update_time             | 9276      |
---------------------------------------
---------------------------------------
| act_time                | 120       |
| current_lr              | 0.0003    |
| discount_q              | 0.00781   |
| env_time                | 254       |
| ep_rewmean              | 964       |
| episodes                | 1832      |
| eplenmean               | 279       |
| fps                     | 13        |
| mean 100 episode reward | 964       |
| n_updates               | 301600    |
| q_grad_norm             | 2861.6123 |
| qfs_loss                | 61.240482 |
| qs_abs_difference       | 87.7      |
| qs_difference           | 87.7      |
| qs_mean                 | 368.86826 |
| time_elapsed            | 13248     |
| total timesteps         | 175760    |
| train_time              | 3360      |
| update_time             | 9343      |
---------------------------------------
---------------------------------------
| act_time                | 121       |
| current_lr              | 0.0003    |
| discount_q              | 0.322     |
| env_time                | 256       |
| ep_rewmean              | 953       |
| episodes                | 1836      |
| eplenmean               | 275       |
| fps                     | 13        |
| mean 100 episode reward | 953       |
| n_updates               | 303600    |
| q_grad_norm             | 3561.074  |
| qfs_loss                | 69.35607  |
| qs_abs_difference       | 13.1      |
| qs_difference           | 9.01      |
| qs_mean                 | 309.93466 |
| time_elapsed            | 13317     |
| total timesteps         | 176759    |
| train_time              | 3382      |
| update_time             | 9388      |
---------------------------------------
---------------------------------------
| act_time                | 122       |
| current_lr              | 0.0003    |
| discount_q              | 0.313     |
| env_time                | 257       |
| ep_rewmean              | 935       |
| episodes                | 1840      |
| eplenmean               | 270       |
| fps                     | 13        |
| mean 100 episode reward | 935       |
| n_updates               | 305200    |
| q_grad_norm             | 3218.3015 |
| qfs_loss                | 64.79878  |
| qs_abs_difference       | 199       |
| qs_difference           | 199       |
| qs_mean                 | 355.36142 |
| time_elapsed            | 13373     |
| total timesteps         | 177542    |
| train_time              | 3400      |
| update_time             | 9423      |
---------------------------------------
---------------------------------------
| act_time                | 122       |
| current_lr              | 0.0003    |
| discount_q              | 0.269     |
| env_time                | 258       |
| ep_rewmean              | 909       |
| episodes                | 1844      |
| eplenmean               | 263       |
| fps                     | 13        |
| mean 100 episode reward | 909       |
| n_updates               | 306600    |
| q_grad_norm             | 2377.6497 |
| qfs_loss                | 49.069    |
| qs_abs_difference       | 230       |
| qs_difference           | 230       |
| qs_mean                 | 346.281   |
| time_elapsed            | 13422     |
| total timesteps         | 178279    |
| train_time              | 3416      |
| update_time             | 9454      |
---------------------------------------
---------------------------------------
| act_time                | 123       |
| current_lr              | 0.0003    |
| discount_q              | 0.171     |
| env_time                | 260       |
| ep_rewmean              | 904       |
| episodes                | 1848      |
| eplenmean               | 261       |
| fps                     | 13        |
| mean 100 episode reward | 904       |
| n_updates               | 308600    |
| q_grad_norm             | 3228.3875 |
| qfs_loss                | 59.57996  |
| qs_abs_difference       | 22        |
| qs_difference           | 21.9      |
| qs_mean                 | 301.31796 |
| time_elapsed            | 13491     |
| total timesteps         | 179295    |
| train_time              | 3438      |
| update_time             | 9499      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.41e+03  |
| eval_abs_qs_difference  | 96.95838  |
| eval_discount_q         | 260       |
| eval_ep_rewmean         | 1.43e+03  |
| eval_eplenmean          | 427       |
| eval_qs                 | 359.91995 |
| eval_qs_difference      | 96.7      |
| eval_time_elapsed       | 10        |
| total timesteps         | 180001    |
---------------------------------------
---------------------------------------
| act_time                | 124       |
| current_lr              | 0.0003    |
| discount_q              | 0.00546   |
| env_time                | 262       |
| ep_rewmean              | 929       |
| episodes                | 1852      |
| eplenmean               | 267       |
| fps                     | 13        |
| mean 100 episode reward | 929       |
| n_updates               | 311600    |
| q_grad_norm             | 3379.4014 |
| qfs_loss                | 77.80232  |
| qs_abs_difference       | 21.9      |
| qs_difference           | 21.6      |
| qs_mean                 | 319.928   |
| time_elapsed            | 13605     |
| total timesteps         | 180740    |
| train_time              | 3472      |
| update_time             | 9565      |
---------------------------------------
---------------------------------------
| act_time                | 125       |
| current_lr              | 0.0003    |
| discount_q              | 0.028     |
| env_time                | 264       |
| ep_rewmean              | 932       |
| episodes                | 1856      |
| eplenmean               | 267       |
| fps                     | 13        |
| mean 100 episode reward | 932       |
| n_updates               | 314000    |
| q_grad_norm             | 4212.6313 |
| qfs_loss                | 88.38415  |
| qs_abs_difference       | 26.2      |
| qs_difference           | 25.5      |
| qs_mean                 | 301.22852 |
| time_elapsed            | 13688     |
| total timesteps         | 181920    |
| train_time              | 3499      |
| update_time             | 9617      |
---------------------------------------
---------------------------------------
| act_time                | 126       |
| current_lr              | 0.0003    |
| discount_q              | 0.018     |
| env_time                | 266       |
| ep_rewmean              | 967       |
| episodes                | 1860      |
| eplenmean               | 276       |
| fps                     | 13        |
| mean 100 episode reward | 967       |
| n_updates               | 317200    |
| q_grad_norm             | 3176.4    |
| qfs_loss                | 60.13403  |
| qs_abs_difference       | 14.2      |
| qs_difference           | 13.2      |
| qs_mean                 | 347.40854 |
| time_elapsed            | 13797     |
| total timesteps         | 183559    |
| train_time              | 3535      |
| update_time             | 9687      |
---------------------------------------
---------------------------------------
| act_time                | 127       |
| current_lr              | 0.0003    |
| discount_q              | 0.0185    |
| env_time                | 268       |
| ep_rewmean              | 983       |
| episodes                | 1864      |
| eplenmean               | 279       |
| fps                     | 13        |
| mean 100 episode reward | 983       |
| n_updates               | 319400    |
| q_grad_norm             | 2491.9236 |
| qfs_loss                | 47.394012 |
| qs_abs_difference       | 200       |
| qs_difference           | 200       |
| qs_mean                 | 358.39948 |
| time_elapsed            | 13873     |
| total timesteps         | 184621    |
| train_time              | 3560      |
| update_time             | 9735      |
---------------------------------------
---------------------------------------
| act_time                | 128       |
| current_lr              | 0.0003    |
| discount_q              | 0.373     |
| env_time                | 269       |
| ep_rewmean              | 986       |
| episodes                | 1868      |
| eplenmean               | 280       |
| fps                     | 13        |
| mean 100 episode reward | 986       |
| n_updates               | 321400    |
| q_grad_norm             | 3911.0479 |
| qfs_loss                | 67.46782  |
| qs_abs_difference       | 10.4      |
| qs_difference           | 6.33      |
| qs_mean                 | 326.19775 |
| time_elapsed            | 13941     |
| total timesteps         | 185654    |
| train_time              | 3582      |
| update_time             | 9778      |
---------------------------------------
---------------------------------------
| act_time                | 129       |
| current_lr              | 0.0003    |
| discount_q              | 0.000149  |
| env_time                | 272       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1872      |
| eplenmean               | 288       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 325000    |
| q_grad_norm             | 2484.6995 |
| qfs_loss                | 50.93019  |
| qs_abs_difference       | 27.6      |
| qs_difference           | 26.5      |
| qs_mean                 | 326.89105 |
| time_elapsed            | 14064     |
| total timesteps         | 187466    |
| train_time              | 3622      |
| update_time             | 9856      |
---------------------------------------
---------------------------------------
| act_time                | 131       |
| current_lr              | 0.0003    |
| discount_q              | 0.12      |
| env_time                | 275       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1876      |
| eplenmean               | 295       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 328600    |
| q_grad_norm             | 3414.7166 |
| qfs_loss                | 61.43937  |
| qs_abs_difference       | 56        |
| qs_difference           | 56        |
| qs_mean                 | 380.63455 |
| time_elapsed            | 14186     |
| total timesteps         | 189235    |
| train_time              | 3663      |
| update_time             | 9934      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.35e+03  |
| eval_abs_qs_difference  | 164.93332 |
| eval_discount_q         | 212       |
| eval_ep_rewmean         | 548       |
| eval_eplenmean          | 169       |
| eval_qs                 | 348.92337 |
| eval_qs_difference      | 165       |
| eval_time_elapsed       | 4         |
| total timesteps         | 190001    |
---------------------------------------
---------------------------------------
| act_time                | 132       |
| current_lr              | 0.0003    |
| discount_q              | 0.0137    |
| env_time                | 276       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1880      |
| eplenmean               | 289       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 330400    |
| q_grad_norm             | 3027.7366 |
| qfs_loss                | 52.422012 |
| qs_abs_difference       | 280       |
| qs_difference           | 280       |
| qs_mean                 | 332.49295 |
| time_elapsed            | 14252     |
| total timesteps         | 190149    |
| train_time              | 3683      |
| update_time             | 9973      |
---------------------------------------
---------------------------------------
| act_time                | 133       |
| current_lr              | 0.0003    |
| discount_q              | 0.00185   |
| env_time                | 279       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1884      |
| eplenmean               | 289       |
| fps                     | 13        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 333400    |
| q_grad_norm             | 3699.706  |
| qfs_loss                | 63.039062 |
| qs_abs_difference       | 12.3      |
| qs_difference           | 9.55      |
| qs_mean                 | 313.91425 |
| time_elapsed            | 14354     |
| total timesteps         | 191675    |
| train_time              | 3716      |
| update_time             | 10037     |
---------------------------------------
---------------------------------------
| act_time                | 134       |
| current_lr              | 0.0003    |
| discount_q              | 0.112     |
| env_time                | 280       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1888      |
| eplenmean               | 293       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 335600    |
| q_grad_norm             | 3131.8608 |
| qfs_loss                | 61.861065 |
| qs_abs_difference       | 77.6      |
| qs_difference           | 77.6      |
| qs_mean                 | 341.02652 |
| time_elapsed            | 14429     |
| total timesteps         | 192727    |
| train_time              | 3741      |
| update_time             | 10085     |
---------------------------------------
----------------------------------------
| act_time                | 135        |
| current_lr              | 0.0003     |
| discount_q              | 0.0471     |
| env_time                | 282        |
| ep_rewmean              | 1.05e+03   |
| episodes                | 1892       |
| eplenmean               | 294        |
| fps                     | 13         |
| mean 100 episode reward | 1.05e+03   |
| n_updates               | 337800     |
| q_grad_norm             | 4943.6597  |
| qfs_loss                | 106.197174 |
| qs_abs_difference       | 24.5       |
| qs_difference           | 24.5       |
| qs_mean                 | 308.06973  |
| time_elapsed            | 14504      |
| total timesteps         | 193882     |
| train_time              | 3766       |
| update_time             | 10132      |
----------------------------------------
---------------------------------------
| act_time                | 136       |
| current_lr              | 0.0003    |
| discount_q              | 0.00232   |
| env_time                | 284       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1896      |
| eplenmean               | 297       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 340800    |
| q_grad_norm             | 2499.7305 |
| qfs_loss                | 48.09431  |
| qs_abs_difference       | 29.5      |
| qs_difference           | 29.5      |
| qs_mean                 | 308.34122 |
| time_elapsed            | 14605     |
| total timesteps         | 195320    |
| train_time              | 3799      |
| update_time             | 10196     |
---------------------------------------
---------------------------------------
| act_time                | 137       |
| current_lr              | 0.0003    |
| discount_q              | 0.0361    |
| env_time                | 286       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1900      |
| eplenmean               | 295       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 343200    |
| q_grad_norm             | 3507.0342 |
| qfs_loss                | 77.11872  |
| qs_abs_difference       | 46.8      |
| qs_difference           | 46.7      |
| qs_mean                 | 317.86877 |
| time_elapsed            | 14686     |
| total timesteps         | 196502    |
| train_time              | 3826      |
| update_time             | 10247     |
---------------------------------------
---------------------------------------
| act_time                | 138       |
| current_lr              | 0.0003    |
| discount_q              | 0.0087    |
| env_time                | 288       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 1904      |
| eplenmean               | 303       |
| fps                     | 13        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 346200    |
| q_grad_norm             | 2370.6516 |
| qfs_loss                | 45.229904 |
| qs_abs_difference       | 15.8      |
| qs_difference           | 15.6      |
| qs_mean                 | 344.2505  |
| time_elapsed            | 14789     |
| total timesteps         | 198063    |
| train_time              | 3860      |
| update_time             | 10312     |
---------------------------------------
--------------------------------------
| act_time                | 139      |
| current_lr              | 0.0003   |
| discount_q              | 0.0877   |
| env_time                | 290      |
| ep_rewmean              | 1.1e+03  |
| episodes                | 1908     |
| eplenmean               | 305      |
| fps                     | 13       |
| mean 100 episode reward | 1.1e+03  |
| n_updates               | 348600   |
| q_grad_norm             | 2305.854 |
| qfs_loss                | 48.17775 |
| qs_abs_difference       | 117      |
| qs_difference           | 117      |
| qs_mean                 | 379.0143 |
| time_elapsed            | 14870    |
| total timesteps         | 199220   |
| train_time              | 3887     |
| update_time             | 10363    |
--------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.49e+03  |
| eval_abs_qs_difference  | 43.380375 |
| eval_discount_q         | 278       |
| eval_ep_rewmean         | 2.41e+03  |
| eval_eplenmean          | 664       |
| eval_qs                 | 359.81195 |
| eval_qs_difference      | 41.8      |
| eval_time_elapsed       | 16        |
| total timesteps         | 200001    |
---------------------------------------
---------------------------------------
| act_time                | 140       |
| current_lr              | 0.0003    |
| discount_q              | 0.0129    |
| env_time                | 292       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 1912      |
| eplenmean               | 309       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 351000    |
| q_grad_norm             | 3553.7207 |
| qfs_loss                | 67.76963  |
| qs_abs_difference       | 30        |
| qs_difference           | 30        |
| qs_mean                 | 311.50623 |
| time_elapsed            | 14968     |
| total timesteps         | 200489    |
| train_time              | 3914      |
| update_time             | 10414     |
---------------------------------------
---------------------------------------
| act_time                | 141       |
| current_lr              | 0.0003    |
| discount_q              | 0.214     |
| env_time                | 293       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 1916      |
| eplenmean               | 305       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 352800    |
| q_grad_norm             | 3004.1248 |
| qfs_loss                | 54.932755 |
| qs_abs_difference       | 135       |
| qs_difference           | 135       |
| qs_mean                 | 347.0176  |
| time_elapsed            | 15030     |
| total timesteps         | 201391    |
| train_time              | 3934      |
| update_time             | 10453     |
---------------------------------------
---------------------------------------
| act_time                | 141       |
| current_lr              | 0.0003    |
| discount_q              | 0.0987    |
| env_time                | 295       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 1920      |
| eplenmean               | 300       |
| fps                     | 13        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 355000    |
| q_grad_norm             | 2898.1084 |
| qfs_loss                | 46.84269  |
| qs_abs_difference       | 50.1      |
| qs_difference           | 49.1      |
| qs_mean                 | 322.78906 |
| time_elapsed            | 15105     |
| total timesteps         | 202473    |
| train_time              | 3958      |
| update_time             | 10501     |
---------------------------------------
---------------------------------------
| act_time                | 142       |
| current_lr              | 0.0003    |
| discount_q              | 0.0747    |
| env_time                | 297       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 1924      |
| eplenmean               | 300       |
| fps                     | 13        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 357600    |
| q_grad_norm             | 2765.1655 |
| qfs_loss                | 51.95255  |
| qs_abs_difference       | 32.1      |
| qs_difference           | 31.5      |
| qs_mean                 | 334.25864 |
| time_elapsed            | 15193     |
| total timesteps         | 203704    |
| train_time              | 3987      |
| update_time             | 10557     |
---------------------------------------
---------------------------------------
| act_time                | 144       |
| current_lr              | 0.0003    |
| discount_q              | 2.5e-06   |
| env_time                | 300       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1928      |
| eplenmean               | 316       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 361600    |
| q_grad_norm             | 3531.2656 |
| qfs_loss                | 62.3387   |
| qs_abs_difference       | 45        |
| qs_difference           | 43.1      |
| qs_mean                 | 292.74252 |
| time_elapsed            | 15329     |
| total timesteps         | 205768    |
| train_time              | 4032      |
| update_time             | 10643     |
---------------------------------------
---------------------------------------
| act_time                | 145       |
| current_lr              | 0.0003    |
| discount_q              | 0.0441    |
| env_time                | 302       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 1932      |
| eplenmean               | 312       |
| fps                     | 13        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 364000    |
| q_grad_norm             | 2743.471  |
| qfs_loss                | 49.543335 |
| qs_abs_difference       | 39.7      |
| qs_difference           | 39.7      |
| qs_mean                 | 325.84482 |
| time_elapsed            | 15411     |
| total timesteps         | 206958    |
| train_time              | 4059      |
| update_time             | 10695     |
---------------------------------------
---------------------------------------
| act_time                | 146       |
| current_lr              | 0.0003    |
| discount_q              | 0.0061    |
| env_time                | 303       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1936      |
| eplenmean               | 315       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 366600    |
| q_grad_norm             | 3539.6426 |
| qfs_loss                | 53.546597 |
| qs_abs_difference       | 140       |
| qs_difference           | 140       |
| qs_mean                 | 367.23444 |
| time_elapsed            | 15499     |
| total timesteps         | 208256    |
| train_time              | 4088      |
| update_time             | 10751     |
---------------------------------------
---------------------------------------
| act_time                | 147       |
| current_lr              | 0.0003    |
| discount_q              | 0.9       |
| env_time                | 305       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1940      |
| eplenmean               | 315       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 368200    |
| q_grad_norm             | 4033.3857 |
| qfs_loss                | 80.75246  |
| qs_abs_difference       | 142       |
| qs_difference           | 142       |
| qs_mean                 | 366.99945 |
| time_elapsed            | 15554     |
| total timesteps         | 209066    |
| train_time              | 4106      |
| update_time             | 10786     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.65e+03  |
| eval_abs_qs_difference  | 37.578674 |
| eval_discount_q         | 278       |
| eval_ep_rewmean         | 2.62e+03  |
| eval_eplenmean          | 734       |
| eval_qs                 | 351.46503 |
| eval_qs_difference      | 34.8      |
| eval_time_elapsed       | 18        |
| total timesteps         | 210001    |
---------------------------------------
---------------------------------------
| act_time                | 147       |
| current_lr              | 0.0003    |
| discount_q              | 0.0294    |
| env_time                | 306       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 1944      |
| eplenmean               | 318       |
| fps                     | 13        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 370400    |
| q_grad_norm             | 5066.7646 |
| qfs_loss                | 78.203835 |
| qs_abs_difference       | 34.9      |
| qs_difference           | 33.1      |
| qs_mean                 | 245.75233 |
| time_elapsed            | 15647     |
| total timesteps         | 210129    |
| train_time              | 4131      |
| update_time             | 10833     |
---------------------------------------
---------------------------------------
| act_time                | 148       |
| current_lr              | 0.0003    |
| discount_q              | 0.199     |
| env_time                | 308       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 1948      |
| eplenmean               | 320       |
| fps                     | 13        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 372600    |
| q_grad_norm             | 3033.064  |
| qfs_loss                | 48.895607 |
| qs_abs_difference       | 19.4      |
| qs_difference           | 19        |
| qs_mean                 | 331.57593 |
| time_elapsed            | 15723     |
| total timesteps         | 211267    |
| train_time              | 4155      |
| update_time             | 10881     |
---------------------------------------
---------------------------------------
| act_time                | 149       |
| current_lr              | 0.0003    |
| discount_q              | 0.0127    |
| env_time                | 310       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 1952      |
| eplenmean               | 318       |
| fps                     | 13        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 375200    |
| q_grad_norm             | 2823.0322 |
| qfs_loss                | 38.772053 |
| qs_abs_difference       | 10.9      |
| qs_difference           | 6.83      |
| qs_mean                 | 301.26147 |
| time_elapsed            | 15812     |
| total timesteps         | 212556    |
| train_time              | 4185      |
| update_time             | 10938     |
---------------------------------------
---------------------------------------
| act_time                | 151       |
| current_lr              | 0.0003    |
| discount_q              | 0.000514  |
| env_time                | 313       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1956      |
| eplenmean               | 329       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 379600    |
| q_grad_norm             | 3771.1785 |
| qfs_loss                | 68.30226  |
| qs_abs_difference       | 14.3      |
| qs_difference           | 13.6      |
| qs_mean                 | 359.07715 |
| time_elapsed            | 15963     |
| total timesteps         | 214797    |
| train_time              | 4234      |
| update_time             | 11033     |
---------------------------------------
---------------------------------------
| act_time                | 152       |
| current_lr              | 0.0003    |
| discount_q              | 0.117     |
| env_time                | 314       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 1960      |
| eplenmean               | 323       |
| fps                     | 13        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 381800    |
| q_grad_norm             | 4092.5024 |
| qfs_loss                | 72.25542  |
| qs_abs_difference       | 27.7      |
| qs_difference           | 27.7      |
| qs_mean                 | 307.71884 |
| time_elapsed            | 16038     |
| total timesteps         | 215845    |
| train_time              | 4259      |
| update_time             | 11081     |
---------------------------------------
---------------------------------------
| act_time                | 153       |
| current_lr              | 0.0003    |
| discount_q              | 0.0425    |
| env_time                | 316       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 1964      |
| eplenmean               | 324       |
| fps                     | 13        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 384200    |
| q_grad_norm             | 3539.9697 |
| qfs_loss                | 56.313107 |
| qs_abs_difference       | 121       |
| qs_difference           | 121       |
| qs_mean                 | 363.53516 |
| time_elapsed            | 16120     |
| total timesteps         | 217055    |
| train_time              | 4286      |
| update_time             | 11133     |
---------------------------------------
---------------------------------------
| act_time                | 154       |
| current_lr              | 0.0003    |
| discount_q              | 0.0013    |
| env_time                | 319       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 1968      |
| eplenmean               | 332       |
| fps                     | 13        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 387800    |
| q_grad_norm             | 3104.2625 |
| qfs_loss                | 43.726757 |
| qs_abs_difference       | 11.3      |
| qs_difference           | 8.9       |
| qs_mean                 | 342.64346 |
| time_elapsed            | 16244     |
| total timesteps         | 218855    |
| train_time              | 4326      |
| update_time             | 11212     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.66e+03  |
| eval_abs_qs_difference  | 39.34013  |
| eval_discount_q         | 265       |
| eval_ep_rewmean         | 1.39e+03  |
| eval_eplenmean          | 377       |
| eval_qs                 | 324.23572 |
| eval_qs_difference      | 32.3      |
| eval_time_elapsed       | 9         |
| total timesteps         | 220001    |
---------------------------------------
---------------------------------------
| act_time                | 156       |
| current_lr              | 0.0003    |
| discount_q              | 0.000167  |
| env_time                | 322       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 1972      |
| eplenmean               | 333       |
| fps                     | 13        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 391600    |
| q_grad_norm             | 3490.1917 |
| qfs_loss                | 57.985107 |
| qs_abs_difference       | 24.6      |
| qs_difference           | 13.1      |
| qs_mean                 | 333.7366  |
| time_elapsed            | 16383     |
| total timesteps         | 220794    |
| train_time              | 4368      |
| update_time             | 11295     |
---------------------------------------
---------------------------------------
| act_time                | 157       |
| current_lr              | 0.0003    |
| discount_q              | 0.0193    |
| env_time                | 324       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1976      |
| eplenmean               | 328       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 394200    |
| q_grad_norm             | 3641.6863 |
| qfs_loss                | 54.208447 |
| qs_abs_difference       | 14.1      |
| qs_difference           | 11        |
| qs_mean                 | 302.96982 |
| time_elapsed            | 16472     |
| total timesteps         | 222053    |
| train_time              | 4397      |
| update_time             | 11351     |
---------------------------------------
---------------------------------------
| act_time                | 158       |
| current_lr              | 0.0003    |
| discount_q              | 0.011     |
| env_time                | 326       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 1980      |
| eplenmean               | 333       |
| fps                     | 13        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 397000    |
| q_grad_norm             | 2658.0232 |
| qfs_loss                | 52.440308 |
| qs_abs_difference       | 11.3      |
| qs_difference           | 3.55      |
| qs_mean                 | 327.8104  |
| time_elapsed            | 16567     |
| total timesteps         | 223461    |
| train_time              | 4429      |
| update_time             | 11412     |
---------------------------------------
---------------------------------------
| act_time                | 159       |
| current_lr              | 0.0003    |
| discount_q              | 0.0156    |
| env_time                | 328       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 1984      |
| eplenmean               | 332       |
| fps                     | 13        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 399800    |
| q_grad_norm             | 3377.3015 |
| qfs_loss                | 55.185528 |
| qs_abs_difference       | 51.4      |
| qs_difference           | 51.4      |
| qs_mean                 | 350.88803 |
| time_elapsed            | 16662     |
| total timesteps         | 224857    |
| train_time              | 4460      |
| update_time             | 11472     |
---------------------------------------
---------------------------------------
| act_time                | 160       |
| current_lr              | 0.0003    |
| discount_q              | 0.0865    |
| env_time                | 330       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 1988      |
| eplenmean               | 332       |
| fps                     | 13        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 401800    |
| q_grad_norm             | 2283.9697 |
| qfs_loss                | 43.230453 |
| qs_abs_difference       | 34.4      |
| qs_difference           | 33        |
| qs_mean                 | 293.26816 |
| time_elapsed            | 16731     |
| total timesteps         | 225879    |
| train_time              | 4482      |
| update_time             | 11516     |
---------------------------------------
---------------------------------------
| act_time                | 161       |
| current_lr              | 0.0003    |
| discount_q              | 0.0528    |
| env_time                | 331       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 1992      |
| eplenmean               | 331       |
| fps                     | 13        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 404000    |
| q_grad_norm             | 3297.6228 |
| qfs_loss                | 51.027603 |
| qs_abs_difference       | 49        |
| qs_difference           | 48.3      |
| qs_mean                 | 286.4988  |
| time_elapsed            | 16805     |
| total timesteps         | 226935    |
| train_time              | 4507      |
| update_time             | 11563     |
---------------------------------------
---------------------------------------
| act_time                | 161       |
| current_lr              | 0.0003    |
| discount_q              | 0.017     |
| env_time                | 333       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 1996      |
| eplenmean               | 328       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 406400    |
| q_grad_norm             | 3073.0205 |
| qfs_loss                | 40.60059  |
| qs_abs_difference       | 30.6      |
| qs_difference           | 10.6      |
| qs_mean                 | 285.1691  |
| time_elapsed            | 16888     |
| total timesteps         | 228152    |
| train_time              | 4533      |
| update_time             | 11615     |
---------------------------------------
--------------------------------------
| act_time                | 162      |
| current_lr              | 0.0003   |
| discount_q              | 0.0967   |
| env_time                | 334      |
| ep_rewmean              | 1.19e+03 |
| episodes                | 2000     |
| eplenmean               | 327      |
| fps                     | 13       |
| mean 100 episode reward | 1.19e+03 |
| n_updates               | 408400   |
| q_grad_norm             | 4629.301 |
| qfs_loss                | 80.4554  |
| qs_abs_difference       | 116      |
| qs_difference           | 116      |
| qs_mean                 | 354.6306 |
| time_elapsed            | 16956    |
| total timesteps         | 229169   |
| train_time              | 4556     |
| update_time             | 11659    |
--------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.64e+03  |
| eval_abs_qs_difference  | 27.440498 |
| eval_discount_q         | 281       |
| eval_ep_rewmean         | 1.53e+03  |
| eval_eplenmean          | 397       |
| eval_qs                 | 337.42233 |
| eval_qs_difference      | 25.5      |
| eval_time_elapsed       | 9         |
| total timesteps         | 230001    |
---------------------------------------
---------------------------------------
| act_time                | 163       |
| current_lr              | 0.0003    |
| discount_q              | 0.0244    |
| env_time                | 336       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2004      |
| eplenmean               | 323       |
| fps                     | 13        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 410800    |
| q_grad_norm             | 3537.922  |
| qfs_loss                | 48.78228  |
| qs_abs_difference       | 47        |
| qs_difference           | 46.2      |
| qs_mean                 | 316.24454 |
| time_elapsed            | 17048     |
| total timesteps         | 230365    |
| train_time              | 4583      |
| update_time             | 11711     |
---------------------------------------
---------------------------------------
| act_time                | 164       |
| current_lr              | 0.0003    |
| discount_q              | 0.0757    |
| env_time                | 338       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2008      |
| eplenmean               | 322       |
| fps                     | 13        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 413000    |
| q_grad_norm             | 4653.91   |
| qfs_loss                | 70.72359  |
| qs_abs_difference       | 23.6      |
| qs_difference           | 19.1      |
| qs_mean                 | 296.71237 |
| time_elapsed            | 17123     |
| total timesteps         | 231434    |
| train_time              | 4607      |
| update_time             | 11758     |
---------------------------------------
---------------------------------------
| act_time                | 165       |
| current_lr              | 0.0003    |
| discount_q              | 0.021     |
| env_time                | 340       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 2012      |
| eplenmean               | 322       |
| fps                     | 13        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 415400    |
| q_grad_norm             | 2817.9082 |
| qfs_loss                | 44.219826 |
| qs_abs_difference       | 20.1      |
| qs_difference           | 17.9      |
| qs_mean                 | 317.48877 |
| time_elapsed            | 17205     |
| total timesteps         | 232690    |
| train_time              | 4634      |
| update_time             | 11811     |
---------------------------------------
---------------------------------------
| act_time                | 166       |
| current_lr              | 0.0003    |
| discount_q              | 0.0241    |
| env_time                | 341       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2016      |
| eplenmean               | 325       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 417800    |
| q_grad_norm             | 3002.1438 |
| qfs_loss                | 52.62238  |
| qs_abs_difference       | 9.42      |
| qs_difference           | -3.02     |
| qs_mean                 | 294.9858  |
| time_elapsed            | 17287     |
| total timesteps         | 233894    |
| train_time              | 4661      |
| update_time             | 11863     |
---------------------------------------
---------------------------------------
| act_time                | 167       |
| current_lr              | 0.0003    |
| discount_q              | 0.191     |
| env_time                | 343       |
| ep_rewmean              | 1.19e+03  |
| episodes                | 2020      |
| eplenmean               | 324       |
| fps                     | 13        |
| mean 100 episode reward | 1.19e+03  |
| n_updates               | 419800    |
| q_grad_norm             | 3701.0125 |
| qfs_loss                | 63.25374  |
| qs_abs_difference       | 137       |
| qs_difference           | 137       |
| qs_mean                 | 376.22787 |
| time_elapsed            | 17355     |
| total timesteps         | 234861    |
| train_time              | 4683      |
| update_time             | 11906     |
---------------------------------------
---------------------------------------
| act_time                | 168       |
| current_lr              | 0.0003    |
| discount_q              | 0.00818   |
| env_time                | 344       |
| ep_rewmean              | 1.19e+03  |
| episodes                | 2024      |
| eplenmean               | 322       |
| fps                     | 13        |
| mean 100 episode reward | 1.19e+03  |
| n_updates               | 422000    |
| q_grad_norm             | 5295.341  |
| qfs_loss                | 86.47967  |
| qs_abs_difference       | 248       |
| qs_difference           | 248       |
| qs_mean                 | 356.13297 |
| time_elapsed            | 17430     |
| total timesteps         | 235929    |
| train_time              | 4708      |
| update_time             | 11954     |
---------------------------------------
---------------------------------------
| act_time                | 168       |
| current_lr              | 0.0003    |
| discount_q              | 0.00826   |
| env_time                | 345       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2028      |
| eplenmean               | 308       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 423200    |
| q_grad_norm             | 2141.558  |
| qfs_loss                | 37.69088  |
| qs_abs_difference       | 294       |
| qs_difference           | 294       |
| qs_mean                 | 297.87503 |
| time_elapsed            | 17471     |
| total timesteps         | 236597    |
| train_time              | 4721      |
| update_time             | 11980     |
---------------------------------------
--------------------------------------
| act_time                | 169      |
| current_lr              | 0.0003   |
| discount_q              | 0.806    |
| env_time                | 346      |
| ep_rewmean              | 1.13e+03 |
| episodes                | 2032     |
| eplenmean               | 305      |
| fps                     | 13       |
| mean 100 episode reward | 1.13e+03 |
| n_updates               | 425000   |
| q_grad_norm             | 4203.408 |
| qfs_loss                | 69.16293 |
| qs_abs_difference       | 29.2     |
| qs_difference           | 29       |
| qs_mean                 | 310.0625 |
| time_elapsed            | 17533    |
| total timesteps         | 237432   |
| train_time              | 4742     |
| update_time             | 12019    |
--------------------------------------
---------------------------------------
| act_time                | 169       |
| current_lr              | 0.0003    |
| discount_q              | 0.345     |
| env_time                | 347       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2036      |
| eplenmean               | 299       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 426400    |
| q_grad_norm             | 3336.5068 |
| qfs_loss                | 57.595394 |
| qs_abs_difference       | 243       |
| qs_difference           | 243       |
| qs_mean                 | 360.88635 |
| time_elapsed            | 17581     |
| total timesteps         | 238145    |
| train_time              | 4757      |
| update_time             | 12049     |
---------------------------------------
---------------------------------------
| act_time                | 170       |
| current_lr              | 0.0003    |
| discount_q              | 0.0187    |
| env_time                | 349       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 2040      |
| eplenmean               | 303       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 428800    |
| q_grad_norm             | 3508.8623 |
| qfs_loss                | 54.218838 |
| qs_abs_difference       | 77.7      |
| qs_difference           | 77.6      |
| qs_mean                 | 334.65607 |
| time_elapsed            | 17663     |
| total timesteps         | 239327    |
| train_time              | 4784      |
| update_time             | 12102     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.49e+03  |
| eval_abs_qs_difference  | 51.6778   |
| eval_discount_q         | 264       |
| eval_ep_rewmean         | 1.23e+03  |
| eval_eplenmean          | 334       |
| eval_qs                 | 328.09393 |
| eval_qs_difference      | 49.9      |
| eval_time_elapsed       | 8         |
| total timesteps         | 240001    |
---------------------------------------
---------------------------------------
| act_time                | 171       |
| current_lr              | 0.0003    |
| discount_q              | 0.149     |
| env_time                | 351       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 2044      |
| eplenmean               | 302       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 430800    |
| q_grad_norm             | 3165.3184 |
| qfs_loss                | 53.99043  |
| qs_abs_difference       | 49.6      |
| qs_difference           | 47.8      |
| qs_mean                 | 319.44754 |
| time_elapsed            | 17740     |
| total timesteps         | 240318    |
| train_time              | 4806      |
| update_time             | 12145     |
---------------------------------------
---------------------------------------
| act_time                | 172       |
| current_lr              | 0.0003    |
| discount_q              | 0.119     |
| env_time                | 352       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 2048      |
| eplenmean               | 300       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 432600    |
| q_grad_norm             | 3541.6655 |
| qfs_loss                | 49.480885 |
| qs_abs_difference       | 40.5      |
| qs_difference           | 40.5      |
| qs_mean                 | 298.564   |
| time_elapsed            | 17802     |
| total timesteps         | 241294    |
| train_time              | 4827      |
| update_time             | 12185     |
---------------------------------------
---------------------------------------
| act_time                | 172       |
| current_lr              | 0.0003    |
| discount_q              | 0.381     |
| env_time                | 353       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2052      |
| eplenmean               | 296       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 434400    |
| q_grad_norm             | 3819.9963 |
| qfs_loss                | 64.75676  |
| qs_abs_difference       | 49.2      |
| qs_difference           | 48.6      |
| qs_mean                 | 294.82278 |
| time_elapsed            | 17863     |
| total timesteps         | 242174    |
| train_time              | 4847      |
| update_time             | 12224     |
---------------------------------------
---------------------------------------
| act_time                | 173       |
| current_lr              | 0.0003    |
| discount_q              | 0.098     |
| env_time                | 355       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2056      |
| eplenmean               | 284       |
| fps                     | 13        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 436400    |
| q_grad_norm             | 4512.303  |
| qfs_loss                | 61.52642  |
| qs_abs_difference       | 61.7      |
| qs_difference           | 61.3      |
| qs_mean                 | 298.81827 |
| time_elapsed            | 17932     |
| total timesteps         | 243181    |
| train_time              | 4869      |
| update_time             | 12268     |
---------------------------------------
---------------------------------------
| act_time                | 174       |
| current_lr              | 0.0003    |
| discount_q              | 0.209     |
| env_time                | 356       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2060      |
| eplenmean               | 283       |
| fps                     | 13        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 438400    |
| q_grad_norm             | 2103.8516 |
| qfs_loss                | 33.998924 |
| qs_abs_difference       | 94.9      |
| qs_difference           | 94.9      |
| qs_mean                 | 315.6753  |
| time_elapsed            | 18000     |
| total timesteps         | 244106    |
| train_time              | 4892      |
| update_time             | 12311     |
---------------------------------------
---------------------------------------
| act_time                | 175       |
| current_lr              | 0.0003    |
| discount_q              | 0.126     |
| env_time                | 358       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2064      |
| eplenmean               | 280       |
| fps                     | 13        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 440200    |
| q_grad_norm             | 3175.002  |
| qfs_loss                | 56.075317 |
| qs_abs_difference       | 55        |
| qs_difference           | 54.6      |
| qs_mean                 | 299.24777 |
| time_elapsed            | 18062     |
| total timesteps         | 245074    |
| train_time              | 4912      |
| update_time             | 12351     |
---------------------------------------
--------------------------------------
| act_time                | 175      |
| current_lr              | 0.0003   |
| discount_q              | 0.317    |
| env_time                | 359      |
| ep_rewmean              | 1.01e+03 |
| episodes                | 2068     |
| eplenmean               | 271      |
| fps                     | 13       |
| mean 100 episode reward | 1.01e+03 |
| n_updates               | 442000   |
| q_grad_norm             | 3604.65  |
| qfs_loss                | 50.85662 |
| qs_abs_difference       | 52.5     |
| qs_difference           | 52.3     |
| qs_mean                 | 304.5662 |
| time_elapsed            | 18125    |
| total timesteps         | 245953   |
| train_time              | 4932     |
| update_time             | 12391    |
--------------------------------------
---------------------------------------
| act_time                | 176       |
| current_lr              | 0.0003    |
| discount_q              | 0.29      |
| env_time                | 360       |
| ep_rewmean              | 979       |
| episodes                | 2072      |
| eplenmean               | 261       |
| fps                     | 13        |
| mean 100 episode reward | 979       |
| n_updates               | 443800    |
| q_grad_norm             | 4303.68   |
| qfs_loss                | 62.574127 |
| qs_abs_difference       | 26.8      |
| qs_difference           | 26.6      |
| qs_mean                 | 317.71216 |
| time_elapsed            | 18187     |
| total timesteps         | 246889    |
| train_time              | 4952      |
| update_time             | 12430     |
---------------------------------------
--------------------------------------
| act_time                | 177      |
| current_lr              | 0.0003   |
| discount_q              | 0.0909   |
| env_time                | 362      |
| ep_rewmean              | 978      |
| episodes                | 2076     |
| eplenmean               | 259      |
| fps                     | 13       |
| mean 100 episode reward | 978      |
| n_updates               | 446000   |
| q_grad_norm             | 3596.413 |
| qfs_loss                | 64.91751 |
| qs_abs_difference       | 26.1     |
| qs_difference           | 23.8     |
| qs_mean                 | 332.7482 |
| time_elapsed            | 18263    |
| total timesteps         | 247992   |
| train_time              | 4977     |
| update_time             | 12479    |
--------------------------------------
---------------------------------------
| act_time                | 178       |
| current_lr              | 0.0003    |
| discount_q              | 0.000655  |
| env_time                | 364       |
| ep_rewmean              | 985       |
| episodes                | 2080      |
| eplenmean               | 260       |
| fps                     | 13        |
| mean 100 episode reward | 984       |
| n_updates               | 449200    |
| q_grad_norm             | 3376.7983 |
| qfs_loss                | 70.214226 |
| qs_abs_difference       | 52.4      |
| qs_difference           | 51.1      |
| qs_mean                 | 317.24844 |
| time_elapsed            | 18379     |
| total timesteps         | 249509    |
| train_time              | 5012      |
| update_time             | 12556     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.45e+03  |
| eval_abs_qs_difference  | 13.249341 |
| eval_discount_q         | 293       |
| eval_ep_rewmean         | 1.14e+03  |
| eval_eplenmean          | 270       |
| eval_qs                 | 308.0535  |
| eval_qs_difference      | -7.6      |
| eval_time_elapsed       | 6         |
| total timesteps         | 250001    |
---------------------------------------
---------------------------------------
| act_time                | 179       |
| current_lr              | 0.0003    |
| discount_q              | 0.151     |
| env_time                | 366       |
| ep_rewmean              | 972       |
| episodes                | 2084      |
| eplenmean               | 257       |
| fps                     | 13        |
| mean 100 episode reward | 972       |
| n_updates               | 451200    |
| q_grad_norm             | 4307.6577 |
| qfs_loss                | 68.30334  |
| qs_abs_difference       | 43.4      |
| qs_difference           | 41.1      |
| qs_mean                 | 318.43634 |
| time_elapsed            | 18455     |
| total timesteps         | 250524    |
| train_time              | 5034      |
| update_time             | 12600     |
---------------------------------------
---------------------------------------
| act_time                | 180       |
| current_lr              | 0.0003    |
| discount_q              | 0.0881    |
| env_time                | 367       |
| ep_rewmean              | 976       |
| episodes                | 2088      |
| eplenmean               | 257       |
| fps                     | 13        |
| mean 100 episode reward | 976       |
| n_updates               | 453200    |
| q_grad_norm             | 4768.63   |
| qfs_loss                | 65.555725 |
| qs_abs_difference       | 88.8      |
| qs_difference           | 88.8      |
| qs_mean                 | 358.57678 |
| time_elapsed            | 18524     |
| total timesteps         | 251560    |
| train_time              | 5057      |
| update_time             | 12644     |
---------------------------------------
---------------------------------------
| act_time                | 180       |
| current_lr              | 0.0003    |
| discount_q              | 0.625     |
| env_time                | 369       |
| ep_rewmean              | 971       |
| episodes                | 2092      |
| eplenmean               | 255       |
| fps                     | 13        |
| mean 100 episode reward | 971       |
| n_updates               | 455000    |
| q_grad_norm             | 3932.411  |
| qfs_loss                | 61.600624 |
| qs_abs_difference       | 48.2      |
| qs_difference           | 48        |
| qs_mean                 | 337.50912 |
| time_elapsed            | 18587     |
| total timesteps         | 252423    |
| train_time              | 5077      |
| update_time             | 12684     |
---------------------------------------
---------------------------------------
| act_time                | 181       |
| current_lr              | 0.0003    |
| discount_q              | 0.121     |
| env_time                | 370       |
| ep_rewmean              | 965       |
| episodes                | 2096      |
| eplenmean               | 252       |
| fps                     | 13        |
| mean 100 episode reward | 965       |
| n_updates               | 456800    |
| q_grad_norm             | 4149.6143 |
| qfs_loss                | 67.49751  |
| qs_abs_difference       | 54.8      |
| qs_difference           | 53.4      |
| qs_mean                 | 302.3986  |
| time_elapsed            | 18649     |
| total timesteps         | 253389    |
| train_time              | 5097      |
| update_time             | 12725     |
---------------------------------------
---------------------------------------
| act_time                | 182       |
| current_lr              | 0.0003    |
| discount_q              | 0.257     |
| env_time                | 372       |
| ep_rewmean              | 967       |
| episodes                | 2100      |
| eplenmean               | 252       |
| fps                     | 13        |
| mean 100 episode reward | 966       |
| n_updates               | 458800    |
| q_grad_norm             | 3549.395  |
| qfs_loss                | 55.66799  |
| qs_abs_difference       | 16.6      |
| qs_difference           | 7.86      |
| qs_mean                 | 310.86862 |
| time_elapsed            | 18741     |
| total timesteps         | 254343    |
| train_time              | 5119      |
| update_time             | 12791     |
---------------------------------------
---------------------------------------
| act_time                | 183       |
| current_lr              | 0.0003    |
| discount_q              | 0.213     |
| env_time                | 373       |
| ep_rewmean              | 959       |
| episodes                | 2104      |
| eplenmean               | 250       |
| fps                     | 13        |
| mean 100 episode reward | 959       |
| n_updates               | 460800    |
| q_grad_norm             | 2493.235  |
| qfs_loss                | 42.117176 |
| qs_abs_difference       | 48.6      |
| qs_difference           | 48.3      |
| qs_mean                 | 325.054   |
| time_elapsed            | 18810     |
| total timesteps         | 255334    |
| train_time              | 5141      |
| update_time             | 12835     |
---------------------------------------
---------------------------------------
| act_time                | 183       |
| current_lr              | 0.0003    |
| discount_q              | 0.0978    |
| env_time                | 375       |
| ep_rewmean              | 957       |
| episodes                | 2108      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 957       |
| n_updates               | 462800    |
| q_grad_norm             | 4270.131  |
| qfs_loss                | 67.51477  |
| qs_abs_difference       | 70.7      |
| qs_difference           | 70.7      |
| qs_mean                 | 335.49442 |
| time_elapsed            | 18879     |
| total timesteps         | 256362    |
| train_time              | 5164      |
| update_time             | 12880     |
---------------------------------------
---------------------------------------
| act_time                | 184       |
| current_lr              | 0.0003    |
| discount_q              | 0.0272    |
| env_time                | 376       |
| ep_rewmean              | 959       |
| episodes                | 2112      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 959       |
| n_updates               | 465200    |
| q_grad_norm             | 4453.5273 |
| qfs_loss                | 73.7154   |
| qs_abs_difference       | 54.2      |
| qs_difference           | 51.6      |
| qs_mean                 | 343.8025  |
| time_elapsed            | 18962     |
| total timesteps         | 257562    |
| train_time              | 5191      |
| update_time             | 12933     |
---------------------------------------
---------------------------------------
| act_time                | 185       |
| current_lr              | 0.0003    |
| discount_q              | 0.0131    |
| env_time                | 378       |
| ep_rewmean              | 965       |
| episodes                | 2116      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 965       |
| n_updates               | 467800    |
| q_grad_norm             | 2899.9233 |
| qfs_loss                | 47.730125 |
| qs_abs_difference       | 40.6      |
| qs_difference           | 40.6      |
| qs_mean                 | 328.4513  |
| time_elapsed            | 19051     |
| total timesteps         | 258835    |
| train_time              | 5220      |
| update_time             | 12990     |
---------------------------------------
---------------------------------------
| act_time                | 186       |
| current_lr              | 0.0003    |
| discount_q              | 0.213     |
| env_time                | 380       |
| ep_rewmean              | 968       |
| episodes                | 2120      |
| eplenmean               | 250       |
| fps                     | 13        |
| mean 100 episode reward | 968       |
| n_updates               | 469800    |
| q_grad_norm             | 4525.464  |
| qfs_loss                | 94.30131  |
| qs_abs_difference       | 51.7      |
| qs_difference           | 51.7      |
| qs_mean                 | 337.51196 |
| time_elapsed            | 19120     |
| total timesteps         | 259845    |
| train_time              | 5242      |
| update_time             | 13033     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.4e+03   |
| eval_abs_qs_difference  | 185.30638 |
| eval_discount_q         | 164       |
| eval_ep_rewmean         | 468       |
| eval_eplenmean          | 135       |
| eval_qs                 | 334.82825 |
| eval_qs_difference      | 183       |
| eval_time_elapsed       | 3         |
| total timesteps         | 260001    |
---------------------------------------
---------------------------------------
| act_time                | 187       |
| current_lr              | 0.0003    |
| discount_q              | 1.17      |
| env_time                | 381       |
| ep_rewmean              | 958       |
| episodes                | 2124      |
| eplenmean               | 247       |
| fps                     | 13        |
| mean 100 episode reward | 958       |
| n_updates               | 471400    |
| q_grad_norm             | 3650.5566 |
| qfs_loss                | 69.7542   |
| qs_abs_difference       | 15.4      |
| qs_difference           | 8.6       |
| qs_mean                 | 300.8689  |
| time_elapsed            | 19179     |
| total timesteps         | 260626    |
| train_time              | 5260      |
| update_time             | 13069     |
---------------------------------------
---------------------------------------
| act_time                | 188       |
| current_lr              | 0.0003    |
| discount_q              | 0.0646    |
| env_time                | 382       |
| ep_rewmean              | 980       |
| episodes                | 2128      |
| eplenmean               | 252       |
| fps                     | 13        |
| mean 100 episode reward | 980       |
| n_updates               | 473600    |
| q_grad_norm             | 4105.5356 |
| qfs_loss                | 65.225555 |
| qs_abs_difference       | 13.4      |
| qs_difference           | -11.7     |
| qs_mean                 | 328.39996 |
| time_elapsed            | 19255     |
| total timesteps         | 261782    |
| train_time              | 5285      |
| update_time             | 13118     |
---------------------------------------
---------------------------------------
| act_time                | 189       |
| current_lr              | 0.0003    |
| discount_q              | 0.0931    |
| env_time                | 384       |
| ep_rewmean              | 989       |
| episodes                | 2132      |
| eplenmean               | 254       |
| fps                     | 13        |
| mean 100 episode reward | 989       |
| n_updates               | 475800    |
| q_grad_norm             | 3471.7832 |
| qfs_loss                | 54.863453 |
| qs_abs_difference       | 27.5      |
| qs_difference           | 22.9      |
| qs_mean                 | 315.94104 |
| time_elapsed            | 19332     |
| total timesteps         | 262848    |
| train_time              | 5309      |
| update_time             | 13167     |
---------------------------------------
---------------------------------------
| act_time                | 189       |
| current_lr              | 0.0003    |
| discount_q              | 0.504     |
| env_time                | 385       |
| ep_rewmean              | 998       |
| episodes                | 2136      |
| eplenmean               | 256       |
| fps                     | 13        |
| mean 100 episode reward | 998       |
| n_updates               | 477600    |
| q_grad_norm             | 2755.2307 |
| qfs_loss                | 57.2738   |
| qs_abs_difference       | 24.8      |
| qs_difference           | 24.5      |
| qs_mean                 | 322.91342 |
| time_elapsed            | 19394     |
| total timesteps         | 263728    |
| train_time              | 5329      |
| update_time             | 13206     |
---------------------------------------
---------------------------------------
| act_time                | 190       |
| current_lr              | 0.0003    |
| discount_q              | 0.0795    |
| env_time                | 387       |
| ep_rewmean              | 998       |
| episodes                | 2140      |
| eplenmean               | 255       |
| fps                     | 13        |
| mean 100 episode reward | 998       |
| n_updates               | 479800    |
| q_grad_norm             | 3486.5278 |
| qfs_loss                | 58.185135 |
| qs_abs_difference       | 12.3      |
| qs_difference           | 11.7      |
| qs_mean                 | 332.1463  |
| time_elapsed            | 19470     |
| total timesteps         | 264832    |
| train_time              | 5354      |
| update_time             | 13255     |
---------------------------------------
---------------------------------------
| act_time                | 191       |
| current_lr              | 0.0003    |
| discount_q              | 0.14      |
| env_time                | 389       |
| ep_rewmean              | 997       |
| episodes                | 2144      |
| eplenmean               | 255       |
| fps                     | 13        |
| mean 100 episode reward | 997       |
| n_updates               | 481600    |
| q_grad_norm             | 3945.3643 |
| qfs_loss                | 60.084816 |
| qs_abs_difference       | 149       |
| qs_difference           | 149       |
| qs_mean                 | 380.91663 |
| time_elapsed            | 19533     |
| total timesteps         | 265780    |
| train_time              | 5374      |
| update_time             | 13295     |
---------------------------------------
---------------------------------------
| act_time                | 192       |
| current_lr              | 0.0003    |
| discount_q              | 0.0743    |
| env_time                | 390       |
| ep_rewmean              | 1e+03     |
| episodes                | 2148      |
| eplenmean               | 256       |
| fps                     | 13        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 483800    |
| q_grad_norm             | 4539.9736 |
| qfs_loss                | 65.34336  |
| qs_abs_difference       | 28.4      |
| qs_difference           | 23.1      |
| qs_mean                 | 314.63647 |
| time_elapsed            | 19609     |
| total timesteps         | 266847    |
| train_time              | 5399      |
| update_time             | 13344     |
---------------------------------------
---------------------------------------
| act_time                | 192       |
| current_lr              | 0.0003    |
| discount_q              | 0.173     |
| env_time                | 391       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2152      |
| eplenmean               | 256       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 485800    |
| q_grad_norm             | 2159.1655 |
| qfs_loss                | 35.708126 |
| qs_abs_difference       | 96.3      |
| qs_difference           | 96.3      |
| qs_mean                 | 369.27078 |
| time_elapsed            | 19678     |
| total timesteps         | 267810    |
| train_time              | 5421      |
| update_time             | 13388     |
---------------------------------------
---------------------------------------
| act_time                | 193       |
| current_lr              | 0.0003    |
| discount_q              | 0.202     |
| env_time                | 393       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2156      |
| eplenmean               | 256       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 487800    |
| q_grad_norm             | 3834.8826 |
| qfs_loss                | 54.658157 |
| qs_abs_difference       | 31.6      |
| qs_difference           | 31.5      |
| qs_mean                 | 336.0764  |
| time_elapsed            | 19747     |
| total timesteps         | 268804    |
| train_time              | 5443      |
| update_time             | 13433     |
---------------------------------------
---------------------------------------
| act_time                | 194       |
| current_lr              | 0.0003    |
| discount_q              | 0.155     |
| env_time                | 395       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2160      |
| eplenmean               | 258       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 489800    |
| q_grad_norm             | 3532.8105 |
| qfs_loss                | 65.57777  |
| qs_abs_difference       | 63.3      |
| qs_difference           | 63.2      |
| qs_mean                 | 353.18112 |
| time_elapsed            | 19817     |
| total timesteps         | 269868    |
| train_time              | 5466      |
| update_time             | 13477     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.37e+03  |
| eval_abs_qs_difference  | 14.299514 |
| eval_discount_q         | 296       |
| eval_ep_rewmean         | 1.14e+03  |
| eval_eplenmean          | 269       |
| eval_qs                 | 324.9007  |
| eval_qs_difference      | 9.97      |
| eval_time_elapsed       | 5         |
| total timesteps         | 270001    |
---------------------------------------
---------------------------------------
| act_time                | 195       |
| current_lr              | 0.0003    |
| discount_q              | 0.0894    |
| env_time                | 396       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2164      |
| eplenmean               | 259       |
| fps                     | 13        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 492000    |
| q_grad_norm             | 3308.709  |
| qfs_loss                | 58.995007 |
| qs_abs_difference       | 22.1      |
| qs_difference           | 19.6      |
| qs_mean                 | 330.90604 |
| time_elapsed            | 19899     |
| total timesteps         | 270937    |
| train_time              | 5490      |
| update_time             | 13526     |
---------------------------------------
---------------------------------------
| act_time                | 196       |
| current_lr              | 0.0003    |
| discount_q              | 0.0158    |
| env_time                | 398       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2168      |
| eplenmean               | 260       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 494000    |
| q_grad_norm             | 2887.9575 |
| qfs_loss                | 45.258324 |
| qs_abs_difference       | 258       |
| qs_difference           | 258       |
| qs_mean                 | 377.43732 |
| time_elapsed            | 19969     |
| total timesteps         | 271951    |
| train_time              | 5513      |
| update_time             | 13571     |
---------------------------------------
---------------------------------------
| act_time                | 197       |
| current_lr              | 0.0003    |
| discount_q              | 0.0963    |
| env_time                | 399       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2172      |
| eplenmean               | 261       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 496000    |
| q_grad_norm             | 3393.364  |
| qfs_loss                | 55.129013 |
| qs_abs_difference       | 33.2      |
| qs_difference           | 32.2      |
| qs_mean                 | 310.0107  |
| time_elapsed            | 20038     |
| total timesteps         | 272970    |
| train_time              | 5535      |
| update_time             | 13615     |
---------------------------------------
---------------------------------------
| act_time                | 197       |
| current_lr              | 0.0003    |
| discount_q              | 0.527     |
| env_time                | 400       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2176      |
| eplenmean               | 258       |
| fps                     | 13        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 497600    |
| q_grad_norm             | 2992.529  |
| qfs_loss                | 44.98928  |
| qs_abs_difference       | 50.5      |
| qs_difference           | 50        |
| qs_mean                 | 296.60776 |
| time_elapsed            | 20094     |
| total timesteps         | 273775    |
| train_time              | 5553      |
| update_time             | 13651     |
---------------------------------------
---------------------------------------
| act_time                | 198       |
| current_lr              | 0.0003    |
| discount_q              | 0.0852    |
| env_time                | 402       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2180      |
| eplenmean               | 253       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 499800    |
| q_grad_norm             | 5543.39   |
| qfs_loss                | 91.495285 |
| qs_abs_difference       | 28.9      |
| qs_difference           | 28.1      |
| qs_mean                 | 309.37897 |
| time_elapsed            | 20171     |
| total timesteps         | 274801    |
| train_time              | 5578      |
| update_time             | 13700     |
---------------------------------------
---------------------------------------
| act_time                | 198       |
| current_lr              | 0.0003    |
| discount_q              | 118       |
| env_time                | 403       |
| ep_rewmean              | 980       |
| episodes                | 2184      |
| eplenmean               | 246       |
| fps                     | 13        |
| mean 100 episode reward | 980       |
| n_updates               | 500400    |
| q_grad_norm             | 2993.4438 |
| qfs_loss                | 59.89836  |
| qs_abs_difference       | 29        |
| qs_difference           | 27.8      |
| qs_mean                 | 317.623   |
| time_elapsed            | 20191     |
| total timesteps         | 275137    |
| train_time              | 5585      |
| update_time             | 13713     |
---------------------------------------
---------------------------------------
| act_time                | 199       |
| current_lr              | 0.0003    |
| discount_q              | 0.0107    |
| env_time                | 404       |
| ep_rewmean              | 977       |
| episodes                | 2188      |
| eplenmean               | 245       |
| fps                     | 13        |
| mean 100 episode reward | 977       |
| n_updates               | 502400    |
| q_grad_norm             | 3354.3635 |
| qfs_loss                | 64.28067  |
| qs_abs_difference       | 284       |
| qs_difference           | 284       |
| qs_mean                 | 352.89032 |
| time_elapsed            | 20261     |
| total timesteps         | 276104    |
| train_time              | 5607      |
| update_time             | 13758     |
---------------------------------------
---------------------------------------
| act_time                | 200       |
| current_lr              | 0.0003    |
| discount_q              | 0.0421    |
| env_time                | 406       |
| ep_rewmean              | 991       |
| episodes                | 2192      |
| eplenmean               | 248       |
| fps                     | 13        |
| mean 100 episode reward | 991       |
| n_updates               | 504600    |
| q_grad_norm             | 3684.0344 |
| qfs_loss                | 70.49903  |
| qs_abs_difference       | 43.9      |
| qs_difference           | 39.4      |
| qs_mean                 | 344.7927  |
| time_elapsed            | 20337     |
| total timesteps         | 277256    |
| train_time              | 5631      |
| update_time             | 13806     |
---------------------------------------
---------------------------------------
| act_time                | 201       |
| current_lr              | 0.0003    |
| discount_q              | 0.0405    |
| env_time                | 407       |
| ep_rewmean              | 995       |
| episodes                | 2196      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 995       |
| n_updates               | 506800    |
| q_grad_norm             | 3583.0254 |
| qfs_loss                | 49.55671  |
| qs_abs_difference       | 51.8      |
| qs_difference           | 49.8      |
| qs_mean                 | 301.27005 |
| time_elapsed            | 20414     |
| total timesteps         | 278321    |
| train_time              | 5656      |
| update_time             | 13856     |
---------------------------------------
---------------------------------------
| act_time                | 202       |
| current_lr              | 0.0003    |
| discount_q              | 0.226     |
| env_time                | 409       |
| ep_rewmean              | 994       |
| episodes                | 2200      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 994       |
| n_updates               | 508600    |
| q_grad_norm             | 4545.04   |
| qfs_loss                | 82.94337  |
| qs_abs_difference       | 24.6      |
| qs_difference           | 24.1      |
| qs_mean                 | 319.30466 |
| time_elapsed            | 20476     |
| total timesteps         | 279275    |
| train_time              | 5676      |
| update_time             | 13895     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.43e+03  |
| eval_abs_qs_difference  | 34.470455 |
| eval_discount_q         | 282       |
| eval_ep_rewmean         | 947       |
| eval_eplenmean          | 230       |
| eval_qs                 | 315.77142 |
| eval_qs_difference      | 28.9      |
| eval_time_elapsed       | 6         |
| total timesteps         | 280001    |
---------------------------------------
---------------------------------------
| act_time                | 202       |
| current_lr              | 0.0003    |
| discount_q              | 0.089     |
| env_time                | 410       |
| ep_rewmean              | 995       |
| episodes                | 2204      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 995       |
| n_updates               | 510600    |
| q_grad_norm             | 3037.7732 |
| qfs_loss                | 54.959904 |
| qs_abs_difference       | 38        |
| qs_difference           | 37.5      |
| qs_mean                 | 303.98218 |
| time_elapsed            | 20552     |
| total timesteps         | 280283    |
| train_time              | 5699      |
| update_time             | 13940     |
---------------------------------------
---------------------------------------
| act_time                | 203       |
| current_lr              | 0.0003    |
| discount_q              | 0.16      |
| env_time                | 412       |
| ep_rewmean              | 993       |
| episodes                | 2208      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 993       |
| n_updates               | 512600    |
| q_grad_norm             | 2736.1016 |
| qfs_loss                | 47.687695 |
| qs_abs_difference       | 164       |
| qs_difference           | 164       |
| qs_mean                 | 400.65952 |
| time_elapsed            | 20622     |
| total timesteps         | 281234    |
| train_time              | 5721      |
| update_time             | 13985     |
---------------------------------------
---------------------------------------
| act_time                | 204       |
| current_lr              | 0.0003    |
| discount_q              | 0.0684    |
| env_time                | 413       |
| ep_rewmean              | 987       |
| episodes                | 2212      |
| eplenmean               | 248       |
| fps                     | 13        |
| mean 100 episode reward | 987       |
| n_updates               | 514800    |
| q_grad_norm             | 3676.4148 |
| qfs_loss                | 59.748886 |
| qs_abs_difference       | 27.8      |
| qs_difference           | 27.4      |
| qs_mean                 | 321.87906 |
| time_elapsed            | 20698     |
| total timesteps         | 282317    |
| train_time              | 5746      |
| update_time             | 14034     |
---------------------------------------
---------------------------------------
| act_time                | 205       |
| current_lr              | 0.0003    |
| discount_q              | 0.182     |
| env_time                | 415       |
| ep_rewmean              | 971       |
| episodes                | 2216      |
| eplenmean               | 244       |
| fps                     | 13        |
| mean 100 episode reward | 971       |
| n_updates               | 516600    |
| q_grad_norm             | 3229.225  |
| qfs_loss                | 61.496685 |
| qs_abs_difference       | 24.6      |
| qs_difference           | 22.5      |
| qs_mean                 | 302.92575 |
| time_elapsed            | 20761     |
| total timesteps         | 283273    |
| train_time              | 5766      |
| update_time             | 14074     |
---------------------------------------
---------------------------------------
| act_time                | 205       |
| current_lr              | 0.0003    |
| discount_q              | 0.0272    |
| env_time                | 416       |
| ep_rewmean              | 959       |
| episodes                | 2220      |
| eplenmean               | 241       |
| fps                     | 13        |
| mean 100 episode reward | 959       |
| n_updates               | 518000    |
| q_grad_norm             | 2530.684  |
| qfs_loss                | 39.925404 |
| qs_abs_difference       | 309       |
| qs_difference           | 309       |
| qs_mean                 | 322.22064 |
| time_elapsed            | 20810     |
| total timesteps         | 283952    |
| train_time              | 5782      |
| update_time             | 14106     |
---------------------------------------
--------------------------------------
| act_time                | 206      |
| current_lr              | 0.0003   |
| discount_q              | 0.0403   |
| env_time                | 417      |
| ep_rewmean              | 977      |
| episodes                | 2224     |
| eplenmean               | 245      |
| fps                     | 13       |
| mean 100 episode reward | 977      |
| n_updates               | 520400   |
| q_grad_norm             | 3347.952 |
| qfs_loss                | 67.42268 |
| qs_abs_difference       | 8.7      |
| qs_difference           | -2.42    |
| qs_mean                 | 330.7105 |
| time_elapsed            | 20894    |
| total timesteps         | 285137   |
| train_time              | 5808     |
| update_time             | 14159    |
--------------------------------------
---------------------------------------
| act_time                | 206       |
| current_lr              | 0.0003    |
| discount_q              | 6.46      |
| env_time                | 418       |
| ep_rewmean              | 930       |
| episodes                | 2228      |
| eplenmean               | 234       |
| fps                     | 13        |
| mean 100 episode reward | 930       |
| n_updates               | 520400    |
| qs_abs_difference       | 305       |
| qs_difference           | 305       |
| qs_mean                 | 311.22443 |
| time_elapsed            | 20894     |
| total timesteps         | 285189    |
| train_time              | 5808      |
| update_time             | 14159     |
---------------------------------------
---------------------------------------
| act_time                | 207       |
| current_lr              | 0.0003    |
| discount_q              | 0.0186    |
| env_time                | 419       |
| ep_rewmean              | 939       |
| episodes                | 2232      |
| eplenmean               | 236       |
| fps                     | 13        |
| mean 100 episode reward | 939       |
| n_updates               | 523000    |
| q_grad_norm             | 3040.4194 |
| qfs_loss                | 64.30083  |
| qs_abs_difference       | 28.2      |
| qs_difference           | 28.2      |
| qs_mean                 | 344.3616  |
| time_elapsed            | 20984     |
| total timesteps         | 286452    |
| train_time              | 5837      |
| update_time             | 14218     |
---------------------------------------
---------------------------------------
| act_time                | 208       |
| current_lr              | 0.0003    |
| discount_q              | 0.178     |
| env_time                | 420       |
| ep_rewmean              | 923       |
| episodes                | 2236      |
| eplenmean               | 232       |
| fps                     | 13        |
| mean 100 episode reward | 923       |
| n_updates               | 524000    |
| q_grad_norm             | 3768.108  |
| qfs_loss                | 58.21168  |
| qs_abs_difference       | 297       |
| qs_difference           | 297       |
| qs_mean                 | 309.85822 |
| time_elapsed            | 21019     |
| total timesteps         | 286942    |
| train_time              | 5849      |
| update_time             | 14240     |
---------------------------------------
--------------------------------------
| act_time                | 208      |
| current_lr              | 0.0003   |
| discount_q              | 12.8     |
| env_time                | 420      |
| ep_rewmean              | 878      |
| episodes                | 2240     |
| eplenmean               | 222      |
| fps                     | 13       |
| mean 100 episode reward | 878      |
| n_updates               | 524200   |
| q_grad_norm             | 3463.785 |
| qfs_loss                | 72.49764 |
| qs_abs_difference       | 299      |
| qs_difference           | 299      |
| qs_mean                 | 312.5968 |
| time_elapsed            | 21026    |
| total timesteps         | 287022   |
| train_time              | 5851     |
| update_time             | 14245    |
--------------------------------------
---------------------------------------
| act_time                | 208       |
| current_lr              | 0.0003    |
| discount_q              | 10.9      |
| env_time                | 420       |
| ep_rewmean              | 842       |
| episodes                | 2244      |
| eplenmean               | 213       |
| fps                     | 13        |
| mean 100 episode reward | 842       |
| n_updates               | 524400    |
| q_grad_norm             | 3487.232  |
| qfs_loss                | 70.87373  |
| qs_abs_difference       | 301       |
| qs_difference           | 301       |
| qs_mean                 | 313.53638 |
| time_elapsed            | 21033     |
| total timesteps         | 287105    |
| train_time              | 5853      |
| update_time             | 14249     |
---------------------------------------
---------------------------------------
| act_time                | 208       |
| current_lr              | 0.0003    |
| discount_q              | 11.5      |
| env_time                | 421       |
| ep_rewmean              | 798       |
| episodes                | 2248      |
| eplenmean               | 203       |
| fps                     | 13        |
| mean 100 episode reward | 798       |
| n_updates               | 524400    |
| qs_abs_difference       | 301       |
| qs_difference           | 301       |
| qs_mean                 | 313.32837 |
| time_elapsed            | 21033     |
| total timesteps         | 287182    |
| train_time              | 5853      |
| update_time             | 14249     |
---------------------------------------
---------------------------------------
| act_time                | 209       |
| current_lr              | 0.0003    |
| discount_q              | 0.136     |
| env_time                | 422       |
| ep_rewmean              | 801       |
| episodes                | 2252      |
| eplenmean               | 204       |
| fps                     | 13        |
| mean 100 episode reward | 801       |
| n_updates               | 526400    |
| q_grad_norm             | 3477.4373 |
| qfs_loss                | 60.366943 |
| qs_abs_difference       | 13.4      |
| qs_difference           | 8.36      |
| qs_mean                 | 310.85477 |
| time_elapsed            | 21103     |
| total timesteps         | 288198    |
| train_time              | 5875      |
| update_time             | 14294     |
---------------------------------------
---------------------------------------
| act_time                | 209       |
| current_lr              | 0.0003    |
| discount_q              | 0.0902    |
| env_time                | 423       |
| ep_rewmean              | 800       |
| episodes                | 2256      |
| eplenmean               | 204       |
| fps                     | 13        |
| mean 100 episode reward | 800       |
| n_updates               | 528600    |
| q_grad_norm             | 3259.9446 |
| qfs_loss                | 59.501377 |
| qs_abs_difference       | 38.6      |
| qs_difference           | 38.1      |
| qs_mean                 | 301.3232  |
| time_elapsed            | 21181     |
| total timesteps         | 289214    |
| train_time              | 5900      |
| update_time             | 14345     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.32e+03  |
| eval_abs_qs_difference  | 9.657411  |
| eval_discount_q         | 298       |
| eval_ep_rewmean         | 1.17e+03  |
| eval_eplenmean          | 276       |
| eval_qs                 | 319.70154 |
| eval_qs_difference      | 1.84      |
| eval_time_elapsed       | 6         |
| total timesteps         | 290001    |
---------------------------------------
---------------------------------------
| act_time                | 210       |
| current_lr              | 0.0003    |
| discount_q              | 0.141     |
| env_time                | 425       |
| ep_rewmean              | 801       |
| episodes                | 2260      |
| eplenmean               | 204       |
| fps                     | 13        |
| mean 100 episode reward | 801       |
| n_updates               | 530600    |
| q_grad_norm             | 3431.4048 |
| qfs_loss                | 72.75559  |
| qs_abs_difference       | 12.9      |
| qs_difference           | 11.8      |
| qs_mean                 | 333.62708 |
| time_elapsed            | 21258     |
| total timesteps         | 290267    |
| train_time              | 5922      |
| update_time             | 14390     |
---------------------------------------
---------------------------------------
| act_time                | 211       |
| current_lr              | 0.0003    |
| discount_q              | 0.0919    |
| env_time                | 427       |
| ep_rewmean              | 802       |
| episodes                | 2264      |
| eplenmean               | 204       |
| fps                     | 13        |
| mean 100 episode reward | 802       |
| n_updates               | 532800    |
| q_grad_norm             | 4294.374  |
| qfs_loss                | 71.345116 |
| qs_abs_difference       | 18.8      |
| qs_difference           | 17.7      |
| qs_mean                 | 334.93256 |
| time_elapsed            | 21335     |
| total timesteps         | 291353    |
| train_time              | 5947      |
| update_time             | 14440     |
---------------------------------------
---------------------------------------
| act_time                | 212       |
| current_lr              | 0.0003    |
| discount_q              | 0.0379    |
| env_time                | 428       |
| ep_rewmean              | 807       |
| episodes                | 2268      |
| eplenmean               | 205       |
| fps                     | 13        |
| mean 100 episode reward | 807       |
| n_updates               | 535000    |
| q_grad_norm             | 2256.498  |
| qfs_loss                | 43.87918  |
| qs_abs_difference       | 29.5      |
| qs_difference           | 28        |
| qs_mean                 | 299.29175 |
| time_elapsed            | 21413     |
| total timesteps         | 292461    |
| train_time              | 5972      |
| update_time             | 14490     |
---------------------------------------
---------------------------------------
| act_time                | 213       |
| current_lr              | 0.0003    |
| discount_q              | 0.108     |
| env_time                | 430       |
| ep_rewmean              | 808       |
| episodes                | 2272      |
| eplenmean               | 205       |
| fps                     | 13        |
| mean 100 episode reward | 808       |
| n_updates               | 537000    |
| q_grad_norm             | 2784.7646 |
| qfs_loss                | 46.080074 |
| qs_abs_difference       | 24.7      |
| qs_difference           | 24        |
| qs_mean                 | 315.91824 |
| time_elapsed            | 21483     |
| total timesteps         | 293485    |
| train_time              | 5994      |
| update_time             | 14536     |
---------------------------------------
---------------------------------------
| act_time                | 213       |
| current_lr              | 0.0003    |
| discount_q              | 0.152     |
| env_time                | 431       |
| ep_rewmean              | 821       |
| episodes                | 2276      |
| eplenmean               | 208       |
| fps                     | 13        |
| mean 100 episode reward | 821       |
| n_updates               | 539200    |
| q_grad_norm             | 3154.5596 |
| qfs_loss                | 56.03876  |
| qs_abs_difference       | 21.1      |
| qs_difference           | 19.6      |
| qs_mean                 | 341.193   |
| time_elapsed            | 21561     |
| total timesteps         | 294536    |
| train_time              | 6019      |
| update_time             | 14586     |
---------------------------------------
---------------------------------------
| act_time                | 214       |
| current_lr              | 0.0003    |
| discount_q              | 0.222     |
| env_time                | 433       |
| ep_rewmean              | 817       |
| episodes                | 2280      |
| eplenmean               | 207       |
| fps                     | 13        |
| mean 100 episode reward | 817       |
| n_updates               | 541000    |
| q_grad_norm             | 2751.295  |
| qfs_loss                | 50.223637 |
| qs_abs_difference       | 29.2      |
| qs_difference           | 27.8      |
| qs_mean                 | 311.3444  |
| time_elapsed            | 21625     |
| total timesteps         | 295486    |
| train_time              | 6039      |
| update_time             | 14627     |
---------------------------------------
---------------------------------------
| act_time                | 215       |
| current_lr              | 0.0003    |
| discount_q              | 0.232     |
| env_time                | 434       |
| ep_rewmean              | 844       |
| episodes                | 2284      |
| eplenmean               | 213       |
| fps                     | 13        |
| mean 100 episode reward | 844       |
| n_updates               | 543000    |
| q_grad_norm             | 2939.4438 |
| qfs_loss                | 59.056133 |
| qs_abs_difference       | 14.3      |
| qs_difference           | 11.5      |
| qs_mean                 | 308.57135 |
| time_elapsed            | 21695     |
| total timesteps         | 296426    |
| train_time              | 6061      |
| update_time             | 14673     |
---------------------------------------
---------------------------------------
| act_time                | 215       |
| current_lr              | 0.0003    |
| discount_q              | 0.0101    |
| env_time                | 435       |
| ep_rewmean              | 833       |
| episodes                | 2288      |
| eplenmean               | 210       |
| fps                     | 13        |
| mean 100 episode reward | 832       |
| n_updates               | 544400    |
| q_grad_norm             | 4579.763  |
| qfs_loss                | 75.92773  |
| qs_abs_difference       | 309       |
| qs_difference           | 309       |
| qs_mean                 | 315.97388 |
| time_elapsed            | 21745     |
| total timesteps         | 297144    |
| train_time              | 6077      |
| update_time             | 14705     |
---------------------------------------
---------------------------------------
| act_time                | 216       |
| current_lr              | 0.0003    |
| discount_q              | 0.0977    |
| env_time                | 436       |
| ep_rewmean              | 828       |
| episodes                | 2292      |
| eplenmean               | 209       |
| fps                     | 13        |
| mean 100 episode reward | 828       |
| n_updates               | 546400    |
| q_grad_norm             | 3637.885  |
| qfs_loss                | 61.68842  |
| qs_abs_difference       | 12.4      |
| qs_difference           | 5.62      |
| qs_mean                 | 308.17905 |
| time_elapsed            | 21816     |
| total timesteps         | 298175    |
| train_time              | 6099      |
| update_time             | 14751     |
---------------------------------------
---------------------------------------
| act_time                | 217       |
| current_lr              | 0.0003    |
| discount_q              | 0.232     |
| env_time                | 438       |
| ep_rewmean              | 827       |
| episodes                | 2296      |
| eplenmean               | 208       |
| fps                     | 13        |
| mean 100 episode reward | 827       |
| n_updates               | 548400    |
| q_grad_norm             | 3051.1582 |
| qfs_loss                | 47.262974 |
| qs_abs_difference       | 15.9      |
| qs_difference           | -2.19     |
| qs_mean                 | 318.6034  |
| time_elapsed            | 21887     |
| total timesteps         | 299144    |
| train_time              | 6122      |
| update_time             | 14797     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.14e+03  |
| eval_abs_qs_difference  | 17.036053 |
| eval_discount_q         | 289       |
| eval_ep_rewmean         | 950       |
| eval_eplenmean          | 225       |
| eval_qs                 | 289.9702  |
| eval_qs_difference      | -5.15     |
| eval_time_elapsed       | 5         |
| total timesteps         | 300001    |
---------------------------------------
---------------------------------------
| act_time                | 218       |
| current_lr              | 0.0003    |
| discount_q              | 0.156     |
| env_time                | 439       |
| ep_rewmean              | 832       |
| episodes                | 2300      |
| eplenmean               | 209       |
| fps                     | 13        |
| mean 100 episode reward | 832       |
| n_updates               | 550400    |
| q_grad_norm             | 3150.6592 |
| qfs_loss                | 51.172867 |
| qs_abs_difference       | 18        |
| qs_difference           | 18        |
| qs_mean                 | 322.98584 |
| time_elapsed            | 21964     |
| total timesteps         | 300149    |
| train_time              | 6145      |
| update_time             | 14843     |
---------------------------------------
---------------------------------------
| act_time                | 218       |
| current_lr              | 0.0003    |
| discount_q              | 0.555     |
| env_time                | 441       |
| ep_rewmean              | 825       |
| episodes                | 2304      |
| eplenmean               | 207       |
| fps                     | 13        |
| mean 100 episode reward | 825       |
| n_updates               | 552000    |
| q_grad_norm             | 2996.305  |
| qfs_loss                | 50.96287  |
| qs_abs_difference       | 43.8      |
| qs_difference           | 43.1      |
| qs_mean                 | 302.43103 |
| time_elapsed            | 22022     |
| total timesteps         | 300964    |
| train_time              | 6164      |
| update_time             | 14880     |
---------------------------------------
---------------------------------------
| act_time                | 219       |
| current_lr              | 0.0003    |
| discount_q              | 0.099     |
| env_time                | 442       |
| ep_rewmean              | 830       |
| episodes                | 2308      |
| eplenmean               | 207       |
| fps                     | 13        |
| mean 100 episode reward | 830       |
| n_updates               | 554000    |
| q_grad_norm             | 4634.9033 |
| qfs_loss                | 83.04482  |
| qs_abs_difference       | 38.4      |
| qs_difference           | 38.4      |
| qs_mean                 | 320.00317 |
| time_elapsed            | 22094     |
| total timesteps         | 301976    |
| train_time              | 6187      |
| update_time             | 14926     |
---------------------------------------
--------------------------------------
| act_time                | 220      |
| current_lr              | 0.0003   |
| discount_q              | 0.208    |
| env_time                | 443      |
| ep_rewmean              | 826      |
| episodes                | 2312     |
| eplenmean               | 206      |
| fps                     | 13       |
| mean 100 episode reward | 826      |
| n_updates               | 556000   |
| q_grad_norm             | 2948.7   |
| qfs_loss                | 48.04932 |
| qs_abs_difference       | 14.6     |
| qs_difference           | 10       |
| qs_mean                 | 302.4477 |
| time_elapsed            | 22165    |
| total timesteps         | 302913   |
| train_time              | 6210     |
| update_time             | 14972    |
--------------------------------------
---------------------------------------
| act_time                | 221       |
| current_lr              | 0.0003    |
| discount_q              | 0.135     |
| env_time                | 445       |
| ep_rewmean              | 832       |
| episodes                | 2316      |
| eplenmean               | 206       |
| fps                     | 13        |
| mean 100 episode reward | 832       |
| n_updates               | 558000    |
| q_grad_norm             | 3902.5466 |
| qfs_loss                | 65.67868  |
| qs_abs_difference       | 13.1      |
| qs_difference           | 8.28      |
| qs_mean                 | 309.72192 |
| time_elapsed            | 22237     |
| total timesteps         | 303920    |
| train_time              | 6233      |
| update_time             | 15018     |
---------------------------------------
---------------------------------------
| act_time                | 221       |
| current_lr              | 0.0003    |
| discount_q              | 0.229     |
| env_time                | 446       |
| ep_rewmean              | 846       |
| episodes                | 2320      |
| eplenmean               | 209       |
| fps                     | 13        |
| mean 100 episode reward | 846       |
| n_updates               | 559800    |
| q_grad_norm             | 3196.539  |
| qfs_loss                | 61.339127 |
| qs_abs_difference       | 29.8      |
| qs_difference           | 28.7      |
| qs_mean                 | 325.48224 |
| time_elapsed            | 22302     |
| total timesteps         | 304870    |
| train_time              | 6254      |
| update_time             | 15060     |
---------------------------------------
---------------------------------------
| act_time                | 222       |
| current_lr              | 0.0003    |
| discount_q              | 0.731     |
| env_time                | 447       |
| ep_rewmean              | 834       |
| episodes                | 2324      |
| eplenmean               | 206       |
| fps                     | 13        |
| mean 100 episode reward | 834       |
| n_updates               | 561600    |
| q_grad_norm             | 4048.9968 |
| qfs_loss                | 70.78437  |
| qs_abs_difference       | 21.4      |
| qs_difference           | 21.1      |
| qs_mean                 | 335.9742  |
| time_elapsed            | 22367     |
| total timesteps         | 305742    |
| train_time              | 6275      |
| update_time             | 15102     |
---------------------------------------
---------------------------------------
| act_time                | 223       |
| current_lr              | 0.0003    |
| discount_q              | 0.132     |
| env_time                | 449       |
| ep_rewmean              | 878       |
| episodes                | 2328      |
| eplenmean               | 216       |
| fps                     | 13        |
| mean 100 episode reward | 878       |
| n_updates               | 563800    |
| q_grad_norm             | 2913.0544 |
| qfs_loss                | 45.387806 |
| qs_abs_difference       | 19.1      |
| qs_difference           | 18.9      |
| qs_mean                 | 348.98654 |
| time_elapsed            | 22446     |
| total timesteps         | 306806    |
| train_time              | 6300      |
| update_time             | 15153     |
---------------------------------------
---------------------------------------
| act_time                | 224       |
| current_lr              | 0.0003    |
| discount_q              | 0.17      |
| env_time                | 451       |
| ep_rewmean              | 873       |
| episodes                | 2332      |
| eplenmean               | 215       |
| fps                     | 13        |
| mean 100 episode reward | 873       |
| n_updates               | 566000    |
| q_grad_norm             | 3358.1677 |
| qfs_loss                | 57.219147 |
| qs_abs_difference       | 10.7      |
| qs_difference           | 6.86      |
| qs_mean                 | 353.4783  |
| time_elapsed            | 22526     |
| total timesteps         | 307904    |
| train_time              | 6326      |
| update_time             | 15204     |
---------------------------------------
--------------------------------------
| act_time                | 224      |
| current_lr              | 0.0003   |
| discount_q              | 1.21     |
| env_time                | 452      |
| ep_rewmean              | 884      |
| episodes                | 2336     |
| eplenmean               | 217      |
| fps                     | 13       |
| mean 100 episode reward | 884      |
| n_updates               | 567400   |
| q_grad_norm             | 3392.508 |
| qfs_loss                | 70.1568  |
| qs_abs_difference       | 45.2     |
| qs_difference           | 37.5     |
| qs_mean                 | 300.9245 |
| time_elapsed            | 22576    |
| total timesteps         | 308663   |
| train_time              | 6342     |
| update_time             | 15237    |
--------------------------------------
---------------------------------------
| act_time                | 225       |
| current_lr              | 0.0003    |
| discount_q              | 0.0904    |
| env_time                | 453       |
| ep_rewmean              | 928       |
| episodes                | 2340      |
| eplenmean               | 227       |
| fps                     | 13        |
| mean 100 episode reward | 928       |
| n_updates               | 569600    |
| q_grad_norm             | 3670.8735 |
| qfs_loss                | 57.66958  |
| qs_abs_difference       | 17.9      |
| qs_difference           | 14.7      |
| qs_mean                 | 330.88925 |
| time_elapsed            | 22655     |
| total timesteps         | 309742    |
| train_time              | 6367      |
| update_time             | 15288     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.04e+03  |
| eval_abs_qs_difference  | 70.502686 |
| eval_discount_q         | 237       |
| eval_ep_rewmean         | 649       |
| eval_eplenmean          | 185       |
| eval_qs                 | 285.91418 |
| eval_qs_difference      | 66        |
| eval_time_elapsed       | 4         |
| total timesteps         | 310001    |
---------------------------------------
---------------------------------------
| act_time                | 226       |
| current_lr              | 0.0003    |
| discount_q              | 0.615     |
| env_time                | 455       |
| ep_rewmean              | 962       |
| episodes                | 2344      |
| eplenmean               | 235       |
| fps                     | 13        |
| mean 100 episode reward | 962       |
| n_updates               | 571400    |
| q_grad_norm             | 3066.5745 |
| qfs_loss                | 59.99984  |
| qs_abs_difference       | 19.8      |
| qs_difference           | 17.1      |
| qs_mean                 | 321.49982 |
| time_elapsed            | 22724     |
| total timesteps         | 310608    |
| train_time              | 6388      |
| update_time             | 15329     |
---------------------------------------
---------------------------------------
| act_time                | 226       |
| current_lr              | 0.0003    |
| discount_q              | 51        |
| env_time                | 455       |
| ep_rewmean              | 978       |
| episodes                | 2348      |
| eplenmean               | 239       |
| fps                     | 13        |
| mean 100 episode reward | 978       |
| n_updates               | 572200    |
| q_grad_norm             | 3280.0476 |
| qfs_loss                | 66.122185 |
| qs_abs_difference       | 6.35      |
| qs_difference           | 0.919     |
| qs_mean                 | 330.17773 |
| time_elapsed            | 22754     |
| total timesteps         | 311055    |
| train_time              | 6397      |
| update_time             | 15348     |
---------------------------------------
---------------------------------------
| act_time                | 227       |
| current_lr              | 0.0003    |
| discount_q              | 0.138     |
| env_time                | 457       |
| ep_rewmean              | 981       |
| episodes                | 2352      |
| eplenmean               | 239       |
| fps                     | 13        |
| mean 100 episode reward | 981       |
| n_updates               | 574400    |
| q_grad_norm             | 2844.71   |
| qfs_loss                | 48.15681  |
| qs_abs_difference       | 10.9      |
| qs_difference           | 7.27      |
| qs_mean                 | 334.21906 |
| time_elapsed            | 22834     |
| total timesteps         | 312114    |
| train_time              | 6423      |
| update_time             | 15400     |
---------------------------------------
---------------------------------------
| act_time                | 228       |
| current_lr              | 0.0003    |
| discount_q              | 0.0434    |
| env_time                | 459       |
| ep_rewmean              | 993       |
| episodes                | 2356      |
| eplenmean               | 242       |
| fps                     | 13        |
| mean 100 episode reward | 993       |
| n_updates               | 576800    |
| q_grad_norm             | 3011.9177 |
| qfs_loss                | 53.86204  |
| qs_abs_difference       | 17.9      |
| qs_difference           | 17.8      |
| qs_mean                 | 354.13892 |
| time_elapsed            | 22920     |
| total timesteps         | 313370    |
| train_time              | 6450      |
| update_time             | 15456     |
---------------------------------------
---------------------------------------
| act_time                | 229       |
| current_lr              | 0.0003    |
| discount_q              | 0.045     |
| env_time                | 461       |
| ep_rewmean              | 998       |
| episodes                | 2360      |
| eplenmean               | 243       |
| fps                     | 13        |
| mean 100 episode reward | 998       |
| n_updates               | 579200    |
| q_grad_norm             | 2940.6694 |
| qfs_loss                | 56.152843 |
| qs_abs_difference       | 6.41      |
| qs_difference           | 4.27      |
| qs_mean                 | 333.87973 |
| time_elapsed            | 23005     |
| total timesteps         | 314535    |
| train_time              | 6476      |
| update_time             | 15512     |
---------------------------------------
---------------------------------------
| act_time                | 230       |
| current_lr              | 0.0003    |
| discount_q              | 0.148     |
| env_time                | 462       |
| ep_rewmean              | 998       |
| episodes                | 2364      |
| eplenmean               | 243       |
| fps                     | 13        |
| mean 100 episode reward | 998       |
| n_updates               | 581400    |
| q_grad_norm             | 3140.3408 |
| qfs_loss                | 56.86239  |
| qs_abs_difference       | 5.86      |
| qs_difference           | 1.94      |
| qs_mean                 | 347.32605 |
| time_elapsed            | 23085     |
| total timesteps         | 315645    |
| train_time              | 6502      |
| update_time             | 15564     |
---------------------------------------
---------------------------------------
| act_time                | 231       |
| current_lr              | 0.0003    |
| discount_q              | 0.0713    |
| env_time                | 464       |
| ep_rewmean              | 996       |
| episodes                | 2368      |
| eplenmean               | 242       |
| fps                     | 13        |
| mean 100 episode reward | 996       |
| n_updates               | 583400    |
| q_grad_norm             | 2746.347  |
| qfs_loss                | 47.201595 |
| qs_abs_difference       | 39.8      |
| qs_difference           | 39.3      |
| qs_mean                 | 306.92493 |
| time_elapsed            | 23157     |
| total timesteps         | 316694    |
| train_time              | 6524      |
| update_time             | 15610     |
---------------------------------------
---------------------------------------
| act_time                | 231       |
| current_lr              | 0.0003    |
| discount_q              | 0.199     |
| env_time                | 465       |
| ep_rewmean              | 992       |
| episodes                | 2372      |
| eplenmean               | 242       |
| fps                     | 13        |
| mean 100 episode reward | 992       |
| n_updates               | 585600    |
| q_grad_norm             | 3216.181  |
| qfs_loss                | 65.072014 |
| qs_abs_difference       | 19.9      |
| qs_difference           | 19.7      |
| qs_mean                 | 333.0615  |
| time_elapsed            | 23236     |
| total timesteps         | 317701    |
| train_time              | 6548      |
| update_time             | 15662     |
---------------------------------------
---------------------------------------
| act_time                | 232       |
| current_lr              | 0.0003    |
| discount_q              | 0.0875    |
| env_time                | 467       |
| ep_rewmean              | 994       |
| episodes                | 2376      |
| eplenmean               | 243       |
| fps                     | 13        |
| mean 100 episode reward | 994       |
| n_updates               | 587800    |
| q_grad_norm             | 4252.9814 |
| qfs_loss                | 72.06455  |
| qs_abs_difference       | 16.7      |
| qs_difference           | 16.3      |
| qs_mean                 | 346.98306 |
| time_elapsed            | 23316     |
| total timesteps         | 318807    |
| train_time              | 6574      |
| update_time             | 15714     |
---------------------------------------
---------------------------------------
| act_time                | 233       |
| current_lr              | 0.0003    |
| discount_q              | 0.192     |
| env_time                | 468       |
| ep_rewmean              | 987       |
| episodes                | 2380      |
| eplenmean               | 241       |
| fps                     | 13        |
| mean 100 episode reward | 987       |
| n_updates               | 589400    |
| q_grad_norm             | 3670.8782 |
| qfs_loss                | 61.933506 |
| qs_abs_difference       | 235       |
| qs_difference           | 235       |
| qs_mean                 | 389.2187  |
| time_elapsed            | 23375     |
| total timesteps         | 319631    |
| train_time              | 6592      |
| update_time             | 15752     |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 993      |
| eval_abs_qs_difference  | 69.44094 |
| eval_discount_q         | 249      |
| eval_ep_rewmean         | 1.18e+03 |
| eval_eplenmean          | 277      |
| eval_qs                 | 336.2668 |
| eval_qs_difference      | 61       |
| eval_time_elapsed       | 7        |
| total timesteps         | 320001   |
--------------------------------------
---------------------------------------
| act_time                | 234       |
| current_lr              | 0.0003    |
| discount_q              | 0.0555    |
| env_time                | 470       |
| ep_rewmean              | 1e+03     |
| episodes                | 2384      |
| eplenmean               | 245       |
| fps                     | 13        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 592000    |
| q_grad_norm             | 3249.5615 |
| qfs_loss                | 59.33501  |
| qs_abs_difference       | 18        |
| qs_difference           | 17.6      |
| qs_mean                 | 357.25504 |
| time_elapsed            | 23477     |
| total timesteps         | 320906    |
| train_time              | 6622      |
| update_time             | 15813     |
---------------------------------------
---------------------------------------
| act_time                | 235       |
| current_lr              | 0.0003    |
| discount_q              | 0.0389    |
| env_time                | 472       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2388      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 594200    |
| q_grad_norm             | 4205.303  |
| qfs_loss                | 77.03579  |
| qs_abs_difference       | 30.2      |
| qs_difference           | 29.3      |
| qs_mean                 | 347.05545 |
| time_elapsed            | 23557     |
| total timesteps         | 322081    |
| train_time              | 6648      |
| update_time             | 15865     |
---------------------------------------
---------------------------------------
| act_time                | 235       |
| current_lr              | 0.0003    |
| discount_q              | 0.245     |
| env_time                | 473       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2392      |
| eplenmean               | 247       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 596000    |
| q_grad_norm             | 4594.5996 |
| qfs_loss                | 80.93527  |
| qs_abs_difference       | 206       |
| qs_difference           | 206       |
| qs_mean                 | 391.16486 |
| time_elapsed            | 23622     |
| total timesteps         | 322921    |
| train_time              | 6669      |
| update_time             | 15908     |
---------------------------------------
---------------------------------------
| act_time                | 236       |
| current_lr              | 0.0003    |
| discount_q              | 0.0388    |
| env_time                | 475       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2396      |
| eplenmean               | 250       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 598400    |
| q_grad_norm             | 3834.5283 |
| qfs_loss                | 62.406403 |
| qs_abs_difference       | 6.86      |
| qs_difference           | -1.92     |
| qs_mean                 | 346.08017 |
| time_elapsed            | 23710     |
| total timesteps         | 324151    |
| train_time              | 6697      |
| update_time             | 15964     |
---------------------------------------
---------------------------------------
| act_time                | 237       |
| current_lr              | 0.0003    |
| discount_q              | 0.146     |
| env_time                | 476       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2400      |
| eplenmean               | 250       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 600400    |
| q_grad_norm             | 3442.08   |
| qfs_loss                | 61.89914  |
| qs_abs_difference       | 37.7      |
| qs_difference           | 37.7      |
| qs_mean                 | 326.57025 |
| time_elapsed            | 23784     |
| total timesteps         | 325145    |
| train_time              | 6720      |
| update_time             | 16012     |
---------------------------------------
---------------------------------------
| act_time                | 238       |
| current_lr              | 0.0003    |
| discount_q              | 0.233     |
| env_time                | 478       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2404      |
| eplenmean               | 252       |
| fps                     | 13        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 602400    |
| q_grad_norm             | 3924.797  |
| qfs_loss                | 66.99952  |
| qs_abs_difference       | 4.26      |
| qs_difference           | -2.98     |
| qs_mean                 | 330.92938 |
| time_elapsed            | 23857     |
| total timesteps         | 326137    |
| train_time              | 6743      |
| update_time             | 16059     |
---------------------------------------
---------------------------------------
| act_time                | 239       |
| current_lr              | 0.0003    |
| discount_q              | 0.0584    |
| env_time                | 480       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2408      |
| eplenmean               | 253       |
| fps                     | 13        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 604600    |
| q_grad_norm             | 3513.819  |
| qfs_loss                | 56.312206 |
| qs_abs_difference       | 17.6      |
| qs_difference           | 16.2      |
| qs_mean                 | 337.10886 |
| time_elapsed            | 23937     |
| total timesteps         | 327261    |
| train_time              | 6768      |
| update_time             | 16112     |
---------------------------------------
---------------------------------------
| act_time                | 240       |
| current_lr              | 0.0003    |
| discount_q              | 0.0419    |
| env_time                | 481       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2412      |
| eplenmean               | 255       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 606800    |
| q_grad_norm             | 2993.757  |
| qfs_loss                | 57.792015 |
| qs_abs_difference       | 29.1      |
| qs_difference           | 28.7      |
| qs_mean                 | 326.77798 |
| time_elapsed            | 24017     |
| total timesteps         | 328370    |
| train_time              | 6794      |
| update_time             | 16164     |
---------------------------------------
---------------------------------------
| act_time                | 241       |
| current_lr              | 0.0003    |
| discount_q              | 0.0677    |
| env_time                | 483       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2416      |
| eplenmean               | 256       |
| fps                     | 13        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 609200    |
| q_grad_norm             | 4274.271  |
| qfs_loss                | 74.615105 |
| qs_abs_difference       | 17.5      |
| qs_difference           | 16.1      |
| qs_mean                 | 349.44888 |
| time_elapsed            | 24105     |
| total timesteps         | 329518    |
| train_time              | 6822      |
| update_time             | 16220     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 995       |
| eval_abs_qs_difference  | 25.248676 |
| eval_discount_q         | 299       |
| eval_ep_rewmean         | 1.38e+03  |
| eval_eplenmean          | 317       |
| eval_qs                 | 349.23483 |
| eval_qs_difference      | 13.6      |
| eval_time_elapsed       | 7         |
| total timesteps         | 330001    |
---------------------------------------
---------------------------------------
| act_time                | 242       |
| current_lr              | 0.0003    |
| discount_q              | 0.0109    |
| env_time                | 485       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2420      |
| eplenmean               | 260       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 611800    |
| q_grad_norm             | 4416.7046 |
| qfs_loss                | 76.95405  |
| qs_abs_difference       | 35.7      |
| qs_difference           | 35.7      |
| qs_mean                 | 355.54227 |
| time_elapsed            | 24206     |
| total timesteps         | 330822    |
| train_time              | 6851      |
| update_time             | 16282     |
---------------------------------------
--------------------------------------
| act_time                | 242      |
| current_lr              | 0.0003   |
| discount_q              | 0.082    |
| env_time                | 486      |
| ep_rewmean              | 1.08e+03 |
| episodes                | 2424     |
| eplenmean               | 262      |
| fps                     | 13       |
| mean 100 episode reward | 1.08e+03 |
| n_updates               | 614000   |
| q_grad_norm             | 4510.324 |
| qfs_loss                | 71.4941  |
| qs_abs_difference       | 7.98     |
| qs_difference           | -7.94    |
| qs_mean                 | 343.0765 |
| time_elapsed            | 24283    |
| total timesteps         | 331953   |
| train_time              | 6874     |
| update_time             | 16333    |
--------------------------------------
---------------------------------------
| act_time                | 243       |
| current_lr              | 0.0003    |
| discount_q              | 0.0284    |
| env_time                | 488       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2428      |
| eplenmean               | 263       |
| fps                     | 13        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 616400    |
| q_grad_norm             | 4634.8267 |
| qfs_loss                | 88.837845 |
| qs_abs_difference       | 31.1      |
| qs_difference           | 30.2      |
| qs_mean                 | 339.8214  |
| time_elapsed            | 24370     |
| total timesteps         | 333130    |
| train_time              | 6900      |
| update_time             | 16390     |
---------------------------------------
---------------------------------------
| act_time                | 244       |
| current_lr              | 0.0003    |
| discount_q              | 0.0825    |
| env_time                | 490       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2432      |
| eplenmean               | 263       |
| fps                     | 13        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 618600    |
| q_grad_norm             | 3761.943  |
| qfs_loss                | 72.035446 |
| qs_abs_difference       | 10.5      |
| qs_difference           | 1.58      |
| qs_mean                 | 329.81537 |
| time_elapsed            | 24446     |
| total timesteps         | 334216    |
| train_time              | 6923      |
| update_time             | 16440     |
---------------------------------------
---------------------------------------
| act_time                | 245       |
| current_lr              | 0.0003    |
| discount_q              | 0.0952    |
| env_time                | 491       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2436      |
| eplenmean               | 266       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 620600    |
| q_grad_norm             | 4522.9116 |
| qfs_loss                | 68.58682  |
| qs_abs_difference       | 11.8      |
| qs_difference           | 3.43      |
| qs_mean                 | 298.12274 |
| time_elapsed            | 24519     |
| total timesteps         | 335248    |
| train_time              | 6946      |
| update_time             | 16488     |
---------------------------------------
---------------------------------------
| act_time                | 246       |
| current_lr              | 0.0003    |
| discount_q              | 0.441     |
| env_time                | 492       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2440      |
| eplenmean               | 264       |
| fps                     | 13        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 622400    |
| q_grad_norm             | 4123.59   |
| qfs_loss                | 63.158844 |
| qs_abs_difference       | 14.6      |
| qs_difference           | 12.8      |
| qs_mean                 | 333.8319  |
| time_elapsed            | 24585     |
| total timesteps         | 336162    |
| train_time              | 6967      |
| update_time             | 16531     |
---------------------------------------
---------------------------------------
| act_time                | 247       |
| current_lr              | 0.0003    |
| discount_q              | 0.11      |
| env_time                | 494       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2444      |
| eplenmean               | 267       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 624800    |
| q_grad_norm             | 4573.489  |
| qfs_loss                | 81.093376 |
| qs_abs_difference       | 4.8       |
| qs_difference           | -1.54     |
| qs_mean                 | 357.55197 |
| time_elapsed            | 24672     |
| total timesteps         | 337336    |
| train_time              | 6994      |
| update_time             | 16587     |
---------------------------------------
---------------------------------------
| act_time                | 247       |
| current_lr              | 0.0003    |
| discount_q              | 1.38      |
| env_time                | 495       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2448      |
| eplenmean               | 270       |
| fps                     | 13        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 626200    |
| q_grad_norm             | 4123.3164 |
| qfs_loss                | 74.864426 |
| qs_abs_difference       | 54.3      |
| qs_difference           | 52        |
| qs_mean                 | 299.4417  |
| time_elapsed            | 24723     |
| total timesteps         | 338079    |
| train_time              | 7011      |
| update_time             | 16621     |
---------------------------------------
---------------------------------------
| act_time                | 247       |
| current_lr              | 0.0003    |
| discount_q              | 8.78      |
| env_time                | 496       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2452      |
| eplenmean               | 263       |
| fps                     | 13        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 626800    |
| q_grad_norm             | 3796.4766 |
| qfs_loss                | 63.349056 |
| qs_abs_difference       | 250       |
| qs_difference           | 250       |
| qs_mean                 | 316.38638 |
| time_elapsed            | 24745     |
| total timesteps         | 338394    |
| train_time              | 7018      |
| update_time             | 16635     |
---------------------------------------
---------------------------------------
| act_time                | 248       |
| current_lr              | 0.0003    |
| discount_q              | 13.6      |
| env_time                | 496       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2456      |
| eplenmean               | 253       |
| fps                     | 13        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 627400    |
| q_grad_norm             | 2797.782  |
| qfs_loss                | 51.974632 |
| qs_abs_difference       | 169       |
| qs_difference           | 167       |
| qs_mean                 | 245.13426 |
| time_elapsed            | 24767     |
| total timesteps         | 338685    |
| train_time              | 7024      |
| update_time             | 16649     |
---------------------------------------
---------------------------------------
| act_time                | 248       |
| current_lr              | 0.0003    |
| discount_q              | 1.07      |
| env_time                | 497       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2460      |
| eplenmean               | 251       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 629200    |
| q_grad_norm             | 3859.4958 |
| qfs_loss                | 71.13781  |
| qs_abs_difference       | 20.7      |
| qs_difference           | 20.7      |
| qs_mean                 | 355.0664  |
| time_elapsed            | 24833     |
| total timesteps         | 339589    |
| train_time              | 7045      |
| update_time             | 16692     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.08e+03  |
| eval_abs_qs_difference  | 30.561346 |
| eval_discount_q         | 260       |
| eval_ep_rewmean         | 1.87e+03  |
| eval_eplenmean          | 473       |
| eval_qs                 | 346.0701  |
| eval_qs_difference      | 23.7      |
| eval_time_elapsed       | 11        |
| total timesteps         | 340001    |
---------------------------------------
---------------------------------------
| act_time                | 249       |
| current_lr              | 0.0003    |
| discount_q              | 0.00519   |
| env_time                | 500       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2464      |
| eplenmean               | 254       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 632200    |
| q_grad_norm             | 3342.4941 |
| qfs_loss                | 54.733334 |
| qs_abs_difference       | 64.1      |
| qs_difference           | 64.1      |
| qs_mean                 | 334.49118 |
| time_elapsed            | 24954     |
| total timesteps         | 341015    |
| train_time              | 7080      |
| update_time             | 16763     |
---------------------------------------
---------------------------------------
| act_time                | 250       |
| current_lr              | 0.0003    |
| discount_q              | 3.12      |
| env_time                | 500       |
| ep_rewmean              | 994       |
| episodes                | 2468      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 994       |
| n_updates               | 633400    |
| q_grad_norm             | 3810.1519 |
| qfs_loss                | 70.93267  |
| qs_abs_difference       | 188       |
| qs_difference           | 188       |
| qs_mean                 | 387.96033 |
| time_elapsed            | 24998     |
| total timesteps         | 341633    |
| train_time              | 7094      |
| update_time             | 16792     |
---------------------------------------
---------------------------------------
| act_time                | 251       |
| current_lr              | 0.0003    |
| discount_q              | 0.241     |
| env_time                | 502       |
| ep_rewmean              | 992       |
| episodes                | 2472      |
| eplenmean               | 249       |
| fps                     | 13        |
| mean 100 episode reward | 992       |
| n_updates               | 635400    |
| q_grad_norm             | 3131.104  |
| qfs_loss                | 53.181362 |
| qs_abs_difference       | 37.1      |
| qs_difference           | 36.6      |
| qs_mean                 | 343.50464 |
| time_elapsed            | 25069     |
| total timesteps         | 342631    |
| train_time              | 7115      |
| update_time             | 16839     |
---------------------------------------
---------------------------------------
| act_time                | 252       |
| current_lr              | 0.0003    |
| discount_q              | 0.0052    |
| env_time                | 504       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2476      |
| eplenmean               | 252       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 638200    |
| q_grad_norm             | 3064.1553 |
| qfs_loss                | 50.558136 |
| qs_abs_difference       | 20.5      |
| qs_difference           | 19.4      |
| qs_mean                 | 349.279   |
| time_elapsed            | 25170     |
| total timesteps         | 344051    |
| train_time              | 7146      |
| update_time             | 16904     |
---------------------------------------
---------------------------------------
| act_time                | 253       |
| current_lr              | 0.0003    |
| discount_q              | 0.0443    |
| env_time                | 506       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2480      |
| eplenmean               | 257       |
| fps                     | 13        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 640800    |
| q_grad_norm             | 4340.9375 |
| qfs_loss                | 84.691475 |
| qs_abs_difference       | 28        |
| qs_difference           | 28        |
| qs_mean                 | 367.2662  |
| time_elapsed            | 25265     |
| total timesteps         | 345301    |
| train_time              | 7176      |
| update_time             | 16966     |
---------------------------------------
---------------------------------------
| act_time                | 253       |
| current_lr              | 0.0003    |
| discount_q              | 0.135     |
| env_time                | 507       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 2484      |
| eplenmean               | 255       |
| fps                     | 13        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 642800    |
| q_grad_norm             | 2969.6548 |
| qfs_loss                | 54.029728 |
| qs_abs_difference       | 7.82      |
| qs_difference           | 3.42      |
| qs_mean                 | 346.26138 |
| time_elapsed            | 25338     |
| total timesteps         | 346384    |
| train_time              | 7200      |
| update_time             | 17014     |
---------------------------------------
---------------------------------------
| act_time                | 255       |
| current_lr              | 0.0003    |
| discount_q              | 0.0201    |
| env_time                | 510       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2488      |
| eplenmean               | 257       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 645600    |
| q_grad_norm             | 3764.999  |
| qfs_loss                | 55.072666 |
| qs_abs_difference       | 9.51      |
| qs_difference           | 8.74      |
| qs_mean                 | 368.4046  |
| time_elapsed            | 25440     |
| total timesteps         | 347790    |
| train_time              | 7232      |
| update_time             | 17080     |
---------------------------------------
---------------------------------------
| act_time                | 256       |
| current_lr              | 0.0003    |
| discount_q              | 0.0122    |
| env_time                | 512       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2492      |
| eplenmean               | 262       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 648400    |
| q_grad_norm             | 3348.9016 |
| qfs_loss                | 69.234955 |
| qs_abs_difference       | 29.4      |
| qs_difference           | 29.4      |
| qs_mean                 | 352.32602 |
| time_elapsed            | 25542     |
| total timesteps         | 349115    |
| train_time              | 7264      |
| update_time             | 17146     |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 1.23e+03 |
| eval_abs_qs_difference  | 28.66971 |
| eval_discount_q         | 297      |
| eval_ep_rewmean         | 1.87e+03 |
| eval_eplenmean          | 455      |
| eval_qs                 | 361.3104 |
| eval_qs_difference      | 19.9     |
| eval_time_elapsed       | 10       |
| total timesteps         | 350001   |
--------------------------------------
---------------------------------------
| act_time                | 257       |
| current_lr              | 0.0003    |
| discount_q              | 0.0156    |
| env_time                | 514       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2496      |
| eplenmean               | 263       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 651000    |
| q_grad_norm             | 2981.6035 |
| qfs_loss                | 42.406307 |
| qs_abs_difference       | 32.1      |
| qs_difference           | 32.1      |
| qs_mean                 | 355.12744 |
| time_elapsed            | 25647     |
| total timesteps         | 350436    |
| train_time              | 7295      |
| update_time             | 17207     |
---------------------------------------
---------------------------------------
| act_time                | 258       |
| current_lr              | 0.0003    |
| discount_q              | 0.00779   |
| env_time                | 516       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2500      |
| eplenmean               | 267       |
| fps                     | 13        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 653800    |
| q_grad_norm             | 3542.692  |
| qfs_loss                | 52.78479  |
| qs_abs_difference       | 9.4       |
| qs_difference           | -3.11     |
| qs_mean                 | 359.32053 |
| time_elapsed            | 25749     |
| total timesteps         | 351869    |
| train_time              | 7327      |
| update_time             | 17273     |
---------------------------------------
---------------------------------------
| act_time                | 259       |
| current_lr              | 0.0003    |
| discount_q              | 0.128     |
| env_time                | 517       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2504      |
| eplenmean               | 269       |
| fps                     | 13        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 656200    |
| q_grad_norm             | 3756.5674 |
| qfs_loss                | 65.95113  |
| qs_abs_difference       | 4.98      |
| qs_difference           | 3.95      |
| qs_mean                 | 365.3099  |
| time_elapsed            | 25836     |
| total timesteps         | 353039    |
| train_time              | 7355      |
| update_time             | 17329     |
---------------------------------------
---------------------------------------
| act_time                | 259       |
| current_lr              | 0.0003    |
| discount_q              | 0.237     |
| env_time                | 519       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2508      |
| eplenmean               | 268       |
| fps                     | 13        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 658200    |
| q_grad_norm             | 3564.8894 |
| qfs_loss                | 53.78779  |
| qs_abs_difference       | 17.7      |
| qs_difference           | 17.3      |
| qs_mean                 | 359.27103 |
| time_elapsed            | 25909     |
| total timesteps         | 354085    |
| train_time              | 7378      |
| update_time             | 17376     |
---------------------------------------
---------------------------------------
| act_time                | 261       |
| current_lr              | 0.0003    |
| discount_q              | 0.00362   |
| env_time                | 521       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2512      |
| eplenmean               | 273       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 661400    |
| q_grad_norm             | 3801.2153 |
| qfs_loss                | 74.611244 |
| qs_abs_difference       | 7.34      |
| qs_difference           | 0.156     |
| qs_mean                 | 360.36923 |
| time_elapsed            | 26025     |
| total timesteps         | 355642    |
| train_time              | 7414      |
| update_time             | 17451     |
---------------------------------------
---------------------------------------
| act_time                | 262       |
| current_lr              | 0.0003    |
| discount_q              | 0.0202    |
| env_time                | 523       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2516      |
| eplenmean               | 271       |
| fps                     | 13        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 663400    |
| q_grad_norm             | 2368.4807 |
| qfs_loss                | 39.160484 |
| qs_abs_difference       | 244       |
| qs_difference           | 244       |
| qs_mean                 | 389.86905 |
| time_elapsed            | 26098     |
| total timesteps         | 356665    |
| train_time              | 7437      |
| update_time             | 17499     |
---------------------------------------
--------------------------------------
| act_time                | 262      |
| current_lr              | 0.0003   |
| discount_q              | 0.0265   |
| env_time                | 524      |
| ep_rewmean              | 1.06e+03 |
| episodes                | 2520     |
| eplenmean               | 265      |
| fps                     | 13       |
| mean 100 episode reward | 1.06e+03 |
| n_updates               | 664800   |
| q_grad_norm             | 3804.683 |
| qfs_loss                | 64.8986  |
| qs_abs_difference       | 288      |
| qs_difference           | 288      |
| qs_mean                 | 295.6859 |
| time_elapsed            | 26148    |
| total timesteps         | 357300   |
| train_time              | 7453     |
| update_time             | 17532    |
--------------------------------------
---------------------------------------
| act_time                | 263       |
| current_lr              | 0.0003    |
| discount_q              | 0.156     |
| env_time                | 525       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2524      |
| eplenmean               | 264       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 666800    |
| q_grad_norm             | 3981.6582 |
| qfs_loss                | 58.964634 |
| qs_abs_difference       | 9.35      |
| qs_difference           | -8.09     |
| qs_mean                 | 339.41486 |
| time_elapsed            | 26220     |
| total timesteps         | 358344    |
| train_time              | 7476      |
| update_time             | 17579     |
---------------------------------------
---------------------------------------
| act_time                | 264       |
| current_lr              | 0.0003    |
| discount_q              | 0.0598    |
| env_time                | 527       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2528      |
| eplenmean               | 264       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 669200    |
| q_grad_norm             | 3468.8105 |
| qfs_loss                | 54.03716  |
| qs_abs_difference       | 14        |
| qs_difference           | 12        |
| qs_mean                 | 356.48337 |
| time_elapsed            | 26308     |
| total timesteps         | 359547    |
| train_time              | 7503      |
| update_time             | 17636     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.37e+03  |
| eval_abs_qs_difference  | 19.156406 |
| eval_discount_q         | 299       |
| eval_ep_rewmean         | 2.39e+03  |
| eval_eplenmean          | 584       |
| eval_qs                 | 366.05936 |
| eval_qs_difference      | 9.53      |
| eval_time_elapsed       | 13        |
| total timesteps         | 360001    |
---------------------------------------
---------------------------------------
| act_time                | 265       |
| current_lr              | 0.0003    |
| discount_q              | 0.00604   |
| env_time                | 529       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2532      |
| eplenmean               | 267       |
| fps                     | 13        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 672000    |
| q_grad_norm             | 5091.662  |
| qfs_loss                | 87.7303   |
| qs_abs_difference       | 17.3      |
| qs_difference           | 16.5      |
| qs_mean                 | 353.06622 |
| time_elapsed            | 26422     |
| total timesteps         | 360955    |
| train_time              | 7535      |
| update_time             | 17701     |
---------------------------------------
--------------------------------------
| act_time                | 266      |
| current_lr              | 0.0003   |
| discount_q              | 0.0593   |
| env_time                | 530      |
| ep_rewmean              | 1.07e+03 |
| episodes                | 2536     |
| eplenmean               | 268      |
| fps                     | 13       |
| mean 100 episode reward | 1.07e+03 |
| n_updates               | 674200   |
| q_grad_norm             | 4814.158 |
| qfs_loss                | 78.55734 |
| qs_abs_difference       | 12.7     |
| qs_difference           | 11.7     |
| qs_mean                 | 332.1715 |
| time_elapsed            | 26502    |
| total timesteps         | 362077   |
| train_time              | 7560     |
| update_time             | 17753    |
--------------------------------------
---------------------------------------
| act_time                | 266       |
| current_lr              | 0.0003    |
| discount_q              | 0.0042    |
| env_time                | 532       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2540      |
| eplenmean               | 270       |
| fps                     | 13        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 676400    |
| q_grad_norm             | 3895.403  |
| qfs_loss                | 61.02911  |
| qs_abs_difference       | 276       |
| qs_difference           | 276       |
| qs_mean                 | 350.33533 |
| time_elapsed            | 26582     |
| total timesteps         | 363163    |
| train_time              | 7585      |
| update_time             | 17805     |
---------------------------------------
---------------------------------------
| act_time                | 267       |
| current_lr              | 0.0003    |
| discount_q              | 0.00915   |
| env_time                | 534       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2544      |
| eplenmean               | 272       |
| fps                     | 13        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 679200    |
| q_grad_norm             | 4219.239  |
| qfs_loss                | 62.342285 |
| qs_abs_difference       | 8.42      |
| qs_difference           | -0.94     |
| qs_mean                 | 333.96152 |
| time_elapsed            | 26683     |
| total timesteps         | 364505    |
| train_time              | 7618      |
| update_time             | 17870     |
---------------------------------------
---------------------------------------
| act_time                | 268       |
| current_lr              | 0.0003    |
| discount_q              | 1.14      |
| env_time                | 535       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2548      |
| eplenmean               | 273       |
| fps                     | 13        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 680800    |
| q_grad_norm             | 4775.8545 |
| qfs_loss                | 83.83496  |
| qs_abs_difference       | 8.69      |
| qs_difference           | 7.09      |
| qs_mean                 | 337.30966 |
| time_elapsed            | 26741     |
| total timesteps         | 365358    |
| train_time              | 7636      |
| update_time             | 17908     |
---------------------------------------
---------------------------------------
| act_time                | 269       |
| current_lr              | 0.0003    |
| discount_q              | 0.000452  |
| env_time                | 538       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 2552      |
| eplenmean               | 286       |
| fps                     | 13        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 684200    |
| q_grad_norm             | 3021.5425 |
| qfs_loss                | 57.034714 |
| qs_abs_difference       | 42.2      |
| qs_difference           | 42.1      |
| qs_mean                 | 357.03522 |
| time_elapsed            | 26864     |
| total timesteps         | 367005    |
| train_time              | 7675      |
| update_time             | 17988     |
---------------------------------------
---------------------------------------
| act_time                | 271       |
| current_lr              | 0.0003    |
| discount_q              | 0.000214  |
| env_time                | 541       |
| ep_rewmean              | 1.24e+03  |
| episodes                | 2556      |
| eplenmean               | 304       |
| fps                     | 13        |
| mean 100 episode reward | 1.24e+03  |
| n_updates               | 688200    |
| q_grad_norm             | 3931.3987 |
| qfs_loss                | 58.690445 |
| qs_abs_difference       | 20.9      |
| qs_difference           | 20.7      |
| qs_mean                 | 374.38736 |
| time_elapsed            | 27009     |
| total timesteps         | 369053    |
| train_time              | 7722      |
| update_time             | 18081     |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 1.56e+03 |
| eval_abs_qs_difference  | 34.70029 |
| eval_discount_q         | 304      |
| eval_ep_rewmean         | 2.68e+03 |
| eval_eplenmean          | 670      |
| eval_qs                 | 382.166  |
| eval_qs_difference      | 25.1     |
| eval_time_elapsed       | 17       |
| total timesteps         | 370001   |
--------------------------------------
---------------------------------------
| act_time                | 272       |
| current_lr              | 0.0003    |
| discount_q              | 0.0701    |
| env_time                | 542       |
| ep_rewmean              | 1.25e+03  |
| episodes                | 2560      |
| eplenmean               | 306       |
| fps                     | 13        |
| mean 100 episode reward | 1.25e+03  |
| n_updates               | 690400    |
| q_grad_norm             | 3913.8118 |
| qfs_loss                | 61.00539  |
| qs_abs_difference       | 5.93      |
| qs_difference           | 4.1       |
| qs_mean                 | 348.00702 |
| time_elapsed            | 27106     |
| total timesteps         | 370187    |
| train_time              | 7747      |
| update_time             | 18132     |
---------------------------------------
---------------------------------------
| act_time                | 273       |
| current_lr              | 0.0003    |
| discount_q              | 0.0169    |
| env_time                | 544       |
| ep_rewmean              | 1.26e+03  |
| episodes                | 2564      |
| eplenmean               | 306       |
| fps                     | 13        |
| mean 100 episode reward | 1.26e+03  |
| n_updates               | 693200    |
| q_grad_norm             | 4427.7783 |
| qfs_loss                | 60.81083  |
| qs_abs_difference       | 5.52      |
| qs_difference           | 2.73      |
| qs_mean                 | 364.34885 |
| time_elapsed            | 27206     |
| total timesteps         | 371575    |
| train_time              | 7779      |
| update_time             | 18197     |
---------------------------------------
--------------------------------------
| act_time                | 274      |
| current_lr              | 0.0003   |
| discount_q              | 0.0318   |
| env_time                | 546      |
| ep_rewmean              | 1.3e+03  |
| episodes                | 2568     |
| eplenmean               | 311      |
| fps                     | 13       |
| mean 100 episode reward | 1.3e+03  |
| n_updates               | 695600   |
| q_grad_norm             | 4202.888 |
| qfs_loss                | 67.2139  |
| qs_abs_difference       | 24.1     |
| qs_difference           | 23.4     |
| qs_mean                 | 321.9121 |
| time_elapsed            | 27293    |
| total timesteps         | 372734   |
| train_time              | 7807     |
| update_time             | 18252    |
--------------------------------------
---------------------------------------
| act_time                | 275       |
| current_lr              | 0.0003    |
| discount_q              | 0.0266    |
| env_time                | 548       |
| ep_rewmean              | 1.31e+03  |
| episodes                | 2572      |
| eplenmean               | 313       |
| fps                     | 13        |
| mean 100 episode reward | 1.31e+03  |
| n_updates               | 698000    |
| q_grad_norm             | 4246.7505 |
| qfs_loss                | 63.94781  |
| qs_abs_difference       | 22.4      |
| qs_difference           | 22.1      |
| qs_mean                 | 336.28027 |
| time_elapsed            | 27378     |
| total timesteps         | 373916    |
| train_time              | 7834      |
| update_time             | 18307     |
---------------------------------------
---------------------------------------
| act_time                | 275       |
| current_lr              | 0.0003    |
| discount_q              | 0.834     |
| env_time                | 549       |
| ep_rewmean              | 1.28e+03  |
| episodes                | 2576      |
| eplenmean               | 307       |
| fps                     | 13        |
| mean 100 episode reward | 1.28e+03  |
| n_updates               | 699600    |
| q_grad_norm             | 3702.1816 |
| qfs_loss                | 64.50301  |
| qs_abs_difference       | 9.33      |
| qs_difference           | 4.15      |
| qs_mean                 | 326.53748 |
| time_elapsed            | 27436     |
| total timesteps         | 374758    |
| train_time              | 7852      |
| update_time             | 18344     |
---------------------------------------
---------------------------------------
| act_time                | 276       |
| current_lr              | 0.0003    |
| discount_q              | 0.0221    |
| env_time                | 551       |
| ep_rewmean              | 1.29e+03  |
| episodes                | 2580      |
| eplenmean               | 308       |
| fps                     | 13        |
| mean 100 episode reward | 1.29e+03  |
| n_updates               | 702400    |
| q_grad_norm             | 3752.308  |
| qfs_loss                | 54.30939  |
| qs_abs_difference       | 8.1       |
| qs_difference           | 4.29      |
| qs_mean                 | 362.60883 |
| time_elapsed            | 27536     |
| total timesteps         | 376109    |
| train_time              | 7885      |
| update_time             | 18409     |
---------------------------------------
---------------------------------------
| act_time                | 277       |
| current_lr              | 0.0003    |
| discount_q              | 0.101     |
| env_time                | 553       |
| ep_rewmean              | 1.29e+03  |
| episodes                | 2584      |
| eplenmean               | 307       |
| fps                     | 13        |
| mean 100 episode reward | 1.29e+03  |
| n_updates               | 704400    |
| q_grad_norm             | 3465.9822 |
| qfs_loss                | 59.778065 |
| qs_abs_difference       | 33.1      |
| qs_difference           | 32.4      |
| qs_mean                 | 308.38257 |
| time_elapsed            | 27608     |
| total timesteps         | 377108    |
| train_time              | 7908      |
| update_time             | 18455     |
---------------------------------------
---------------------------------------
| act_time                | 278       |
| current_lr              | 0.0003    |
| discount_q              | 0.13      |
| env_time                | 554       |
| ep_rewmean              | 1.27e+03  |
| episodes                | 2588      |
| eplenmean               | 304       |
| fps                     | 13        |
| mean 100 episode reward | 1.27e+03  |
| n_updates               | 706400    |
| q_grad_norm             | 3458.4094 |
| qfs_loss                | 46.424713 |
| qs_abs_difference       | 17.9      |
| qs_difference           | 17.3      |
| qs_mean                 | 344.80453 |
| time_elapsed            | 27680     |
| total timesteps         | 378161    |
| train_time              | 7931      |
| update_time             | 18501     |
---------------------------------------
--------------------------------------
| act_time                | 279      |
| current_lr              | 0.0003   |
| discount_q              | 0.0383   |
| env_time                | 556      |
| ep_rewmean              | 1.27e+03 |
| episodes                | 2592     |
| eplenmean               | 302      |
| fps                     | 13       |
| mean 100 episode reward | 1.27e+03 |
| n_updates               | 708800   |
| q_grad_norm             | 6062.518 |
| qfs_loss                | 82.80294 |
| qs_abs_difference       | 8.52     |
| qs_difference           | 7.69     |
| qs_mean                 | 340.3378 |
| time_elapsed            | 27766    |
| total timesteps         | 379345   |
| train_time              | 7959     |
| update_time             | 18556    |
--------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.59e+03  |
| eval_abs_qs_difference  | 16.841993 |
| eval_discount_q         | 305       |
| eval_ep_rewmean         | 1.4e+03   |
| eval_eplenmean          | 324       |
| eval_qs                 | 347.87054 |
| eval_qs_difference      | 7.89      |
| eval_time_elapsed       | 7         |
| total timesteps         | 380001    |
---------------------------------------
---------------------------------------
| act_time                | 280       |
| current_lr              | 0.0003    |
| discount_q              | 0.399     |
| env_time                | 557       |
| ep_rewmean              | 1.25e+03  |
| episodes                | 2596      |
| eplenmean               | 298       |
| fps                     | 13        |
| mean 100 episode reward | 1.25e+03  |
| n_updates               | 710600    |
| q_grad_norm             | 3053.6316 |
| qfs_loss                | 50.716026 |
| qs_abs_difference       | 26.4      |
| qs_difference           | 26        |
| qs_mean                 | 344.05402 |
| time_elapsed            | 27838     |
| total timesteps         | 380278    |
| train_time              | 7980      |
| update_time             | 18597     |
---------------------------------------
---------------------------------------
| act_time                | 280       |
| current_lr              | 0.0003    |
| discount_q              | 0.529     |
| env_time                | 559       |
| ep_rewmean              | 1.23e+03  |
| episodes                | 2600      |
| eplenmean               | 294       |
| fps                     | 13        |
| mean 100 episode reward | 1.23e+03  |
| n_updates               | 712600    |
| q_grad_norm             | 2622.444  |
| qfs_loss                | 39.679016 |
| qs_abs_difference       | 11.4      |
| qs_difference           | 7.5       |
| qs_mean                 | 356.20978 |
| time_elapsed            | 27909     |
| total timesteps         | 381219    |
| train_time              | 8003      |
| update_time             | 18643     |
---------------------------------------
---------------------------------------
| act_time                | 281       |
| current_lr              | 0.0003    |
| discount_q              | 0.0694    |
| env_time                | 560       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 2604      |
| eplenmean               | 292       |
| fps                     | 13        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 714600    |
| q_grad_norm             | 2971.2415 |
| qfs_loss                | 42.505848 |
| qs_abs_difference       | 25.2      |
| qs_difference           | 24.3      |
| qs_mean                 | 308.53326 |
| time_elapsed            | 27981     |
| total timesteps         | 382263    |
| train_time              | 8026      |
| update_time             | 18689     |
---------------------------------------
---------------------------------------
| act_time                | 282       |
| current_lr              | 0.0003    |
| discount_q              | 0.306     |
| env_time                | 562       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 2608      |
| eplenmean               | 292       |
| fps                     | 13        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 716600    |
| q_grad_norm             | 3873.7747 |
| qfs_loss                | 58.501553 |
| qs_abs_difference       | 11.3      |
| qs_difference           | 10.1      |
| qs_mean                 | 336.95956 |
| time_elapsed            | 28052     |
| total timesteps         | 383250    |
| train_time              | 8049      |
| update_time             | 18735     |
---------------------------------------
---------------------------------------
| act_time                | 282       |
| current_lr              | 0.0003    |
| discount_q              | 0.354     |
| env_time                | 563       |
| ep_rewmean              | 1.19e+03  |
| episodes                | 2612      |
| eplenmean               | 285       |
| fps                     | 13        |
| mean 100 episode reward | 1.19e+03  |
| n_updates               | 718200    |
| q_grad_norm             | 2844.117  |
| qfs_loss                | 52.405445 |
| qs_abs_difference       | 179       |
| qs_difference           | 179       |
| qs_mean                 | 403.28537 |
| time_elapsed            | 28110     |
| total timesteps         | 384097    |
| train_time              | 8068      |
| update_time             | 18772     |
---------------------------------------
---------------------------------------
| act_time                | 283       |
| current_lr              | 0.0003    |
| discount_q              | 0.132     |
| env_time                | 564       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2616      |
| eplenmean               | 285       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 720400    |
| q_grad_norm             | 4271.3447 |
| qfs_loss                | 60.46838  |
| qs_abs_difference       | 7.51      |
| qs_difference           | 5.58      |
| qs_mean                 | 330.28314 |
| time_elapsed            | 28188     |
| total timesteps         | 385131    |
| train_time              | 8093      |
| update_time             | 18823     |
---------------------------------------
---------------------------------------
| act_time                | 284       |
| current_lr              | 0.0003    |
| discount_q              | 0.112     |
| env_time                | 566       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2620      |
| eplenmean               | 288       |
| fps                     | 13        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 722400    |
| q_grad_norm             | 3271.212  |
| qfs_loss                | 45.315395 |
| qs_abs_difference       | 20.6      |
| qs_difference           | 19.8      |
| qs_mean                 | 319.13358 |
| time_elapsed            | 28260     |
| total timesteps         | 386143    |
| train_time              | 8116      |
| update_time             | 18869     |
---------------------------------------
---------------------------------------
| act_time                | 285       |
| current_lr              | 0.0003    |
| discount_q              | 0.0516    |
| env_time                | 567       |
| ep_rewmean              | 1.22e+03  |
| episodes                | 2624      |
| eplenmean               | 290       |
| fps                     | 13        |
| mean 100 episode reward | 1.22e+03  |
| n_updates               | 724800    |
| q_grad_norm             | 3969.9712 |
| qfs_loss                | 60.438034 |
| qs_abs_difference       | 15.6      |
| qs_difference           | 14.1      |
| qs_mean                 | 362.10867 |
| time_elapsed            | 28346     |
| total timesteps         | 387346    |
| train_time              | 8144      |
| update_time             | 18924     |
---------------------------------------
--------------------------------------
| act_time                | 286      |
| current_lr              | 0.0003   |
| discount_q              | 0.153    |
| env_time                | 569      |
| ep_rewmean              | 1.21e+03 |
| episodes                | 2628     |
| eplenmean               | 288      |
| fps                     | 13       |
| mean 100 episode reward | 1.21e+03 |
| n_updates               | 726800   |
| q_grad_norm             | 3863.635 |
| qfs_loss                | 65.74276 |
| qs_abs_difference       | 40.4     |
| qs_difference           | 39.6     |
| qs_mean                 | 358.4116 |
| time_elapsed            | 28417    |
| total timesteps         | 388383   |
| train_time              | 8167     |
| update_time             | 18969    |
--------------------------------------
---------------------------------------
| act_time                | 287       |
| current_lr              | 0.0003    |
| discount_q              | 0.0476    |
| env_time                | 571       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2632      |
| eplenmean               | 285       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 729200    |
| q_grad_norm             | 4165.941  |
| qfs_loss                | 55.651142 |
| qs_abs_difference       | 9.95      |
| qs_difference           | 7.59      |
| qs_mean                 | 324.49918 |
| time_elapsed            | 28502     |
| total timesteps         | 389500    |
| train_time              | 8195      |
| update_time             | 19024     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.62e+03  |
| eval_abs_qs_difference  | 8.921246  |
| eval_discount_q         | 307       |
| eval_ep_rewmean         | 1.32e+03  |
| eval_eplenmean          | 303       |
| eval_qs                 | 333.43466 |
| eval_qs_difference      | -1.22     |
| eval_time_elapsed       | 7         |
| total timesteps         | 390001    |
---------------------------------------
---------------------------------------
| act_time                | 288       |
| current_lr              | 0.0003    |
| discount_q              | 0.0344    |
| env_time                | 573       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2636      |
| eplenmean               | 287       |
| fps                     | 13        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 731600    |
| q_grad_norm             | 3519.2622 |
| qfs_loss                | 56.24121  |
| qs_abs_difference       | 30        |
| qs_difference           | 30        |
| qs_mean                 | 367.10498 |
| time_elapsed            | 28596     |
| total timesteps         | 390738    |
| train_time              | 8222      |
| update_time             | 19079     |
---------------------------------------
---------------------------------------
| act_time                | 288       |
| current_lr              | 0.0003    |
| discount_q              | 0.179     |
| env_time                | 574       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2640      |
| eplenmean               | 287       |
| fps                     | 13        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 733800    |
| q_grad_norm             | 2973.998  |
| qfs_loss                | 47.842197 |
| qs_abs_difference       | 6.84      |
| qs_difference           | 6.66      |
| qs_mean                 | 361.94025 |
| time_elapsed            | 28674     |
| total timesteps         | 391837    |
| train_time              | 8248      |
| update_time             | 19129     |
---------------------------------------
---------------------------------------
| act_time                | 289       |
| current_lr              | 0.0003    |
| discount_q              | 1.21      |
| env_time                | 576       |
| ep_rewmean              | 1.19e+03  |
| episodes                | 2644      |
| eplenmean               | 283       |
| fps                     | 13        |
| mean 100 episode reward | 1.19e+03  |
| n_updates               | 735600    |
| q_grad_norm             | 4425.547  |
| qfs_loss                | 61.593918 |
| qs_abs_difference       | 12.4      |
| qs_difference           | 11.3      |
| qs_mean                 | 366.3003  |
| time_elapsed            | 28738     |
| total timesteps         | 392769    |
| train_time              | 8269      |
| update_time             | 19170     |
---------------------------------------
---------------------------------------
| act_time                | 290       |
| current_lr              | 0.0003    |
| discount_q              | 0.0326    |
| env_time                | 577       |
| ep_rewmean              | 1.21e+03  |
| episodes                | 2648      |
| eplenmean               | 286       |
| fps                     | 13        |
| mean 100 episode reward | 1.21e+03  |
| n_updates               | 738200    |
| q_grad_norm             | 2828.1138 |
| qfs_loss                | 49.147198 |
| qs_abs_difference       | 4.71      |
| qs_difference           | -3.41     |
| qs_mean                 | 352.96008 |
| time_elapsed            | 28831     |
| total timesteps         | 394008    |
| train_time              | 8299      |
| update_time             | 19229     |
---------------------------------------
---------------------------------------
| act_time                | 291       |
| current_lr              | 0.0003    |
| discount_q              | 0.00742   |
| env_time                | 579       |
| ep_rewmean              | 1.2e+03   |
| episodes                | 2652      |
| eplenmean               | 282       |
| fps                     | 13        |
| mean 100 episode reward | 1.2e+03   |
| n_updates               | 740600    |
| q_grad_norm             | 2542.5354 |
| qfs_loss                | 33.56739  |
| qs_abs_difference       | 174       |
| qs_difference           | 174       |
| qs_mean                 | 399.59326 |
| time_elapsed            | 28916     |
| total timesteps         | 395247    |
| train_time              | 8327      |
| update_time             | 19283     |
---------------------------------------
---------------------------------------
| act_time                | 292       |
| current_lr              | 0.0003    |
| discount_q              | 0.00408   |
| env_time                | 582       |
| ep_rewmean              | 1.17e+03  |
| episodes                | 2656      |
| eplenmean               | 277       |
| fps                     | 13        |
| mean 100 episode reward | 1.17e+03  |
| n_updates               | 743600    |
| q_grad_norm             | 4762.8286 |
| qfs_loss                | 75.836685 |
| qs_abs_difference       | 45        |
| qs_difference           | 43.4      |
| qs_mean                 | 359.2818  |
| time_elapsed            | 29023     |
| total timesteps         | 396767    |
| train_time              | 8361      |
| update_time             | 19351     |
---------------------------------------
--------------------------------------
| act_time                | 293      |
| current_lr              | 0.0003   |
| discount_q              | 0.261    |
| env_time                | 582      |
| ep_rewmean              | 1.14e+03 |
| episodes                | 2660     |
| eplenmean               | 270      |
| fps                     | 13       |
| mean 100 episode reward | 1.14e+03 |
| n_updates               | 744400   |
| q_grad_norm             | 3198.366 |
| qfs_loss                | 54.01479 |
| qs_abs_difference       | 313      |
| qs_difference           | 313      |
| qs_mean                 | 320.9486 |
| time_elapsed            | 29052    |
| total timesteps         | 397172   |
| train_time              | 8371     |
| update_time             | 19369    |
--------------------------------------
---------------------------------------
| act_time                | 294       |
| current_lr              | 0.0003    |
| discount_q              | 0.035     |
| env_time                | 584       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 2664      |
| eplenmean               | 267       |
| fps                     | 13        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 746800    |
| q_grad_norm             | 3867.846  |
| qfs_loss                | 53.965004 |
| qs_abs_difference       | 34.7      |
| qs_difference           | 34.1      |
| qs_mean                 | 322.23148 |
| time_elapsed            | 29137     |
| total timesteps         | 398321    |
| train_time              | 8398      |
| update_time             | 19424     |
---------------------------------------
---------------------------------------
| act_time                | 295       |
| current_lr              | 0.0003    |
| discount_q              | 0.00258   |
| env_time                | 586       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2668      |
| eplenmean               | 271       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 749800    |
| q_grad_norm             | 3967.6123 |
| qfs_loss                | 57.85303  |
| qs_abs_difference       | 6.23      |
| qs_difference           | 2.32      |
| qs_mean                 | 352.14972 |
| time_elapsed            | 29243     |
| total timesteps         | 399833    |
| train_time              | 8433      |
| update_time             | 19492     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.69e+03  |
| eval_abs_qs_difference  | 65.4249   |
| eval_discount_q         | 280       |
| eval_ep_rewmean         | 1.31e+03  |
| eval_eplenmean          | 350       |
| eval_qs                 | 349.91052 |
| eval_qs_difference      | 61.4      |
| eval_time_elapsed       | 8         |
| total timesteps         | 400001    |
---------------------------------------
total runtime: 29272.053478240967s
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 3, 'comment': 'hopper_gem+tbp_3', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_3
max_step:  1000
Box(-inf, inf, (11,), float64) Box(-1.0, 1.0, (3,), float32)
max_step:  1000
seed=3, logdir=./log_gem/mujoco/gem+tbp/hopper_gem+tbp_3
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/run/train.py:30: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-05-05 17:06:08.166428: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-05-05 17:06:08.200586: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz
2022-05-05 17:06:08.201460: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c1a8e69290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-05-05 17:06:08.201540: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:98: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/policies.py:283: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:138: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:203: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:226: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:251: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:261: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:264: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

GEM Agent Here
TD3 Update Memory Many Agent here
here (?, 1)
model building finished
--------------------------------------
| eval mean 100 episod... | 3.9      |
| eval_abs_qs_difference  | 2.427679 |
| eval_discount_q         | 3.83     |
| eval_ep_rewmean         | 3.9      |
| eval_eplenmean          | 7        |
| eval_qs                 | -0.89583 |
| eval_qs_difference      | -2.43    |
| eval_time_elapsed       | 0        |
| total timesteps         | 1        |
--------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 8.26      |
| env_time                | 0         |
| ep_rewmean              | 16.8      |
| episodes                | 4         |
| eplenmean               | 22        |
| fps                     | 87        |
| mean 100 episode reward | 16.8      |
| n_updates               | 0         |
| qs_abs_difference       | 5.63      |
| qs_difference           | -5.62     |
| qs_mean                 | 0.0867242 |
| time_elapsed            | 0         |
| total timesteps         | 88        |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 10.7       |
| env_time                | 0          |
| ep_rewmean              | 17.1       |
| episodes                | 8          |
| eplenmean               | 22.8       |
| fps                     | 118        |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 11.2       |
| qs_difference           | -11.2      |
| qs_mean                 | 0.09828581 |
| time_elapsed            | 1          |
| total timesteps         | 182        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.23        |
| env_time                | 0           |
| ep_rewmean              | 15.2        |
| episodes                | 12          |
| eplenmean               | 20.8        |
| fps                     | 144         |
| mean 100 episode reward | 15.2        |
| n_updates               | 0           |
| qs_abs_difference       | 3.65        |
| qs_difference           | -3.65       |
| qs_mean                 | 0.044418525 |
| time_elapsed            | 1           |
| total timesteps         | 249         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.02       |
| env_time                | 0          |
| ep_rewmean              | 14.5       |
| episodes                | 16         |
| eplenmean               | 19.8       |
| fps                     | 165        |
| mean 100 episode reward | 14.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.39       |
| qs_difference           | -4.39      |
| qs_mean                 | 0.16753028 |
| time_elapsed            | 1          |
| total timesteps         | 316        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.35       |
| env_time                | 0          |
| ep_rewmean              | 15.6       |
| episodes                | 20         |
| eplenmean               | 22.1       |
| fps                     | 194        |
| mean 100 episode reward | 15.6       |
| n_updates               | 0          |
| qs_abs_difference       | 3.65       |
| qs_difference           | -2.01      |
| qs_mean                 | 0.07104709 |
| time_elapsed            | 2          |
| total timesteps         | 442        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
-------------------------------------------
| act_time                | 0             |
| current_lr              | 0.0003        |
| discount_q              | 6.61          |
| env_time                | 1             |
| ep_rewmean              | 15            |
| episodes                | 24            |
| eplenmean               | 21.8          |
| fps                     | 210           |
| mean 100 episode reward | 15            |
| n_updates               | 0             |
| qs_abs_difference       | 3.27          |
| qs_difference           | -1.69         |
| qs_mean                 | 0.00089472905 |
| time_elapsed            | 2             |
| total timesteps         | 523           |
| train_time              | 0             |
| update_time             | 0             |
-------------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 2.35       |
| env_time                | 1          |
| ep_rewmean              | 19.8       |
| episodes                | 28         |
| eplenmean               | 25         |
| fps                     | 226        |
| mean 100 episode reward | 19.8       |
| n_updates               | 0          |
| qs_abs_difference       | 3.9        |
| qs_difference           | -3.78      |
| qs_mean                 | 0.07089149 |
| time_elapsed            | 3          |
| total timesteps         | 701        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 9.05      |
| env_time                | 1         |
| ep_rewmean              | 18.7      |
| episodes                | 32        |
| eplenmean               | 23.9      |
| fps                     | 239       |
| mean 100 episode reward | 18.7      |
| n_updates               | 0         |
| qs_abs_difference       | 7.24      |
| qs_difference           | -7.24     |
| qs_mean                 | 0.0976887 |
| time_elapsed            | 3         |
| total timesteps         | 764       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.87        |
| env_time                | 1           |
| ep_rewmean              | 17.7        |
| episodes                | 36          |
| eplenmean               | 23          |
| fps                     | 239         |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.86        |
| qs_difference           | -3.86       |
| qs_mean                 | 0.019629575 |
| time_elapsed            | 3           |
| total timesteps         | 827         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 17.5       |
| env_time                | 1          |
| ep_rewmean              | 19         |
| episodes                | 40         |
| eplenmean               | 24.1       |
| fps                     | 246        |
| mean 100 episode reward | 19         |
| n_updates               | 0          |
| qs_abs_difference       | 28.1       |
| qs_difference           | -28.1      |
| qs_mean                 | 0.18475458 |
| time_elapsed            | 3          |
| total timesteps         | 965        |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 9.02       |
| env_time                | 1          |
| ep_rewmean              | 18.5       |
| episodes                | 44         |
| eplenmean               | 23.7       |
| fps                     | 244        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 7.84       |
| qs_difference           | -7.84      |
| qs_mean                 | 0.13039884 |
| time_elapsed            | 4          |
| total timesteps         | 1043       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.21        |
| env_time                | 2           |
| ep_rewmean              | 17.6        |
| episodes                | 48          |
| eplenmean               | 23          |
| fps                     | 241         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 2.32        |
| qs_difference           | -1.78       |
| qs_mean                 | 0.076840855 |
| time_elapsed            | 4           |
| total timesteps         | 1106        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.53        |
| env_time                | 2           |
| ep_rewmean              | 17.4        |
| episodes                | 52          |
| eplenmean               | 22.5        |
| fps                     | 249         |
| mean 100 episode reward | 17.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.85        |
| qs_difference           | -3.85       |
| qs_mean                 | -0.04072054 |
| time_elapsed            | 4           |
| total timesteps         | 1172        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.86        |
| env_time                | 2           |
| ep_rewmean              | 17          |
| episodes                | 56          |
| eplenmean               | 22.2        |
| fps                     | 244         |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 3.44        |
| qs_difference           | -3.28       |
| qs_mean                 | 0.045898985 |
| time_elapsed            | 5           |
| total timesteps         | 1244        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 2.75         |
| env_time                | 2            |
| ep_rewmean              | 17.8         |
| episodes                | 60           |
| eplenmean               | 22.4         |
| fps                     | 246          |
| mean 100 episode reward | 17.8         |
| n_updates               | 0            |
| qs_abs_difference       | 1.88         |
| qs_difference           | -0.713       |
| qs_mean                 | -0.069170944 |
| time_elapsed            | 5            |
| total timesteps         | 1347         |
| train_time              | 0            |
| update_time             | 1            |
------------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 10.1       |
| env_time                | 2          |
| ep_rewmean              | 17.7       |
| episodes                | 64         |
| eplenmean               | 22.2       |
| fps                     | 245        |
| mean 100 episode reward | 17.7       |
| n_updates               | 0          |
| qs_abs_difference       | 6.51       |
| qs_difference           | -6.51      |
| qs_mean                 | 0.09106394 |
| time_elapsed            | 5          |
| total timesteps         | 1419       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
-------------------------------------------
| act_time                | 0             |
| current_lr              | 0.0003        |
| discount_q              | 4.39          |
| env_time                | 2             |
| ep_rewmean              | 17.2          |
| episodes                | 68            |
| eplenmean               | 21.8          |
| fps                     | 250           |
| mean 100 episode reward | 17.2          |
| n_updates               | 0             |
| qs_abs_difference       | 3.27          |
| qs_difference           | -3.27         |
| qs_mean                 | 0.00010052594 |
| time_elapsed            | 5             |
| total timesteps         | 1481          |
| train_time              | 0             |
| update_time             | 1             |
-------------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 12.4       |
| env_time                | 2          |
| ep_rewmean              | 17         |
| episodes                | 72         |
| eplenmean               | 21.7       |
| fps                     | 244        |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 10.1       |
| qs_difference           | -10.1      |
| qs_mean                 | 0.07519671 |
| time_elapsed            | 6          |
| total timesteps         | 1562       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 15.7        |
| env_time                | 2           |
| ep_rewmean              | 16.9        |
| episodes                | 76          |
| eplenmean               | 21.4        |
| fps                     | 238         |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 11.8        |
| qs_difference           | -11.8       |
| qs_mean                 | 0.076223195 |
| time_elapsed            | 6           |
| total timesteps         | 1629        |
| train_time              | 0           |
| update_time             | 2           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 16.6       |
| env_time                | 2          |
| ep_rewmean              | 17.2       |
| episodes                | 80         |
| eplenmean               | 21.5       |
| fps                     | 235        |
| mean 100 episode reward | 17.2       |
| n_updates               | 0          |
| qs_abs_difference       | 17.8       |
| qs_difference           | -17.8      |
| qs_mean                 | 0.19923683 |
| time_elapsed            | 7          |
| total timesteps         | 1720       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.12        |
| env_time                | 3           |
| ep_rewmean              | 17          |
| episodes                | 84          |
| eplenmean               | 21.5        |
| fps                     | 231         |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 4.21        |
| qs_difference           | -4.14       |
| qs_mean                 | 0.103977054 |
| time_elapsed            | 7           |
| total timesteps         | 1808        |
| train_time              | 0           |
| update_time             | 3           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 9.72       |
| env_time                | 3          |
| ep_rewmean              | 17.1       |
| episodes                | 88         |
| eplenmean               | 21.4       |
| fps                     | 235        |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 9.24       |
| qs_difference           | -9.24      |
| qs_mean                 | 0.14627188 |
| time_elapsed            | 8          |
| total timesteps         | 1884       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 9.76       |
| env_time                | 3          |
| ep_rewmean              | 16.9       |
| episodes                | 92         |
| eplenmean               | 21.2       |
| fps                     | 230        |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 8.66       |
| qs_difference           | -8.66      |
| qs_mean                 | 0.10070961 |
| time_elapsed            | 8          |
| total timesteps         | 1950       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.76       |
| env_time                | 3          |
| ep_rewmean              | 16.9       |
| episodes                | 96         |
| eplenmean               | 21.2       |
| fps                     | 228        |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 8.47       |
| qs_difference           | -8.47      |
| qs_mean                 | 0.09473382 |
| time_elapsed            | 8          |
| total timesteps         | 2038       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 16.7       |
| env_time                | 3          |
| ep_rewmean              | 17         |
| episodes                | 100        |
| eplenmean               | 21.3       |
| fps                     | 226        |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 16.3       |
| qs_difference           | -16.3      |
| qs_mean                 | 0.08298976 |
| time_elapsed            | 9          |
| total timesteps         | 2126       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 4.96         |
| env_time                | 3            |
| ep_rewmean              | 17           |
| episodes                | 104          |
| eplenmean               | 21.1         |
| fps                     | 221          |
| mean 100 episode reward | 17           |
| n_updates               | 0            |
| qs_abs_difference       | 4.2          |
| qs_difference           | -4.2         |
| qs_mean                 | -0.066394195 |
| time_elapsed            | 9            |
| total timesteps         | 2200         |
| train_time              | 0            |
| update_time             | 4            |
------------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.29        |
| env_time                | 3           |
| ep_rewmean              | 16.9        |
| episodes                | 108         |
| eplenmean               | 21.1        |
| fps                     | 226         |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 5.9         |
| qs_difference           | -5.89       |
| qs_mean                 | 0.030741462 |
| time_elapsed            | 10          |
| total timesteps         | 2294        |
| train_time              | 0           |
| update_time             | 4           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.47       |
| env_time                | 3          |
| ep_rewmean              | 17         |
| episodes                | 112        |
| eplenmean               | 21.4       |
| fps                     | 221        |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 2.7        |
| qs_difference           | -2.33      |
| qs_mean                 | 0.06829692 |
| time_elapsed            | 10         |
| total timesteps         | 2385       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.92       |
| env_time                | 3          |
| ep_rewmean              | 17         |
| episodes                | 116        |
| eplenmean               | 21.5       |
| fps                     | 218        |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 5.54       |
| qs_difference           | -5.54      |
| qs_mean                 | 0.13492504 |
| time_elapsed            | 11         |
| total timesteps         | 2466       |
| train_time              | 0          |
| update_time             | 5          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.79       |
| env_time                | 4          |
| ep_rewmean              | 16.8       |
| episodes                | 120        |
| eplenmean               | 20.9       |
| fps                     | 213        |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 6.83       |
| qs_difference           | -6.83      |
| qs_mean                 | 0.19103524 |
| time_elapsed            | 11         |
| total timesteps         | 2529       |
| train_time              | 0          |
| update_time             | 5          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.44        |
| env_time                | 4           |
| ep_rewmean              | 17          |
| episodes                | 124         |
| eplenmean               | 20.9        |
| fps                     | 210         |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 8.36        |
| qs_difference           | -8.36       |
| qs_mean                 | 0.058286108 |
| time_elapsed            | 12          |
| total timesteps         | 2616        |
| train_time              | 0           |
| update_time             | 6           |
-----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 5.41         |
| env_time                | 4            |
| ep_rewmean              | 15.5         |
| episodes                | 128          |
| eplenmean               | 19.9         |
| fps                     | 213          |
| mean 100 episode reward | 15.5         |
| n_updates               | 0            |
| qs_abs_difference       | 4.38         |
| qs_difference           | -4.38        |
| qs_mean                 | -0.026515057 |
| time_elapsed            | 12           |
| total timesteps         | 2688         |
| train_time              | 0            |
| update_time             | 6            |
------------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 17.6        |
| env_time                | 4           |
| ep_rewmean              | 15.8        |
| episodes                | 132         |
| eplenmean               | 20.1        |
| fps                     | 209         |
| mean 100 episode reward | 15.8        |
| n_updates               | 0           |
| qs_abs_difference       | 16.3        |
| qs_difference           | -16.3       |
| qs_mean                 | 0.045684583 |
| time_elapsed            | 13          |
| total timesteps         | 2775        |
| train_time              | 0           |
| update_time             | 6           |
-----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 2.47         |
| env_time                | 4            |
| ep_rewmean              | 16.1         |
| episodes                | 136          |
| eplenmean               | 20.5         |
| fps                     | 206          |
| mean 100 episode reward | 16.1         |
| n_updates               | 0            |
| qs_abs_difference       | 3.01         |
| qs_difference           | -3.01        |
| qs_mean                 | -0.028656874 |
| time_elapsed            | 13           |
| total timesteps         | 2874         |
| train_time              | 0            |
| update_time             | 6            |
------------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.51        |
| env_time                | 4           |
| ep_rewmean              | 15.8        |
| episodes                | 140         |
| eplenmean               | 20.1        |
| fps                     | 202         |
| mean 100 episode reward | 15.8        |
| n_updates               | 0           |
| qs_abs_difference       | 2.54        |
| qs_difference           | -2.1        |
| qs_mean                 | 0.070098795 |
| time_elapsed            | 14          |
| total timesteps         | 2977        |
| train_time              | 0           |
| update_time             | 7           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 27.8       |
| env_time                | 4          |
| ep_rewmean              | 16.5       |
| episodes                | 144        |
| eplenmean               | 20.6       |
| fps                     | 193        |
| mean 100 episode reward | 16.5       |
| n_updates               | 0          |
| qs_abs_difference       | 35.6       |
| qs_difference           | -35.6      |
| qs_mean                 | 0.08510318 |
| time_elapsed            | 16         |
| total timesteps         | 3104       |
| train_time              | 0          |
| update_time             | 8          |
----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 4            |
| env_time                | 5            |
| ep_rewmean              | 17           |
| episodes                | 148          |
| eplenmean               | 21           |
| fps                     | 190          |
| mean 100 episode reward | 17           |
| n_updates               | 0            |
| qs_abs_difference       | 4.52         |
| qs_difference           | -4.52        |
| qs_mean                 | -0.003097729 |
| time_elapsed            | 16           |
| total timesteps         | 3203         |
| train_time              | 0            |
| update_time             | 9            |
------------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 14.6       |
| env_time                | 5          |
| ep_rewmean              | 17.1       |
| episodes                | 152        |
| eplenmean               | 21.1       |
| fps                     | 192        |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 14.2       |
| qs_difference           | -14.2      |
| qs_mean                 | 0.09618879 |
| time_elapsed            | 17         |
| total timesteps         | 3277       |
| train_time              | 0          |
| update_time             | 9          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 2.5        |
| env_time                | 5          |
| ep_rewmean              | 18.8       |
| episodes                | 156        |
| eplenmean               | 22         |
| fps                     | 186        |
| mean 100 episode reward | 18.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.69       |
| qs_difference           | -4.69      |
| qs_mean                 | 0.05470667 |
| time_elapsed            | 18         |
| total timesteps         | 3442       |
| train_time              | 0          |
| update_time             | 10         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.74        |
| env_time                | 5           |
| ep_rewmean              | 18          |
| episodes                | 160         |
| eplenmean               | 21.4        |
| fps                     | 187         |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 3.83        |
| qs_difference           | -3.83       |
| qs_mean                 | 0.039351992 |
| time_elapsed            | 18          |
| total timesteps         | 3492        |
| train_time              | 0           |
| update_time             | 10          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.66        |
| env_time                | 5           |
| ep_rewmean              | 17.8        |
| episodes                | 164         |
| eplenmean               | 21.3        |
| fps                     | 183         |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.2         |
| qs_difference           | -5.2        |
| qs_mean                 | 0.053335413 |
| time_elapsed            | 19          |
| total timesteps         | 3553        |
| train_time              | 0           |
| update_time             | 10          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.19        |
| env_time                | 5           |
| ep_rewmean              | 17.9        |
| episodes                | 168         |
| eplenmean               | 21.5        |
| fps                     | 180         |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 2.74        |
| qs_difference           | -2.74       |
| qs_mean                 | 0.022047741 |
| time_elapsed            | 20          |
| total timesteps         | 3629        |
| train_time              | 0           |
| update_time             | 11          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 10.2       |
| env_time                | 5          |
| ep_rewmean              | 17.8       |
| episodes                | 172        |
| eplenmean               | 21.3       |
| fps                     | 181        |
| mean 100 episode reward | 17.8       |
| n_updates               | 0          |
| qs_abs_difference       | 9.31       |
| qs_difference           | -9.31      |
| qs_mean                 | 0.21607715 |
| time_elapsed            | 20         |
| total timesteps         | 3692       |
| train_time              | 0          |
| update_time             | 11         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.62        |
| env_time                | 6           |
| ep_rewmean              | 18.7        |
| episodes                | 176         |
| eplenmean               | 21.8        |
| fps                     | 174         |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 5.11        |
| qs_difference           | -5.11       |
| qs_mean                 | 0.022229137 |
| time_elapsed            | 21          |
| total timesteps         | 3812        |
| train_time              | 0           |
| update_time             | 12          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.45       |
| env_time                | 6          |
| ep_rewmean              | 18.2       |
| episodes                | 180        |
| eplenmean               | 21.5       |
| fps                     | 176        |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 3.51       |
| qs_difference           | -3.51      |
| qs_mean                 | 0.10733028 |
| time_elapsed            | 21         |
| total timesteps         | 3867       |
| train_time              | 0          |
| update_time             | 12         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 2.97        |
| env_time                | 6           |
| ep_rewmean              | 18.4        |
| episodes                | 184         |
| eplenmean               | 21.6        |
| fps                     | 173         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.08        |
| qs_difference           | -3.08       |
| qs_mean                 | -0.06014719 |
| time_elapsed            | 22          |
| total timesteps         | 3963        |
| train_time              | 0           |
| update_time             | 13          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 23          |
| env_time                | 6           |
| ep_rewmean              | 18.5        |
| episodes                | 188         |
| eplenmean               | 21.7        |
| fps                     | 171         |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 17.5        |
| qs_difference           | -17.5       |
| qs_mean                 | 0.040318172 |
| time_elapsed            | 23          |
| total timesteps         | 4058        |
| train_time              | 0           |
| update_time             | 13          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.71       |
| env_time                | 6          |
| ep_rewmean              | 19         |
| episodes                | 192        |
| eplenmean               | 22.1       |
| fps                     | 169        |
| mean 100 episode reward | 19         |
| n_updates               | 0          |
| qs_abs_difference       | 6.15       |
| qs_difference           | -6.15      |
| qs_mean                 | 0.17525223 |
| time_elapsed            | 24         |
| total timesteps         | 4161       |
| train_time              | 0          |
| update_time             | 14         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.69       |
| env_time                | 6          |
| ep_rewmean              | 19         |
| episodes                | 196        |
| eplenmean               | 22         |
| fps                     | 166        |
| mean 100 episode reward | 19         |
| n_updates               | 0          |
| qs_abs_difference       | 5.5        |
| qs_difference           | -5.5       |
| qs_mean                 | 0.10369986 |
| time_elapsed            | 25         |
| total timesteps         | 4237       |
| train_time              | 0          |
| update_time             | 15         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.25        |
| env_time                | 6           |
| ep_rewmean              | 18.8        |
| episodes                | 200         |
| eplenmean               | 22          |
| fps                     | 163         |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 3.13        |
| qs_difference           | -3.1        |
| qs_mean                 | 0.029669086 |
| time_elapsed            | 26          |
| total timesteps         | 4327        |
| train_time              | 0           |
| update_time             | 16          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.87        |
| env_time                | 7           |
| ep_rewmean              | 18.6        |
| episodes                | 204         |
| eplenmean               | 21.9        |
| fps                     | 164         |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 6.22        |
| qs_difference           | -6.22       |
| qs_mean                 | 0.036808297 |
| time_elapsed            | 26          |
| total timesteps         | 4389        |
| train_time              | 0           |
| update_time             | 16          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.04       |
| env_time                | 7          |
| ep_rewmean              | 18.8       |
| episodes                | 208        |
| eplenmean               | 21.8       |
| fps                     | 162        |
| mean 100 episode reward | 18.8       |
| n_updates               | 0          |
| qs_abs_difference       | 6.41       |
| qs_difference           | -6.41      |
| qs_mean                 | 0.22974251 |
| time_elapsed            | 27         |
| total timesteps         | 4475       |
| train_time              | 0          |
| update_time             | 16         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.99       |
| env_time                | 7          |
| ep_rewmean              | 18.9       |
| episodes                | 212        |
| eplenmean               | 21.6       |
| fps                     | 159        |
| mean 100 episode reward | 18.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.44       |
| qs_difference           | -5.44      |
| qs_mean                 | 0.03413713 |
| time_elapsed            | 28         |
| total timesteps         | 4550       |
| train_time              | 0          |
| update_time             | 17         |
----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 6.76         |
| env_time                | 7            |
| ep_rewmean              | 18.8         |
| episodes                | 216          |
| eplenmean               | 21.6         |
| fps                     | 156          |
| mean 100 episode reward | 18.8         |
| n_updates               | 0            |
| qs_abs_difference       | 5.25         |
| qs_difference           | -5.25        |
| qs_mean                 | 0.0142746465 |
| time_elapsed            | 29           |
| total timesteps         | 4621         |
| train_time              | 0            |
| update_time             | 18           |
------------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 3.46         |
| env_time                | 7            |
| ep_rewmean              | 19.5         |
| episodes                | 220          |
| eplenmean               | 21.9         |
| fps                     | 155          |
| mean 100 episode reward | 19.5         |
| n_updates               | 0            |
| qs_abs_difference       | 4.06         |
| qs_difference           | -4.06        |
| qs_mean                 | -0.043157578 |
| time_elapsed            | 30           |
| total timesteps         | 4718         |
| train_time              | 0            |
| update_time             | 19           |
------------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 3.39         |
| env_time                | 7            |
| ep_rewmean              | 19.6         |
| episodes                | 224          |
| eplenmean               | 22           |
| fps                     | 153          |
| mean 100 episode reward | 19.6         |
| n_updates               | 0            |
| qs_abs_difference       | 4.02         |
| qs_difference           | -4.02        |
| qs_mean                 | -0.083811514 |
| time_elapsed            | 31           |
| total timesteps         | 4816         |
| train_time              | 0            |
| update_time             | 19           |
------------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 6.22         |
| env_time                | 7            |
| ep_rewmean              | 19.7         |
| episodes                | 228          |
| eplenmean               | 21.9         |
| fps                     | 154          |
| mean 100 episode reward | 19.7         |
| n_updates               | 0            |
| qs_abs_difference       | 4.29         |
| qs_difference           | -4.29        |
| qs_mean                 | -0.011644373 |
| time_elapsed            | 31           |
| total timesteps         | 4875         |
| train_time              | 0            |
| update_time             | 19           |
------------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.17        |
| env_time                | 7           |
| ep_rewmean              | 19.4        |
| episodes                | 232         |
| eplenmean               | 21.6        |
| fps                     | 151         |
| mean 100 episode reward | 19.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.35        |
| qs_difference           | -3.33       |
| qs_mean                 | 0.088483185 |
| time_elapsed            | 32          |
| total timesteps         | 4934        |
| train_time              | 0           |
| update_time             | 20          |
-----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 7.97      |
| env_time                | 8         |
| ep_rewmean              | 19.2      |
| episodes                | 236       |
| eplenmean               | 21.2      |
| fps                     | 152       |
| mean 100 episode reward | 19.2      |
| n_updates               | 0         |
| qs_abs_difference       | 4.55      |
| qs_difference           | -4.55     |
| qs_mean                 | 0.1601152 |
| time_elapsed            | 32        |
| total timesteps         | 4994      |
| train_time              | 0         |
| update_time             | 20        |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 3.44      |
| env_time                | 8         |
| ep_rewmean              | 19.9      |
| episodes                | 240       |
| eplenmean               | 21.4      |
| fps                     | 147       |
| mean 100 episode reward | 19.9      |
| n_updates               | 0         |
| qs_abs_difference       | 5.34      |
| qs_difference           | -5.34     |
| qs_mean                 | 0.1657859 |
| time_elapsed            | 34        |
| total timesteps         | 5115      |
| train_time              | 0         |
| update_time             | 22        |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.01        |
| env_time                | 8           |
| ep_rewmean              | 19.5        |
| episodes                | 244         |
| eplenmean               | 20.9        |
| fps                     | 149         |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 6.92        |
| qs_difference           | -6.92       |
| qs_mean                 | 0.051038798 |
| time_elapsed            | 34          |
| total timesteps         | 5198        |
| train_time              | 0           |
| update_time             | 22          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 2.81        |
| env_time                | 8           |
| ep_rewmean              | 19.7        |
| episodes                | 248         |
| eplenmean               | 21.1        |
| fps                     | 144         |
| mean 100 episode reward | 19.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.96        |
| qs_difference           | -3.96       |
| qs_mean                 | 0.063839726 |
| time_elapsed            | 36          |
| total timesteps         | 5311        |
| train_time              | 0           |
| update_time             | 24          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 2.21        |
| env_time                | 8           |
| ep_rewmean              | 20.3        |
| episodes                | 252         |
| eplenmean               | 21.4        |
| fps                     | 142         |
| mean 100 episode reward | 20.3        |
| n_updates               | 0           |
| qs_abs_difference       | 2.75        |
| qs_difference           | -2.75       |
| qs_mean                 | -0.00870703 |
| time_elapsed            | 37          |
| total timesteps         | 5413        |
| train_time              | 0           |
| update_time             | 25          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.24       |
| env_time                | 8          |
| ep_rewmean              | 18.5       |
| episodes                | 256        |
| eplenmean               | 20.4       |
| fps                     | 143        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 5.36       |
| qs_difference           | -5.36      |
| qs_mean                 | 0.08003225 |
| time_elapsed            | 38         |
| total timesteps         | 5482       |
| train_time              | 0          |
| update_time             | 25         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.71       |
| env_time                | 8          |
| ep_rewmean              | 18.5       |
| episodes                | 260        |
| eplenmean               | 20.5       |
| fps                     | 141        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.12       |
| qs_difference           | -3.12      |
| qs_mean                 | 0.07928249 |
| time_elapsed            | 39         |
| total timesteps         | 5542       |
| train_time              | 0          |
| update_time             | 26         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 9.16       |
| env_time                | 9          |
| ep_rewmean              | 18.9       |
| episodes                | 264        |
| eplenmean               | 20.9       |
| fps                     | 139        |
| mean 100 episode reward | 18.9       |
| n_updates               | 0          |
| qs_abs_difference       | 10.6       |
| qs_difference           | -10.6      |
| qs_mean                 | 0.10484041 |
| time_elapsed            | 40         |
| total timesteps         | 5640       |
| train_time              | 0          |
| update_time             | 27         |
----------------------------------------
------------------------------------------
| act_time                | 0            |
| current_lr              | 0.0003       |
| discount_q              | 6.04         |
| env_time                | 9            |
| ep_rewmean              | 18.9         |
| episodes                | 268          |
| eplenmean               | 20.8         |
| fps                     | 137          |
| mean 100 episode reward | 18.9         |
| n_updates               | 0            |
| qs_abs_difference       | 3.13         |
| qs_difference           | -2.95        |
| qs_mean                 | -0.030370701 |
| time_elapsed            | 41           |
| total timesteps         | 5708         |
| train_time              | 0            |
| update_time             | 27           |
------------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.48        |
| env_time                | 9           |
| ep_rewmean              | 19.1        |
| episodes                | 272         |
| eplenmean               | 21          |
| fps                     | 139         |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 7.76        |
| qs_difference           | -7.76       |
| qs_mean                 | 0.112118125 |
| time_elapsed            | 41          |
| total timesteps         | 5795        |
| train_time              | 0           |
| update_time             | 27          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 37.5       |
| env_time                | 9          |
| ep_rewmean              | 18.9       |
| episodes                | 276        |
| eplenmean               | 20.9       |
| fps                     | 134        |
| mean 100 episode reward | 18.9       |
| n_updates               | 0          |
| qs_abs_difference       | 38.6       |
| qs_difference           | -38.6      |
| qs_mean                 | 0.18487307 |
| time_elapsed            | 43         |
| total timesteps         | 5902       |
| train_time              | 0          |
| update_time             | 29         |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 5.79      |
| env_time                | 9         |
| ep_rewmean              | 18.9      |
| episodes                | 280       |
| eplenmean               | 21.1      |
| fps                     | 135       |
| mean 100 episode reward | 18.9      |
| n_updates               | 0         |
| qs_abs_difference       | 4.69      |
| qs_difference           | -4.69     |
| qs_mean                 | 0.1170441 |
| time_elapsed            | 44        |
| total timesteps         | 5976      |
| train_time              | 0         |
| update_time             | 29        |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.71        |
| env_time                | 9           |
| ep_rewmean              | 18.8        |
| episodes                | 284         |
| eplenmean               | 21          |
| fps                     | 133         |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 7.79        |
| qs_difference           | -7.79       |
| qs_mean                 | 0.103282094 |
| time_elapsed            | 45          |
| total timesteps         | 6067        |
| train_time              | 0           |
| update_time             | 30          |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 24.4        |
| env_time                | 9           |
| ep_rewmean              | 18.9        |
| episodes                | 288         |
| eplenmean               | 21          |
| fps                     | 132         |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 23.9        |
| qs_difference           | -23.9       |
| qs_mean                 | 0.119505286 |
| time_elapsed            | 46          |
| total timesteps         | 6162        |
| train_time              | 0           |
| update_time             | 31          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.48       |
| env_time                | 10         |
| ep_rewmean              | 18.5       |
| episodes                | 292        |
| eplenmean               | 20.9       |
| fps                     | 130        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 7.79       |
| qs_difference           | -7.79      |
| qs_mean                 | 0.12561212 |
| time_elapsed            | 47         |
| total timesteps         | 6246       |
| train_time              | 0          |
| update_time             | 32         |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 20          |
| env_time                | 10          |
| ep_rewmean              | 18.6        |
| episodes                | 296         |
| eplenmean               | 21          |
| fps                     | 129         |
| mean 100 episode reward | 18.6        |
| n_updates               | 0           |
| qs_abs_difference       | 20          |
| qs_difference           | -20         |
| qs_mean                 | 0.040856205 |
| time_elapsed            | 49          |
| total timesteps         | 6335        |
| train_time              | 0           |
| update_time             | 34          |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.55       |
| env_time                | 10         |
| ep_rewmean              | 18.5       |
| episodes                | 300        |
| eplenmean               | 20.7       |
| fps                     | 130        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.91       |
| qs_difference           | -4.91      |
| qs_mean                 | 0.04514851 |
| time_elapsed            | 49         |
| total timesteps         | 6397       |
| train_time              | 0          |
| update_time             | 34         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.21       |
| env_time                | 10         |
| ep_rewmean              | 18.6       |
| episodes                | 304        |
| eplenmean               | 20.8       |
| fps                     | 128        |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.96       |
| qs_difference           | -5.96      |
| qs_mean                 | 0.03761654 |
| time_elapsed            | 50         |
| total timesteps         | 6468       |
| train_time              | 0          |
| update_time             | 35         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.2        |
| env_time                | 10         |
| ep_rewmean              | 18.9       |
| episodes                | 308        |
| eplenmean               | 20.9       |
| fps                     | 127        |
| mean 100 episode reward | 18.9       |
| n_updates               | 0          |
| qs_abs_difference       | 8.18       |
| qs_difference           | -8.18      |
| qs_mean                 | 0.09305872 |
| time_elapsed            | 51         |
| total timesteps         | 6567       |
| train_time              | 0          |
| update_time             | 36         |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.53       |
| env_time                | 10         |
| ep_rewmean              | 19.4       |
| episodes                | 312        |
| eplenmean               | 21.4       |
| fps                     | 126        |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 5.96       |
| qs_difference           | -5.96      |
| qs_mean                 | 0.07982154 |
| time_elapsed            | 53         |
| total timesteps         | 6694       |
| train_time              | 0          |
| update_time             | 37         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.68        |
| env_time                | 10          |
| ep_rewmean              | 19.3        |
| episodes                | 316         |
| eplenmean               | 21.3        |
| fps                     | 124         |
| mean 100 episode reward | 19.3        |
| n_updates               | 0           |
| qs_abs_difference       | 4.22        |
| qs_difference           | -4.22       |
| qs_mean                 | 0.044267703 |
| time_elapsed            | 54          |
| total timesteps         | 6748        |
| train_time              | 0           |
| update_time             | 38          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.59        |
| env_time                | 10          |
| ep_rewmean              | 18.8        |
| episodes                | 320         |
| eplenmean               | 21.4        |
| fps                     | 123         |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 7.12        |
| qs_difference           | -7.12       |
| qs_mean                 | 0.086556055 |
| time_elapsed            | 55          |
| total timesteps         | 6853        |
| train_time              | 0           |
| update_time             | 39          |
-----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 8.01      |
| env_time                | 11        |
| ep_rewmean              | 18.6      |
| episodes                | 324       |
| eplenmean               | 21.1      |
| fps                     | 121       |
| mean 100 episode reward | 18.6      |
| n_updates               | 0         |
| qs_abs_difference       | 6.54      |
| qs_difference           | -6.54     |
| qs_mean                 | 0.1570795 |
| time_elapsed            | 57        |
| total timesteps         | 6929      |
| train_time              | 0         |
| update_time             | 40        |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.22        |
| env_time                | 11          |
| ep_rewmean              | 18.9        |
| episodes                | 328         |
| eplenmean               | 21.4        |
| fps                     | 119         |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 3.73        |
| qs_difference           | -3.73       |
| qs_mean                 | 0.040183917 |
| time_elapsed            | 58          |
| total timesteps         | 7010        |
| train_time              | 0           |
| update_time             | 41          |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 2.76         |
| env_time                | 11           |
| ep_rewmean              | 19.9         |
| episodes                | 332          |
| eplenmean               | 22           |
| fps                     | 119          |
| mean 100 episode reward | 19.9         |
| n_updates               | 0            |
| qs_abs_difference       | 3.51         |
| qs_difference           | -3.49        |
| qs_mean                 | 0.0045421184 |
| time_elapsed            | 59           |
| total timesteps         | 7137         |
| train_time              | 0            |
| update_time             | 43           |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.9         |
| env_time                | 11          |
| ep_rewmean              | 20.2        |
| episodes                | 336         |
| eplenmean               | 22.2        |
| fps                     | 117         |
| mean 100 episode reward | 20.2        |
| n_updates               | 0           |
| qs_abs_difference       | 5.4         |
| qs_difference           | -5.4        |
| qs_mean                 | 0.116356805 |
| time_elapsed            | 61          |
| total timesteps         | 7217        |
| train_time              | 0           |
| update_time             | 44          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.47        |
| env_time                | 11          |
| ep_rewmean              | 19.6        |
| episodes                | 340         |
| eplenmean               | 22.1        |
| fps                     | 116         |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 4.52        |
| qs_difference           | -4.52       |
| qs_mean                 | 0.043941446 |
| time_elapsed            | 62          |
| total timesteps         | 7327        |
| train_time              | 0           |
| update_time             | 45          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 10.2       |
| env_time                | 11         |
| ep_rewmean              | 19.3       |
| episodes                | 344        |
| eplenmean               | 21.9       |
| fps                     | 117        |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 7.97       |
| qs_difference           | -7.97      |
| qs_mean                 | 0.18483397 |
| time_elapsed            | 62         |
| total timesteps         | 7384       |
| train_time              | 0          |
| update_time             | 45         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 11         |
| env_time                | 11         |
| ep_rewmean              | 18.8       |
| episodes                | 348        |
| eplenmean               | 21.6       |
| fps                     | 116        |
| mean 100 episode reward | 18.8       |
| n_updates               | 0          |
| qs_abs_difference       | 8.47       |
| qs_difference           | -8.47      |
| qs_mean                 | 0.07682786 |
| time_elapsed            | 64         |
| total timesteps         | 7476       |
| train_time              | 0          |
| update_time             | 46         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 19.3        |
| env_time                | 12          |
| ep_rewmean              | 18.4        |
| episodes                | 352         |
| eplenmean               | 21.7        |
| fps                     | 115         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 18.2        |
| qs_difference           | -18.2       |
| qs_mean                 | 0.105619065 |
| time_elapsed            | 65          |
| total timesteps         | 7586        |
| train_time              | 0           |
| update_time             | 48          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.59       |
| env_time                | 12         |
| ep_rewmean              | 18.5       |
| episodes                | 356        |
| eplenmean               | 21.9       |
| fps                     | 113        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.72       |
| qs_difference           | -3.29      |
| qs_mean                 | 0.09699118 |
| time_elapsed            | 67         |
| total timesteps         | 7671       |
| train_time              | 0          |
| update_time             | 49         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.81       |
| env_time                | 12         |
| ep_rewmean              | 18.7       |
| episodes                | 360        |
| eplenmean               | 21.9       |
| fps                     | 112        |
| mean 100 episode reward | 18.7       |
| n_updates               | 0          |
| qs_abs_difference       | 5.47       |
| qs_difference           | -5.47      |
| qs_mean                 | 0.15905985 |
| time_elapsed            | 68         |
| total timesteps         | 7730       |
| train_time              | 0          |
| update_time             | 50         |
----------------------------------------
--------------------------------------
| act_time                | 1        |
| current_lr              | 0.0003   |
| discount_q              | 16.4     |
| env_time                | 12       |
| ep_rewmean              | 18.8     |
| episodes                | 364      |
| eplenmean               | 22.1     |
| fps                     | 111      |
| mean 100 episode reward | 18.8     |
| n_updates               | 0        |
| qs_abs_difference       | 20.2     |
| qs_difference           | -20.2    |
| qs_mean                 | 0.142066 |
| time_elapsed            | 70       |
| total timesteps         | 7851     |
| train_time              | 0        |
| update_time             | 51       |
--------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 3.55         |
| env_time                | 12           |
| ep_rewmean              | 18.8         |
| episodes                | 368          |
| eplenmean               | 22.3         |
| fps                     | 110          |
| mean 100 episode reward | 18.8         |
| n_updates               | 0            |
| qs_abs_difference       | 2.48         |
| qs_difference           | -2.47        |
| qs_mean                 | -0.039208744 |
| time_elapsed            | 71           |
| total timesteps         | 7934         |
| train_time              | 0            |
| update_time             | 53           |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.94       |
| env_time                | 12         |
| ep_rewmean              | 18.5       |
| episodes                | 372        |
| eplenmean               | 22         |
| fps                     | 110        |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.37       |
| qs_difference           | -4.34      |
| qs_mean                 | 0.10127161 |
| time_elapsed            | 72         |
| total timesteps         | 7998       |
| train_time              | 0          |
| update_time             | 53         |
----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 10.8         |
| env_time                | 13           |
| ep_rewmean              | 18.2         |
| episodes                | 376          |
| eplenmean               | 22.1         |
| fps                     | 108          |
| mean 100 episode reward | 18.2         |
| n_updates               | 0            |
| qs_abs_difference       | 15.3         |
| qs_difference           | -15.3        |
| qs_mean                 | -0.036474038 |
| time_elapsed            | 75           |
| total timesteps         | 8113         |
| train_time              | 0            |
| update_time             | 55           |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.95       |
| env_time                | 13         |
| ep_rewmean              | 18.4       |
| episodes                | 380        |
| eplenmean               | 22.2       |
| fps                     | 108        |
| mean 100 episode reward | 18.4       |
| n_updates               | 0          |
| qs_abs_difference       | 3.36       |
| qs_difference           | -3.2       |
| qs_mean                 | 0.08180214 |
| time_elapsed            | 75         |
| total timesteps         | 8194       |
| train_time              | 0          |
| update_time             | 55         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.15        |
| env_time                | 13          |
| ep_rewmean              | 18.8        |
| episodes                | 384         |
| eplenmean               | 22.6        |
| fps                     | 106         |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 11.4        |
| qs_difference           | -11.4       |
| qs_mean                 | 0.116634056 |
| time_elapsed            | 78          |
| total timesteps         | 8330        |
| train_time              | 0           |
| update_time             | 58          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 16.4        |
| env_time                | 13          |
| ep_rewmean              | 19.1        |
| episodes                | 388         |
| eplenmean               | 23          |
| fps                     | 105         |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 17.9        |
| qs_difference           | -17.9       |
| qs_mean                 | 0.006046278 |
| time_elapsed            | 79          |
| total timesteps         | 8459        |
| train_time              | 0           |
| update_time             | 60          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.33       |
| env_time                | 13         |
| ep_rewmean              | 19         |
| episodes                | 392        |
| eplenmean               | 22.8       |
| fps                     | 104        |
| mean 100 episode reward | 19         |
| n_updates               | 0          |
| qs_abs_difference       | 6.74       |
| qs_difference           | -6.74      |
| qs_mean                 | 0.08610671 |
| time_elapsed            | 81         |
| total timesteps         | 8530       |
| train_time              | 0          |
| update_time             | 61         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 36.5       |
| env_time                | 13         |
| ep_rewmean              | 19.5       |
| episodes                | 396        |
| eplenmean               | 23.2       |
| fps                     | 104        |
| mean 100 episode reward | 19.5       |
| n_updates               | 0          |
| qs_abs_difference       | 38.1       |
| qs_difference           | -38.1      |
| qs_mean                 | 0.04875239 |
| time_elapsed            | 83         |
| total timesteps         | 8658       |
| train_time              | 0          |
| update_time             | 62         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.39       |
| env_time                | 13         |
| ep_rewmean              | 19.6       |
| episodes                | 400        |
| eplenmean               | 23.3       |
| fps                     | 102        |
| mean 100 episode reward | 19.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.1        |
| qs_difference           | -4.1       |
| qs_mean                 | 0.02836296 |
| time_elapsed            | 84         |
| total timesteps         | 8725       |
| train_time              | 0          |
| update_time             | 64         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.84        |
| env_time                | 14          |
| ep_rewmean              | 19.5        |
| episodes                | 404         |
| eplenmean               | 23.2        |
| fps                     | 103         |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 6.98        |
| qs_difference           | -6.98       |
| qs_mean                 | 0.055497702 |
| time_elapsed            | 85          |
| total timesteps         | 8788        |
| train_time              | 0           |
| update_time             | 64          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.15       |
| env_time                | 14         |
| ep_rewmean              | 19         |
| episodes                | 408        |
| eplenmean               | 23.2       |
| fps                     | 102        |
| mean 100 episode reward | 19         |
| n_updates               | 0          |
| qs_abs_difference       | 3.53       |
| qs_difference           | -3.42      |
| qs_mean                 | 0.03613971 |
| time_elapsed            | 86         |
| total timesteps         | 8888       |
| train_time              | 0          |
| update_time             | 65         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.27       |
| env_time                | 14         |
| ep_rewmean              | 18.6       |
| episodes                | 412        |
| eplenmean               | 22.9       |
| fps                     | 101        |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.31       |
| qs_difference           | -5.31      |
| qs_mean                 | 0.15989503 |
| time_elapsed            | 88         |
| total timesteps         | 8980       |
| train_time              | 0          |
| update_time             | 67         |
----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 7.05         |
| env_time                | 14           |
| ep_rewmean              | 18.8         |
| episodes                | 416          |
| eplenmean               | 23.2         |
| fps                     | 100          |
| mean 100 episode reward | 18.8         |
| n_updates               | 0            |
| qs_abs_difference       | 3.67         |
| qs_difference           | -2.82        |
| qs_mean                 | 0.0039946516 |
| time_elapsed            | 90           |
| total timesteps         | 9065         |
| train_time              | 0            |
| update_time             | 68           |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 8.58       |
| env_time                | 14         |
| ep_rewmean              | 18.6       |
| episodes                | 420        |
| eplenmean               | 23         |
| fps                     | 99         |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 7.66       |
| qs_difference           | -7.66      |
| qs_mean                 | 0.04695332 |
| time_elapsed            | 91         |
| total timesteps         | 9150       |
| train_time              | 0          |
| update_time             | 70         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.13       |
| env_time                | 14         |
| ep_rewmean              | 18.5       |
| episodes                | 424        |
| eplenmean               | 23         |
| fps                     | 98         |
| mean 100 episode reward | 18.5       |
| n_updates               | 0          |
| qs_abs_difference       | 5.87       |
| qs_difference           | -5.87      |
| qs_mean                 | 0.08113634 |
| time_elapsed            | 93         |
| total timesteps         | 9232       |
| train_time              | 0          |
| update_time             | 72         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.29        |
| env_time                | 14          |
| ep_rewmean              | 18.3        |
| episodes                | 428         |
| eplenmean               | 23          |
| fps                     | 97          |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 3.37        |
| qs_difference           | -3.37       |
| qs_mean                 | -0.03483977 |
| time_elapsed            | 95          |
| total timesteps         | 9307        |
| train_time              | 0           |
| update_time             | 73          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.74       |
| env_time                | 15         |
| ep_rewmean              | 17.3       |
| episodes                | 432        |
| eplenmean               | 22.6       |
| fps                     | 98         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.91       |
| qs_difference           | -4.91      |
| qs_mean                 | 0.03857187 |
| time_elapsed            | 95         |
| total timesteps         | 9392       |
| train_time              | 0          |
| update_time             | 73         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.39       |
| env_time                | 15         |
| ep_rewmean              | 17.1       |
| episodes                | 436        |
| eplenmean               | 22.4       |
| fps                     | 97         |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 3.8        |
| qs_difference           | -3.8       |
| qs_mean                 | 0.04746961 |
| time_elapsed            | 97         |
| total timesteps         | 9455       |
| train_time              | 0          |
| update_time             | 75         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.24       |
| env_time                | 15         |
| ep_rewmean              | 16.8       |
| episodes                | 440        |
| eplenmean               | 22.1       |
| fps                     | 96         |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.1        |
| qs_difference           | -3.93      |
| qs_mean                 | 0.09323788 |
| time_elapsed            | 99         |
| total timesteps         | 9539       |
| train_time              | 0          |
| update_time             | 76         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.29        |
| env_time                | 15          |
| ep_rewmean              | 16.8        |
| episodes                | 444         |
| eplenmean               | 22.3        |
| fps                     | 95          |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.46        |
| qs_difference           | -5.46       |
| qs_mean                 | 0.022920841 |
| time_elapsed            | 101         |
| total timesteps         | 9615        |
| train_time              | 0           |
| update_time             | 78          |
-----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 5.05      |
| env_time                | 15        |
| ep_rewmean              | 16.6      |
| episodes                | 448       |
| eplenmean               | 22.1      |
| fps                     | 95        |
| mean 100 episode reward | 16.6      |
| n_updates               | 0         |
| qs_abs_difference       | 4.93      |
| qs_difference           | -4.93     |
| qs_mean                 | 0.0846067 |
| time_elapsed            | 101       |
| total timesteps         | 9686      |
| train_time              | 0         |
| update_time             | 78        |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.91        |
| env_time                | 15          |
| ep_rewmean              | 16.3        |
| episodes                | 452         |
| eplenmean               | 21.7        |
| fps                     | 94          |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 3.84        |
| qs_difference           | -3.84       |
| qs_mean                 | 0.054855295 |
| time_elapsed            | 102         |
| total timesteps         | 9759        |
| train_time              | 0           |
| update_time             | 79          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.85        |
| env_time                | 15          |
| ep_rewmean              | 16.3        |
| episodes                | 456         |
| eplenmean               | 21.6        |
| fps                     | 93          |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 5.44        |
| qs_difference           | -5.44       |
| qs_mean                 | 0.017528603 |
| time_elapsed            | 104         |
| total timesteps         | 9830        |
| train_time              | 0           |
| update_time             | 81          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 11.2        |
| env_time                | 15          |
| ep_rewmean              | 16.4        |
| episodes                | 460         |
| eplenmean               | 21.8        |
| fps                     | 92          |
| mean 100 episode reward | 16.4        |
| n_updates               | 0           |
| qs_abs_difference       | 9.05        |
| qs_difference           | -9.05       |
| qs_mean                 | 0.080684304 |
| time_elapsed            | 106         |
| total timesteps         | 9907        |
| train_time              | 0           |
| update_time             | 83          |
-----------------------------------------
----------------------------------------
| eval mean 100 episod... | 3.9        |
| eval_abs_qs_difference  | 2.4626489  |
| eval_discount_q         | 3.84       |
| eval_ep_rewmean         | 3.91       |
| eval_eplenmean          | 7          |
| eval_qs                 | -0.9053001 |
| eval_qs_difference      | -2.46      |
| eval_time_elapsed       | 0          |
| total timesteps         | 10001      |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 29.2       |
| env_time                | 16         |
| ep_rewmean              | 16.6       |
| episodes                | 464        |
| eplenmean               | 21.6       |
| fps                     | 92         |
| mean 100 episode reward | 16.6       |
| n_updates               | 0          |
| qs_abs_difference       | 31.3       |
| qs_difference           | -31.3      |
| qs_mean                 | 0.13049315 |
| time_elapsed            | 108        |
| total timesteps         | 10007      |
| train_time              | 0          |
| update_time             | 84         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.21        |
| env_time                | 16          |
| ep_rewmean              | 16.7        |
| episodes                | 468         |
| eplenmean               | 21.5        |
| fps                     | 92          |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.15        |
| qs_difference           | -3.15       |
| qs_mean                 | 0.008567607 |
| time_elapsed            | 108         |
| total timesteps         | 10087       |
| train_time              | 0           |
| update_time             | 84          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.13       |
| env_time                | 16         |
| ep_rewmean              | 16.8       |
| episodes                | 472        |
| eplenmean               | 21.7       |
| fps                     | 91         |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.39       |
| qs_difference           | -4.39      |
| qs_mean                 | 0.07990161 |
| time_elapsed            | 110        |
| total timesteps         | 10165      |
| train_time              | 0          |
| update_time             | 86         |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 19.1        |
| env_time                | 16          |
| ep_rewmean              | 17.9        |
| episodes                | 476         |
| eplenmean               | 22.3        |
| fps                     | 90          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 35.6        |
| qs_difference           | -35.6       |
| qs_mean                 | 0.090755604 |
| time_elapsed            | 114         |
| total timesteps         | 10341       |
| train_time              | 0           |
| update_time             | 90          |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.49        |
| env_time                | 16          |
| ep_rewmean              | 17.9        |
| episodes                | 480         |
| eplenmean               | 22.5        |
| fps                     | 89          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 8.31        |
| qs_difference           | -8.31       |
| qs_mean                 | 0.045547713 |
| time_elapsed            | 116         |
| total timesteps         | 10441       |
| train_time              | 0           |
| update_time             | 91          |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 16.4         |
| env_time                | 16           |
| ep_rewmean              | 17.6         |
| episodes                | 484          |
| eplenmean               | 22           |
| fps                     | 88           |
| mean 100 episode reward | 17.6         |
| n_updates               | 0            |
| qs_abs_difference       | 16.7         |
| qs_difference           | -16.7        |
| qs_mean                 | -0.023317594 |
| time_elapsed            | 118          |
| total timesteps         | 10527        |
| train_time              | 0            |
| update_time             | 93           |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 26.3        |
| env_time                | 17          |
| ep_rewmean              | 17.5        |
| episodes                | 488         |
| eplenmean               | 21.8        |
| fps                     | 88          |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 27.6        |
| qs_difference           | -27.6       |
| qs_mean                 | 0.090885565 |
| time_elapsed            | 120         |
| total timesteps         | 10643       |
| train_time              | 0           |
| update_time             | 95          |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 14.2       |
| env_time                | 17         |
| ep_rewmean              | 17.5       |
| episodes                | 492        |
| eplenmean               | 21.9       |
| fps                     | 87         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 13.8       |
| qs_difference           | -13.8      |
| qs_mean                 | 0.10439922 |
| time_elapsed            | 122        |
| total timesteps         | 10722      |
| train_time              | 0          |
| update_time             | 97         |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.64       |
| env_time                | 17         |
| ep_rewmean              | 16.7       |
| episodes                | 496        |
| eplenmean               | 21.4       |
| fps                     | 87         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.14       |
| qs_difference           | -2.96      |
| qs_mean                 | 0.04259343 |
| time_elapsed            | 122        |
| total timesteps         | 10796      |
| train_time              | 0          |
| update_time             | 97         |
----------------------------------------
---------------------------------------
| act_time                | 1         |
| current_lr              | 0.0003    |
| discount_q              | 5.27      |
| env_time                | 17        |
| ep_rewmean              | 17.3      |
| episodes                | 500       |
| eplenmean               | 21.8      |
| fps                     | 86        |
| mean 100 episode reward | 17.3      |
| n_updates               | 0         |
| qs_abs_difference       | 7.56      |
| qs_difference           | -7.56     |
| qs_mean                 | 0.2202482 |
| time_elapsed            | 126       |
| total timesteps         | 10908     |
| train_time              | 0         |
| update_time             | 100       |
---------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 4.67        |
| env_time                | 17          |
| ep_rewmean              | 17.3        |
| episodes                | 504         |
| eplenmean               | 21.9        |
| fps                     | 86          |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 2.65        |
| qs_difference           | -2.54       |
| qs_mean                 | 0.032995917 |
| time_elapsed            | 126         |
| total timesteps         | 10977       |
| train_time              | 0           |
| update_time             | 100         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.79        |
| env_time                | 17          |
| ep_rewmean              | 17.2        |
| episodes                | 508         |
| eplenmean               | 21.6        |
| fps                     | 85          |
| mean 100 episode reward | 17.2        |
| n_updates               | 0           |
| qs_abs_difference       | 4.17        |
| qs_difference           | -4.17       |
| qs_mean                 | 0.073580615 |
| time_elapsed            | 128         |
| total timesteps         | 11045       |
| train_time              | 0           |
| update_time             | 102         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.32       |
| env_time                | 17         |
| ep_rewmean              | 16.9       |
| episodes                | 512        |
| eplenmean               | 21.2       |
| fps                     | 86         |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 5.55       |
| qs_difference           | -5.55      |
| qs_mean                 | 0.14011133 |
| time_elapsed            | 128        |
| total timesteps         | 11096      |
| train_time              | 0          |
| update_time             | 102        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 1.38        |
| env_time                | 17          |
| ep_rewmean              | 16.9        |
| episodes                | 516         |
| eplenmean               | 21.4        |
| fps                     | 84          |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 2.77        |
| qs_difference           | 1.98        |
| qs_mean                 | 0.044822626 |
| time_elapsed            | 132         |
| total timesteps         | 11200       |
| train_time              | 0           |
| update_time             | 106         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 6.96         |
| env_time                | 18           |
| ep_rewmean              | 16.7         |
| episodes                | 520          |
| eplenmean               | 21.1         |
| fps                     | 84           |
| mean 100 episode reward | 16.7         |
| n_updates               | 0            |
| qs_abs_difference       | 4.93         |
| qs_difference           | -4.93        |
| qs_mean                 | -0.018293338 |
| time_elapsed            | 133          |
| total timesteps         | 11261        |
| train_time              | 0            |
| update_time             | 106          |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.42       |
| env_time                | 18         |
| ep_rewmean              | 17.5       |
| episodes                | 524        |
| eplenmean               | 21.4       |
| fps                     | 84         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 7.46       |
| qs_difference           | -7.46      |
| qs_mean                 | 0.12626179 |
| time_elapsed            | 135        |
| total timesteps         | 11373      |
| train_time              | 0          |
| update_time             | 108        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.2        |
| env_time                | 18         |
| ep_rewmean              | 17.6       |
| episodes                | 528        |
| eplenmean               | 21.4       |
| fps                     | 83         |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 6.68       |
| qs_difference           | -6.68      |
| qs_mean                 | 0.11942776 |
| time_elapsed            | 137        |
| total timesteps         | 11447      |
| train_time              | 0          |
| update_time             | 110        |
----------------------------------------
-------------------------------------------
| act_time                | 1             |
| current_lr              | 0.0003        |
| discount_q              | 4.23          |
| env_time                | 18            |
| ep_rewmean              | 17.6          |
| episodes                | 532           |
| eplenmean               | 21.3          |
| fps                     | 82            |
| mean 100 episode reward | 17.6          |
| n_updates               | 0             |
| qs_abs_difference       | 2.72          |
| qs_difference           | -2.72         |
| qs_mean                 | -0.0073773563 |
| time_elapsed            | 139           |
| total timesteps         | 11521         |
| train_time              | 0             |
| update_time             | 112           |
-------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.2         |
| env_time                | 18          |
| ep_rewmean              | 17.8        |
| episodes                | 536         |
| eplenmean               | 21.6        |
| fps                     | 82          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 4.91        |
| qs_difference           | -4.91       |
| qs_mean                 | 0.030565575 |
| time_elapsed            | 141         |
| total timesteps         | 11616       |
| train_time              | 0           |
| update_time             | 114         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 8.45        |
| env_time                | 18          |
| ep_rewmean              | 17.7        |
| episodes                | 540         |
| eplenmean               | 21.6        |
| fps                     | 82          |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 8           |
| qs_difference           | -8          |
| qs_mean                 | 0.075340725 |
| time_elapsed            | 141         |
| total timesteps         | 11694       |
| train_time              | 0           |
| update_time             | 114         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 5.83        |
| env_time                | 18          |
| ep_rewmean              | 17.7        |
| episodes                | 544         |
| eplenmean               | 21.5        |
| fps                     | 81          |
| mean 100 episode reward | 17.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.22        |
| qs_difference           | -2.98       |
| qs_mean                 | 0.009236711 |
| time_elapsed            | 143         |
| total timesteps         | 11763       |
| train_time              | 0           |
| update_time             | 116         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 2.81         |
| env_time                | 19           |
| ep_rewmean              | 18.7         |
| episodes                | 548          |
| eplenmean               | 22.2         |
| fps                     | 80           |
| mean 100 episode reward | 18.7         |
| n_updates               | 0            |
| qs_abs_difference       | 2.98         |
| qs_difference           | -0.198       |
| qs_mean                 | 0.0054209637 |
| time_elapsed            | 148          |
| total timesteps         | 11909        |
| train_time              | 0            |
| update_time             | 120          |
------------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 3.41         |
| env_time                | 19           |
| ep_rewmean              | 18.7         |
| episodes                | 552          |
| eplenmean               | 22.3         |
| fps                     | 80           |
| mean 100 episode reward | 18.7         |
| n_updates               | 0            |
| qs_abs_difference       | 3.18         |
| qs_difference           | -3.18        |
| qs_mean                 | -0.009004921 |
| time_elapsed            | 148          |
| total timesteps         | 11986        |
| train_time              | 0            |
| update_time             | 120          |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 6.06       |
| env_time                | 19         |
| ep_rewmean              | 18.6       |
| episodes                | 556        |
| eplenmean               | 22.2       |
| fps                     | 80         |
| mean 100 episode reward | 18.6       |
| n_updates               | 0          |
| qs_abs_difference       | 5.5        |
| qs_difference           | -5.5       |
| qs_mean                 | 0.11871623 |
| time_elapsed            | 150        |
| total timesteps         | 12054      |
| train_time              | 0          |
| update_time             | 122        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 6.15        |
| env_time                | 19          |
| ep_rewmean              | 18.7        |
| episodes                | 560         |
| eplenmean               | 22.3        |
| fps                     | 79          |
| mean 100 episode reward | 18.7        |
| n_updates               | 0           |
| qs_abs_difference       | 5.47        |
| qs_difference           | -5.47       |
| qs_mean                 | 0.043278486 |
| time_elapsed            | 152         |
| total timesteps         | 12135       |
| train_time              | 0           |
| update_time             | 124         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 4.71       |
| env_time                | 19         |
| ep_rewmean              | 18         |
| episodes                | 564        |
| eplenmean               | 21.9       |
| fps                     | 79         |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 3.66       |
| qs_difference           | -3.66      |
| qs_mean                 | 0.15736742 |
| time_elapsed            | 152        |
| total timesteps         | 12194      |
| train_time              | 0          |
| update_time             | 124        |
----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 4.5          |
| env_time                | 19           |
| ep_rewmean              | 18           |
| episodes                | 568          |
| eplenmean               | 22           |
| fps                     | 79           |
| mean 100 episode reward | 18           |
| n_updates               | 0            |
| qs_abs_difference       | 2.49         |
| qs_difference           | -0.226       |
| qs_mean                 | 0.0011611767 |
| time_elapsed            | 155          |
| total timesteps         | 12288        |
| train_time              | 0            |
| update_time             | 126          |
------------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 3.38         |
| env_time                | 19           |
| ep_rewmean              | 18.1         |
| episodes                | 572          |
| eplenmean               | 22           |
| fps                     | 78           |
| mean 100 episode reward | 18.1         |
| n_updates               | 0            |
| qs_abs_difference       | 2.42         |
| qs_difference           | -2.39        |
| qs_mean                 | -0.044152357 |
| time_elapsed            | 157          |
| total timesteps         | 12365        |
| train_time              | 0            |
| update_time             | 128          |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 9.13       |
| env_time                | 20         |
| ep_rewmean              | 16.9       |
| episodes                | 576        |
| eplenmean               | 21.2       |
| fps                     | 78         |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 11         |
| qs_difference           | -11        |
| qs_mean                 | 0.14832518 |
| time_elapsed            | 159        |
| total timesteps         | 12462      |
| train_time              | 0          |
| update_time             | 130        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 9.05       |
| env_time                | 20         |
| ep_rewmean              | 16.9       |
| episodes                | 580        |
| eplenmean               | 21.1       |
| fps                     | 77         |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 7.66       |
| qs_difference           | -7.66      |
| qs_mean                 | 0.05510823 |
| time_elapsed            | 161        |
| total timesteps         | 12548      |
| train_time              | 0          |
| update_time             | 132        |
----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 7.63       |
| env_time                | 20         |
| ep_rewmean              | 16.8       |
| episodes                | 584        |
| eplenmean               | 21         |
| fps                     | 76         |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 6.59       |
| qs_difference           | -6.59      |
| qs_mean                 | 0.10138995 |
| time_elapsed            | 164        |
| total timesteps         | 12630      |
| train_time              | 0          |
| update_time             | 134        |
----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 13          |
| env_time                | 20          |
| ep_rewmean              | 16.4        |
| episodes                | 588         |
| eplenmean               | 20.8        |
| fps                     | 76          |
| mean 100 episode reward | 16.4        |
| n_updates               | 0           |
| qs_abs_difference       | 9.71        |
| qs_difference           | -9.71       |
| qs_mean                 | -0.02035688 |
| time_elapsed            | 166         |
| total timesteps         | 12723       |
| train_time              | 0           |
| update_time             | 136         |
-----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 5.64         |
| env_time                | 20           |
| ep_rewmean              | 16.2         |
| episodes                | 592          |
| eplenmean               | 20.6         |
| fps                     | 76           |
| mean 100 episode reward | 16.2         |
| n_updates               | 0            |
| qs_abs_difference       | 3.46         |
| qs_difference           | -3.44        |
| qs_mean                 | -0.029991528 |
| time_elapsed            | 166          |
| total timesteps         | 12780        |
| train_time              | 0            |
| update_time             | 136          |
------------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 8.24       |
| env_time                | 20         |
| ep_rewmean              | 16.5       |
| episodes                | 596        |
| eplenmean               | 20.6       |
| fps                     | 76         |
| mean 100 episode reward | 16.5       |
| n_updates               | 0          |
| qs_abs_difference       | 7.63       |
| qs_difference           | -7.63      |
| qs_mean                 | 0.03474578 |
| time_elapsed            | 169        |
| total timesteps         | 12861      |
| train_time              | 0          |
| update_time             | 138        |
----------------------------------------
------------------------------------------
| act_time                | 1            |
| current_lr              | 0.0003       |
| discount_q              | 5            |
| env_time                | 20           |
| ep_rewmean              | 15.8         |
| episodes                | 600          |
| eplenmean               | 20.2         |
| fps                     | 75           |
| mean 100 episode reward | 15.8         |
| n_updates               | 0            |
| qs_abs_difference       | 4.22         |
| qs_difference           | -4.22        |
| qs_mean                 | -0.024671955 |
| time_elapsed            | 171          |
| total timesteps         | 12925        |
| train_time              | 0            |
| update_time             | 140          |
------------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 3.39        |
| env_time                | 20          |
| ep_rewmean              | 15.9        |
| episodes                | 604         |
| eplenmean               | 20.3        |
| fps                     | 74          |
| mean 100 episode reward | 15.9        |
| n_updates               | 0           |
| qs_abs_difference       | 2.73        |
| qs_difference           | -2.73       |
| qs_mean                 | -0.20848049 |
| time_elapsed            | 173         |
| total timesteps         | 13003       |
| train_time              | 0           |
| update_time             | 143         |
-----------------------------------------
-----------------------------------------
| act_time                | 1           |
| current_lr              | 0.0003      |
| discount_q              | 7.97        |
| env_time                | 21          |
| ep_rewmean              | 16.3        |
| episodes                | 608         |
| eplenmean               | 20.4        |
| fps                     | 75          |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 8.54        |
| qs_difference           | -8.54       |
| qs_mean                 | 0.025311958 |
| time_elapsed            | 173         |
| total timesteps         | 13090       |
| train_time              | 0           |
| update_time             | 143         |
-----------------------------------------
----------------------------------------
| act_time                | 1          |
| current_lr              | 0.0003     |
| discount_q              | 5.77       |
| env_time                | 21         |
| ep_rewmean              | 16.4       |
| episodes                | 612        |
| eplenmean               | 20.6       |
| fps                     | 74         |
| mean 100 episode reward | 16.4       |
| n_updates               | 0          |
| qs_abs_difference       | 5.04       |
| qs_difference           | -5.04      |
| qs_mean                 | 0.12326319 |
| time_elapsed            | 176        |
| total timesteps         | 13161      |
| train_time              | 0          |
| update_time             | 145        |
----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 3.85         |
| env_time                | 21           |
| ep_rewmean              | 16.5         |
| episodes                | 616          |
| eplenmean               | 20.5         |
| fps                     | 74           |
| mean 100 episode reward | 16.5         |
| n_updates               | 0            |
| qs_abs_difference       | 3.51         |
| qs_difference           | -3.51        |
| qs_mean                 | -0.050575342 |
| time_elapsed            | 178          |
| total timesteps         | 13247        |
| train_time              | 0            |
| update_time             | 147          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.21        |
| env_time                | 21          |
| ep_rewmean              | 16.8        |
| episodes                | 620         |
| eplenmean               | 20.6        |
| fps                     | 73          |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 2.96        |
| qs_difference           | -2.96       |
| qs_mean                 | -0.08494324 |
| time_elapsed            | 181         |
| total timesteps         | 13325       |
| train_time              | 0           |
| update_time             | 149         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 2.91        |
| env_time                | 21          |
| ep_rewmean              | 16.3        |
| episodes                | 624         |
| eplenmean               | 20.5        |
| fps                     | 73          |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 3.75        |
| qs_difference           | -3.75       |
| qs_mean                 | -0.07423131 |
| time_elapsed            | 183         |
| total timesteps         | 13421       |
| train_time              | 0           |
| update_time             | 152         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 8.3        |
| env_time                | 21         |
| ep_rewmean              | 16         |
| episodes                | 628        |
| eplenmean               | 20.3       |
| fps                     | 73         |
| mean 100 episode reward | 16         |
| n_updates               | 0          |
| qs_abs_difference       | 6.18       |
| qs_difference           | -6.18      |
| qs_mean                 | 0.12229713 |
| time_elapsed            | 183        |
| total timesteps         | 13478      |
| train_time              | 0          |
| update_time             | 152        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 9.33       |
| env_time                | 21         |
| ep_rewmean              | 15.8       |
| episodes                | 632        |
| eplenmean               | 20.2       |
| fps                     | 72         |
| mean 100 episode reward | 15.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.82       |
| qs_difference           | -4.77      |
| qs_mean                 | 0.13543616 |
| time_elapsed            | 186        |
| total timesteps         | 13538      |
| train_time              | 0          |
| update_time             | 154        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.34        |
| env_time                | 21          |
| ep_rewmean              | 15.7        |
| episodes                | 636         |
| eplenmean               | 19.9        |
| fps                     | 72          |
| mean 100 episode reward | 15.7        |
| n_updates               | 0           |
| qs_abs_difference       | 4.55        |
| qs_difference           | -4.55       |
| qs_mean                 | 0.032204524 |
| time_elapsed            | 188         |
| total timesteps         | 13608       |
| train_time              | 0           |
| update_time             | 156         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.25       |
| env_time                | 22         |
| ep_rewmean              | 16.1       |
| episodes                | 640        |
| eplenmean               | 20.6       |
| fps                     | 71         |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 6.29       |
| qs_difference           | -6.29      |
| qs_mean                 | 0.20455658 |
| time_elapsed            | 191        |
| total timesteps         | 13752      |
| train_time              | 0          |
| update_time             | 159        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.89       |
| env_time                | 22         |
| ep_rewmean              | 16.3       |
| episodes                | 644        |
| eplenmean               | 20.6       |
| fps                     | 71         |
| mean 100 episode reward | 16.3       |
| n_updates               | 0          |
| qs_abs_difference       | 3.99       |
| qs_difference           | -3.99      |
| qs_mean                 | 0.08151903 |
| time_elapsed            | 193        |
| total timesteps         | 13827      |
| train_time              | 0          |
| update_time             | 161        |
----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 4.09         |
| env_time                | 22           |
| ep_rewmean              | 15.5         |
| episodes                | 648          |
| eplenmean               | 19.9         |
| fps                     | 71           |
| mean 100 episode reward | 15.5         |
| n_updates               | 0            |
| qs_abs_difference       | 3.95         |
| qs_difference           | -3.95        |
| qs_mean                 | -0.017779272 |
| time_elapsed            | 194          |
| total timesteps         | 13897        |
| train_time              | 0            |
| update_time             | 161          |
------------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.78       |
| env_time                | 22         |
| ep_rewmean              | 15.5       |
| episodes                | 652        |
| eplenmean               | 20         |
| fps                     | 71         |
| mean 100 episode reward | 15.5       |
| n_updates               | 0          |
| qs_abs_difference       | 8.38       |
| qs_difference           | -8.38      |
| qs_mean                 | 0.07069979 |
| time_elapsed            | 196        |
| total timesteps         | 13986      |
| train_time              | 0          |
| update_time             | 163        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 18.7      |
| env_time                | 22        |
| ep_rewmean              | 15.8      |
| episodes                | 656       |
| eplenmean               | 20.2      |
| fps                     | 70        |
| mean 100 episode reward | 15.8      |
| n_updates               | 0         |
| qs_abs_difference       | 20.3      |
| qs_difference           | -20.3     |
| qs_mean                 | 0.1340139 |
| time_elapsed            | 199       |
| total timesteps         | 14078     |
| train_time              | 0         |
| update_time             | 166       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 27.5       |
| env_time                | 22         |
| ep_rewmean              | 16         |
| episodes                | 660        |
| eplenmean               | 20.3       |
| fps                     | 70         |
| mean 100 episode reward | 16         |
| n_updates               | 0          |
| qs_abs_difference       | 24.6       |
| qs_difference           | -24.6      |
| qs_mean                 | 0.13783112 |
| time_elapsed            | 201        |
| total timesteps         | 14166      |
| train_time              | 0          |
| update_time             | 168        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.8        |
| env_time                | 22         |
| ep_rewmean              | 16.2       |
| episodes                | 664        |
| eplenmean               | 20.4       |
| fps                     | 69         |
| mean 100 episode reward | 16.2       |
| n_updates               | 0          |
| qs_abs_difference       | 5.19       |
| qs_difference           | -5.19      |
| qs_mean                 | 0.13108733 |
| time_elapsed            | 204        |
| total timesteps         | 14239      |
| train_time              | 0          |
| update_time             | 170        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.51       |
| env_time                | 22         |
| ep_rewmean              | 16.7       |
| episodes                | 668        |
| eplenmean               | 20.5       |
| fps                     | 69         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 7.36       |
| qs_difference           | -7.36      |
| qs_mean                 | 0.11066847 |
| time_elapsed            | 206        |
| total timesteps         | 14334      |
| train_time              | 0          |
| update_time             | 173        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.1         |
| env_time                | 23          |
| ep_rewmean              | 16.7        |
| episodes                | 672         |
| eplenmean               | 20.5        |
| fps                     | 68          |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 4.11        |
| qs_difference           | -4.11       |
| qs_mean                 | 0.052892026 |
| time_elapsed            | 209         |
| total timesteps         | 14413       |
| train_time              | 0           |
| update_time             | 175         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.15        |
| env_time                | 23          |
| ep_rewmean              | 16.6        |
| episodes                | 676         |
| eplenmean               | 20.3        |
| fps                     | 69          |
| mean 100 episode reward | 16.6        |
| n_updates               | 0           |
| qs_abs_difference       | 4.84        |
| qs_difference           | -4.84       |
| qs_mean                 | 0.052176457 |
| time_elapsed            | 209         |
| total timesteps         | 14492       |
| train_time              | 0           |
| update_time             | 175         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 4.88         |
| env_time                | 23           |
| ep_rewmean              | 16.5         |
| episodes                | 680          |
| eplenmean               | 20.4         |
| fps                     | 68           |
| mean 100 episode reward | 16.5         |
| n_updates               | 0            |
| qs_abs_difference       | 4.21         |
| qs_difference           | -4.21        |
| qs_mean                 | -0.076104626 |
| time_elapsed            | 212          |
| total timesteps         | 14585        |
| train_time              | 0            |
| update_time             | 178          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 9.51        |
| env_time                | 23          |
| ep_rewmean              | 16.3        |
| episodes                | 684         |
| eplenmean               | 20.2        |
| fps                     | 68          |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 8.51        |
| qs_difference           | -8.51       |
| qs_mean                 | 0.066579975 |
| time_elapsed            | 215         |
| total timesteps         | 14651       |
| train_time              | 0           |
| update_time             | 180         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 3.74         |
| env_time                | 23           |
| ep_rewmean              | 16.2         |
| episodes                | 688          |
| eplenmean               | 20.1         |
| fps                     | 67           |
| mean 100 episode reward | 16.2         |
| n_updates               | 0            |
| qs_abs_difference       | 2.52         |
| qs_difference           | -0.665       |
| qs_mean                 | -0.034484155 |
| time_elapsed            | 217          |
| total timesteps         | 14736        |
| train_time              | 0            |
| update_time             | 183          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 11.1        |
| env_time                | 23          |
| ep_rewmean              | 16.3        |
| episodes                | 692         |
| eplenmean               | 20.5        |
| fps                     | 67          |
| mean 100 episode reward | 16.3        |
| n_updates               | 0           |
| qs_abs_difference       | 9.99        |
| qs_difference           | -9.99       |
| qs_mean                 | 0.020375608 |
| time_elapsed            | 220         |
| total timesteps         | 14829       |
| train_time              | 0           |
| update_time             | 185         |
-----------------------------------------
--------------------------------------
| act_time                | 2        |
| current_lr              | 0.0003   |
| discount_q              | 8.98     |
| env_time                | 24       |
| ep_rewmean              | 16.6     |
| episodes                | 696      |
| eplenmean               | 20.9     |
| fps                     | 66       |
| mean 100 episode reward | 16.6     |
| n_updates               | 0        |
| qs_abs_difference       | 11.8     |
| qs_difference           | -11.8    |
| qs_mean                 | 0.063463 |
| time_elapsed            | 223      |
| total timesteps         | 14949    |
| train_time              | 0        |
| update_time             | 188      |
--------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.02       |
| env_time                | 24         |
| ep_rewmean              | 17         |
| episodes                | 700        |
| eplenmean               | 21.1       |
| fps                     | 66         |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 3.92       |
| qs_difference           | -3.92      |
| qs_mean                 | 0.12705272 |
| time_elapsed            | 226        |
| total timesteps         | 15030      |
| train_time              | 0          |
| update_time             | 190        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.69       |
| env_time                | 24         |
| ep_rewmean              | 17.3       |
| episodes                | 704        |
| eplenmean               | 21.2       |
| fps                     | 66         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 3.84       |
| qs_difference           | -3.84      |
| qs_mean                 | 0.06771695 |
| time_elapsed            | 228        |
| total timesteps         | 15127      |
| train_time              | 0          |
| update_time             | 193        |
----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 3.75         |
| env_time                | 24           |
| ep_rewmean              | 17.1         |
| episodes                | 708          |
| eplenmean               | 21.4         |
| fps                     | 65           |
| mean 100 episode reward | 17.1         |
| n_updates               | 0            |
| qs_abs_difference       | 2.55         |
| qs_difference           | -0.377       |
| qs_mean                 | -0.014404427 |
| time_elapsed            | 231          |
| total timesteps         | 15225        |
| train_time              | 0            |
| update_time             | 195          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.33        |
| env_time                | 24          |
| ep_rewmean              | 17.1        |
| episodes                | 712         |
| eplenmean               | 21.4        |
| fps                     | 65          |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 3.32        |
| qs_difference           | -3.32       |
| qs_mean                 | -0.04921541 |
| time_elapsed            | 231         |
| total timesteps         | 15299       |
| train_time              | 0           |
| update_time             | 195         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.93       |
| env_time                | 24         |
| ep_rewmean              | 17         |
| episodes                | 716        |
| eplenmean               | 21.2       |
| fps                     | 65         |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 4.83       |
| qs_difference           | -4.83      |
| qs_mean                 | 0.11737151 |
| time_elapsed            | 234        |
| total timesteps         | 15371      |
| train_time              | 0          |
| update_time             | 198        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.77        |
| env_time                | 24          |
| ep_rewmean              | 16.7        |
| episodes                | 720         |
| eplenmean               | 21.2        |
| fps                     | 65          |
| mean 100 episode reward | 16.7        |
| n_updates               | 0           |
| qs_abs_difference       | 3.76        |
| qs_difference           | -3.76       |
| qs_mean                 | 0.058404293 |
| time_elapsed            | 237         |
| total timesteps         | 15442       |
| train_time              | 0           |
| update_time             | 201         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.17       |
| env_time                | 24         |
| ep_rewmean              | 16.7       |
| episodes                | 724        |
| eplenmean               | 21         |
| fps                     | 64         |
| mean 100 episode reward | 16.7       |
| n_updates               | 0          |
| qs_abs_difference       | 4.81       |
| qs_difference           | -4.81      |
| qs_mean                 | 0.05781171 |
| time_elapsed            | 240        |
| total timesteps         | 15521      |
| train_time              | 0          |
| update_time             | 203        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.33       |
| env_time                | 25         |
| ep_rewmean              | 17.2       |
| episodes                | 728        |
| eplenmean               | 21.6       |
| fps                     | 64         |
| mean 100 episode reward | 17.2       |
| n_updates               | 0          |
| qs_abs_difference       | 9.26       |
| qs_difference           | -9.26      |
| qs_mean                 | 0.01520997 |
| time_elapsed            | 243        |
| total timesteps         | 15639      |
| train_time              | 0          |
| update_time             | 206        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 8.09        |
| env_time                | 25          |
| ep_rewmean              | 17.3        |
| episodes                | 732         |
| eplenmean               | 21.8        |
| fps                     | 63          |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 7.32        |
| qs_difference           | -7.32       |
| qs_mean                 | 0.058368415 |
| time_elapsed            | 245         |
| total timesteps         | 15721       |
| train_time              | 0           |
| update_time             | 208         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 10.1        |
| env_time                | 25          |
| ep_rewmean              | 17.6        |
| episodes                | 736         |
| eplenmean               | 22.1        |
| fps                     | 63          |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 8.9         |
| qs_difference           | -8.9        |
| qs_mean                 | 0.109089896 |
| time_elapsed            | 248         |
| total timesteps         | 15816       |
| train_time              | 0           |
| update_time             | 211         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 38          |
| env_time                | 25          |
| ep_rewmean              | 17.9        |
| episodes                | 740         |
| eplenmean               | 22          |
| fps                     | 63          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 31          |
| qs_difference           | -31         |
| qs_mean                 | 0.022610003 |
| time_elapsed            | 251         |
| total timesteps         | 15948       |
| train_time              | 0           |
| update_time             | 214         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 4.31         |
| env_time                | 25           |
| ep_rewmean              | 19.6         |
| episodes                | 744          |
| eplenmean               | 22.9         |
| fps                     | 62           |
| mean 100 episode reward | 19.6         |
| n_updates               | 0            |
| qs_abs_difference       | 7.48         |
| qs_difference           | -7.48        |
| qs_mean                 | 0.0137029225 |
| time_elapsed            | 257          |
| total timesteps         | 16120        |
| train_time              | 0            |
| update_time             | 219          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.03        |
| env_time                | 26          |
| ep_rewmean              | 19.8        |
| episodes                | 748         |
| eplenmean               | 23.1        |
| fps                     | 62          |
| mean 100 episode reward | 19.8        |
| n_updates               | 0           |
| qs_abs_difference       | 3.79        |
| qs_difference           | -3.79       |
| qs_mean                 | -0.02038629 |
| time_elapsed            | 260         |
| total timesteps         | 16211       |
| train_time              | 0           |
| update_time             | 222         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 17.5       |
| env_time                | 26         |
| ep_rewmean              | 20         |
| episodes                | 752        |
| eplenmean               | 23.5       |
| fps                     | 61         |
| mean 100 episode reward | 20         |
| n_updates               | 0          |
| qs_abs_difference       | 18.1       |
| qs_difference           | -18.1      |
| qs_mean                 | 0.03795609 |
| time_elapsed            | 263        |
| total timesteps         | 16332      |
| train_time              | 0          |
| update_time             | 225        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 7.65       |
| env_time                | 26         |
| ep_rewmean              | 19.7       |
| episodes                | 756        |
| eplenmean               | 23.2       |
| fps                     | 62         |
| mean 100 episode reward | 19.7       |
| n_updates               | 0          |
| qs_abs_difference       | 5.56       |
| qs_difference           | -5.56      |
| qs_mean                 | 0.09246002 |
| time_elapsed            | 263        |
| total timesteps         | 16397      |
| train_time              | 0          |
| update_time             | 225        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.98       |
| env_time                | 26         |
| ep_rewmean              | 19.5       |
| episodes                | 760        |
| eplenmean               | 23.2       |
| fps                     | 61         |
| mean 100 episode reward | 19.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.03       |
| qs_difference           | -2.85      |
| qs_mean                 | 0.03442474 |
| time_elapsed            | 266        |
| total timesteps         | 16484      |
| train_time              | 0          |
| update_time             | 227        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 15.1       |
| env_time                | 26         |
| ep_rewmean              | 19.6       |
| episodes                | 764        |
| eplenmean               | 23.4       |
| fps                     | 61         |
| mean 100 episode reward | 19.6       |
| n_updates               | 0          |
| qs_abs_difference       | 15.2       |
| qs_difference           | -15.2      |
| qs_mean                 | 0.10870957 |
| time_elapsed            | 269        |
| total timesteps         | 16579      |
| train_time              | 0          |
| update_time             | 230        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 10.2        |
| env_time                | 26          |
| ep_rewmean              | 19.1        |
| episodes                | 768         |
| eplenmean               | 23.1        |
| fps                     | 61          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 8.56        |
| qs_difference           | -8.56       |
| qs_mean                 | 0.061122656 |
| time_elapsed            | 272         |
| total timesteps         | 16641       |
| train_time              | 0           |
| update_time             | 233         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 5.49         |
| env_time                | 26           |
| ep_rewmean              | 18.9         |
| episodes                | 772          |
| eplenmean               | 22.9         |
| fps                     | 61           |
| mean 100 episode reward | 18.9         |
| n_updates               | 0            |
| qs_abs_difference       | 4.56         |
| qs_difference           | -4.56        |
| qs_mean                 | -0.027705627 |
| time_elapsed            | 272          |
| total timesteps         | 16698        |
| train_time              | 0            |
| update_time             | 233          |
------------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.52        |
| env_time                | 26          |
| ep_rewmean              | 19          |
| episodes                | 776         |
| eplenmean               | 23.1        |
| fps                     | 60          |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 2.41        |
| qs_difference           | -0.489      |
| qs_mean                 | 0.030323146 |
| time_elapsed            | 278         |
| total timesteps         | 16800       |
| train_time              | 0           |
| update_time             | 239         |
-----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 4.5          |
| env_time                | 27           |
| ep_rewmean              | 19           |
| episodes                | 780          |
| eplenmean               | 23           |
| fps                     | 60           |
| mean 100 episode reward | 19           |
| n_updates               | 0            |
| qs_abs_difference       | 3.26         |
| qs_difference           | -3.21        |
| qs_mean                 | -0.004820687 |
| time_elapsed            | 278          |
| total timesteps         | 16883        |
| train_time              | 0            |
| update_time             | 239          |
------------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 10.2       |
| env_time                | 27         |
| ep_rewmean              | 19.4       |
| episodes                | 784        |
| eplenmean               | 23.4       |
| fps                     | 60         |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 10.9       |
| qs_difference           | -10.9      |
| qs_mean                 | 0.09920141 |
| time_elapsed            | 281        |
| total timesteps         | 16987      |
| train_time              | 0          |
| update_time             | 242        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.7         |
| env_time                | 27          |
| ep_rewmean              | 19.2        |
| episodes                | 788         |
| eplenmean               | 23.1        |
| fps                     | 59          |
| mean 100 episode reward | 19.2        |
| n_updates               | 0           |
| qs_abs_difference       | 4.58        |
| qs_difference           | -4.58       |
| qs_mean                 | 0.040738996 |
| time_elapsed            | 284         |
| total timesteps         | 17045       |
| train_time              | 0           |
| update_time             | 244         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 2.9         |
| env_time                | 27          |
| ep_rewmean              | 19.6        |
| episodes                | 792         |
| eplenmean               | 23.2        |
| fps                     | 59          |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 3.26        |
| qs_difference           | -3.26       |
| qs_mean                 | -0.05511927 |
| time_elapsed            | 287         |
| total timesteps         | 17154       |
| train_time              | 0           |
| update_time             | 247         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.7        |
| env_time                | 27         |
| ep_rewmean              | 19.3       |
| episodes                | 796        |
| eplenmean               | 22.9       |
| fps                     | 59         |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.71       |
| qs_difference           | -4.7       |
| qs_mean                 | 0.08639572 |
| time_elapsed            | 290        |
| total timesteps         | 17241      |
| train_time              | 0          |
| update_time             | 250        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 10.3      |
| env_time                | 27        |
| ep_rewmean              | 19.2      |
| episodes                | 800       |
| eplenmean               | 23        |
| fps                     | 58        |
| mean 100 episode reward | 19.2      |
| n_updates               | 0         |
| qs_abs_difference       | 10.7      |
| qs_difference           | -10.7     |
| qs_mean                 | 0.1250367 |
| time_elapsed            | 294       |
| total timesteps         | 17329     |
| train_time              | 0         |
| update_time             | 253       |
---------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 12.9        |
| env_time                | 27          |
| ep_rewmean              | 19          |
| episodes                | 804         |
| eplenmean               | 22.8        |
| fps                     | 58          |
| mean 100 episode reward | 19          |
| n_updates               | 0           |
| qs_abs_difference       | 12.9        |
| qs_difference           | -12.9       |
| qs_mean                 | 0.050682638 |
| time_elapsed            | 297         |
| total timesteps         | 17410       |
| train_time              | 0           |
| update_time             | 256         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.75        |
| env_time                | 28          |
| ep_rewmean              | 18.8        |
| episodes                | 808         |
| eplenmean               | 22.6        |
| fps                     | 58          |
| mean 100 episode reward | 18.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.62        |
| qs_difference           | -5.62       |
| qs_mean                 | 0.086462095 |
| time_elapsed            | 297         |
| total timesteps         | 17485       |
| train_time              | 0           |
| update_time             | 256         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.38       |
| env_time                | 28         |
| ep_rewmean              | 20         |
| episodes                | 812        |
| eplenmean               | 23.4       |
| fps                     | 58         |
| mean 100 episode reward | 20         |
| n_updates               | 0          |
| qs_abs_difference       | 11.8       |
| qs_difference           | -11.8      |
| qs_mean                 | 0.13759828 |
| time_elapsed            | 303        |
| total timesteps         | 17643      |
| train_time              | 0          |
| update_time             | 262        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.31        |
| env_time                | 28          |
| ep_rewmean              | 19.9        |
| episodes                | 816         |
| eplenmean               | 23.4        |
| fps                     | 57          |
| mean 100 episode reward | 19.9        |
| n_updates               | 0           |
| qs_abs_difference       | 3           |
| qs_difference           | -2.54       |
| qs_mean                 | 0.019516071 |
| time_elapsed            | 306         |
| total timesteps         | 17715       |
| train_time              | 0           |
| update_time             | 265         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 37.1       |
| env_time                | 28         |
| ep_rewmean              | 20.6       |
| episodes                | 820        |
| eplenmean               | 23.7       |
| fps                     | 57         |
| mean 100 episode reward | 20.6       |
| n_updates               | 0          |
| qs_abs_difference       | 37.8       |
| qs_difference           | -37.8      |
| qs_mean                 | 0.11725799 |
| time_elapsed            | 309        |
| total timesteps         | 17815      |
| train_time              | 0          |
| update_time             | 268        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 11.4        |
| env_time                | 28          |
| ep_rewmean              | 20.7        |
| episodes                | 824         |
| eplenmean               | 24.2        |
| fps                     | 57          |
| mean 100 episode reward | 20.7        |
| n_updates               | 0           |
| qs_abs_difference       | 9.25        |
| qs_difference           | -9.04       |
| qs_mean                 | 0.051767975 |
| time_elapsed            | 313         |
| total timesteps         | 17940       |
| train_time              | 0           |
| update_time             | 271         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 6.71        |
| env_time                | 28          |
| ep_rewmean              | 20.4        |
| episodes                | 828         |
| eplenmean               | 23.7        |
| fps                     | 56          |
| mean 100 episode reward | 20.4        |
| n_updates               | 0           |
| qs_abs_difference       | 6.3         |
| qs_difference           | -6.3        |
| qs_mean                 | 0.022016026 |
| time_elapsed            | 316         |
| total timesteps         | 18006       |
| train_time              | 0           |
| update_time             | 274         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 5.27       |
| env_time                | 29         |
| ep_rewmean              | 20.8       |
| episodes                | 832        |
| eplenmean               | 23.9       |
| fps                     | 56         |
| mean 100 episode reward | 20.8       |
| n_updates               | 0          |
| qs_abs_difference       | 6.43       |
| qs_difference           | -6.43      |
| qs_mean                 | 0.15486492 |
| time_elapsed            | 319        |
| total timesteps         | 18114      |
| train_time              | 0          |
| update_time             | 277        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 2.23        |
| env_time                | 29          |
| ep_rewmean              | 21.4        |
| episodes                | 836         |
| eplenmean               | 24.1        |
| fps                     | 56          |
| mean 100 episode reward | 21.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.5         |
| qs_difference           | -3.5        |
| qs_mean                 | 0.013599511 |
| time_elapsed            | 323         |
| total timesteps         | 18230       |
| train_time              | 0           |
| update_time             | 280         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.67       |
| env_time                | 29         |
| ep_rewmean              | 20.9       |
| episodes                | 840        |
| eplenmean               | 24.1       |
| fps                     | 56         |
| mean 100 episode reward | 20.9       |
| n_updates               | 0          |
| qs_abs_difference       | 6.17       |
| qs_difference           | -6.17      |
| qs_mean                 | 0.01915011 |
| time_elapsed            | 326        |
| total timesteps         | 18357      |
| train_time              | 0          |
| update_time             | 283        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.89        |
| env_time                | 29          |
| ep_rewmean              | 19.4        |
| episodes                | 844         |
| eplenmean               | 23.1        |
| fps                     | 55          |
| mean 100 episode reward | 19.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.02        |
| qs_difference           | -3.02       |
| qs_mean                 | 0.071963884 |
| time_elapsed            | 329         |
| total timesteps         | 18432       |
| train_time              | 0           |
| update_time             | 286         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 5.72        |
| env_time                | 29          |
| ep_rewmean              | 19.5        |
| episodes                | 848         |
| eplenmean               | 23.2        |
| fps                     | 55          |
| mean 100 episode reward | 19.5        |
| n_updates               | 0           |
| qs_abs_difference       | 5.41        |
| qs_difference           | -5.41       |
| qs_mean                 | 0.046390057 |
| time_elapsed            | 333         |
| total timesteps         | 18529       |
| train_time              | 0           |
| update_time             | 289         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 4.24        |
| env_time                | 29          |
| ep_rewmean              | 19.1        |
| episodes                | 852         |
| eplenmean               | 22.9        |
| fps                     | 55          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 2.89        |
| qs_difference           | -2.84       |
| qs_mean                 | 0.039022703 |
| time_elapsed            | 336         |
| total timesteps         | 18620       |
| train_time              | 0           |
| update_time             | 292         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 6.31       |
| env_time                | 30         |
| ep_rewmean              | 19.4       |
| episodes                | 856        |
| eplenmean               | 23.2       |
| fps                     | 55         |
| mean 100 episode reward | 19.4       |
| n_updates               | 0          |
| qs_abs_difference       | 3.97       |
| qs_difference           | -3.8       |
| qs_mean                 | 0.07316005 |
| time_elapsed            | 339        |
| total timesteps         | 18721      |
| train_time              | 0          |
| update_time             | 296        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 3.91      |
| env_time                | 30        |
| ep_rewmean              | 19.3      |
| episodes                | 860       |
| eplenmean               | 23.1      |
| fps                     | 55        |
| mean 100 episode reward | 19.3      |
| n_updates               | 0         |
| qs_abs_difference       | 3.3       |
| qs_difference           | -3.3      |
| qs_mean                 | 0.0816901 |
| time_elapsed            | 339       |
| total timesteps         | 18796     |
| train_time              | 0         |
| update_time             | 296       |
---------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 11.6       |
| env_time                | 30         |
| ep_rewmean              | 19.3       |
| episodes                | 864        |
| eplenmean               | 22.9       |
| fps                     | 54         |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 10.5       |
| qs_difference           | -10.5      |
| qs_mean                 | 0.03449687 |
| time_elapsed            | 343        |
| total timesteps         | 18874      |
| train_time              | 0          |
| update_time             | 299        |
----------------------------------------
---------------------------------------
| act_time                | 2         |
| current_lr              | 0.0003    |
| discount_q              | 3.52      |
| env_time                | 30        |
| ep_rewmean              | 19.9      |
| episodes                | 868       |
| eplenmean               | 23.5      |
| fps                     | 54        |
| mean 100 episode reward | 19.9      |
| n_updates               | 0         |
| qs_abs_difference       | 5.13      |
| qs_difference           | -5.13     |
| qs_mean                 | 0.0404502 |
| time_elapsed            | 346       |
| total timesteps         | 18989     |
| train_time              | 0         |
| update_time             | 302       |
---------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 8.68        |
| env_time                | 30          |
| ep_rewmean              | 20.1        |
| episodes                | 872         |
| eplenmean               | 23.8        |
| fps                     | 54          |
| mean 100 episode reward | 20.1        |
| n_updates               | 0           |
| qs_abs_difference       | 9.76        |
| qs_difference           | -9.76       |
| qs_mean                 | 0.033341218 |
| time_elapsed            | 350         |
| total timesteps         | 19082       |
| train_time              | 0           |
| update_time             | 305         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 2.26       |
| env_time                | 30         |
| ep_rewmean              | 21.4       |
| episodes                | 876        |
| eplenmean               | 24.3       |
| fps                     | 53         |
| mean 100 episode reward | 21.4       |
| n_updates               | 0          |
| qs_abs_difference       | 4.3        |
| qs_difference           | -4.3       |
| qs_mean                 | 0.23459959 |
| time_elapsed            | 356        |
| total timesteps         | 19227      |
| train_time              | 0          |
| update_time             | 311        |
----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 3.16        |
| env_time                | 31          |
| ep_rewmean              | 21.6        |
| episodes                | 880         |
| eplenmean               | 24.4        |
| fps                     | 53          |
| mean 100 episode reward | 21.6        |
| n_updates               | 0           |
| qs_abs_difference       | 3.91        |
| qs_difference           | -3.91       |
| qs_mean                 | 0.045038406 |
| time_elapsed            | 360         |
| total timesteps         | 19324       |
| train_time              | 0           |
| update_time             | 315         |
-----------------------------------------
-----------------------------------------
| act_time                | 2           |
| current_lr              | 0.0003      |
| discount_q              | 11.6        |
| env_time                | 31          |
| ep_rewmean              | 21.2        |
| episodes                | 884         |
| eplenmean               | 24          |
| fps                     | 53          |
| mean 100 episode reward | 21.2        |
| n_updates               | 0           |
| qs_abs_difference       | 10.6        |
| qs_difference           | -10.6       |
| qs_mean                 | 0.056215752 |
| time_elapsed            | 360         |
| total timesteps         | 19388       |
| train_time              | 0           |
| update_time             | 315         |
-----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 4.69       |
| env_time                | 31         |
| ep_rewmean              | 21.5       |
| episodes                | 888        |
| eplenmean               | 24.3       |
| fps                     | 53         |
| mean 100 episode reward | 21.5       |
| n_updates               | 0          |
| qs_abs_difference       | 3.75       |
| qs_difference           | -3.73      |
| qs_mean                 | 0.08386028 |
| time_elapsed            | 363        |
| total timesteps         | 19472      |
| train_time              | 0          |
| update_time             | 318        |
----------------------------------------
----------------------------------------
| act_time                | 2          |
| current_lr              | 0.0003     |
| discount_q              | 3.39       |
| env_time                | 31         |
| ep_rewmean              | 21.7       |
| episodes                | 892        |
| eplenmean               | 24.4       |
| fps                     | 53         |
| mean 100 episode reward | 21.7       |
| n_updates               | 0          |
| qs_abs_difference       | 4.98       |
| qs_difference           | -4.98      |
| qs_mean                 | 0.12781216 |
| time_elapsed            | 367        |
| total timesteps         | 19589      |
| train_time              | 0          |
| update_time             | 321        |
----------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 5.84         |
| env_time                | 31           |
| ep_rewmean              | 21.4         |
| episodes                | 896          |
| eplenmean               | 24.1         |
| fps                     | 53           |
| mean 100 episode reward | 21.4         |
| n_updates               | 0            |
| qs_abs_difference       | 4.74         |
| qs_difference           | -4.74        |
| qs_mean                 | -0.013023927 |
| time_elapsed            | 370          |
| total timesteps         | 19650        |
| train_time              | 0            |
| update_time             | 324          |
------------------------------------------
------------------------------------------
| act_time                | 2            |
| current_lr              | 0.0003       |
| discount_q              | 3.36         |
| env_time                | 31           |
| ep_rewmean              | 21.8         |
| episodes                | 900          |
| eplenmean               | 24.2         |
| fps                     | 52           |
| mean 100 episode reward | 21.8         |
| n_updates               | 0            |
| qs_abs_difference       | 4.13         |
| qs_difference           | -4.13        |
| qs_mean                 | -0.051971246 |
| time_elapsed            | 374          |
| total timesteps         | 19749        |
| train_time              | 0            |
| update_time             | 328          |
------------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 9.92        |
| env_time                | 31          |
| ep_rewmean              | 21.7        |
| episodes                | 904         |
| eplenmean               | 24.1        |
| fps                     | 52          |
| mean 100 episode reward | 21.7        |
| n_updates               | 0           |
| qs_abs_difference       | 8.74        |
| qs_difference           | -8.74       |
| qs_mean                 | 0.087910704 |
| time_elapsed            | 377         |
| total timesteps         | 19821       |
| train_time              | 0           |
| update_time             | 331         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 12.3        |
| env_time                | 31          |
| ep_rewmean              | 21.6        |
| episodes                | 908         |
| eplenmean               | 24          |
| fps                     | 52          |
| mean 100 episode reward | 21.6        |
| n_updates               | 0           |
| qs_abs_difference       | 9.2         |
| qs_difference           | -9.2        |
| qs_mean                 | 0.013435884 |
| time_elapsed            | 377         |
| total timesteps         | 19886       |
| train_time              | 0           |
| update_time             | 331         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 10.1        |
| env_time                | 31          |
| ep_rewmean              | 20.3        |
| episodes                | 912         |
| eplenmean               | 23.2        |
| fps                     | 52          |
| mean 100 episode reward | 20.3        |
| n_updates               | 0           |
| qs_abs_difference       | 5.94        |
| qs_difference           | -5.94       |
| qs_mean                 | 0.045952618 |
| time_elapsed            | 381         |
| total timesteps         | 19964       |
| train_time              | 0           |
| update_time             | 334         |
-----------------------------------------
-----------------------------------------
| eval mean 100 episod... | 3.9         |
| eval_abs_qs_difference  | 2.5028703   |
| eval_discount_q         | 3.9         |
| eval_ep_rewmean         | 3.97        |
| eval_eplenmean          | 7           |
| eval_qs                 | -0.89940125 |
| eval_qs_difference      | -2.5        |
| eval_time_elapsed       | 0           |
| total timesteps         | 20001       |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 8.97       |
| env_time                | 32         |
| ep_rewmean              | 20.8       |
| episodes                | 916        |
| eplenmean               | 23.4       |
| fps                     | 52         |
| mean 100 episode reward | 20.8       |
| n_updates               | 0          |
| qs_abs_difference       | 10.1       |
| qs_difference           | -10.1      |
| qs_mean                 | 0.11534323 |
| time_elapsed            | 384        |
| total timesteps         | 20053      |
| train_time              | 0          |
| update_time             | 338        |
----------------------------------------
------------------------------------------
| act_time                | 3            |
| current_lr              | 0.0003       |
| discount_q              | 3.95         |
| env_time                | 32           |
| ep_rewmean              | 20.2         |
| episodes                | 920          |
| eplenmean               | 23.1         |
| fps                     | 51           |
| mean 100 episode reward | 20.2         |
| n_updates               | 0            |
| qs_abs_difference       | 3.56         |
| qs_difference           | -3.56        |
| qs_mean                 | -0.012218608 |
| time_elapsed            | 388          |
| total timesteps         | 20121        |
| train_time              | 0            |
| update_time             | 341          |
------------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 3.2        |
| env_time                | 32         |
| ep_rewmean              | 19.7       |
| episodes                | 924        |
| eplenmean               | 22.8       |
| fps                     | 51         |
| mean 100 episode reward | 19.7       |
| n_updates               | 0          |
| qs_abs_difference       | 3.43       |
| qs_difference           | -3.43      |
| qs_mean                 | 0.07359198 |
| time_elapsed            | 392        |
| total timesteps         | 20215      |
| train_time              | 0          |
| update_time             | 344        |
----------------------------------------
------------------------------------------
| act_time                | 3            |
| current_lr              | 0.0003       |
| discount_q              | 4.83         |
| env_time                | 32           |
| ep_rewmean              | 19.7         |
| episodes                | 928          |
| eplenmean               | 22.8         |
| fps                     | 51           |
| mean 100 episode reward | 19.7         |
| n_updates               | 0            |
| qs_abs_difference       | 3.91         |
| qs_difference           | -3.91        |
| qs_mean                 | -0.090683535 |
| time_elapsed            | 392          |
| total timesteps         | 20283        |
| train_time              | 0            |
| update_time             | 344          |
------------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 6.53      |
| env_time                | 32        |
| ep_rewmean              | 19.3      |
| episodes                | 932       |
| eplenmean               | 22.2      |
| fps                     | 51        |
| mean 100 episode reward | 19.3      |
| n_updates               | 0         |
| qs_abs_difference       | 4.45      |
| qs_difference           | -4.45     |
| qs_mean                 | 0.1762987 |
| time_elapsed            | 395       |
| total timesteps         | 20339     |
| train_time              | 0         |
| update_time             | 348       |
---------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 5.84       |
| env_time                | 32         |
| ep_rewmean              | 18.3       |
| episodes                | 936        |
| eplenmean               | 21.7       |
| fps                     | 51         |
| mean 100 episode reward | 18.3       |
| n_updates               | 0          |
| qs_abs_difference       | 4.8        |
| qs_difference           | -4.8       |
| qs_mean                 | 0.08931199 |
| time_elapsed            | 399        |
| total timesteps         | 20400      |
| train_time              | 0          |
| update_time             | 351        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 4.54        |
| env_time                | 32          |
| ep_rewmean              | 18          |
| episodes                | 940         |
| eplenmean               | 21.3        |
| fps                     | 51          |
| mean 100 episode reward | 18          |
| n_updates               | 0           |
| qs_abs_difference       | 5.04        |
| qs_difference           | -5.04       |
| qs_mean                 | 0.020200294 |
| time_elapsed            | 399         |
| total timesteps         | 20487       |
| train_time              | 0           |
| update_time             | 351         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 10.1       |
| env_time                | 32         |
| ep_rewmean              | 17.8       |
| episodes                | 944        |
| eplenmean               | 21.4       |
| fps                     | 51         |
| mean 100 episode reward | 17.8       |
| n_updates               | 0          |
| qs_abs_difference       | 9.3        |
| qs_difference           | -9.3       |
| qs_mean                 | 0.07260172 |
| time_elapsed            | 403        |
| total timesteps         | 20577      |
| train_time              | 0          |
| update_time             | 355        |
----------------------------------------
------------------------------------------
| act_time                | 3            |
| current_lr              | 0.0003       |
| discount_q              | 3.17         |
| env_time                | 33           |
| ep_rewmean              | 17.9         |
| episodes                | 948          |
| eplenmean               | 21.5         |
| fps                     | 50           |
| mean 100 episode reward | 17.9         |
| n_updates               | 0            |
| qs_abs_difference       | 3.62         |
| qs_difference           | -3.62        |
| qs_mean                 | -0.011962279 |
| time_elapsed            | 406          |
| total timesteps         | 20676        |
| train_time              | 0            |
| update_time             | 358          |
------------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 6.67        |
| env_time                | 33          |
| ep_rewmean              | 17.9        |
| episodes                | 952         |
| eplenmean               | 21.4        |
| fps                     | 50          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 4.01        |
| qs_difference           | -2.23       |
| qs_mean                 | 0.016777743 |
| time_elapsed            | 410         |
| total timesteps         | 20762       |
| train_time              | 0           |
| update_time             | 362         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 9.03        |
| env_time                | 33          |
| ep_rewmean              | 17.8        |
| episodes                | 956         |
| eplenmean               | 21.2        |
| fps                     | 50          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 8.14        |
| qs_difference           | -8.14       |
| qs_mean                 | 0.030634472 |
| time_elapsed            | 414         |
| total timesteps         | 20839       |
| train_time              | 0           |
| update_time             | 365         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 4.28        |
| env_time                | 33          |
| ep_rewmean              | 17.9        |
| episodes                | 960         |
| eplenmean               | 21.4        |
| fps                     | 50          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 4.45        |
| qs_difference           | -4.45       |
| qs_mean                 | 0.036436852 |
| time_elapsed            | 417         |
| total timesteps         | 20933       |
| train_time              | 0           |
| update_time             | 369         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 11.5       |
| env_time                | 33         |
| ep_rewmean              | 18         |
| episodes                | 964        |
| eplenmean               | 21.5       |
| fps                     | 49         |
| mean 100 episode reward | 18         |
| n_updates               | 0          |
| qs_abs_difference       | 13.3       |
| qs_difference           | -13.3      |
| qs_mean                 | 0.09064024 |
| time_elapsed            | 421        |
| total timesteps         | 21024      |
| train_time              | 0          |
| update_time             | 372        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 6.6        |
| env_time                | 33         |
| ep_rewmean              | 17.6       |
| episodes                | 968        |
| eplenmean               | 21.2       |
| fps                     | 49         |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 7.31       |
| qs_difference           | -7.31      |
| qs_mean                 | 0.20633377 |
| time_elapsed            | 425        |
| total timesteps         | 21106      |
| train_time              | 0          |
| update_time             | 376        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 7.02        |
| env_time                | 33          |
| ep_rewmean              | 17.8        |
| episodes                | 972         |
| eplenmean               | 21.2        |
| fps                     | 49          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.1         |
| qs_difference           | -5.09       |
| qs_mean                 | 0.053581122 |
| time_elapsed            | 429         |
| total timesteps         | 21200       |
| train_time              | 0           |
| update_time             | 379         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 18.8       |
| env_time                | 34         |
| ep_rewmean              | 16.6       |
| episodes                | 976        |
| eplenmean               | 20.6       |
| fps                     | 49         |
| mean 100 episode reward | 16.6       |
| n_updates               | 0          |
| qs_abs_difference       | 17         |
| qs_difference           | -17        |
| qs_mean                 | 0.08373879 |
| time_elapsed            | 429        |
| total timesteps         | 21286      |
| train_time              | 0          |
| update_time             | 379        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 6.38        |
| env_time                | 34          |
| ep_rewmean              | 16.2        |
| episodes                | 980         |
| eplenmean               | 20.4        |
| fps                     | 49          |
| mean 100 episode reward | 16.2        |
| n_updates               | 0           |
| qs_abs_difference       | 3.95        |
| qs_difference           | -3.95       |
| qs_mean                 | -0.05577553 |
| time_elapsed            | 433         |
| total timesteps         | 21359       |
| train_time              | 0           |
| update_time             | 383         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 4.96       |
| env_time                | 34         |
| ep_rewmean              | 16.1       |
| episodes                | 984        |
| eplenmean               | 20.5       |
| fps                     | 49         |
| mean 100 episode reward | 16.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.16       |
| qs_difference           | -5.16      |
| qs_mean                 | 0.13417344 |
| time_elapsed            | 436        |
| total timesteps         | 21441      |
| train_time              | 0          |
| update_time             | 386        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 5.05        |
| env_time                | 34          |
| ep_rewmean              | 16          |
| episodes                | 988         |
| eplenmean               | 20.4        |
| fps                     | 48          |
| mean 100 episode reward | 16          |
| n_updates               | 0           |
| qs_abs_difference       | 3.6         |
| qs_difference           | -3.59       |
| qs_mean                 | 0.084577456 |
| time_elapsed            | 440         |
| total timesteps         | 21512       |
| train_time              | 0           |
| update_time             | 390         |
-----------------------------------------
------------------------------------------
| act_time                | 3            |
| current_lr              | 0.0003       |
| discount_q              | 4.98         |
| env_time                | 34           |
| ep_rewmean              | 15.5         |
| episodes                | 992          |
| eplenmean               | 20           |
| fps                     | 48           |
| mean 100 episode reward | 15.5         |
| n_updates               | 0            |
| qs_abs_difference       | 3.87         |
| qs_difference           | -3.86        |
| qs_mean                 | -0.010119049 |
| time_elapsed            | 440          |
| total timesteps         | 21592        |
| train_time              | 0            |
| update_time             | 390          |
------------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 7.98       |
| env_time                | 34         |
| ep_rewmean              | 15.5       |
| episodes                | 996        |
| eplenmean               | 20.2       |
| fps                     | 48         |
| mean 100 episode reward | 15.5       |
| n_updates               | 0          |
| qs_abs_difference       | 6.73       |
| qs_difference           | -6.73      |
| qs_mean                 | 0.16157857 |
| time_elapsed            | 444        |
| total timesteps         | 21669      |
| train_time              | 0          |
| update_time             | 393        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 5.67       |
| env_time                | 34         |
| ep_rewmean              | 15.4       |
| episodes                | 1000       |
| eplenmean               | 20.2       |
| fps                     | 48         |
| mean 100 episode reward | 15.4       |
| n_updates               | 0          |
| qs_abs_difference       | 6.86       |
| qs_difference           | -6.86      |
| qs_mean                 | 0.15686554 |
| time_elapsed            | 448        |
| total timesteps         | 21768      |
| train_time              | 0          |
| update_time             | 397        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 6.56       |
| env_time                | 34         |
| ep_rewmean              | 15.4       |
| episodes                | 1004       |
| eplenmean               | 20         |
| fps                     | 48         |
| mean 100 episode reward | 15.4       |
| n_updates               | 0          |
| qs_abs_difference       | 5.13       |
| qs_difference           | -5.13      |
| qs_mean                 | 0.28446203 |
| time_elapsed            | 452        |
| total timesteps         | 21825      |
| train_time              | 0          |
| update_time             | 401        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 5.81        |
| env_time                | 35          |
| ep_rewmean              | 15.5        |
| episodes                | 1008        |
| eplenmean               | 20.2        |
| fps                     | 48          |
| mean 100 episode reward | 15.5        |
| n_updates               | 0           |
| qs_abs_difference       | 3.64        |
| qs_difference           | -3.24       |
| qs_mean                 | 0.032562185 |
| time_elapsed            | 456         |
| total timesteps         | 21911       |
| train_time              | 0           |
| update_time             | 405         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 1.08        |
| env_time                | 35          |
| ep_rewmean              | 17.6        |
| episodes                | 1012        |
| eplenmean               | 21.8        |
| fps                     | 47          |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 5.29        |
| qs_difference           | -5.29       |
| qs_mean                 | 0.012594037 |
| time_elapsed            | 464         |
| total timesteps         | 22139       |
| train_time              | 0           |
| update_time             | 412         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 3.84       |
| env_time                | 35         |
| ep_rewmean              | 17.6       |
| episodes                | 1016       |
| eplenmean               | 21.8       |
| fps                     | 47         |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.07       |
| qs_difference           | -4.07      |
| qs_mean                 | 0.09205551 |
| time_elapsed            | 468        |
| total timesteps         | 22234      |
| train_time              | 0          |
| update_time             | 416        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 7.36       |
| env_time                | 35         |
| ep_rewmean              | 17.6       |
| episodes                | 1020       |
| eplenmean               | 21.7       |
| fps                     | 47         |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.49       |
| qs_difference           | -4.49      |
| qs_mean                 | 0.09992684 |
| time_elapsed            | 468        |
| total timesteps         | 22295      |
| train_time              | 0          |
| update_time             | 416        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 12.1        |
| env_time                | 35          |
| ep_rewmean              | 17.6        |
| episodes                | 1024        |
| eplenmean               | 21.4        |
| fps                     | 47          |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 9.49        |
| qs_difference           | -9.49       |
| qs_mean                 | 0.051664017 |
| time_elapsed            | 472         |
| total timesteps         | 22356       |
| train_time              | 0           |
| update_time             | 419         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 2.83       |
| env_time                | 35         |
| ep_rewmean              | 17.6       |
| episodes                | 1028       |
| eplenmean               | 21.4       |
| fps                     | 47         |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 2.1        |
| qs_difference           | -2.1       |
| qs_mean                 | 0.02827879 |
| time_elapsed            | 475        |
| total timesteps         | 22424      |
| train_time              | 0          |
| update_time             | 423        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 5.4        |
| env_time                | 36         |
| ep_rewmean              | 17.6       |
| episodes                | 1032       |
| eplenmean               | 21.7       |
| fps                     | 46         |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 3.17       |
| qs_difference           | -3.07      |
| qs_mean                 | 0.05887815 |
| time_elapsed            | 479        |
| total timesteps         | 22510      |
| train_time              | 0          |
| update_time             | 427        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 5.9         |
| env_time                | 36          |
| ep_rewmean              | 17.9        |
| episodes                | 1036        |
| eplenmean               | 21.9        |
| fps                     | 47          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 5.56        |
| qs_difference           | -5.56       |
| qs_mean                 | 0.014982537 |
| time_elapsed            | 480         |
| total timesteps         | 22587       |
| train_time              | 0           |
| update_time             | 427         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 7.19       |
| env_time                | 36         |
| ep_rewmean              | 17.9       |
| episodes                | 1040       |
| eplenmean               | 21.7       |
| fps                     | 46         |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 4.64       |
| qs_difference           | -4.62      |
| qs_mean                 | 0.09437586 |
| time_elapsed            | 484        |
| total timesteps         | 22660      |
| train_time              | 0          |
| update_time             | 431        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 4.04        |
| env_time                | 36          |
| ep_rewmean              | 17.9        |
| episodes                | 1044        |
| eplenmean               | 21.7        |
| fps                     | 46          |
| mean 100 episode reward | 17.9        |
| n_updates               | 0           |
| qs_abs_difference       | 2.84        |
| qs_difference           | -2.84       |
| qs_mean                 | -0.04053308 |
| time_elapsed            | 488         |
| total timesteps         | 22744       |
| train_time              | 0           |
| update_time             | 434         |
-----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 8.39      |
| env_time                | 36        |
| ep_rewmean              | 17.3      |
| episodes                | 1048      |
| eplenmean               | 21.3      |
| fps                     | 46        |
| mean 100 episode reward | 17.3      |
| n_updates               | 0         |
| qs_abs_difference       | 6.94      |
| qs_difference           | -6.94     |
| qs_mean                 | 0.2316065 |
| time_elapsed            | 491       |
| total timesteps         | 22805     |
| train_time              | 0         |
| update_time             | 438       |
---------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 10.7       |
| env_time                | 36         |
| ep_rewmean              | 17.5       |
| episodes                | 1052       |
| eplenmean               | 21.2       |
| fps                     | 46         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 8.99       |
| qs_difference           | -8.99      |
| qs_mean                 | 0.14358854 |
| time_elapsed            | 492        |
| total timesteps         | 22879      |
| train_time              | 0          |
| update_time             | 438        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 6.05        |
| env_time                | 36          |
| ep_rewmean              | 17.8        |
| episodes                | 1056        |
| eplenmean               | 21.3        |
| fps                     | 46          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.91        |
| qs_difference           | -5.91       |
| qs_mean                 | 0.039592132 |
| time_elapsed            | 496         |
| total timesteps         | 22972       |
| train_time              | 0           |
| update_time             | 442         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 7.77        |
| env_time                | 36          |
| ep_rewmean              | 17.8        |
| episodes                | 1060        |
| eplenmean               | 21.2        |
| fps                     | 46          |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 7.98        |
| qs_difference           | -7.98       |
| qs_mean                 | 0.061409235 |
| time_elapsed            | 500         |
| total timesteps         | 23052       |
| train_time              | 0           |
| update_time             | 446         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 9.04        |
| env_time                | 37          |
| ep_rewmean              | 18.3        |
| episodes                | 1064        |
| eplenmean               | 21.5        |
| fps                     | 45          |
| mean 100 episode reward | 18.3        |
| n_updates               | 0           |
| qs_abs_difference       | 11.6        |
| qs_difference           | -11.6       |
| qs_mean                 | 0.060319185 |
| time_elapsed            | 504         |
| total timesteps         | 23173       |
| train_time              | 0           |
| update_time             | 450         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 7.15        |
| env_time                | 37          |
| ep_rewmean              | 18.5        |
| episodes                | 1068        |
| eplenmean               | 21.6        |
| fps                     | 45          |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 7.67        |
| qs_difference           | -7.67       |
| qs_mean                 | 0.057237197 |
| time_elapsed            | 508         |
| total timesteps         | 23269       |
| train_time              | 0           |
| update_time             | 454         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 6.19        |
| env_time                | 37          |
| ep_rewmean              | 18.5        |
| episodes                | 1072        |
| eplenmean               | 21.5        |
| fps                     | 45          |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 6.58        |
| qs_difference           | -6.58       |
| qs_mean                 | 0.054828085 |
| time_elapsed            | 512         |
| total timesteps         | 23351       |
| train_time              | 0           |
| update_time             | 458         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 8.74       |
| env_time                | 37         |
| ep_rewmean              | 18.1       |
| episodes                | 1076       |
| eplenmean               | 21.3       |
| fps                     | 45         |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 5.66       |
| qs_difference           | -5.65      |
| qs_mean                 | 0.07115821 |
| time_elapsed            | 516        |
| total timesteps         | 23415      |
| train_time              | 0          |
| update_time             | 462        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 6.48      |
| env_time                | 37        |
| ep_rewmean              | 18.2      |
| episodes                | 1080      |
| eplenmean               | 21.3      |
| fps                     | 45        |
| mean 100 episode reward | 18.2      |
| n_updates               | 0         |
| qs_abs_difference       | 6.24      |
| qs_difference           | -6.24     |
| qs_mean                 | 0.1277982 |
| time_elapsed            | 516       |
| total timesteps         | 23491     |
| train_time              | 0         |
| update_time             | 462       |
---------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 9.45        |
| env_time                | 37          |
| ep_rewmean              | 18.5        |
| episodes                | 1084        |
| eplenmean               | 21.6        |
| fps                     | 44          |
| mean 100 episode reward | 18.5        |
| n_updates               | 0           |
| qs_abs_difference       | 7.16        |
| qs_difference           | -7.15       |
| qs_mean                 | 0.013575094 |
| time_elapsed            | 524         |
| total timesteps         | 23602       |
| train_time              | 0           |
| update_time             | 469         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 13.7        |
| env_time                | 37          |
| ep_rewmean              | 18.9        |
| episodes                | 1088        |
| eplenmean               | 21.8        |
| fps                     | 45          |
| mean 100 episode reward | 18.9        |
| n_updates               | 0           |
| qs_abs_difference       | 14          |
| qs_difference           | -14         |
| qs_mean                 | 0.029620534 |
| time_elapsed            | 525         |
| total timesteps         | 23689       |
| train_time              | 0           |
| update_time             | 469         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 7.61       |
| env_time                | 37         |
| ep_rewmean              | 18.8       |
| episodes                | 1092       |
| eplenmean               | 21.8       |
| fps                     | 44         |
| mean 100 episode reward | 18.8       |
| n_updates               | 0          |
| qs_abs_difference       | 8.59       |
| qs_difference           | -8.59      |
| qs_mean                 | 0.10293704 |
| time_elapsed            | 529        |
| total timesteps         | 23775      |
| train_time              | 0          |
| update_time             | 474        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 2.56        |
| env_time                | 38          |
| ep_rewmean              | 19.6        |
| episodes                | 1096        |
| eplenmean               | 22.1        |
| fps                     | 44          |
| mean 100 episode reward | 19.6        |
| n_updates               | 0           |
| qs_abs_difference       | 1.94        |
| qs_difference           | -0.665      |
| qs_mean                 | 0.114176154 |
| time_elapsed            | 533         |
| total timesteps         | 23880       |
| train_time              | 0           |
| update_time             | 478         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 5.8         |
| env_time                | 38          |
| ep_rewmean              | 19.1        |
| episodes                | 1100        |
| eplenmean               | 21.9        |
| fps                     | 44          |
| mean 100 episode reward | 19.1        |
| n_updates               | 0           |
| qs_abs_difference       | 5.16        |
| qs_difference           | -5.16       |
| qs_mean                 | 0.080723286 |
| time_elapsed            | 537         |
| total timesteps         | 23957       |
| train_time              | 0           |
| update_time             | 481         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 12.1        |
| env_time                | 38          |
| ep_rewmean              | 19.3        |
| episodes                | 1104        |
| eplenmean               | 22.2        |
| fps                     | 44          |
| mean 100 episode reward | 19.3        |
| n_updates               | 0           |
| qs_abs_difference       | 12.5        |
| qs_difference           | -12.5       |
| qs_mean                 | 0.057494897 |
| time_elapsed            | 541         |
| total timesteps         | 24047       |
| train_time              | 0           |
| update_time             | 485         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 5.45        |
| env_time                | 38          |
| ep_rewmean              | 19.3        |
| episodes                | 1108        |
| eplenmean               | 22          |
| fps                     | 44          |
| mean 100 episode reward | 19.3        |
| n_updates               | 0           |
| qs_abs_difference       | 3.72        |
| qs_difference           | -3.72       |
| qs_mean                 | 0.020113204 |
| time_elapsed            | 546         |
| total timesteps         | 24113       |
| train_time              | 0           |
| update_time             | 489         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 15.4       |
| env_time                | 38         |
| ep_rewmean              | 17.3       |
| episodes                | 1112       |
| eplenmean               | 20.5       |
| fps                     | 44         |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 14.9       |
| qs_difference           | -14.9      |
| qs_mean                 | 0.04633478 |
| time_elapsed            | 546        |
| total timesteps         | 24192      |
| train_time              | 0          |
| update_time             | 489        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 3.28        |
| env_time                | 38          |
| ep_rewmean              | 16.9        |
| episodes                | 1116        |
| eplenmean               | 20.4        |
| fps                     | 44          |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 2.18        |
| qs_difference           | -2.15       |
| qs_mean                 | 0.017454924 |
| time_elapsed            | 550         |
| total timesteps         | 24269       |
| train_time              | 0           |
| update_time             | 494         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 8.71        |
| env_time                | 38          |
| ep_rewmean              | 16.9        |
| episodes                | 1120        |
| eplenmean               | 20.4        |
| fps                     | 43          |
| mean 100 episode reward | 16.9        |
| n_updates               | 0           |
| qs_abs_difference       | 6.5         |
| qs_difference           | -6.5        |
| qs_mean                 | 0.075404845 |
| time_elapsed            | 554         |
| total timesteps         | 24333       |
| train_time              | 0           |
| update_time             | 498         |
-----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 6.75        |
| env_time                | 39          |
| ep_rewmean              | 17          |
| episodes                | 1124        |
| eplenmean               | 20.6        |
| fps                     | 43          |
| mean 100 episode reward | 17          |
| n_updates               | 0           |
| qs_abs_difference       | 4.32        |
| qs_difference           | -4.28       |
| qs_mean                 | 0.026491426 |
| time_elapsed            | 559         |
| total timesteps         | 24414       |
| train_time              | 0           |
| update_time             | 502         |
-----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 15.7       |
| env_time                | 39         |
| ep_rewmean              | 17.1       |
| episodes                | 1128       |
| eplenmean               | 20.6       |
| fps                     | 43         |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 14.6       |
| qs_difference           | -14.6      |
| qs_mean                 | 0.15200347 |
| time_elapsed            | 559        |
| total timesteps         | 24486      |
| train_time              | 0          |
| update_time             | 502        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 10.8       |
| env_time                | 39         |
| ep_rewmean              | 17.1       |
| episodes                | 1132       |
| eplenmean               | 20.4       |
| fps                     | 43         |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 6.56       |
| qs_difference           | -6.51      |
| qs_mean                 | 0.15445535 |
| time_elapsed            | 563        |
| total timesteps         | 24552      |
| train_time              | 0          |
| update_time             | 506        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 9.74       |
| env_time                | 39         |
| ep_rewmean              | 16.9       |
| episodes                | 1136       |
| eplenmean               | 20.4       |
| fps                     | 43         |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 9.53       |
| qs_difference           | -9.53      |
| qs_mean                 | 0.13798004 |
| time_elapsed            | 567        |
| total timesteps         | 24628      |
| train_time              | 0          |
| update_time             | 510        |
----------------------------------------
-----------------------------------------
| act_time                | 3           |
| current_lr              | 0.0003      |
| discount_q              | 8.97        |
| env_time                | 39          |
| ep_rewmean              | 17.3        |
| episodes                | 1140        |
| eplenmean               | 21.1        |
| fps                     | 43          |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 11.9        |
| qs_difference           | -11.9       |
| qs_mean                 | 0.033265047 |
| time_elapsed            | 572         |
| total timesteps         | 24766       |
| train_time              | 0           |
| update_time             | 514         |
-----------------------------------------
------------------------------------------
| act_time                | 3            |
| current_lr              | 0.0003       |
| discount_q              | 2.89         |
| env_time                | 39           |
| ep_rewmean              | 17.2         |
| episodes                | 1144         |
| eplenmean               | 21           |
| fps                     | 43           |
| mean 100 episode reward | 17.2         |
| n_updates               | 0            |
| qs_abs_difference       | 2.65         |
| qs_difference           | -2.65        |
| qs_mean                 | -0.007836913 |
| time_elapsed            | 576          |
| total timesteps         | 24842        |
| train_time              | 0            |
| update_time             | 518          |
------------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 2.87       |
| env_time                | 39         |
| ep_rewmean              | 17.5       |
| episodes                | 1148       |
| eplenmean               | 21.5       |
| fps                     | 42         |
| mean 100 episode reward | 17.5       |
| n_updates               | 0          |
| qs_abs_difference       | 4.01       |
| qs_difference           | -4.01      |
| qs_mean                 | 0.04529862 |
| time_elapsed            | 581        |
| total timesteps         | 24957      |
| train_time              | 0          |
| update_time             | 522        |
----------------------------------------
----------------------------------------
| act_time                | 3          |
| current_lr              | 0.0003     |
| discount_q              | 13.7       |
| env_time                | 40         |
| ep_rewmean              | 18.5       |
| episodes                | 1152       |
| eplenmean               | 22         |
| fps                     | 42         |
| mean 100 episode reward | 18.5       |
| n_updates               | 200        |
| q_grad_norm             | 28.63916   |
| qfs_loss                | 108.185555 |
| qs_abs_difference       | 22.7       |
| qs_difference           | -22.7      |
| qs_mean                 | 0.24039137 |
| time_elapsed            | 590        |
| total timesteps         | 25082      |
| train_time              | 5          |
| update_time             | 527        |
----------------------------------------
---------------------------------------
| act_time                | 3         |
| current_lr              | 0.0003    |
| discount_q              | 11        |
| env_time                | 40        |
| ep_rewmean              | 20.3      |
| episodes                | 1156      |
| eplenmean               | 22.6      |
| fps                     | 41        |
| mean 100 episode reward | 20.3      |
| n_updates               | 600       |
| q_grad_norm             | 44.722984 |
| qfs_loss                | 86.68916  |
| qs_abs_difference       | 10.2      |
| qs_difference           | -1.51     |
| qs_mean                 | 21.08732  |
| time_elapsed            | 604       |
| total timesteps         | 25227     |
| train_time              | 9         |
| update_time             | 535       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 17.1      |
| env_time                | 40        |
| ep_rewmean              | 21.1      |
| episodes                | 1160      |
| eplenmean               | 22.7      |
| fps                     | 41        |
| mean 100 episode reward | 21.1      |
| n_updates               | 800       |
| q_grad_norm             | 63.820072 |
| qfs_loss                | 85.61761  |
| qs_abs_difference       | 10.8      |
| qs_difference           | 5.88      |
| qs_mean                 | 27.108538 |
| time_elapsed            | 610       |
| total timesteps         | 25319     |
| train_time              | 11        |
| update_time             | 539       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 18.2      |
| env_time                | 40        |
| ep_rewmean              | 21.5      |
| episodes                | 1164      |
| eplenmean               | 22.4      |
| fps                     | 41        |
| mean 100 episode reward | 21.5      |
| n_updates               | 1000      |
| q_grad_norm             | 89.08776  |
| qfs_loss                | 77.562614 |
| qs_abs_difference       | 12.9      |
| qs_difference           | 9.17      |
| qs_mean                 | 30.896147 |
| time_elapsed            | 617       |
| total timesteps         | 25409     |
| train_time              | 14        |
| update_time             | 543       |
---------------------------------------
----------------------------------------
| act_time                | 4          |
| current_lr              | 0.0003     |
| discount_q              | 18         |
| env_time                | 40         |
| ep_rewmean              | 22.1       |
| episodes                | 1168       |
| eplenmean               | 22.3       |
| fps                     | 40         |
| mean 100 episode reward | 22.1       |
| n_updates               | 1200       |
| q_grad_norm             | 108.757355 |
| qfs_loss                | 74.162506  |
| qs_abs_difference       | 13.9       |
| qs_difference           | 13.5       |
| qs_mean                 | 35.34594   |
| time_elapsed            | 624        |
| total timesteps         | 25500      |
| train_time              | 16         |
| update_time             | 548        |
----------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 17.3      |
| env_time                | 40        |
| ep_rewmean              | 22.8      |
| episodes                | 1172      |
| eplenmean               | 22.4      |
| fps                     | 40        |
| mean 100 episode reward | 22.8      |
| n_updates               | 1200      |
| qs_abs_difference       | 21.1      |
| qs_difference           | 21.1      |
| qs_mean                 | 42.109695 |
| time_elapsed            | 624       |
| total timesteps         | 25590     |
| train_time              | 16        |
| update_time             | 548       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 17.4      |
| env_time                | 41        |
| ep_rewmean              | 24        |
| episodes                | 1176      |
| eplenmean               | 22.6      |
| fps                     | 40        |
| mean 100 episode reward | 24        |
| n_updates               | 1400      |
| q_grad_norm             | 155.57922 |
| qfs_loss                | 72.40408  |
| qs_abs_difference       | 27.6      |
| qs_difference           | 27.6      |
| qs_mean                 | 48.55277  |
| time_elapsed            | 631       |
| total timesteps         | 25679     |
| train_time              | 18        |
| update_time             | 552       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 16.8      |
| env_time                | 41        |
| ep_rewmean              | 27.3      |
| episodes                | 1180      |
| eplenmean               | 24        |
| fps                     | 40        |
| mean 100 episode reward | 27.3      |
| n_updates               | 1800      |
| q_grad_norm             | 241.31099 |
| qfs_loss                | 64.62862  |
| qs_abs_difference       | 21.6      |
| qs_difference           | 13.7      |
| qs_mean                 | 59.490116 |
| time_elapsed            | 645       |
| total timesteps         | 25894     |
| train_time              | 23        |
| update_time             | 561       |
---------------------------------------
---------------------------------------
| act_time                | 4         |
| current_lr              | 0.0003    |
| discount_q              | 3.41      |
| env_time                | 42        |
| ep_rewmean              | 34.9      |
| episodes                | 1184      |
| eplenmean               | 27.5      |
| fps                     | 38        |
| mean 100 episode reward | 34.9      |
| n_updates               | 2800      |
| q_grad_norm             | 519.55865 |
| qfs_loss                | 68.17541  |
| qs_abs_difference       | 26.8      |
| qs_difference           | -3.43     |
| qs_mean                 | 78.661896 |
| time_elapsed            | 679       |
| total timesteps         | 26355     |
| train_time              | 35        |
| update_time             | 582       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 8.14      |
| env_time                | 42        |
| ep_rewmean              | 40.2      |
| episodes                | 1188      |
| eplenmean               | 30        |
| fps                     | 38        |
| mean 100 episode reward | 40.2      |
| n_updates               | 3400      |
| q_grad_norm             | 817.2572  |
| qfs_loss                | 73.12871  |
| qs_abs_difference       | 35.4      |
| qs_difference           | 35.3      |
| qs_mean                 | 97.366135 |
| time_elapsed            | 700       |
| total timesteps         | 26687     |
| train_time              | 41        |
| update_time             | 595       |
---------------------------------------
---------------------------------------
| act_time                | 5         |
| current_lr              | 0.0003    |
| discount_q              | 5.7       |
| env_time                | 43        |
| ep_rewmean              | 47.7      |
| episodes                | 1192      |
| eplenmean               | 33.4      |
| fps                     | 36        |
| mean 100 episode reward | 47.7      |
| n_updates               | 4400      |
| q_grad_norm             | 1566.4503 |
| qfs_loss                | 83.57757  |
| qs_abs_difference       | 33.2      |
| qs_difference           | 32.5      |
| qs_mean                 | 120.65956 |
| time_elapsed            | 735       |
| total timesteps         | 27119     |
| train_time              | 53        |
| update_time             | 617       |
---------------------------------------
----------------------------------------
| act_time                | 5          |
| current_lr              | 0.0003     |
| discount_q              | 9.46       |
| env_time                | 44         |
| ep_rewmean              | 54         |
| episodes                | 1196       |
| eplenmean               | 36.6       |
| fps                     | 36         |
| mean 100 episode reward | 54         |
| n_updates               | 5200       |
| q_grad_norm             | 1681.1655  |
| qfs_loss                | 77.85347   |
| qs_abs_difference       | 26.4       |
| qs_difference           | 25.7       |
| qs_mean                 | 127.057396 |
| time_elapsed            | 764        |
| total timesteps         | 27544      |
| train_time              | 62         |
| update_time             | 635        |
----------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 3.12      |
| env_time                | 44        |
| ep_rewmean              | 62.3      |
| episodes                | 1200      |
| eplenmean               | 40.6      |
| fps                     | 35        |
| mean 100 episode reward | 62.3      |
| n_updates               | 6200      |
| q_grad_norm             | 2443.712  |
| qfs_loss                | 87.52497  |
| qs_abs_difference       | 49.5      |
| qs_difference           | 49.2      |
| qs_mean                 | 124.73304 |
| time_elapsed            | 799       |
| total timesteps         | 28014     |
| train_time              | 74        |
| update_time             | 658       |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 6.7       |
| env_time                | 45        |
| ep_rewmean              | 68.3      |
| episodes                | 1204      |
| eplenmean               | 43.5      |
| fps                     | 34        |
| mean 100 episode reward | 68.3      |
| n_updates               | 6800      |
| q_grad_norm             | 2556.593  |
| qfs_loss                | 81.10062  |
| qs_abs_difference       | 66.1      |
| qs_difference           | 66.1      |
| qs_mean                 | 138.62318 |
| time_elapsed            | 821       |
| total timesteps         | 28399     |
| train_time              | 81        |
| update_time             | 672       |
---------------------------------------
---------------------------------------
| act_time                | 6         |
| current_lr              | 0.0003    |
| discount_q              | 5.91      |
| env_time                | 45        |
| ep_rewmean              | 74.7      |
| episodes                | 1208      |
| eplenmean               | 46.2      |
| fps                     | 33        |
| mean 100 episode reward | 74.7      |
| n_updates               | 7600      |
| q_grad_norm             | 2678.9534 |
| qfs_loss                | 65.30673  |
| qs_abs_difference       | 107       |
| qs_difference           | 107       |
| qs_mean                 | 159.99635 |
| time_elapsed            | 849       |
| total timesteps         | 28731     |
| train_time              | 90        |
| update_time             | 690       |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 9.05      |
| env_time                | 46        |
| ep_rewmean              | 79.3      |
| episodes                | 1212      |
| eplenmean               | 48.2      |
| fps                     | 33        |
| mean 100 episode reward | 79.3      |
| n_updates               | 8200      |
| q_grad_norm             | 2709.3494 |
| qfs_loss                | 86.840164 |
| qs_abs_difference       | 118       |
| qs_difference           | 118       |
| qs_mean                 | 164.532   |
| time_elapsed            | 870       |
| total timesteps         | 29011     |
| train_time              | 97        |
| update_time             | 703       |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 6.77      |
| env_time                | 47        |
| ep_rewmean              | 86.7      |
| episodes                | 1216      |
| eplenmean               | 51.3      |
| fps                     | 32        |
| mean 100 episode reward | 86.7      |
| n_updates               | 8800      |
| q_grad_norm             | 2670.7678 |
| qfs_loss                | 75.99039  |
| qs_abs_difference       | 72.5      |
| qs_difference           | 72.5      |
| qs_mean                 | 156.32436 |
| time_elapsed            | 892       |
| total timesteps         | 29398     |
| train_time              | 104       |
| update_time             | 717       |
---------------------------------------
---------------------------------------
| act_time                | 7         |
| current_lr              | 0.0003    |
| discount_q              | 4.89      |
| env_time                | 47        |
| ep_rewmean              | 94.4      |
| episodes                | 1220      |
| eplenmean               | 54.7      |
| fps                     | 32        |
| mean 100 episode reward | 94.4      |
| n_updates               | 9800      |
| q_grad_norm             | 2806.503  |
| qfs_loss                | 76.610504 |
| qs_abs_difference       | 68.5      |
| qs_difference           | 68.5      |
| qs_mean                 | 145.6773  |
| time_elapsed            | 928       |
| total timesteps         | 29807     |
| train_time              | 115       |
| update_time             | 740       |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 46.9      |
| eval_abs_qs_difference  | 47.18718  |
| eval_discount_q         | 115       |
| eval_ep_rewmean         | 190       |
| eval_eplenmean          | 98        |
| eval_qs                 | 120.30025 |
| eval_qs_difference      | 43.2      |
| eval_time_elapsed       | 2         |
| total timesteps         | 30001     |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 5.54      |
| env_time                | 48        |
| ep_rewmean              | 102       |
| episodes                | 1224      |
| eplenmean               | 58.1      |
| fps                     | 31        |
| mean 100 episode reward | 102       |
| n_updates               | 10600     |
| q_grad_norm             | 2920.5762 |
| qfs_loss                | 82.69414  |
| qs_abs_difference       | 52.1      |
| qs_difference           | 52.1      |
| qs_mean                 | 139.7406  |
| time_elapsed            | 960       |
| total timesteps         | 30222     |
| train_time              | 125       |
| update_time             | 759       |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 6.71      |
| env_time                | 48        |
| ep_rewmean              | 109       |
| episodes                | 1228      |
| eplenmean               | 61.3      |
| fps                     | 30        |
| mean 100 episode reward | 109       |
| n_updates               | 11400     |
| q_grad_norm             | 2881.606  |
| qfs_loss                | 83.15112  |
| qs_abs_difference       | 56.8      |
| qs_difference           | 56.8      |
| qs_mean                 | 138.33081 |
| time_elapsed            | 989       |
| total timesteps         | 30612     |
| train_time              | 134       |
| update_time             | 778       |
---------------------------------------
---------------------------------------
| act_time                | 8         |
| current_lr              | 0.0003    |
| discount_q              | 10.7      |
| env_time                | 49        |
| ep_rewmean              | 115       |
| episodes                | 1232      |
| eplenmean               | 64.1      |
| fps                     | 30        |
| mean 100 episode reward | 115       |
| n_updates               | 12000     |
| q_grad_norm             | 3764.671  |
| qfs_loss                | 104.16284 |
| qs_abs_difference       | 67.7      |
| qs_difference           | 67.7      |
| qs_mean                 | 153.71902 |
| time_elapsed            | 1011      |
| total timesteps         | 30966     |
| train_time              | 141       |
| update_time             | 792       |
---------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 5.88      |
| env_time                | 50        |
| ep_rewmean              | 123       |
| episodes                | 1236      |
| eplenmean               | 67.6      |
| fps                     | 30        |
| mean 100 episode reward | 123       |
| n_updates               | 12800     |
| q_grad_norm             | 4233.7886 |
| qfs_loss                | 113.91892 |
| qs_abs_difference       | 56.8      |
| qs_difference           | 56.8      |
| qs_mean                 | 147.26825 |
| time_elapsed            | 1041      |
| total timesteps         | 31384     |
| train_time              | 150       |
| update_time             | 811       |
---------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 4.8       |
| env_time                | 50        |
| ep_rewmean              | 131       |
| episodes                | 1240      |
| eplenmean               | 70.5      |
| fps                     | 29        |
| mean 100 episode reward | 131       |
| n_updates               | 13800     |
| q_grad_norm             | 3128.681  |
| qfs_loss                | 96.2133   |
| qs_abs_difference       | 63        |
| qs_difference           | 63        |
| qs_mean                 | 149.17494 |
| time_elapsed            | 1077      |
| total timesteps         | 31814     |
| train_time              | 162       |
| update_time             | 835       |
---------------------------------------
---------------------------------------
| act_time                | 9         |
| current_lr              | 0.0003    |
| discount_q              | 5         |
| env_time                | 51        |
| ep_rewmean              | 138       |
| episodes                | 1244      |
| eplenmean               | 73.8      |
| fps                     | 29        |
| mean 100 episode reward | 138       |
| n_updates               | 14600     |
| q_grad_norm             | 3182.3044 |
| qfs_loss                | 90.73601  |
| qs_abs_difference       | 87.5      |
| qs_difference           | 87.5      |
| qs_mean                 | 164.41652 |
| time_elapsed            | 1107      |
| total timesteps         | 32219     |
| train_time              | 171       |
| update_time             | 854       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 5.6       |
| env_time                | 52        |
| ep_rewmean              | 146       |
| episodes                | 1248      |
| eplenmean               | 76.8      |
| fps                     | 28        |
| mean 100 episode reward | 146       |
| n_updates               | 15400     |
| q_grad_norm             | 3476.4893 |
| qfs_loss                | 92.379074 |
| qs_abs_difference       | 72.7      |
| qs_difference           | 72.7      |
| qs_mean                 | 150.99922 |
| time_elapsed            | 1137      |
| total timesteps         | 32632     |
| train_time              | 180       |
| update_time             | 874       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 4.91      |
| env_time                | 52        |
| ep_rewmean              | 153       |
| episodes                | 1252      |
| eplenmean               | 79.7      |
| fps                     | 28        |
| mean 100 episode reward | 153       |
| n_updates               | 16200     |
| q_grad_norm             | 3239.8782 |
| qfs_loss                | 89.63983  |
| qs_abs_difference       | 65.2      |
| qs_difference           | 65.2      |
| qs_mean                 | 145.07631 |
| time_elapsed            | 1167      |
| total timesteps         | 33054     |
| train_time              | 190       |
| update_time             | 893       |
---------------------------------------
---------------------------------------
| act_time                | 10        |
| current_lr              | 0.0003    |
| discount_q              | 5.13      |
| env_time                | 53        |
| ep_rewmean              | 159       |
| episodes                | 1256      |
| eplenmean               | 82.4      |
| fps                     | 27        |
| mean 100 episode reward | 159       |
| n_updates               | 17000     |
| q_grad_norm             | 3916.275  |
| qfs_loss                | 96.63539  |
| qs_abs_difference       | 51.2      |
| qs_difference           | 46.7      |
| qs_mean                 | 133.02898 |
| time_elapsed            | 1197      |
| total timesteps         | 33464     |
| train_time              | 199       |
| update_time             | 913       |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 5.63      |
| env_time                | 54        |
| ep_rewmean              | 166       |
| episodes                | 1260      |
| eplenmean               | 85.7      |
| fps                     | 27        |
| mean 100 episode reward | 166       |
| n_updates               | 17800     |
| q_grad_norm             | 3546.9568 |
| qfs_loss                | 82.88823  |
| qs_abs_difference       | 58.9      |
| qs_difference           | 56.9      |
| qs_mean                 | 146.97568 |
| time_elapsed            | 1227      |
| total timesteps         | 33893     |
| train_time              | 208       |
| update_time             | 933       |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 3.61      |
| env_time                | 55        |
| ep_rewmean              | 175       |
| episodes                | 1264      |
| eplenmean               | 89.7      |
| fps                     | 27        |
| mean 100 episode reward | 175       |
| n_updates               | 18800     |
| q_grad_norm             | 3849.9822 |
| qfs_loss                | 75.801506 |
| qs_abs_difference       | 43        |
| qs_difference           | 42.5      |
| qs_mean                 | 145.85329 |
| time_elapsed            | 1265      |
| total timesteps         | 34377     |
| train_time              | 220       |
| update_time             | 957       |
---------------------------------------
---------------------------------------
| act_time                | 11        |
| current_lr              | 0.0003    |
| discount_q              | 4.78      |
| env_time                | 55        |
| ep_rewmean              | 183       |
| episodes                | 1268      |
| eplenmean               | 93.3      |
| fps                     | 26        |
| mean 100 episode reward | 183       |
| n_updates               | 19800     |
| q_grad_norm             | 3502.9163 |
| qfs_loss                | 73.01566  |
| qs_abs_difference       | 42.7      |
| qs_difference           | 42.2      |
| qs_mean                 | 148.91998 |
| time_elapsed            | 1303      |
| total timesteps         | 34834     |
| train_time              | 231       |
| update_time             | 982       |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 4         |
| env_time                | 56        |
| ep_rewmean              | 191       |
| episodes                | 1272      |
| eplenmean               | 96.9      |
| fps                     | 26        |
| mean 100 episode reward | 191       |
| n_updates               | 20600     |
| q_grad_norm             | 3480.3535 |
| qfs_loss                | 84.44731  |
| qs_abs_difference       | 55.8      |
| qs_difference           | 55.8      |
| qs_mean                 | 145.8069  |
| time_elapsed            | 1333      |
| total timesteps         | 35283     |
| train_time              | 240       |
| update_time             | 1002      |
---------------------------------------
---------------------------------------
| act_time                | 12        |
| current_lr              | 0.0003    |
| discount_q              | 4.99      |
| env_time                | 57        |
| ep_rewmean              | 199       |
| episodes                | 1276      |
| eplenmean               | 100       |
| fps                     | 26        |
| mean 100 episode reward | 199       |
| n_updates               | 21600     |
| q_grad_norm             | 3590.0498 |
| qfs_loss                | 78.198425 |
| qs_abs_difference       | 39.5      |
| qs_difference           | 39.5      |
| qs_mean                 | 137.78053 |
| time_elapsed            | 1371      |
| total timesteps         | 35727     |
| train_time              | 252       |
| update_time             | 1028      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 5.37      |
| env_time                | 57        |
| ep_rewmean              | 205       |
| episodes                | 1280      |
| eplenmean               | 103       |
| fps                     | 25        |
| mean 100 episode reward | 205       |
| n_updates               | 22400     |
| q_grad_norm             | 3840.2615 |
| qfs_loss                | 83.71669  |
| qs_abs_difference       | 39.1      |
| qs_difference           | 39.1      |
| qs_mean                 | 138.90096 |
| time_elapsed            | 1402      |
| total timesteps         | 36171     |
| train_time              | 261       |
| update_time             | 1048      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 5.37      |
| env_time                | 58        |
| ep_rewmean              | 206       |
| episodes                | 1284      |
| eplenmean               | 103       |
| fps                     | 25        |
| mean 100 episode reward | 206       |
| n_updates               | 23400     |
| q_grad_norm             | 4188.1533 |
| qfs_loss                | 92.85467  |
| qs_abs_difference       | 34.7      |
| qs_difference           | 34.6      |
| qs_mean                 | 141.51804 |
| time_elapsed            | 1440      |
| total timesteps         | 36611     |
| train_time              | 273       |
| update_time             | 1074      |
---------------------------------------
---------------------------------------
| act_time                | 13        |
| current_lr              | 0.0003    |
| discount_q              | 14        |
| env_time                | 59        |
| ep_rewmean              | 207       |
| episodes                | 1288      |
| eplenmean               | 102       |
| fps                     | 25        |
| mean 100 episode reward | 207       |
| n_updates               | 24000     |
| q_grad_norm             | 3722.2766 |
| qfs_loss                | 81.22357  |
| qs_abs_difference       | 62.3      |
| qs_difference           | 62.3      |
| qs_mean                 | 151.19308 |
| time_elapsed            | 1464      |
| total timesteps         | 36931     |
| train_time              | 280       |
| update_time             | 1089      |
---------------------------------------
---------------------------------------
| act_time                | 14        |
| current_lr              | 0.0003    |
| discount_q              | 5.19      |
| env_time                | 59        |
| ep_rewmean              | 207       |
| episodes                | 1292      |
| eplenmean               | 102       |
| fps                     | 24        |
| mean 100 episode reward | 207       |
| n_updates               | 24800     |
| q_grad_norm             | 2843.4495 |
| qfs_loss                | 61.966705 |
| qs_abs_difference       | 67.1      |
| qs_difference           | 67.1      |
| qs_mean                 | 149.08138 |
| time_elapsed            | 1495      |
| total timesteps         | 37342     |
| train_time              | 289       |
| update_time             | 1110      |
---------------------------------------
---------------------------------------
| act_time                | 14        |
| current_lr              | 0.0003    |
| discount_q              | 6.63      |
| env_time                | 60        |
| ep_rewmean              | 209       |
| episodes                | 1296      |
| eplenmean               | 102       |
| fps                     | 24        |
| mean 100 episode reward | 209       |
| n_updates               | 25600     |
| q_grad_norm             | 3559.2153 |
| qfs_loss                | 79.7506   |
| qs_abs_difference       | 45.7      |
| qs_difference           | 45.7      |
| qs_mean                 | 141.42587 |
| time_elapsed            | 1526      |
| total timesteps         | 37743     |
| train_time              | 298       |
| update_time             | 1131      |
---------------------------------------
---------------------------------------
| act_time                | 14        |
| current_lr              | 0.0003    |
| discount_q              | 5.33      |
| env_time                | 61        |
| ep_rewmean              | 209       |
| episodes                | 1300      |
| eplenmean               | 101       |
| fps                     | 24        |
| mean 100 episode reward | 209       |
| n_updates               | 26400     |
| q_grad_norm             | 3149.9963 |
| qfs_loss                | 64.96648  |
| qs_abs_difference       | 56.6      |
| qs_difference           | 56.6      |
| qs_mean                 | 143.99503 |
| time_elapsed            | 1557      |
| total timesteps         | 38162     |
| train_time              | 307       |
| update_time             | 1152      |
---------------------------------------
---------------------------------------
| act_time                | 15        |
| current_lr              | 0.0003    |
| discount_q              | 4.61      |
| env_time                | 61        |
| ep_rewmean              | 213       |
| episodes                | 1304      |
| eplenmean               | 102       |
| fps                     | 24        |
| mean 100 episode reward | 213       |
| n_updates               | 27400     |
| q_grad_norm             | 3409.2412 |
| qfs_loss                | 71.153076 |
| qs_abs_difference       | 28.2      |
| qs_difference           | 25.3      |
| qs_mean                 | 138.69463 |
| time_elapsed            | 1596      |
| total timesteps         | 38638     |
| train_time              | 319       |
| update_time             | 1178      |
---------------------------------------
---------------------------------------
| act_time                | 15        |
| current_lr              | 0.0003    |
| discount_q              | 2.74      |
| env_time                | 62        |
| ep_rewmean              | 218       |
| episodes                | 1308      |
| eplenmean               | 105       |
| fps                     | 23        |
| mean 100 episode reward | 218       |
| n_updates               | 28400     |
| q_grad_norm             | 3195.0037 |
| qfs_loss                | 71.77191  |
| qs_abs_difference       | 33.3      |
| qs_difference           | 32.9      |
| qs_mean                 | 146.70724 |
| time_elapsed            | 1636      |
| total timesteps         | 39183     |
| train_time              | 330       |
| update_time             | 1205      |
---------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 2.22      |
| env_time                | 63        |
| ep_rewmean              | 225       |
| episodes                | 1312      |
| eplenmean               | 107       |
| fps                     | 23        |
| mean 100 episode reward | 225       |
| n_updates               | 29600     |
| q_grad_norm             | 2781.0732 |
| qfs_loss                | 52.839245 |
| qs_abs_difference       | 46        |
| qs_difference           | 45.3      |
| qs_mean                 | 151.59355 |
| time_elapsed            | 1683      |
| total timesteps         | 39740     |
| train_time              | 344       |
| update_time             | 1237      |
---------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 5.4       |
| env_time                | 63        |
| ep_rewmean              | 221       |
| episodes                | 1316      |
| eplenmean               | 106       |
| fps                     | 23        |
| mean 100 episode reward | 221       |
| n_updates               | 30000     |
| q_grad_norm             | 3179.2312 |
| qfs_loss                | 64.50629  |
| qs_abs_difference       | 173       |
| qs_difference           | 173       |
| qs_mean                 | 195.10771 |
| time_elapsed            | 1700      |
| total timesteps         | 39955     |
| train_time              | 349       |
| update_time             | 1247      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 93.7      |
| eval_abs_qs_difference  | 33.907734 |
| eval_discount_q         | 147       |
| eval_ep_rewmean         | 285       |
| eval_eplenmean          | 130       |
| eval_qs                 | 132.618   |
| eval_qs_difference      | 25.9      |
| eval_time_elapsed       | 3         |
| total timesteps         | 40001     |
---------------------------------------
---------------------------------------
| act_time                | 16        |
| current_lr              | 0.0003    |
| discount_q              | 1.96      |
| env_time                | 64        |
| ep_rewmean              | 225       |
| episodes                | 1320      |
| eplenmean               | 108       |
| fps                     | 23        |
| mean 100 episode reward | 225       |
| n_updates               | 31200     |
| q_grad_norm             | 2737.2153 |
| qfs_loss                | 63.61741  |
| qs_abs_difference       | 31.6      |
| qs_difference           | 31        |
| qs_mean                 | 142.66243 |
| time_elapsed            | 1751      |
| total timesteps         | 40558     |
| train_time              | 363       |
| update_time             | 1280      |
---------------------------------------
---------------------------------------
| act_time                | 17        |
| current_lr              | 0.0003    |
| discount_q              | 2.41      |
| env_time                | 65        |
| ep_rewmean              | 229       |
| episodes                | 1324      |
| eplenmean               | 109       |
| fps                     | 22        |
| mean 100 episode reward | 229       |
| n_updates               | 32400     |
| q_grad_norm             | 3321.0796 |
| qfs_loss                | 67.89126  |
| qs_abs_difference       | 32.5      |
| qs_difference           | 31.5      |
| qs_mean                 | 144.96169 |
| time_elapsed            | 1800      |
| total timesteps         | 41116     |
| train_time              | 376       |
| update_time             | 1313      |
---------------------------------------
---------------------------------------
| act_time                | 17        |
| current_lr              | 0.0003    |
| discount_q              | 2.55      |
| env_time                | 66        |
| ep_rewmean              | 233       |
| episodes                | 1328      |
| eplenmean               | 110       |
| fps                     | 22        |
| mean 100 episode reward | 233       |
| n_updates               | 33400     |
| q_grad_norm             | 3300.6091 |
| qfs_loss                | 75.50104  |
| qs_abs_difference       | 35.1      |
| qs_difference           | 35.1      |
| qs_mean                 | 141.90732 |
| time_elapsed            | 1840      |
| total timesteps         | 41656     |
| train_time              | 388       |
| update_time             | 1341      |
---------------------------------------
---------------------------------------
| act_time                | 18        |
| current_lr              | 0.0003    |
| discount_q              | 1.29      |
| env_time                | 67        |
| ep_rewmean              | 239       |
| episodes                | 1332      |
| eplenmean               | 113       |
| fps                     | 22        |
| mean 100 episode reward | 239       |
| n_updates               | 34600     |
| q_grad_norm             | 2871.104  |
| qfs_loss                | 63.693703 |
| qs_abs_difference       | 29.3      |
| qs_difference           | 29.3      |
| qs_mean                 | 136.73872 |
| time_elapsed            | 1889      |
| total timesteps         | 42261     |
| train_time              | 402       |
| update_time             | 1374      |
---------------------------------------
--------------------------------------
| act_time                | 18       |
| current_lr              | 0.0003   |
| discount_q              | 1.56     |
| env_time                | 68       |
| ep_rewmean              | 244      |
| episodes                | 1336     |
| eplenmean               | 115      |
| fps                     | 22       |
| mean 100 episode reward | 244      |
| n_updates               | 35800    |
| q_grad_norm             | 3440.29  |
| qfs_loss                | 70.36932 |
| qs_abs_difference       | 44.1     |
| qs_difference           | 42.9     |
| qs_mean                 | 151.8123 |
| time_elapsed            | 1938     |
| total timesteps         | 42876    |
| train_time              | 416      |
| update_time             | 1407     |
--------------------------------------
---------------------------------------
| act_time                | 19        |
| current_lr              | 0.0003    |
| discount_q              | 1.56      |
| env_time                | 69        |
| ep_rewmean              | 249       |
| episodes                | 1340      |
| eplenmean               | 117       |
| fps                     | 21        |
| mean 100 episode reward | 249       |
| n_updates               | 37200     |
| q_grad_norm             | 2895.152  |
| qfs_loss                | 64.64733  |
| qs_abs_difference       | 46.3      |
| qs_difference           | 46.2      |
| qs_mean                 | 160.53807 |
| time_elapsed            | 1994      |
| total timesteps         | 43547     |
| train_time              | 432       |
| update_time             | 1445      |
---------------------------------------
---------------------------------------
| act_time                | 19        |
| current_lr              | 0.0003    |
| discount_q              | 0.629     |
| env_time                | 70        |
| ep_rewmean              | 255       |
| episodes                | 1344      |
| eplenmean               | 120       |
| fps                     | 21        |
| mean 100 episode reward | 255       |
| n_updates               | 38600     |
| q_grad_norm             | 2991.7012 |
| qfs_loss                | 61.8676   |
| qs_abs_difference       | 29.5      |
| qs_difference           | 28.4      |
| qs_mean                 | 143.3652  |
| time_elapsed            | 2052      |
| total timesteps         | 44242     |
| train_time              | 448       |
| update_time             | 1485      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 1.37      |
| env_time                | 72        |
| ep_rewmean              | 260       |
| episodes                | 1348      |
| eplenmean               | 123       |
| fps                     | 21        |
| mean 100 episode reward | 260       |
| n_updates               | 40000     |
| q_grad_norm             | 2501.876  |
| qfs_loss                | 49.986256 |
| qs_abs_difference       | 39.6      |
| qs_difference           | 38.7      |
| qs_mean                 | 153.6776  |
| time_elapsed            | 2110      |
| total timesteps         | 44920     |
| train_time              | 464       |
| update_time             | 1524      |
---------------------------------------
---------------------------------------
| act_time                | 20        |
| current_lr              | 0.0003    |
| discount_q              | 1.39      |
| env_time                | 73        |
| ep_rewmean              | 265       |
| episodes                | 1352      |
| eplenmean               | 125       |
| fps                     | 21        |
| mean 100 episode reward | 265       |
| n_updates               | 41200     |
| q_grad_norm             | 2931.2822 |
| qfs_loss                | 55.21341  |
| qs_abs_difference       | 34.1      |
| qs_difference           | 31.4      |
| qs_mean                 | 149.18422 |
| time_elapsed            | 2159      |
| total timesteps         | 45558     |
| train_time              | 478       |
| update_time             | 1559      |
---------------------------------------
---------------------------------------
| act_time                | 21        |
| current_lr              | 0.0003    |
| discount_q              | 2.17      |
| env_time                | 74        |
| ep_rewmean              | 268       |
| episodes                | 1356      |
| eplenmean               | 127       |
| fps                     | 20        |
| mean 100 episode reward | 268       |
| n_updates               | 42400     |
| q_grad_norm             | 2383.4998 |
| qfs_loss                | 45.883877 |
| qs_abs_difference       | 35.8      |
| qs_difference           | 35.8      |
| qs_mean                 | 142.96085 |
| time_elapsed            | 2209      |
| total timesteps         | 46129     |
| train_time              | 492       |
| update_time             | 1593      |
---------------------------------------
---------------------------------------
| act_time                | 21        |
| current_lr              | 0.0003    |
| discount_q              | 1.88      |
| env_time                | 75        |
| ep_rewmean              | 271       |
| episodes                | 1360      |
| eplenmean               | 128       |
| fps                     | 20        |
| mean 100 episode reward | 271       |
| n_updates               | 43400     |
| q_grad_norm             | 2331.2869 |
| qfs_loss                | 42.964756 |
| qs_abs_difference       | 41.1      |
| qs_difference           | 40.2      |
| qs_mean                 | 143.29013 |
| time_elapsed            | 2251      |
| total timesteps         | 46697     |
| train_time              | 503       |
| update_time             | 1622      |
---------------------------------------
---------------------------------------
| act_time                | 22        |
| current_lr              | 0.0003    |
| discount_q              | 1.16      |
| env_time                | 76        |
| ep_rewmean              | 274       |
| episodes                | 1364      |
| eplenmean               | 130       |
| fps                     | 20        |
| mean 100 episode reward | 274       |
| n_updates               | 44800     |
| q_grad_norm             | 2006.6211 |
| qfs_loss                | 45.874897 |
| qs_abs_difference       | 37.9      |
| qs_difference           | 37.5      |
| qs_mean                 | 143.38205 |
| time_elapsed            | 2310      |
| total timesteps         | 47336     |
| train_time              | 520       |
| update_time             | 1662      |
---------------------------------------
---------------------------------------
| act_time                | 23        |
| current_lr              | 0.0003    |
| discount_q              | 1.12      |
| env_time                | 77        |
| ep_rewmean              | 277       |
| episodes                | 1368      |
| eplenmean               | 131       |
| fps                     | 20        |
| mean 100 episode reward | 277       |
| n_updates               | 46000     |
| q_grad_norm             | 2388.3716 |
| qfs_loss                | 46.39629  |
| qs_abs_difference       | 27.8      |
| qs_difference           | 27.6      |
| qs_mean                 | 134.73344 |
| time_elapsed            | 2360      |
| total timesteps         | 47965     |
| train_time              | 533       |
| update_time             | 1697      |
---------------------------------------
---------------------------------------
| act_time                | 23        |
| current_lr              | 0.0003    |
| discount_q              | 1.09      |
| env_time                | 78        |
| ep_rewmean              | 280       |
| episodes                | 1372      |
| eplenmean               | 133       |
| fps                     | 20        |
| mean 100 episode reward | 280       |
| n_updates               | 47200     |
| q_grad_norm             | 2086.6726 |
| qfs_loss                | 38.733223 |
| qs_abs_difference       | 30.4      |
| qs_difference           | 30.3      |
| qs_mean                 | 137.09334 |
| time_elapsed            | 2411      |
| total timesteps         | 48596     |
| train_time              | 547       |
| update_time             | 1732      |
---------------------------------------
---------------------------------------
| act_time                | 24        |
| current_lr              | 0.0003    |
| discount_q              | 1.52      |
| env_time                | 79        |
| ep_rewmean              | 284       |
| episodes                | 1376      |
| eplenmean               | 135       |
| fps                     | 19        |
| mean 100 episode reward | 284       |
| n_updates               | 48600     |
| q_grad_norm             | 2721.4988 |
| qfs_loss                | 49.506977 |
| qs_abs_difference       | 33.3      |
| qs_difference           | 33.3      |
| qs_mean                 | 147.56282 |
| time_elapsed            | 2470      |
| total timesteps         | 49261     |
| train_time              | 563       |
| update_time             | 1773      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 126       |
| eval_abs_qs_difference  | 47.596146 |
| eval_discount_q         | 138       |
| eval_ep_rewmean         | 282       |
| eval_eplenmean          | 151       |
| eval_qs                 | 141.56044 |
| eval_qs_difference      | 45.3      |
| eval_time_elapsed       | 4         |
| total timesteps         | 50001     |
---------------------------------------
---------------------------------------
| act_time                | 24        |
| current_lr              | 0.0003    |
| discount_q              | 0.275     |
| env_time                | 80        |
| ep_rewmean              | 289       |
| episodes                | 1380      |
| eplenmean               | 139       |
| fps                     | 19        |
| mean 100 episode reward | 289       |
| n_updates               | 50200     |
| q_grad_norm             | 2500.7114 |
| qfs_loss                | 57.292362 |
| qs_abs_difference       | 40.3      |
| qs_difference           | 40.2      |
| qs_mean                 | 146.06273 |
| time_elapsed            | 2543      |
| total timesteps         | 50077     |
| train_time              | 582       |
| update_time             | 1821      |
---------------------------------------
---------------------------------------
| act_time                | 25        |
| current_lr              | 0.0003    |
| discount_q              | 1.22      |
| env_time                | 81        |
| ep_rewmean              | 292       |
| episodes                | 1384      |
| eplenmean               | 141       |
| fps                     | 19        |
| mean 100 episode reward | 292       |
| n_updates               | 51400     |
| q_grad_norm             | 2300.7168 |
| qfs_loss                | 44.015083 |
| qs_abs_difference       | 28        |
| qs_difference           | 28        |
| qs_mean                 | 135.3157  |
| time_elapsed            | 2595      |
| total timesteps         | 50687     |
| train_time              | 596       |
| update_time             | 1857      |
---------------------------------------
---------------------------------------
| act_time                | 25        |
| current_lr              | 0.0003    |
| discount_q              | 1.67      |
| env_time                | 82        |
| ep_rewmean              | 298       |
| episodes                | 1388      |
| eplenmean               | 144       |
| fps                     | 19        |
| mean 100 episode reward | 298       |
| n_updates               | 52600     |
| q_grad_norm             | 1823.0658 |
| qfs_loss                | 37.191933 |
| qs_abs_difference       | 26.6      |
| qs_difference           | 26.2      |
| qs_mean                 | 140.47847 |
| time_elapsed            | 2646      |
| total timesteps         | 51286     |
| train_time              | 610       |
| update_time             | 1893      |
---------------------------------------
--------------------------------------
| act_time                | 26       |
| current_lr              | 0.0003   |
| discount_q              | 1.33     |
| env_time                | 83       |
| ep_rewmean              | 301      |
| episodes                | 1392     |
| eplenmean               | 146      |
| fps                     | 19       |
| mean 100 episode reward | 301      |
| n_updates               | 54000    |
| q_grad_norm             | 1892.336 |
| qfs_loss                | 39.8885  |
| qs_abs_difference       | 55.7     |
| qs_difference           | 55.7     |
| qs_mean                 | 157.8483 |
| time_elapsed            | 2707     |
| total timesteps         | 51947    |
| train_time              | 626      |
| update_time             | 1936     |
--------------------------------------
---------------------------------------
| act_time                | 26        |
| current_lr              | 0.0003    |
| discount_q              | 2.42      |
| env_time                | 84        |
| ep_rewmean              | 304       |
| episodes                | 1396      |
| eplenmean               | 148       |
| fps                     | 19        |
| mean 100 episode reward | 304       |
| n_updates               | 55200     |
| q_grad_norm             | 2164.8167 |
| qfs_loss                | 43.7503   |
| qs_abs_difference       | 25.7      |
| qs_difference           | 25.7      |
| qs_mean                 | 133.30844 |
| time_elapsed            | 2759      |
| total timesteps         | 52505     |
| train_time              | 640       |
| update_time             | 1972      |
---------------------------------------
---------------------------------------
| act_time                | 27        |
| current_lr              | 0.0003    |
| discount_q              | 5.92      |
| env_time                | 85        |
| ep_rewmean              | 304       |
| episodes                | 1400      |
| eplenmean               | 148       |
| fps                     | 18        |
| mean 100 episode reward | 304       |
| n_updates               | 56000     |
| q_grad_norm             | 1906.645  |
| qfs_loss                | 36.593758 |
| qs_abs_difference       | 21.5      |
| qs_difference           | 21.4      |
| qs_mean                 | 129.95685 |
| time_elapsed            | 2794      |
| total timesteps         | 52954     |
| train_time              | 649       |
| update_time             | 1997      |
---------------------------------------
---------------------------------------
| act_time                | 27        |
| current_lr              | 0.0003    |
| discount_q              | 2.91      |
| env_time                | 86        |
| ep_rewmean              | 305       |
| episodes                | 1404      |
| eplenmean               | 148       |
| fps                     | 18        |
| mean 100 episode reward | 305       |
| n_updates               | 57000     |
| q_grad_norm             | 1791.9889 |
| qfs_loss                | 35.902935 |
| qs_abs_difference       | 24.5      |
| qs_difference           | 24.5      |
| qs_mean                 | 132.60619 |
| time_elapsed            | 2837      |
| total timesteps         | 53476     |
| train_time              | 660       |
| update_time             | 2028      |
---------------------------------------
---------------------------------------
| act_time                | 28        |
| current_lr              | 0.0003    |
| discount_q              | 2.34      |
| env_time                | 87        |
| ep_rewmean              | 305       |
| episodes                | 1408      |
| eplenmean               | 148       |
| fps                     | 18        |
| mean 100 episode reward | 305       |
| n_updates               | 58200     |
| q_grad_norm             | 1633.5447 |
| qfs_loss                | 42.482246 |
| qs_abs_difference       | 29.5      |
| qs_difference           | 29.5      |
| qs_mean                 | 134.14273 |
| time_elapsed            | 2890      |
| total timesteps         | 54025     |
| train_time              | 674       |
| update_time             | 2065      |
---------------------------------------
---------------------------------------
| act_time                | 28        |
| current_lr              | 0.0003    |
| discount_q              | 2.1       |
| env_time                | 88        |
| ep_rewmean              | 306       |
| episodes                | 1412      |
| eplenmean               | 149       |
| fps                     | 18        |
| mean 100 episode reward | 306       |
| n_updates               | 59400     |
| q_grad_norm             | 1932.3378 |
| qfs_loss                | 38.317738 |
| qs_abs_difference       | 12        |
| qs_difference           | 5.99      |
| qs_mean                 | 130.86057 |
| time_elapsed            | 2943      |
| total timesteps         | 54622     |
| train_time              | 688       |
| update_time             | 2103      |
---------------------------------------
---------------------------------------
| act_time                | 29        |
| current_lr              | 0.0003    |
| discount_q              | 2.93      |
| env_time                | 89        |
| ep_rewmean              | 314       |
| episodes                | 1416      |
| eplenmean               | 152       |
| fps                     | 18        |
| mean 100 episode reward | 314       |
| n_updates               | 60400     |
| q_grad_norm             | 2072.3716 |
| qfs_loss                | 46.852463 |
| qs_abs_difference       | 11.6      |
| qs_difference           | 10.5      |
| qs_mean                 | 130.02599 |
| time_elapsed            | 2987      |
| total timesteps         | 55170     |
| train_time              | 699       |
| update_time             | 2134      |
---------------------------------------
---------------------------------------
| act_time                | 29        |
| current_lr              | 0.0003    |
| discount_q              | 2.62      |
| env_time                | 89        |
| ep_rewmean              | 314       |
| episodes                | 1420      |
| eplenmean               | 151       |
| fps                     | 18        |
| mean 100 episode reward | 314       |
| n_updates               | 61400     |
| q_grad_norm             | 1529.705  |
| qfs_loss                | 33.227943 |
| qs_abs_difference       | 24.7      |
| qs_difference           | 24.7      |
| qs_mean                 | 128.97827 |
| time_elapsed            | 3032      |
| total timesteps         | 55692     |
| train_time              | 711       |
| update_time             | 2166      |
---------------------------------------
---------------------------------------
| act_time                | 30        |
| current_lr              | 0.0003    |
| discount_q              | 2.03      |
| env_time                | 90        |
| ep_rewmean              | 314       |
| episodes                | 1424      |
| eplenmean               | 151       |
| fps                     | 18        |
| mean 100 episode reward | 314       |
| n_updates               | 62600     |
| q_grad_norm             | 1892.5328 |
| qfs_loss                | 35.82591  |
| qs_abs_difference       | 34.8      |
| qs_difference           | 34.8      |
| qs_mean                 | 135.32922 |
| time_elapsed            | 3085      |
| total timesteps         | 56213     |
| train_time              | 725       |
| update_time             | 2203      |
---------------------------------------
---------------------------------------
| act_time                | 30        |
| current_lr              | 0.0003    |
| discount_q              | 3.85      |
| env_time                | 91        |
| ep_rewmean              | 314       |
| episodes                | 1428      |
| eplenmean               | 151       |
| fps                     | 18        |
| mean 100 episode reward | 314       |
| n_updates               | 63600     |
| q_grad_norm             | 1928.7323 |
| qfs_loss                | 43.864033 |
| qs_abs_difference       | 16.1      |
| qs_difference           | 15.9      |
| qs_mean                 | 131.93651 |
| time_elapsed            | 3130      |
| total timesteps         | 56723     |
| train_time              | 736       |
| update_time             | 2235      |
---------------------------------------
---------------------------------------
| act_time                | 30        |
| current_lr              | 0.0003    |
| discount_q              | 2.22      |
| env_time                | 92        |
| ep_rewmean              | 314       |
| episodes                | 1432      |
| eplenmean               | 151       |
| fps                     | 18        |
| mean 100 episode reward | 314       |
| n_updates               | 64800     |
| q_grad_norm             | 2014.0487 |
| qfs_loss                | 44.02983  |
| qs_abs_difference       | 7.46      |
| qs_difference           | 1.88      |
| qs_mean                 | 133.92975 |
| time_elapsed            | 3183      |
| total timesteps         | 57312     |
| train_time              | 750       |
| update_time             | 2273      |
---------------------------------------
---------------------------------------
| act_time                | 31        |
| current_lr              | 0.0003    |
| discount_q              | 3.07      |
| env_time                | 93        |
| ep_rewmean              | 313       |
| episodes                | 1436      |
| eplenmean               | 150       |
| fps                     | 17        |
| mean 100 episode reward | 314       |
| n_updates               | 65800     |
| q_grad_norm             | 1948.6244 |
| qfs_loss                | 45.042183 |
| qs_abs_difference       | 10.2      |
| qs_difference           | 7.8       |
| qs_mean                 | 131.25874 |
| time_elapsed            | 3229      |
| total timesteps         | 57841     |
| train_time              | 762       |
| update_time             | 2305      |
---------------------------------------
---------------------------------------
| act_time                | 31        |
| current_lr              | 0.0003    |
| discount_q              | 1.91      |
| env_time                | 94        |
| ep_rewmean              | 314       |
| episodes                | 1440      |
| eplenmean               | 149       |
| fps                     | 17        |
| mean 100 episode reward | 314       |
| n_updates               | 67000     |
| q_grad_norm             | 1689.2098 |
| qfs_loss                | 39.67602  |
| qs_abs_difference       | 6.24      |
| qs_difference           | 2.33      |
| qs_mean                 | 140.81606 |
| time_elapsed            | 3283      |
| total timesteps         | 58443     |
| train_time              | 775       |
| update_time             | 2344      |
---------------------------------------
---------------------------------------
| act_time                | 32        |
| current_lr              | 0.0003    |
| discount_q              | 1.46      |
| env_time                | 95        |
| ep_rewmean              | 316       |
| episodes                | 1444      |
| eplenmean               | 149       |
| fps                     | 17        |
| mean 100 episode reward | 316       |
| n_updates               | 68200     |
| q_grad_norm             | 1536.3152 |
| qfs_loss                | 35.681072 |
| qs_abs_difference       | 18.2      |
| qs_difference           | -15.3     |
| qs_mean                 | 139.64401 |
| time_elapsed            | 3338      |
| total timesteps         | 59093     |
| train_time              | 789       |
| update_time             | 2383      |
---------------------------------------
---------------------------------------
| act_time                | 32        |
| current_lr              | 0.0003    |
| discount_q              | 1.82      |
| env_time                | 96        |
| ep_rewmean              | 316       |
| episodes                | 1448      |
| eplenmean               | 148       |
| fps                     | 17        |
| mean 100 episode reward | 316       |
| n_updates               | 69400     |
| q_grad_norm             | 1771.501  |
| qfs_loss                | 43.847973 |
| qs_abs_difference       | 41.8      |
| qs_difference           | 40        |
| qs_mean                 | 157.30766 |
| time_elapsed            | 3392      |
| total timesteps         | 59692     |
| train_time              | 803       |
| update_time             | 2422      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 185       |
| eval_abs_qs_difference  | 33.019966 |
| eval_discount_q         | 188       |
| eval_ep_rewmean         | 546       |
| eval_eplenmean          | 223       |
| eval_qs                 | 167.47955 |
| eval_qs_difference      | 10.2      |
| eval_time_elapsed       | 5         |
| total timesteps         | 60001     |
---------------------------------------
---------------------------------------
| act_time                | 33        |
| current_lr              | 0.0003    |
| discount_q              | 1.72      |
| env_time                | 97        |
| ep_rewmean              | 319       |
| episodes                | 1452      |
| eplenmean               | 148       |
| fps                     | 17        |
| mean 100 episode reward | 319       |
| n_updates               | 70800     |
| q_grad_norm             | 1907.5598 |
| qfs_loss                | 45.55408  |
| qs_abs_difference       | 11.4      |
| qs_difference           | 4.74      |
| qs_mean                 | 160.19412 |
| time_elapsed            | 3462      |
| total timesteps         | 60335     |
| train_time              | 819       |
| update_time             | 2468      |
---------------------------------------
---------------------------------------
| act_time                | 34        |
| current_lr              | 0.0003    |
| discount_q              | 1.62      |
| env_time                | 98        |
| ep_rewmean              | 325       |
| episodes                | 1456      |
| eplenmean               | 149       |
| fps                     | 17        |
| mean 100 episode reward | 325       |
| n_updates               | 72200     |
| q_grad_norm             | 2266.032  |
| qfs_loss                | 59.684624 |
| qs_abs_difference       | 10.9      |
| qs_difference           | -4.96     |
| qs_mean                 | 172.75296 |
| time_elapsed            | 3526      |
| total timesteps         | 61022     |
| train_time              | 835       |
| update_time             | 2515      |
---------------------------------------
---------------------------------------
| act_time                | 34        |
| current_lr              | 0.0003    |
| discount_q              | 0.599     |
| env_time                | 99        |
| ep_rewmean              | 333       |
| episodes                | 1460      |
| eplenmean               | 151       |
| fps                     | 17        |
| mean 100 episode reward | 333       |
| n_updates               | 73800     |
| q_grad_norm             | 2072.2449 |
| qfs_loss                | 53.674854 |
| qs_abs_difference       | 13.6      |
| qs_difference           | -2.57     |
| qs_mean                 | 179.90399 |
| time_elapsed            | 3600      |
| total timesteps         | 61817     |
| train_time              | 854       |
| update_time             | 2568      |
---------------------------------------
---------------------------------------
| act_time                | 35        |
| current_lr              | 0.0003    |
| discount_q              | 2.36      |
| env_time                | 100       |
| ep_rewmean              | 334       |
| episodes                | 1464      |
| eplenmean               | 151       |
| fps                     | 17        |
| mean 100 episode reward | 334       |
| n_updates               | 74800     |
| q_grad_norm             | 2323.167  |
| qfs_loss                | 62.041958 |
| qs_abs_difference       | 44.5      |
| qs_difference           | 44        |
| qs_mean                 | 181.14857 |
| time_elapsed            | 3647      |
| total timesteps         | 62395     |
| train_time              | 865       |
| update_time             | 2601      |
---------------------------------------
---------------------------------------
| act_time                | 35        |
| current_lr              | 0.0003    |
| discount_q              | 1.34      |
| env_time                | 101       |
| ep_rewmean              | 340       |
| episodes                | 1468      |
| eplenmean               | 151       |
| fps                     | 16        |
| mean 100 episode reward | 340       |
| n_updates               | 76200     |
| q_grad_norm             | 2508.5388 |
| qfs_loss                | 64.25664  |
| qs_abs_difference       | 7.71      |
| qs_difference           | 4.9       |
| qs_mean                 | 185.2594  |
| time_elapsed            | 3712      |
| total timesteps         | 63099     |
| train_time              | 882       |
| update_time             | 2648      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 0.457     |
| env_time                | 102       |
| ep_rewmean              | 339       |
| episodes                | 1472      |
| eplenmean               | 150       |
| fps                     | 16        |
| mean 100 episode reward | 339       |
| n_updates               | 77200     |
| q_grad_norm             | 2803.8367 |
| qfs_loss                | 68.03391  |
| qs_abs_difference       | 204       |
| qs_difference           | 204       |
| qs_mean                 | 224.90405 |
| time_elapsed            | 3759      |
| total timesteps         | 63551     |
| train_time              | 893       |
| update_time             | 2682      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 17.9      |
| env_time                | 102       |
| ep_rewmean              | 327       |
| episodes                | 1476      |
| eplenmean               | 144       |
| fps                     | 16        |
| mean 100 episode reward | 327       |
| n_updates               | 77400     |
| q_grad_norm             | 2801.9602 |
| qfs_loss                | 61.767582 |
| qs_abs_difference       | 204       |
| qs_difference           | 204       |
| qs_mean                 | 225.7824  |
| time_elapsed            | 3768      |
| total timesteps         | 63643     |
| train_time              | 895       |
| update_time             | 2689      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 18.9      |
| env_time                | 102       |
| ep_rewmean              | 314       |
| episodes                | 1480      |
| eplenmean               | 137       |
| fps                     | 16        |
| mean 100 episode reward | 314       |
| n_updates               | 77600     |
| q_grad_norm             | 2737.4602 |
| qfs_loss                | 89.51367  |
| qs_abs_difference       | 203       |
| qs_difference           | 203       |
| qs_mean                 | 226.6576  |
| time_elapsed            | 3777      |
| total timesteps         | 63740     |
| train_time              | 898       |
| update_time             | 2696      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 16.8      |
| env_time                | 102       |
| ep_rewmean              | 304       |
| episodes                | 1484      |
| eplenmean               | 131       |
| fps                     | 16        |
| mean 100 episode reward | 304       |
| n_updates               | 77800     |
| q_grad_norm             | 2991.511  |
| qfs_loss                | 72.76354  |
| qs_abs_difference       | 203       |
| qs_difference           | 203       |
| qs_mean                 | 224.69936 |
| time_elapsed            | 3787      |
| total timesteps         | 63834     |
| train_time              | 900       |
| update_time             | 2702      |
---------------------------------------
---------------------------------------
| act_time                | 36        |
| current_lr              | 0.0003    |
| discount_q              | 10.2      |
| env_time                | 103       |
| ep_rewmean              | 297       |
| episodes                | 1488      |
| eplenmean               | 128       |
| fps                     | 16        |
| mean 100 episode reward | 297       |
| n_updates               | 78200     |
| q_grad_norm             | 2415.915  |
| qfs_loss                | 67.68327  |
| qs_abs_difference       | 182       |
| qs_difference           | 182       |
| qs_mean                 | 227.37053 |
| time_elapsed            | 3806      |
| total timesteps         | 64094     |
| train_time              | 905       |
| update_time             | 2716      |
---------------------------------------
---------------------------------------
| act_time                | 37        |
| current_lr              | 0.0003    |
| discount_q              | 2.05      |
| env_time                | 104       |
| ep_rewmean              | 299       |
| episodes                | 1492      |
| eplenmean               | 127       |
| fps                     | 16        |
| mean 100 episode reward | 299       |
| n_updates               | 79400     |
| q_grad_norm             | 3059.2893 |
| qfs_loss                | 97.88687  |
| qs_abs_difference       | 37.8      |
| qs_difference           | 35.3      |
| qs_mean                 | 177.84154 |
| time_elapsed            | 3862      |
| total timesteps         | 64682     |
| train_time              | 919       |
| update_time             | 2757      |
---------------------------------------
---------------------------------------
| act_time                | 37        |
| current_lr              | 0.0003    |
| discount_q              | 1.17      |
| env_time                | 105       |
| ep_rewmean              | 305       |
| episodes                | 1496      |
| eplenmean               | 129       |
| fps                     | 16        |
| mean 100 episode reward | 305       |
| n_updates               | 80800     |
| q_grad_norm             | 2972.3215 |
| qfs_loss                | 77.440994 |
| qs_abs_difference       | 72.3      |
| qs_difference           | 72.1      |
| qs_mean                 | 214.70247 |
| time_elapsed            | 3929      |
| total timesteps         | 65363     |
| train_time              | 935       |
| update_time             | 2805      |
---------------------------------------
---------------------------------------
| act_time                | 38        |
| current_lr              | 0.0003    |
| discount_q              | 0.769     |
| env_time                | 106       |
| ep_rewmean              | 315       |
| episodes                | 1500      |
| eplenmean               | 131       |
| fps                     | 16        |
| mean 100 episode reward | 315       |
| n_updates               | 82200     |
| q_grad_norm             | 3070.6292 |
| qfs_loss                | 79.72471  |
| qs_abs_difference       | 26.7      |
| qs_difference           | 24.5      |
| qs_mean                 | 191.82043 |
| time_elapsed            | 3995      |
| total timesteps         | 66081     |
| train_time              | 951       |
| update_time             | 2854      |
---------------------------------------
---------------------------------------
| act_time                | 38        |
| current_lr              | 0.0003    |
| discount_q              | 2.47      |
| env_time                | 107       |
| ep_rewmean              | 319       |
| episodes                | 1504      |
| eplenmean               | 132       |
| fps                     | 16        |
| mean 100 episode reward | 319       |
| n_updates               | 83400     |
| q_grad_norm             | 2782.941  |
| qfs_loss                | 72.0939   |
| qs_abs_difference       | 74.5      |
| qs_difference           | 74.5      |
| qs_mean                 | 217.38492 |
| time_elapsed            | 4052      |
| total timesteps         | 66683     |
| train_time              | 965       |
| update_time             | 2895      |
---------------------------------------
---------------------------------------
| act_time                | 39        |
| current_lr              | 0.0003    |
| discount_q              | 1.18      |
| env_time                | 108       |
| ep_rewmean              | 325       |
| episodes                | 1508      |
| eplenmean               | 133       |
| fps                     | 16        |
| mean 100 episode reward | 324       |
| n_updates               | 84800     |
| q_grad_norm             | 3450.4    |
| qfs_loss                | 85.6922   |
| qs_abs_difference       | 46.7      |
| qs_difference           | 45.6      |
| qs_mean                 | 201.19579 |
| time_elapsed            | 4119      |
| total timesteps         | 67347     |
| train_time              | 981       |
| update_time             | 2944      |
---------------------------------------
---------------------------------------
| act_time                | 39        |
| current_lr              | 0.0003    |
| discount_q              | 0.993     |
| env_time                | 109       |
| ep_rewmean              | 325       |
| episodes                | 1512      |
| eplenmean               | 133       |
| fps                     | 16        |
| mean 100 episode reward | 325       |
| n_updates               | 86000     |
| q_grad_norm             | 3396.6985 |
| qfs_loss                | 80.05635  |
| qs_abs_difference       | 176       |
| qs_difference           | 176       |
| qs_mean                 | 255.60167 |
| time_elapsed            | 4177      |
| total timesteps         | 67917     |
| train_time              | 995       |
| update_time             | 2987      |
---------------------------------------
---------------------------------------
| act_time                | 40        |
| current_lr              | 0.0003    |
| discount_q              | 0.843     |
| env_time                | 110       |
| ep_rewmean              | 326       |
| episodes                | 1516      |
| eplenmean               | 132       |
| fps                     | 16        |
| mean 100 episode reward | 326       |
| n_updates               | 86800     |
| q_grad_norm             | 2986.9077 |
| qfs_loss                | 80.85113  |
| qs_abs_difference       | 218       |
| qs_difference           | 218       |
| qs_mean                 | 255.03078 |
| time_elapsed            | 4216      |
| total timesteps         | 68395     |
| train_time              | 1004      |
| update_time             | 3015      |
---------------------------------------
--------------------------------------
| act_time                | 40       |
| current_lr              | 0.0003   |
| discount_q              | 5.21     |
| env_time                | 110      |
| ep_rewmean              | 321      |
| episodes                | 1520     |
| eplenmean               | 130      |
| fps                     | 16       |
| mean 100 episode reward | 320      |
| n_updates               | 87400    |
| q_grad_norm             | 3045.897 |
| qfs_loss                | 75.24016 |
| qs_abs_difference       | 220      |
| qs_difference           | 220      |
| qs_mean                 | 258.5073 |
| time_elapsed            | 4245     |
| total timesteps         | 68695    |
| train_time              | 1011     |
| update_time             | 3036     |
--------------------------------------
----------------------------------------
| act_time                | 41         |
| current_lr              | 0.0003     |
| discount_q              | 0.645      |
| env_time                | 111        |
| ep_rewmean              | 328        |
| episodes                | 1524       |
| eplenmean               | 133        |
| fps                     | 16         |
| mean 100 episode reward | 328        |
| n_updates               | 89000      |
| q_grad_norm             | 3326.3171  |
| qfs_loss                | 103.049934 |
| qs_abs_difference       | 65.5       |
| qs_difference           | 64.9       |
| qs_mean                 | 218.66202  |
| time_elapsed            | 4323       |
| total timesteps         | 69468      |
| train_time              | 1029       |
| update_time             | 3094       |
----------------------------------------
---------------------------------------
| eval mean 100 episod... | 204       |
| eval_abs_qs_difference  | 94.48604  |
| eval_discount_q         | 158       |
| eval_ep_rewmean         | 326       |
| eval_eplenmean          | 150       |
| eval_qs                 | 202.58714 |
| eval_qs_difference      | 89.3      |
| eval_time_elapsed       | 3         |
| total timesteps         | 70001     |
---------------------------------------
---------------------------------------
| act_time                | 41        |
| current_lr              | 0.0003    |
| discount_q              | 0.567     |
| env_time                | 113       |
| ep_rewmean              | 331       |
| episodes                | 1528      |
| eplenmean               | 135       |
| fps                     | 15        |
| mean 100 episode reward | 331       |
| n_updates               | 90600     |
| q_grad_norm             | 2922.8806 |
| qfs_loss                | 82.1066   |
| qs_abs_difference       | 101       |
| qs_difference           | 101       |
| qs_mean                 | 224.22253 |
| time_elapsed            | 4405      |
| total timesteps         | 70203     |
| train_time              | 1048      |
| update_time             | 3151      |
---------------------------------------
---------------------------------------
| act_time                | 42        |
| current_lr              | 0.0003    |
| discount_q              | 3.42      |
| env_time                | 114       |
| ep_rewmean              | 331       |
| episodes                | 1532      |
| eplenmean               | 135       |
| fps                     | 15        |
| mean 100 episode reward | 330       |
| n_updates               | 91600     |
| q_grad_norm             | 3486.696  |
| qfs_loss                | 85.358246 |
| qs_abs_difference       | 94.4      |
| qs_difference           | 94.3      |
| qs_mean                 | 221.9194  |
| time_elapsed            | 4454      |
| total timesteps         | 70780     |
| train_time              | 1060      |
| update_time             | 3187      |
---------------------------------------
---------------------------------------
| act_time                | 42        |
| current_lr              | 0.0003    |
| discount_q              | 0.855     |
| env_time                | 115       |
| ep_rewmean              | 335       |
| episodes                | 1536      |
| eplenmean               | 137       |
| fps                     | 15        |
| mean 100 episode reward | 335       |
| n_updates               | 93000     |
| q_grad_norm             | 3813.213  |
| qfs_loss                | 90.90799  |
| qs_abs_difference       | 68.4      |
| qs_difference           | 68.4      |
| qs_mean                 | 214.13124 |
| time_elapsed            | 4523      |
| total timesteps         | 71493     |
| train_time              | 1076      |
| update_time             | 3238      |
---------------------------------------
---------------------------------------
| act_time                | 43        |
| current_lr              | 0.0003    |
| discount_q              | 0.268     |
| env_time                | 116       |
| ep_rewmean              | 342       |
| episodes                | 1540      |
| eplenmean               | 139       |
| fps                     | 15        |
| mean 100 episode reward | 342       |
| n_updates               | 94800     |
| q_grad_norm             | 4009.271  |
| qfs_loss                | 83.71169  |
| qs_abs_difference       | 62.8      |
| qs_difference           | 62.8      |
| qs_mean                 | 219.84425 |
| time_elapsed            | 4612      |
| total timesteps         | 72344     |
| train_time              | 1096      |
| update_time             | 3303      |
---------------------------------------
---------------------------------------
| act_time                | 44        |
| current_lr              | 0.0003    |
| discount_q              | 0.119     |
| env_time                | 118       |
| ep_rewmean              | 350       |
| episodes                | 1544      |
| eplenmean               | 142       |
| fps                     | 15        |
| mean 100 episode reward | 350       |
| n_updates               | 96800     |
| q_grad_norm             | 2904.9194 |
| qfs_loss                | 75.14368  |
| qs_abs_difference       | 57.2      |
| qs_difference           | 57.2      |
| qs_mean                 | 232.08961 |
| time_elapsed            | 4711      |
| total timesteps         | 73336     |
| train_time              | 1119      |
| update_time             | 3377      |
---------------------------------------
---------------------------------------
| act_time                | 45        |
| current_lr              | 0.0003    |
| discount_q              | 0.46      |
| env_time                | 119       |
| ep_rewmean              | 357       |
| episodes                | 1548      |
| eplenmean               | 145       |
| fps                     | 15        |
| mean 100 episode reward | 357       |
| n_updates               | 98400     |
| q_grad_norm             | 3539.0972 |
| qfs_loss                | 100.01765 |
| qs_abs_difference       | 51.2      |
| qs_difference           | 50.1      |
| qs_mean                 | 219.00883 |
| time_elapsed            | 4791      |
| total timesteps         | 74152     |
| train_time              | 1138      |
| update_time             | 3436      |
---------------------------------------
---------------------------------------
| act_time                | 45        |
| current_lr              | 0.0003    |
| discount_q              | 0.517     |
| env_time                | 121       |
| ep_rewmean              | 364       |
| episodes                | 1552      |
| eplenmean               | 146       |
| fps                     | 15        |
| mean 100 episode reward | 364       |
| n_updates               | 100000    |
| q_grad_norm             | 2719.8987 |
| qfs_loss                | 73.912346 |
| qs_abs_difference       | 43.6      |
| qs_difference           | 43.5      |
| qs_mean                 | 225.89973 |
| time_elapsed            | 4871      |
| total timesteps         | 74964     |
| train_time              | 1156      |
| update_time             | 3496      |
---------------------------------------
---------------------------------------
| act_time                | 46        |
| current_lr              | 0.0003    |
| discount_q              | 0.322     |
| env_time                | 122       |
| ep_rewmean              | 375       |
| episodes                | 1556      |
| eplenmean               | 149       |
| fps                     | 15        |
| mean 100 episode reward | 375       |
| n_updates               | 101800    |
| q_grad_norm             | 3375.7075 |
| qfs_loss                | 97.97936  |
| qs_abs_difference       | 19.6      |
| qs_difference           | -2.83     |
| qs_mean                 | 228.34827 |
| time_elapsed            | 4961      |
| total timesteps         | 75888     |
| train_time              | 1177      |
| update_time             | 3563      |
---------------------------------------
---------------------------------------
| act_time                | 47        |
| current_lr              | 0.0003    |
| discount_q              | 0.0649    |
| env_time                | 124       |
| ep_rewmean              | 385       |
| episodes                | 1560      |
| eplenmean               | 151       |
| fps                     | 15        |
| mean 100 episode reward | 385       |
| n_updates               | 104000    |
| q_grad_norm             | 3296.2295 |
| qfs_loss                | 86.60663  |
| qs_abs_difference       | 41.4      |
| qs_difference           | 41.1      |
| qs_mean                 | 236.24193 |
| time_elapsed            | 5072      |
| total timesteps         | 76939     |
| train_time              | 1202      |
| update_time             | 3645      |
---------------------------------------
---------------------------------------
| act_time                | 48        |
| current_lr              | 0.0003    |
| discount_q              | 3.87      |
| env_time                | 125       |
| ep_rewmean              | 386       |
| episodes                | 1564      |
| eplenmean               | 151       |
| fps                     | 15        |
| mean 100 episode reward | 386       |
| n_updates               | 105200    |
| q_grad_norm             | 3406.2085 |
| qfs_loss                | 82.84932  |
| qs_abs_difference       | 49.4      |
| qs_difference           | 49.4      |
| qs_mean                 | 221.6283  |
| time_elapsed            | 5133      |
| total timesteps         | 77521     |
| train_time              | 1216      |
| update_time             | 3691      |
---------------------------------------
---------------------------------------
| act_time                | 48        |
| current_lr              | 0.0003    |
| discount_q              | 0.516     |
| env_time                | 126       |
| ep_rewmean              | 390       |
| episodes                | 1568      |
| eplenmean               | 153       |
| fps                     | 15        |
| mean 100 episode reward | 390       |
| n_updates               | 106800    |
| q_grad_norm             | 3228.7288 |
| qfs_loss                | 99.264206 |
| qs_abs_difference       | 29.1      |
| qs_difference           | 28.4      |
| qs_mean                 | 238.51448 |
| time_elapsed            | 5215      |
| total timesteps         | 78360     |
| train_time              | 1234      |
| update_time             | 3751      |
---------------------------------------
---------------------------------------
| act_time                | 49        |
| current_lr              | 0.0003    |
| discount_q              | 0.0239    |
| env_time                | 128       |
| ep_rewmean              | 416       |
| episodes                | 1572      |
| eplenmean               | 160       |
| fps                     | 14        |
| mean 100 episode reward | 416       |
| n_updates               | 109200    |
| q_grad_norm             | 2963.7366 |
| qfs_loss                | 81.64236  |
| qs_abs_difference       | 15.6      |
| qs_difference           | 11.5      |
| qs_mean                 | 250.11612 |
| time_elapsed            | 5338      |
| total timesteps         | 79578     |
| train_time              | 1262      |
| update_time             | 3843      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 265       |
| eval_abs_qs_difference  | 28.419323 |
| eval_discount_q         | 235       |
| eval_ep_rewmean         | 794       |
| eval_eplenmean          | 251       |
| eval_qs                 | 233.7123  |
| eval_qs_difference      | 16.9      |
| eval_time_elapsed       | 6         |
| total timesteps         | 80001     |
---------------------------------------
---------------------------------------
| act_time                | 50        |
| current_lr              | 0.0003    |
| discount_q              | 0.221     |
| env_time                | 130       |
| ep_rewmean              | 440       |
| episodes                | 1576      |
| eplenmean               | 168       |
| fps                     | 14        |
| mean 100 episode reward | 440       |
| n_updates               | 111000    |
| q_grad_norm             | 3131.2153 |
| qfs_loss                | 86.37247  |
| qs_abs_difference       | 21.3      |
| qs_difference           | 16.1      |
| qs_mean                 | 214.544   |
| time_elapsed            | 5436      |
| total timesteps         | 80453     |
| train_time              | 1283      |
| update_time             | 3912      |
---------------------------------------
----------------------------------------
| act_time                | 51         |
| current_lr              | 0.0003     |
| discount_q              | 0.000764   |
| env_time                | 132        |
| ep_rewmean              | 485        |
| episodes                | 1580       |
| eplenmean               | 183        |
| fps                     | 14         |
| mean 100 episode reward | 485        |
| n_updates               | 114200     |
| q_grad_norm             | 4179.2227  |
| qfs_loss                | 114.150986 |
| qs_abs_difference       | 108        |
| qs_difference           | 108        |
| qs_mean                 | 297.98685  |
| time_elapsed            | 5602       |
| total timesteps         | 82038      |
| train_time              | 1320       |
| update_time             | 4036       |
----------------------------------------
---------------------------------------
| act_time                | 53        |
| current_lr              | 0.0003    |
| discount_q              | 4.1e-05   |
| env_time                | 135       |
| ep_rewmean              | 534       |
| episodes                | 1584      |
| eplenmean               | 200       |
| fps                     | 14        |
| mean 100 episode reward | 534       |
| n_updates               | 117600    |
| q_grad_norm             | 3801.4316 |
| qfs_loss                | 111.43741 |
| qs_abs_difference       | 69.1      |
| qs_difference           | 67.9      |
| qs_mean                 | 251.23187 |
| time_elapsed            | 5779      |
| total timesteps         | 83791     |
| train_time              | 1359      |
| update_time             | 4169      |
---------------------------------------
---------------------------------------
| act_time                | 55        |
| current_lr              | 0.0003    |
| discount_q              | 6.53e-05  |
| env_time                | 138       |
| ep_rewmean              | 580       |
| episodes                | 1588      |
| eplenmean               | 216       |
| fps                     | 14        |
| mean 100 episode reward | 580       |
| n_updates               | 121400    |
| q_grad_norm             | 3459.868  |
| qfs_loss                | 101.11639 |
| qs_abs_difference       | 75.9      |
| qs_difference           | 75.1      |
| qs_mean                 | 294.98993 |
| time_elapsed            | 5977      |
| total timesteps         | 85657     |
| train_time              | 1403      |
| update_time             | 4318      |
---------------------------------------
---------------------------------------
| act_time                | 56        |
| current_lr              | 0.0003    |
| discount_q              | 0.00194   |
| env_time                | 141       |
| ep_rewmean              | 614       |
| episodes                | 1592      |
| eplenmean               | 226       |
| fps                     | 14        |
| mean 100 episode reward | 614       |
| n_updates               | 124800    |
| q_grad_norm             | 3515.1213 |
| qfs_loss                | 89.023865 |
| qs_abs_difference       | 47        |
| qs_difference           | 45.9      |
| qs_mean                 | 297.84842 |
| time_elapsed            | 6156      |
| total timesteps         | 87331     |
| train_time              | 1442      |
| update_time             | 4454      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 434       |
| eval_abs_qs_difference  | 46.397617 |
| eval_discount_q         | 231       |
| eval_ep_rewmean         | 1.78e+03  |
| eval_eplenmean          | 603       |
| eval_qs                 | 297.83035 |
| eval_qs_difference      | 45.7      |
| eval_time_elapsed       | 16        |
| total timesteps         | 90001     |
---------------------------------------
---------------------------------------
| act_time                | 58        |
| current_lr              | 0.0003    |
| discount_q              | 1.69e-08  |
| env_time                | 146       |
| ep_rewmean              | 675       |
| episodes                | 1596      |
| eplenmean               | 246       |
| fps                     | 13        |
| mean 100 episode reward | 674       |
| n_updates               | 130200    |
| q_grad_norm             | 3855.0793 |
| qfs_loss                | 103.12577 |
| qs_abs_difference       | 49.9      |
| qs_difference           | 49.8      |
| qs_mean                 | 282.12985 |
| time_elapsed            | 6459      |
| total timesteps         | 90002     |
| train_time              | 1504      |
| update_time             | 4671      |
---------------------------------------
--------------------------------------
| act_time                | 60       |
| current_lr              | 0.0003   |
| discount_q              | 0.00126  |
| env_time                | 148      |
| ep_rewmean              | 703      |
| episodes                | 1600     |
| eplenmean               | 255      |
| fps                     | 13       |
| mean 100 episode reward | 703      |
| n_updates               | 133200   |
| q_grad_norm             | 3072.747 |
| qfs_loss                | 82.38876 |
| qs_abs_difference       | 53       |
| qs_difference           | 51.9     |
| qs_mean                 | 280.1565 |
| time_elapsed            | 6621     |
| total timesteps         | 91582    |
| train_time              | 1539     |
| update_time             | 4793     |
--------------------------------------
---------------------------------------
| act_time                | 61        |
| current_lr              | 0.0003    |
| discount_q              | 0.000654  |
| env_time                | 151       |
| ep_rewmean              | 732       |
| episodes                | 1604      |
| eplenmean               | 264       |
| fps                     | 13        |
| mean 100 episode reward | 732       |
| n_updates               | 136400    |
| q_grad_norm             | 2951.6987 |
| qfs_loss                | 79.24764  |
| qs_abs_difference       | 123       |
| qs_difference           | 123       |
| qs_mean                 | 321.62054 |
| time_elapsed            | 6792      |
| total timesteps         | 93107     |
| train_time              | 1576      |
| update_time             | 4923      |
---------------------------------------
---------------------------------------
| act_time                | 62        |
| current_lr              | 0.0003    |
| discount_q              | 0.000673  |
| env_time                | 153       |
| ep_rewmean              | 761       |
| episodes                | 1608      |
| eplenmean               | 273       |
| fps                     | 13        |
| mean 100 episode reward | 761       |
| n_updates               | 139400    |
| q_grad_norm             | 3242.88   |
| qfs_loss                | 87.828064 |
| qs_abs_difference       | 49.5      |
| qs_difference           | 46.7      |
| qs_mean                 | 268.45398 |
| time_elapsed            | 6956      |
| total timesteps         | 94654     |
| train_time              | 1610      |
| update_time             | 5048      |
---------------------------------------
---------------------------------------
| act_time                | 63        |
| current_lr              | 0.0003    |
| discount_q              | 0.00228   |
| env_time                | 155       |
| ep_rewmean              | 788       |
| episodes                | 1612      |
| eplenmean               | 281       |
| fps                     | 13        |
| mean 100 episode reward | 788       |
| n_updates               | 142200    |
| q_grad_norm             | 3024.5146 |
| qfs_loss                | 67.43281  |
| qs_abs_difference       | 67.7      |
| qs_difference           | 66.8      |
| qs_mean                 | 266.75424 |
| time_elapsed            | 7109      |
| total timesteps         | 96060     |
| train_time              | 1643      |
| update_time             | 5165      |
---------------------------------------
---------------------------------------
| act_time                | 65        |
| current_lr              | 0.0003    |
| discount_q              | 0.00112   |
| env_time                | 158       |
| ep_rewmean              | 827       |
| episodes                | 1616      |
| eplenmean               | 293       |
| fps                     | 13        |
| mean 100 episode reward | 827       |
| n_updates               | 145400    |
| q_grad_norm             | 2784.5461 |
| qfs_loss                | 78.847664 |
| qs_abs_difference       | 36.2      |
| qs_difference           | 35.9      |
| qs_mean                 | 291.1661  |
| time_elapsed            | 7285      |
| total timesteps         | 97690     |
| train_time              | 1680      |
| update_time             | 5299      |
---------------------------------------
---------------------------------------
| act_time                | 66        |
| current_lr              | 0.0003    |
| discount_q              | 0.0127    |
| env_time                | 160       |
| ep_rewmean              | 859       |
| episodes                | 1620      |
| eplenmean               | 303       |
| fps                     | 13        |
| mean 100 episode reward | 859       |
| n_updates               | 148200    |
| q_grad_norm             | 2827.6528 |
| qfs_loss                | 69.364006 |
| qs_abs_difference       | 50.7      |
| qs_difference           | 49.1      |
| qs_mean                 | 282.18594 |
| time_elapsed            | 7439      |
| total timesteps         | 99010     |
| train_time              | 1712      |
| update_time             | 5417      |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 568      |
| eval_abs_qs_difference  | 39.9848  |
| eval_discount_q         | 242      |
| eval_ep_rewmean         | 1.04e+03 |
| eval_eplenmean          | 333      |
| eval_qs                 | 276.6086 |
| eval_qs_difference      | 37.4     |
| eval_time_elapsed       | 8        |
| total timesteps         | 100001   |
--------------------------------------
---------------------------------------
| act_time                | 67        |
| current_lr              | 0.0003    |
| discount_q              | 0.0391    |
| env_time                | 162       |
| ep_rewmean              | 876       |
| episodes                | 1624      |
| eplenmean               | 307       |
| fps                     | 13        |
| mean 100 episode reward | 876       |
| n_updates               | 150600    |
| q_grad_norm             | 3207.6543 |
| qfs_loss                | 69.05945  |
| qs_abs_difference       | 44.7      |
| qs_difference           | 42.1      |
| qs_mean                 | 268.80896 |
| time_elapsed            | 7580      |
| total timesteps         | 100217    |
| train_time              | 1740      |
| update_time             | 5518      |
---------------------------------------
---------------------------------------
| act_time                | 68        |
| current_lr              | 0.0003    |
| discount_q              | 0.00035   |
| env_time                | 165       |
| ep_rewmean              | 913       |
| episodes                | 1628      |
| eplenmean               | 317       |
| fps                     | 13        |
| mean 100 episode reward | 913       |
| n_updates               | 154000    |
| q_grad_norm             | 3174.3862 |
| qfs_loss                | 90.50296  |
| qs_abs_difference       | 36.1      |
| qs_difference           | 34.5      |
| qs_mean                 | 279.44745 |
| time_elapsed            | 7763      |
| total timesteps         | 101914    |
| train_time              | 1779      |
| update_time             | 5657      |
---------------------------------------
---------------------------------------
| act_time                | 70        |
| current_lr              | 0.0003    |
| discount_q              | 0.000769  |
| env_time                | 167       |
| ep_rewmean              | 945       |
| episodes                | 1632      |
| eplenmean               | 326       |
| fps                     | 13        |
| mean 100 episode reward | 945       |
| n_updates               | 157000    |
| q_grad_norm             | 2671.5674 |
| qfs_loss                | 65.72528  |
| qs_abs_difference       | 75.9      |
| qs_difference           | 75.7      |
| qs_mean                 | 269.69482 |
| time_elapsed            | 7921      |
| total timesteps         | 103403    |
| train_time              | 1813      |
| update_time             | 5777      |
---------------------------------------
---------------------------------------
| act_time                | 71        |
| current_lr              | 0.0003    |
| discount_q              | 0.00184   |
| env_time                | 170       |
| ep_rewmean              | 983       |
| episodes                | 1636      |
| eplenmean               | 337       |
| fps                     | 12        |
| mean 100 episode reward | 984       |
| n_updates               | 160600    |
| q_grad_norm             | 2807.8105 |
| qfs_loss                | 77.57737  |
| qs_abs_difference       | 26.3      |
| qs_difference           | 25.6      |
| qs_mean                 | 299.25586 |
| time_elapsed            | 8108      |
| total timesteps         | 105233    |
| train_time              | 1855      |
| update_time             | 5917      |
---------------------------------------
---------------------------------------
| act_time                | 72        |
| current_lr              | 0.0003    |
| discount_q              | 0.00412   |
| env_time                | 172       |
| ep_rewmean              | 990       |
| episodes                | 1640      |
| eplenmean               | 339       |
| fps                     | 12        |
| mean 100 episode reward | 990       |
| n_updates               | 162600    |
| q_grad_norm             | 2442.745  |
| qfs_loss                | 63.052055 |
| qs_abs_difference       | 258       |
| qs_difference           | 258       |
| qs_mean                 | 289.78818 |
| time_elapsed            | 8210      |
| total timesteps         | 106212    |
| train_time              | 1878      |
| update_time             | 5993      |
---------------------------------------
---------------------------------------
| act_time                | 73        |
| current_lr              | 0.0003    |
| discount_q              | 0.196     |
| env_time                | 174       |
| ep_rewmean              | 1e+03     |
| episodes                | 1644      |
| eplenmean               | 341       |
| fps                     | 12        |
| mean 100 episode reward | 1e+03     |
| n_updates               | 165000    |
| q_grad_norm             | 2801.0515 |
| qfs_loss                | 70.84534  |
| qs_abs_difference       | 29.2      |
| qs_difference           | 26.3      |
| qs_mean                 | 293.77167 |
| time_elapsed            | 8331      |
| total timesteps         | 107436    |
| train_time              | 1906      |
| update_time             | 6083      |
---------------------------------------
---------------------------------------
| act_time                | 75        |
| current_lr              | 0.0003    |
| discount_q              | 0.000102  |
| env_time                | 177       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1648      |
| eplenmean               | 350       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 168400    |
| q_grad_norm             | 2808.8516 |
| qfs_loss                | 78.80757  |
| qs_abs_difference       | 44.1      |
| qs_difference           | 44.1      |
| qs_mean                 | 274.43152 |
| time_elapsed            | 8500      |
| total timesteps         | 109196    |
| train_time              | 1945      |
| update_time             | 6208      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 724       |
| eval_abs_qs_difference  | 49.136063 |
| eval_discount_q         | 229       |
| eval_ep_rewmean         | 1.45e+03  |
| eval_eplenmean          | 495       |
| eval_qs                 | 291.313   |
| eval_qs_difference      | 48        |
| eval_time_elapsed       | 13        |
| total timesteps         | 110001    |
---------------------------------------
---------------------------------------
| act_time                | 76        |
| current_lr              | 0.0003    |
| discount_q              | 0.000319  |
| env_time                | 179       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1652      |
| eplenmean               | 359       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 171800    |
| q_grad_norm             | 2858.5583 |
| qfs_loss                | 97.594284 |
| qs_abs_difference       | 45.9      |
| qs_difference           | 45.7      |
| qs_mean                 | 277.62704 |
| time_elapsed            | 8679      |
| total timesteps         | 110890    |
| train_time              | 1985      |
| update_time             | 6329      |
---------------------------------------
---------------------------------------
| act_time                | 77        |
| current_lr              | 0.0003    |
| discount_q              | 0.0227    |
| env_time                | 182       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 1656      |
| eplenmean               | 363       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 174400    |
| q_grad_norm             | 3426.7668 |
| qfs_loss                | 94.37391  |
| qs_abs_difference       | 36        |
| qs_difference           | 35.9      |
| qs_mean                 | 277.63992 |
| time_elapsed            | 8802      |
| total timesteps         | 112174    |
| train_time              | 2015      |
| update_time             | 6419      |
---------------------------------------
---------------------------------------
| act_time                | 79        |
| current_lr              | 0.0003    |
| discount_q              | 9.94e-05  |
| env_time                | 185       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 1660      |
| eplenmean               | 371       |
| fps                     | 12        |
| mean 100 episode reward | 1.1e+03   |
| n_updates               | 178200    |
| q_grad_norm             | 2516.6445 |
| qfs_loss                | 82.55713  |
| qs_abs_difference       | 35.4      |
| qs_difference           | 34.7      |
| qs_mean                 | 284.6003  |
| time_elapsed            | 8979      |
| total timesteps         | 114053    |
| train_time              | 2058      |
| update_time             | 6547      |
---------------------------------------
---------------------------------------
| act_time                | 80        |
| current_lr              | 0.0003    |
| discount_q              | 0.00885   |
| env_time                | 187       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 1664      |
| eplenmean               | 379       |
| fps                     | 12        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 181000    |
| q_grad_norm             | 1974.0273 |
| qfs_loss                | 43.609787 |
| qs_abs_difference       | 16.3      |
| qs_difference           | 15.6      |
| qs_mean                 | 267.60263 |
| time_elapsed            | 9106      |
| total timesteps         | 115405    |
| train_time              | 2091      |
| update_time             | 6638      |
---------------------------------------
---------------------------------------
| act_time                | 81        |
| current_lr              | 0.0003    |
| discount_q              | 0.0106    |
| env_time                | 190       |
| ep_rewmean              | 1.16e+03  |
| episodes                | 1668      |
| eplenmean               | 388       |
| fps                     | 12        |
| mean 100 episode reward | 1.16e+03  |
| n_updates               | 184400    |
| q_grad_norm             | 2798.7869 |
| qfs_loss                | 88.45861  |
| qs_abs_difference       | 17.9      |
| qs_difference           | 17.8      |
| qs_mean                 | 301.7485  |
| time_elapsed            | 9258      |
| total timesteps         | 117152    |
| train_time              | 2130      |
| update_time             | 6746      |
---------------------------------------
---------------------------------------
| act_time                | 83        |
| current_lr              | 0.0003    |
| discount_q              | 0.106     |
| env_time                | 193       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 1672      |
| eplenmean               | 393       |
| fps                     | 12        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 188000    |
| q_grad_norm             | 2164.9958 |
| qfs_loss                | 71.780914 |
| qs_abs_difference       | 13.9      |
| qs_difference           | 13        |
| qs_mean                 | 312.135   |
| time_elapsed            | 9416      |
| total timesteps         | 118917    |
| train_time              | 2172      |
| update_time             | 6857      |
---------------------------------------
---------------------------------------
| act_time                | 83        |
| current_lr              | 0.0003    |
| discount_q              | 0.614     |
| env_time                | 194       |
| ep_rewmean              | 1.18e+03  |
| episodes                | 1676      |
| eplenmean               | 393       |
| fps                     | 12        |
| mean 100 episode reward | 1.18e+03  |
| n_updates               | 189600    |
| q_grad_norm             | 2889.5505 |
| qfs_loss                | 93.19591  |
| qs_abs_difference       | 23        |
| qs_difference           | 19.5      |
| qs_mean                 | 256.9519  |
| time_elapsed            | 9484      |
| total timesteps         | 119767    |
| train_time              | 2190      |
| update_time             | 6904      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 729       |
| eval_abs_qs_difference  | 236.9401  |
| eval_discount_q         | 75.3      |
| eval_ep_rewmean         | 98.7      |
| eval_eplenmean          | 54.7      |
| eval_qs                 | 280.67233 |
| eval_qs_difference      | 237       |
| eval_time_elapsed       | 1         |
| total timesteps         | 120001    |
---------------------------------------
---------------------------------------
| act_time                | 84        |
| current_lr              | 0.0003    |
| discount_q              | 1.25      |
| env_time                | 195       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 1680      |
| eplenmean               | 381       |
| fps                     | 12        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 190400    |
| q_grad_norm             | 2288.9082 |
| qfs_loss                | 74.51515  |
| qs_abs_difference       | 257       |
| qs_difference           | 257       |
| qs_mean                 | 290.9063  |
| time_elapsed            | 9520      |
| total timesteps         | 120186    |
| train_time              | 2200      |
| update_time             | 6928      |
---------------------------------------
---------------------------------------
| act_time                | 85        |
| current_lr              | 0.0003    |
| discount_q              | 0.101     |
| env_time                | 196       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 1684      |
| eplenmean               | 375       |
| fps                     | 12        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 192600    |
| q_grad_norm             | 2421.6035 |
| qfs_loss                | 74.86395  |
| qs_abs_difference       | 33.1      |
| qs_difference           | 33        |
| qs_mean                 | 269.41513 |
| time_elapsed            | 9612      |
| total timesteps         | 121255    |
| train_time              | 2225      |
| update_time             | 6992      |
---------------------------------------
---------------------------------------
| act_time                | 86        |
| current_lr              | 0.0003    |
| discount_q              | 2.82e-06  |
| env_time                | 200       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 1688      |
| eplenmean               | 376       |
| fps                     | 12        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 196600    |
| q_grad_norm             | 2610.33   |
| qfs_loss                | 92.46122  |
| qs_abs_difference       | 159       |
| qs_difference           | 159       |
| qs_mean                 | 318.82477 |
| time_elapsed            | 9777      |
| total timesteps         | 123248    |
| train_time              | 2271      |
| update_time             | 7105      |
---------------------------------------
---------------------------------------
| act_time                | 87        |
| current_lr              | 0.0003    |
| discount_q              | 0.0824    |
| env_time                | 201       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 1692      |
| eplenmean               | 370       |
| fps                     | 12        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 198800    |
| q_grad_norm             | 2137.0571 |
| qfs_loss                | 58.598732 |
| qs_abs_difference       | 16.2      |
| qs_difference           | 12.3      |
| qs_mean                 | 256.52298 |
| time_elapsed            | 9866      |
| total timesteps         | 124316    |
| train_time              | 2297      |
| update_time             | 7165      |
---------------------------------------
---------------------------------------
| act_time                | 88        |
| current_lr              | 0.0003    |
| discount_q              | 0.824     |
| env_time                | 203       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 1696      |
| eplenmean               | 352       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 200600    |
| q_grad_norm             | 1989.8811 |
| qfs_loss                | 63.248363 |
| qs_abs_difference       | 27.4      |
| qs_difference           | 24.3      |
| qs_mean                 | 263.3204  |
| time_elapsed            | 9937      |
| total timesteps         | 125205    |
| train_time              | 2318      |
| update_time             | 7213      |
---------------------------------------
---------------------------------------
| act_time                | 89        |
| current_lr              | 0.0003    |
| discount_q              | 0.0291    |
| env_time                | 205       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 1700      |
| eplenmean               | 348       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 202800    |
| q_grad_norm             | 1354.7456 |
| qfs_loss                | 45.688618 |
| qs_abs_difference       | 46.9      |
| qs_difference           | 46.9      |
| qs_mean                 | 267.39563 |
| time_elapsed            | 10023     |
| total timesteps         | 126393    |
| train_time              | 2343      |
| update_time             | 7271      |
---------------------------------------
---------------------------------------
| act_time                | 90        |
| current_lr              | 0.0003    |
| discount_q              | 0.0143    |
| env_time                | 206       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 1704      |
| eplenmean               | 345       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 205200    |
| q_grad_norm             | 1449.636  |
| qfs_loss                | 53.296585 |
| qs_abs_difference       | 30.2      |
| qs_difference           | 30.1      |
| qs_mean                 | 246.64932 |
| time_elapsed            | 10117     |
| total timesteps         | 127599    |
| train_time              | 2370      |
| update_time             | 7334      |
---------------------------------------
---------------------------------------
| act_time                | 91        |
| current_lr              | 0.0003    |
| discount_q              | 0.218     |
| env_time                | 208       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1708      |
| eplenmean               | 336       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 206800    |
| q_grad_norm             | 1864.5934 |
| qfs_loss                | 52.139515 |
| qs_abs_difference       | 231       |
| qs_difference           | 231       |
| qs_mean                 | 306.6851  |
| time_elapsed            | 10179     |
| total timesteps         | 128304    |
| train_time              | 2389      |
| update_time             | 7375      |
---------------------------------------
---------------------------------------
| act_time                | 91        |
| current_lr              | 0.0003    |
| discount_q              | 0.0296    |
| env_time                | 209       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 1712      |
| eplenmean               | 330       |
| fps                     | 12        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 208200    |
| q_grad_norm             | 1982.9875 |
| qfs_loss                | 46.300816 |
| qs_abs_difference       | 263       |
| qs_difference           | 263       |
| qs_mean                 | 296.32605 |
| time_elapsed            | 10233     |
| total timesteps         | 129098    |
| train_time              | 2405      |
| update_time             | 7411      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 784       |
| eval_abs_qs_difference  | 23.210554 |
| eval_discount_q         | 241       |
| eval_ep_rewmean         | 834       |
| eval_eplenmean          | 250       |
| eval_qs                 | 252.344   |
| eval_qs_difference      | 14.7      |
| eval_time_elapsed       | 6         |
| total timesteps         | 130001    |
---------------------------------------
---------------------------------------
| act_time                | 92        |
| current_lr              | 0.0003    |
| discount_q              | 0.0373    |
| env_time                | 211       |
| ep_rewmean              | 994       |
| episodes                | 1716      |
| eplenmean               | 325       |
| fps                     | 12        |
| mean 100 episode reward | 994       |
| n_updates               | 210600    |
| q_grad_norm             | 2216.7402 |
| qfs_loss                | 67.94321  |
| qs_abs_difference       | 32        |
| qs_difference           | 30.5      |
| qs_mean                 | 256.98386 |
| time_elapsed            | 10332     |
| total timesteps         | 130201    |
| train_time              | 2433      |
| update_time             | 7473      |
---------------------------------------
---------------------------------------
| act_time                | 93        |
| current_lr              | 0.0003    |
| discount_q              | 0.259     |
| env_time                | 212       |
| ep_rewmean              | 982       |
| episodes                | 1720      |
| eplenmean               | 321       |
| fps                     | 12        |
| mean 100 episode reward | 982       |
| n_updates               | 212400    |
| q_grad_norm             | 1975.1669 |
| qfs_loss                | 76.009026 |
| qs_abs_difference       | 23.1      |
| qs_difference           | 20.1      |
| qs_mean                 | 256.1345  |
| time_elapsed            | 10401     |
| total timesteps         | 131136    |
| train_time              | 2454      |
| update_time             | 7519      |
---------------------------------------
---------------------------------------
| act_time                | 94        |
| current_lr              | 0.0003    |
| discount_q              | 0.383     |
| env_time                | 213       |
| ep_rewmean              | 974       |
| episodes                | 1724      |
| eplenmean               | 318       |
| fps                     | 12        |
| mean 100 episode reward | 974       |
| n_updates               | 214000    |
| q_grad_norm             | 2140.7231 |
| qfs_loss                | 76.2848   |
| qs_abs_difference       | 42.3      |
| qs_difference           | 42        |
| qs_mean                 | 255.6166  |
| time_elapsed            | 10463     |
| total timesteps         | 131994    |
| train_time              | 2472      |
| update_time             | 7560      |
---------------------------------------
---------------------------------------
| act_time                | 94        |
| current_lr              | 0.0003    |
| discount_q              | 0.148     |
| env_time                | 215       |
| ep_rewmean              | 952       |
| episodes                | 1728      |
| eplenmean               | 311       |
| fps                     | 12        |
| mean 100 episode reward | 952       |
| n_updates               | 216000    |
| q_grad_norm             | 1917.0085 |
| qfs_loss                | 61.428608 |
| qs_abs_difference       | 18.3      |
| qs_difference           | 11.4      |
| qs_mean                 | 255.12701 |
| time_elapsed            | 10540     |
| total timesteps         | 132994    |
| train_time              | 2495      |
| update_time             | 7611      |
---------------------------------------
---------------------------------------
| act_time                | 95        |
| current_lr              | 0.0003    |
| discount_q              | 0.403     |
| env_time                | 216       |
| ep_rewmean              | 936       |
| episodes                | 1732      |
| eplenmean               | 305       |
| fps                     | 12        |
| mean 100 episode reward | 936       |
| n_updates               | 217800    |
| q_grad_norm             | 1287.8523 |
| qfs_loss                | 43.174183 |
| qs_abs_difference       | 36.5      |
| qs_difference           | 36.5      |
| qs_mean                 | 271.08206 |
| time_elapsed            | 10608     |
| total timesteps         | 133897    |
| train_time              | 2516      |
| update_time             | 7656      |
---------------------------------------
---------------------------------------
| act_time                | 96        |
| current_lr              | 0.0003    |
| discount_q              | 0.178     |
| env_time                | 218       |
| ep_rewmean              | 909       |
| episodes                | 1736      |
| eplenmean               | 296       |
| fps                     | 12        |
| mean 100 episode reward | 909       |
| n_updates               | 219800    |
| q_grad_norm             | 2328.5227 |
| qfs_loss                | 74.417854 |
| qs_abs_difference       | 44.1      |
| qs_difference           | 43.5      |
| qs_mean                 | 259.15582 |
| time_elapsed            | 10684     |
| total timesteps         | 134833    |
| train_time              | 2539      |
| update_time             | 7706      |
---------------------------------------
---------------------------------------
| act_time                | 97        |
| current_lr              | 0.0003    |
| discount_q              | 0.0883    |
| env_time                | 220       |
| ep_rewmean              | 916       |
| episodes                | 1740      |
| eplenmean               | 297       |
| fps                     | 12        |
| mean 100 episode reward | 916       |
| n_updates               | 221800    |
| q_grad_norm             | 2322.6091 |
| qfs_loss                | 66.57683  |
| qs_abs_difference       | 12.3      |
| qs_difference           | 10.1      |
| qs_mean                 | 256.8687  |
| time_elapsed            | 10760     |
| total timesteps         | 135893    |
| train_time              | 2562      |
| update_time             | 7756      |
---------------------------------------
---------------------------------------
| act_time                | 97        |
| current_lr              | 0.0003    |
| discount_q              | 0.467     |
| env_time                | 221       |
| ep_rewmean              | 910       |
| episodes                | 1744      |
| eplenmean               | 294       |
| fps                     | 12        |
| mean 100 episode reward | 910       |
| n_updates               | 223800    |
| q_grad_norm             | 2425.7852 |
| qfs_loss                | 73.8271   |
| qs_abs_difference       | 40.8      |
| qs_difference           | 40.7      |
| qs_mean                 | 279.21182 |
| time_elapsed            | 10836     |
| total timesteps         | 136830    |
| train_time              | 2585      |
| update_time             | 7807      |
---------------------------------------
---------------------------------------
| act_time                | 98        |
| current_lr              | 0.0003    |
| discount_q              | 0.0627    |
| env_time                | 223       |
| ep_rewmean              | 892       |
| episodes                | 1748      |
| eplenmean               | 287       |
| fps                     | 12        |
| mean 100 episode reward | 892       |
| n_updates               | 226000    |
| q_grad_norm             | 1675.3661 |
| qfs_loss                | 46.1543   |
| qs_abs_difference       | 21        |
| qs_difference           | 17.3      |
| qs_mean                 | 259.74405 |
| time_elapsed            | 10918     |
| total timesteps         | 137923    |
| train_time              | 2610      |
| update_time             | 7861      |
---------------------------------------
---------------------------------------
| act_time                | 99        |
| current_lr              | 0.0003    |
| discount_q              | 0.0168    |
| env_time                | 225       |
| ep_rewmean              | 881       |
| episodes                | 1752      |
| eplenmean               | 283       |
| fps                     | 12        |
| mean 100 episode reward | 881       |
| n_updates               | 228400    |
| q_grad_norm             | 1371.5557 |
| qfs_loss                | 45.030235 |
| qs_abs_difference       | 16        |
| qs_difference           | 9.38      |
| qs_mean                 | 260.1139  |
| time_elapsed            | 11009     |
| total timesteps         | 139160    |
| train_time              | 2638      |
| update_time             | 7920      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 854       |
| eval_abs_qs_difference  | 18.966574 |
| eval_discount_q         | 245       |
| eval_ep_rewmean         | 926       |
| eval_eplenmean          | 279       |
| eval_qs                 | 253.50835 |
| eval_qs_difference      | 8.38      |
| eval_time_elapsed       | 7         |
| total timesteps         | 140001    |
---------------------------------------
---------------------------------------
| act_time                | 100       |
| current_lr              | 0.0003    |
| discount_q              | 0.0547    |
| env_time                | 227       |
| ep_rewmean              | 879       |
| episodes                | 1756      |
| eplenmean               | 281       |
| fps                     | 12        |
| mean 100 episode reward | 879       |
| n_updates               | 230600    |
| q_grad_norm             | 1535.0392 |
| qfs_loss                | 40.59061  |
| qs_abs_difference       | 25.2      |
| qs_difference           | 23.9      |
| qs_mean                 | 259.5825  |
| time_elapsed            | 11099     |
| total timesteps         | 140239    |
| train_time              | 2664      |
| update_time             | 7974      |
---------------------------------------
---------------------------------------
| act_time                | 101       |
| current_lr              | 0.0003    |
| discount_q              | 0.133     |
| env_time                | 228       |
| ep_rewmean              | 853       |
| episodes                | 1760      |
| eplenmean               | 272       |
| fps                     | 12        |
| mean 100 episode reward | 853       |
| n_updates               | 232600    |
| q_grad_norm             | 2482.4695 |
| qfs_loss                | 65.82775  |
| qs_abs_difference       | 14.9      |
| qs_difference           | 9.39      |
| qs_mean                 | 259.3732  |
| time_elapsed            | 11174     |
| total timesteps         | 141269    |
| train_time              | 2687      |
| update_time             | 8023      |
---------------------------------------
---------------------------------------
| act_time                | 102       |
| current_lr              | 0.0003    |
| discount_q              | 0.0643    |
| env_time                | 230       |
| ep_rewmean              | 847       |
| episodes                | 1764      |
| eplenmean               | 270       |
| fps                     | 12        |
| mean 100 episode reward | 847       |
| n_updates               | 234800    |
| q_grad_norm             | 1968.3978 |
| qfs_loss                | 50.001064 |
| qs_abs_difference       | 13.8      |
| qs_difference           | 5.04      |
| qs_mean                 | 256.81036 |
| time_elapsed            | 11256     |
| total timesteps         | 142362    |
| train_time              | 2712      |
| update_time             | 8077      |
---------------------------------------
---------------------------------------
| act_time                | 103       |
| current_lr              | 0.0003    |
| discount_q              | 0.171     |
| env_time                | 231       |
| ep_rewmean              | 811       |
| episodes                | 1768      |
| eplenmean               | 258       |
| fps                     | 12        |
| mean 100 episode reward | 811       |
| n_updates               | 236000    |
| q_grad_norm             | 2281.2207 |
| qfs_loss                | 51.01562  |
| qs_abs_difference       | 252       |
| qs_difference           | 252       |
| qs_mean                 | 284.3061  |
| time_elapsed            | 11301     |
| total timesteps         | 142980    |
| train_time              | 2726      |
| update_time             | 8106      |
---------------------------------------
---------------------------------------
| act_time                | 103       |
| current_lr              | 0.0003    |
| discount_q              | 0.0476    |
| env_time                | 232       |
| ep_rewmean              | 776       |
| episodes                | 1772      |
| eplenmean               | 248       |
| fps                     | 12        |
| mean 100 episode reward | 776       |
| n_updates               | 237600    |
| q_grad_norm             | 1681.4543 |
| qfs_loss                | 49.145805 |
| qs_abs_difference       | 257       |
| qs_difference           | 257       |
| qs_mean                 | 288.49002 |
| time_elapsed            | 11361     |
| total timesteps         | 143720    |
| train_time              | 2745      |
| update_time             | 8145      |
---------------------------------------
---------------------------------------
| act_time                | 104       |
| current_lr              | 0.0003    |
| discount_q              | 0.0135    |
| env_time                | 234       |
| ep_rewmean              | 778       |
| episodes                | 1776      |
| eplenmean               | 248       |
| fps                     | 12        |
| mean 100 episode reward | 778       |
| n_updates               | 239200    |
| q_grad_norm             | 1663.8867 |
| qfs_loss                | 43.06677  |
| qs_abs_difference       | 255       |
| qs_difference           | 255       |
| qs_mean                 | 284.2945  |
| time_elapsed            | 11420     |
| total timesteps         | 144575    |
| train_time              | 2763      |
| update_time             | 8184      |
---------------------------------------
---------------------------------------
| act_time                | 105       |
| current_lr              | 0.0003    |
| discount_q              | 0.101     |
| env_time                | 235       |
| ep_rewmean              | 801       |
| episodes                | 1780      |
| eplenmean               | 254       |
| fps                     | 12        |
| mean 100 episode reward | 801       |
| n_updates               | 241400    |
| q_grad_norm             | 2623.7556 |
| qfs_loss                | 75.839485 |
| qs_abs_difference       | 15.5      |
| qs_difference           | 14.9      |
| qs_mean                 | 254.9509  |
| time_elapsed            | 11502     |
| total timesteps         | 145611    |
| train_time              | 2789      |
| update_time             | 8237      |
---------------------------------------
---------------------------------------
| act_time                | 106       |
| current_lr              | 0.0003    |
| discount_q              | 0.0558    |
| env_time                | 237       |
| ep_rewmean              | 803       |
| episodes                | 1784      |
| eplenmean               | 255       |
| fps                     | 12        |
| mean 100 episode reward | 803       |
| n_updates               | 243600    |
| q_grad_norm             | 1692.6534 |
| qfs_loss                | 53.41765  |
| qs_abs_difference       | 14.6      |
| qs_difference           | 12.1      |
| qs_mean                 | 260.5153  |
| time_elapsed            | 11584     |
| total timesteps         | 146725    |
| train_time              | 2814      |
| update_time             | 8290      |
---------------------------------------
---------------------------------------
| act_time                | 107       |
| current_lr              | 0.0003    |
| discount_q              | 0.395     |
| env_time                | 239       |
| ep_rewmean              | 778       |
| episodes                | 1788      |
| eplenmean               | 246       |
| fps                     | 12        |
| mean 100 episode reward | 778       |
| n_updates               | 245800    |
| q_grad_norm             | 2483.2095 |
| qfs_loss                | 66.04827  |
| qs_abs_difference       | 24.1      |
| qs_difference           | 20.2      |
| qs_mean                 | 296.01056 |
| time_elapsed            | 11665     |
| total timesteps         | 147891    |
| train_time              | 2839      |
| update_time             | 8344      |
---------------------------------------
---------------------------------------
| act_time                | 108       |
| current_lr              | 0.0003    |
| discount_q              | 0.226     |
| env_time                | 241       |
| ep_rewmean              | 783       |
| episodes                | 1792      |
| eplenmean               | 247       |
| fps                     | 12        |
| mean 100 episode reward | 783       |
| n_updates               | 248200    |
| q_grad_norm             | 1762.7616 |
| qfs_loss                | 47.96003  |
| qs_abs_difference       | 18.1      |
| qs_difference           | 7.34      |
| qs_mean                 | 291.37457 |
| time_elapsed            | 11754     |
| total timesteps         | 149060    |
| train_time              | 2867      |
| update_time             | 8401      |
---------------------------------------
---------------------------------------
| act_time                | 108       |
| current_lr              | 0.0003    |
| discount_q              | 0.343     |
| env_time                | 242       |
| ep_rewmean              | 780       |
| episodes                | 1796      |
| eplenmean               | 246       |
| fps                     | 12        |
| mean 100 episode reward | 780       |
| n_updates               | 249800    |
| q_grad_norm             | 2408.8818 |
| qfs_loss                | 66.72722  |
| qs_abs_difference       | 93.1      |
| qs_difference           | 93.1      |
| qs_mean                 | 240.30217 |
| time_elapsed            | 11813     |
| total timesteps         | 149845    |
| train_time              | 2886      |
| update_time             | 8440      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 871       |
| eval_abs_qs_difference  | 39.479904 |
| eval_discount_q         | 222       |
| eval_ep_rewmean         | 640       |
| eval_eplenmean          | 206       |
| eval_qs                 | 242.10883 |
| eval_qs_difference      | 38.2      |
| eval_time_elapsed       | 5         |
| total timesteps         | 150001    |
---------------------------------------
---------------------------------------
| act_time                | 109       |
| current_lr              | 0.0003    |
| discount_q              | 0.819     |
| env_time                | 244       |
| ep_rewmean              | 771       |
| episodes                | 1800      |
| eplenmean               | 243       |
| fps                     | 12        |
| mean 100 episode reward | 771       |
| n_updates               | 251600    |
| q_grad_norm             | 2266.4478 |
| qfs_loss                | 58.26716  |
| qs_abs_difference       | 18.8      |
| qs_difference           | 18.7      |
| qs_mean                 | 267.11716 |
| time_elapsed            | 11885     |
| total timesteps         | 150703    |
| train_time              | 2906      |
| update_time             | 8483      |
---------------------------------------
---------------------------------------
| act_time                | 110       |
| current_lr              | 0.0003    |
| discount_q              | 4.87      |
| env_time                | 245       |
| ep_rewmean              | 750       |
| episodes                | 1804      |
| eplenmean               | 237       |
| fps                     | 12        |
| mean 100 episode reward | 750       |
| n_updates               | 252600    |
| q_grad_norm             | 1584.7113 |
| qfs_loss                | 39.856476 |
| qs_abs_difference       | 45.4      |
| qs_difference           | 45.4      |
| qs_mean                 | 243.84915 |
| time_elapsed            | 11922     |
| total timesteps         | 151281    |
| train_time              | 2918      |
| update_time             | 8507      |
---------------------------------------
---------------------------------------
| act_time                | 110       |
| current_lr              | 0.0003    |
| discount_q              | 0.824     |
| env_time                | 246       |
| ep_rewmean              | 748       |
| episodes                | 1808      |
| eplenmean               | 237       |
| fps                     | 12        |
| mean 100 episode reward | 748       |
| n_updates               | 254000    |
| q_grad_norm             | 1956.3024 |
| qfs_loss                | 63.063984 |
| qs_abs_difference       | 75        |
| qs_difference           | 73.9      |
| qs_mean                 | 216.97989 |
| time_elapsed            | 11974     |
| total timesteps         | 151955    |
| train_time              | 2934      |
| update_time             | 8540      |
---------------------------------------
---------------------------------------
| act_time                | 111       |
| current_lr              | 0.0003    |
| discount_q              | 1.92      |
| env_time                | 247       |
| ep_rewmean              | 744       |
| episodes                | 1812      |
| eplenmean               | 235       |
| fps                     | 12        |
| mean 100 episode reward | 744       |
| n_updates               | 255200    |
| q_grad_norm             | 2499.2825 |
| qfs_loss                | 65.398125 |
| qs_abs_difference       | 37.4      |
| qs_difference           | 36.6      |
| qs_mean                 | 221.32603 |
| time_elapsed            | 12018     |
| total timesteps         | 152587    |
| train_time              | 2948      |
| update_time             | 8569      |
---------------------------------------
---------------------------------------
| act_time                | 112       |
| current_lr              | 0.0003    |
| discount_q              | 0.249     |
| env_time                | 248       |
| ep_rewmean              | 738       |
| episodes                | 1816      |
| eplenmean               | 233       |
| fps                     | 12        |
| mean 100 episode reward | 738       |
| n_updates               | 257000    |
| q_grad_norm             | 2694.0981 |
| qfs_loss                | 61.307426 |
| qs_abs_difference       | 48        |
| qs_difference           | 47.9      |
| qs_mean                 | 263.26376 |
| time_elapsed            | 12084     |
| total timesteps         | 153491    |
| train_time              | 2969      |
| update_time             | 8612      |
---------------------------------------
---------------------------------------
| act_time                | 112       |
| current_lr              | 0.0003    |
| discount_q              | 0.0752    |
| env_time                | 250       |
| ep_rewmean              | 744       |
| episodes                | 1820      |
| eplenmean               | 234       |
| fps                     | 12        |
| mean 100 episode reward | 744       |
| n_updates               | 259200    |
| q_grad_norm             | 3634.4773 |
| qfs_loss                | 81.278595 |
| qs_abs_difference       | 49.9      |
| qs_difference           | 49.9      |
| qs_mean                 | 266.3522  |
| time_elapsed            | 12165     |
| total timesteps         | 154516    |
| train_time              | 2994      |
| update_time             | 8664      |
---------------------------------------
---------------------------------------
| act_time                | 113       |
| current_lr              | 0.0003    |
| discount_q              | 0.536     |
| env_time                | 251       |
| ep_rewmean              | 736       |
| episodes                | 1824      |
| eplenmean               | 232       |
| fps                     | 12        |
| mean 100 episode reward | 736       |
| n_updates               | 260400    |
| q_grad_norm             | 2132.307  |
| qfs_loss                | 46.975376 |
| qs_abs_difference       | 211       |
| qs_difference           | 211       |
| qs_mean                 | 308.0048  |
| time_elapsed            | 12209     |
| total timesteps         | 155165    |
| train_time              | 3008      |
| update_time             | 8693      |
---------------------------------------
---------------------------------------
| act_time                | 114       |
| current_lr              | 0.0003    |
| discount_q              | 0.162     |
| env_time                | 252       |
| ep_rewmean              | 734       |
| episodes                | 1828      |
| eplenmean               | 231       |
| fps                     | 12        |
| mean 100 episode reward | 734       |
| n_updates               | 262200    |
| q_grad_norm             | 2589.1238 |
| qfs_loss                | 57.12332  |
| qs_abs_difference       | 37.4      |
| qs_difference           | 37.3      |
| qs_mean                 | 238.13559 |
| time_elapsed            | 12275     |
| total timesteps         | 156080    |
| train_time              | 3029      |
| update_time             | 8736      |
---------------------------------------
---------------------------------------
| act_time                | 114       |
| current_lr              | 0.0003    |
| discount_q              | 1.03      |
| env_time                | 254       |
| ep_rewmean              | 727       |
| episodes                | 1832      |
| eplenmean               | 229       |
| fps                     | 12        |
| mean 100 episode reward | 728       |
| n_updates               | 263600    |
| q_grad_norm             | 2380.5403 |
| qfs_loss                | 48.804424 |
| qs_abs_difference       | 33.2      |
| qs_difference           | 33        |
| qs_mean                 | 223.66443 |
| time_elapsed            | 12326     |
| total timesteps         | 156780    |
| train_time              | 3045      |
| update_time             | 8769      |
---------------------------------------
---------------------------------------
| act_time                | 115       |
| current_lr              | 0.0003    |
| discount_q              | 1.05      |
| env_time                | 255       |
| ep_rewmean              | 722       |
| episodes                | 1836      |
| eplenmean               | 227       |
| fps                     | 12        |
| mean 100 episode reward | 722       |
| n_updates               | 265200    |
| q_grad_norm             | 2506.929  |
| qfs_loss                | 67.98103  |
| qs_abs_difference       | 28.9      |
| qs_difference           | 28.2      |
| qs_mean                 | 229.48238 |
| time_elapsed            | 12385     |
| total timesteps         | 157501    |
| train_time              | 3064      |
| update_time             | 8806      |
---------------------------------------
---------------------------------------
| act_time                | 116       |
| current_lr              | 0.0003    |
| discount_q              | 0.354     |
| env_time                | 257       |
| ep_rewmean              | 728       |
| episodes                | 1840      |
| eplenmean               | 228       |
| fps                     | 12        |
| mean 100 episode reward | 728       |
| n_updates               | 267600    |
| q_grad_norm             | 2368.1592 |
| qfs_loss                | 62.931328 |
| qs_abs_difference       | 8.83      |
| qs_difference           | 5.19      |
| qs_mean                 | 298.5522  |
| time_elapsed            | 12472     |
| total timesteps         | 158743    |
| train_time              | 3091      |
| update_time             | 8863      |
---------------------------------------
---------------------------------------
| act_time                | 116       |
| current_lr              | 0.0003    |
| discount_q              | 0.683     |
| env_time                | 258       |
| ep_rewmean              | 713       |
| episodes                | 1844      |
| eplenmean               | 224       |
| fps                     | 12        |
| mean 100 episode reward | 713       |
| n_updates               | 268600    |
| q_grad_norm             | 2421.7502 |
| qfs_loss                | 63.315746 |
| qs_abs_difference       | 247       |
| qs_difference           | 247       |
| qs_mean                 | 291.58154 |
| time_elapsed            | 12508     |
| total timesteps         | 159265    |
| train_time              | 3103      |
| update_time             | 8886      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 920       |
| eval_abs_qs_difference  | 37.564686 |
| eval_discount_q         | 242       |
| eval_ep_rewmean         | 809       |
| eval_eplenmean          | 246       |
| eval_qs                 | 269.11154 |
| eval_qs_difference      | 37.5      |
| eval_time_elapsed       | 6         |
| total timesteps         | 160001    |
---------------------------------------
---------------------------------------
| act_time                | 117       |
| current_lr              | 0.0003    |
| discount_q              | 0.818     |
| env_time                | 259       |
| ep_rewmean              | 703       |
| episodes                | 1848      |
| eplenmean               | 222       |
| fps                     | 12        |
| mean 100 episode reward | 703       |
| n_updates               | 270200    |
| q_grad_norm             | 2627.9092 |
| qfs_loss                | 55.564644 |
| qs_abs_difference       | 22.5      |
| qs_difference           | 20.4      |
| qs_mean                 | 260.85913 |
| time_elapsed            | 12574     |
| total timesteps         | 160097    |
| train_time              | 3122      |
| update_time             | 8924      |
---------------------------------------
---------------------------------------
| act_time                | 118       |
| current_lr              | 0.0003    |
| discount_q              | 0.121     |
| env_time                | 261       |
| ep_rewmean              | 697       |
| episodes                | 1852      |
| eplenmean               | 220       |
| fps                     | 12        |
| mean 100 episode reward | 698       |
| n_updates               | 272400    |
| q_grad_norm             | 2183.2664 |
| qfs_loss                | 48.71697  |
| qs_abs_difference       | 49.2      |
| qs_difference           | 49.2      |
| qs_mean                 | 288.85132 |
| time_elapsed            | 12654     |
| total timesteps         | 161152    |
| train_time              | 3147      |
| update_time             | 8975      |
---------------------------------------
---------------------------------------
| act_time                | 119       |
| current_lr              | 0.0003    |
| discount_q              | 0.0178    |
| env_time                | 263       |
| ep_rewmean              | 703       |
| episodes                | 1856      |
| eplenmean               | 221       |
| fps                     | 12        |
| mean 100 episode reward | 703       |
| n_updates               | 274800    |
| q_grad_norm             | 1903.4692 |
| qfs_loss                | 35.057186 |
| qs_abs_difference       | 20.4      |
| qs_difference           | 20.3      |
| qs_mean                 | 266.24854 |
| time_elapsed            | 12741     |
| total timesteps         | 162382    |
| train_time              | 3175      |
| update_time             | 9032      |
---------------------------------------
---------------------------------------
| act_time                | 120       |
| current_lr              | 0.0003    |
| discount_q              | 0.0165    |
| env_time                | 265       |
| ep_rewmean              | 711       |
| episodes                | 1860      |
| eplenmean               | 223       |
| fps                     | 12        |
| mean 100 episode reward | 711       |
| n_updates               | 277400    |
| q_grad_norm             | 2638.5613 |
| qfs_loss                | 55.506695 |
| qs_abs_difference       | 18        |
| qs_difference           | 15.4      |
| qs_mean                 | 263.10876 |
| time_elapsed            | 12835     |
| total timesteps         | 163607    |
| train_time              | 3205      |
| update_time             | 9092      |
---------------------------------------
---------------------------------------
| act_time                | 121       |
| current_lr              | 0.0003    |
| discount_q              | 0.0441    |
| env_time                | 267       |
| ep_rewmean              | 713       |
| episodes                | 1864      |
| eplenmean               | 224       |
| fps                     | 12        |
| mean 100 episode reward | 713       |
| n_updates               | 279600    |
| q_grad_norm             | 2051.753  |
| qfs_loss                | 43.556656 |
| qs_abs_difference       | 17.8      |
| qs_difference           | 17.4      |
| qs_mean                 | 269.8398  |
| time_elapsed            | 12915     |
| total timesteps         | 164757    |
| train_time              | 3230      |
| update_time             | 9143      |
---------------------------------------
---------------------------------------
| act_time                | 122       |
| current_lr              | 0.0003    |
| discount_q              | 0.0726    |
| env_time                | 268       |
| ep_rewmean              | 726       |
| episodes                | 1868      |
| eplenmean               | 228       |
| fps                     | 12        |
| mean 100 episode reward | 726       |
| n_updates               | 281600    |
| q_grad_norm             | 2210.834  |
| qfs_loss                | 50.942608 |
| qs_abs_difference       | 25.2      |
| qs_difference           | 25.1      |
| qs_mean                 | 226.84541 |
| time_elapsed            | 12986     |
| total timesteps         | 165739    |
| train_time              | 3253      |
| update_time             | 9189      |
---------------------------------------
---------------------------------------
| act_time                | 123       |
| current_lr              | 0.0003    |
| discount_q              | 0.139     |
| env_time                | 270       |
| ep_rewmean              | 730       |
| episodes                | 1872      |
| eplenmean               | 229       |
| fps                     | 12        |
| mean 100 episode reward | 730       |
| n_updates               | 283400    |
| q_grad_norm             | 3286.1882 |
| qfs_loss                | 71.40471  |
| qs_abs_difference       | 165       |
| qs_difference           | 165       |
| qs_mean                 | 325.51978 |
| time_elapsed            | 13051     |
| total timesteps         | 166643    |
| train_time              | 3274      |
| update_time             | 9230      |
---------------------------------------
---------------------------------------
| act_time                | 124       |
| current_lr              | 0.0003    |
| discount_q              | 0.00912   |
| env_time                | 272       |
| ep_rewmean              | 745       |
| episodes                | 1876      |
| eplenmean               | 234       |
| fps                     | 12        |
| mean 100 episode reward | 746       |
| n_updates               | 286000    |
| q_grad_norm             | 1685.6099 |
| qfs_loss                | 51.217552 |
| qs_abs_difference       | 36.3      |
| qs_difference           | 36.2      |
| qs_mean                 | 274.37625 |
| time_elapsed            | 13144     |
| total timesteps         | 167943    |
| train_time              | 3304      |
| update_time             | 9290      |
---------------------------------------
---------------------------------------
| act_time                | 125       |
| current_lr              | 0.0003    |
| discount_q              | 0.0748    |
| env_time                | 274       |
| ep_rewmean              | 755       |
| episodes                | 1880      |
| eplenmean               | 237       |
| fps                     | 12        |
| mean 100 episode reward | 755       |
| n_updates               | 288600    |
| q_grad_norm             | 1511.9272 |
| qfs_loss                | 50.866196 |
| qs_abs_difference       | 29.2      |
| qs_difference           | 29.1      |
| qs_mean                 | 308.43808 |
| time_elapsed            | 13237     |
| total timesteps         | 169297    |
| train_time              | 3334      |
| update_time             | 9349      |
---------------------------------------
---------------------------------------
| act_time                | 125       |
| current_lr              | 0.0003    |
| discount_q              | 0.878     |
| env_time                | 275       |
| ep_rewmean              | 735       |
| episodes                | 1884      |
| eplenmean               | 232       |
| fps                     | 12        |
| mean 100 episode reward | 735       |
| n_updates               | 289800    |
| q_grad_norm             | 1795.5468 |
| qfs_loss                | 51.89676  |
| qs_abs_difference       | 218       |
| qs_difference           | 218       |
| qs_mean                 | 312.2389  |
| time_elapsed            | 13280     |
| total timesteps         | 169890    |
| train_time              | 3348      |
| update_time             | 9376      |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 870       |
| eval_abs_qs_difference  | 218.66255 |
| eval_discount_q         | 130       |
| eval_ep_rewmean         | 218       |
| eval_eplenmean          | 94.7      |
| eval_qs                 | 312.3005  |
| eval_qs_difference      | 219       |
| eval_time_elapsed       | 2         |
| total timesteps         | 170001    |
---------------------------------------
---------------------------------------
| act_time                | 126       |
| current_lr              | 0.0003    |
| discount_q              | 3.21      |
| env_time                | 276       |
| ep_rewmean              | 716       |
| episodes                | 1888      |
| eplenmean               | 226       |
| fps                     | 12        |
| mean 100 episode reward | 716       |
| n_updates               | 291200    |
| q_grad_norm             | 2266.9468 |
| qfs_loss                | 50.31969  |
| qs_abs_difference       | 53.4      |
| qs_difference           | 53.3      |
| qs_mean                 | 261.59256 |
| time_elapsed            | 13332     |
| total timesteps         | 170515    |
| train_time              | 3364      |
| update_time             | 9408      |
---------------------------------------
---------------------------------------
| act_time                | 127       |
| current_lr              | 0.0003    |
| discount_q              | 0.0244    |
| env_time                | 278       |
| ep_rewmean              | 723       |
| episodes                | 1892      |
| eplenmean               | 228       |
| fps                     | 12        |
| mean 100 episode reward | 723       |
| n_updates               | 293800    |
| q_grad_norm             | 2600.7039 |
| qfs_loss                | 62.290627 |
| qs_abs_difference       | 16.4      |
| qs_difference           | 16.1      |
| qs_mean                 | 293.6618  |
| time_elapsed            | 13424     |
| total timesteps         | 171886    |
| train_time              | 3394      |
| update_time             | 9467      |
---------------------------------------
---------------------------------------
| act_time                | 128       |
| current_lr              | 0.0003    |
| discount_q              | 0.0523    |
| env_time                | 279       |
| ep_rewmean              | 731       |
| episodes                | 1896      |
| eplenmean               | 230       |
| fps                     | 12        |
| mean 100 episode reward | 731       |
| n_updates               | 295800    |
| q_grad_norm             | 1534.8992 |
| qfs_loss                | 31.961407 |
| qs_abs_difference       | 162       |
| qs_difference           | 162       |
| qs_mean                 | 317.97244 |
| time_elapsed            | 13495     |
| total timesteps         | 172880    |
| train_time              | 3417      |
| update_time             | 9512      |
---------------------------------------
---------------------------------------
| act_time                | 128       |
| current_lr              | 0.0003    |
| discount_q              | 2.42      |
| env_time                | 281       |
| ep_rewmean              | 726       |
| episodes                | 1900      |
| eplenmean               | 229       |
| fps                     | 12        |
| mean 100 episode reward | 726       |
| n_updates               | 297400    |
| q_grad_norm             | 2654.5493 |
| qfs_loss                | 67.18287  |
| qs_abs_difference       | 21.6      |
| qs_difference           | 21.4      |
| qs_mean                 | 266.62555 |
| time_elapsed            | 13552     |
| total timesteps         | 173627    |
| train_time              | 3436      |
| update_time             | 9548      |
---------------------------------------
---------------------------------------
| act_time                | 130       |
| current_lr              | 0.0003    |
| discount_q              | 0.004     |
| env_time                | 283       |
| ep_rewmean              | 761       |
| episodes                | 1904      |
| eplenmean               | 239       |
| fps                     | 12        |
| mean 100 episode reward | 761       |
| n_updates               | 300400    |
| q_grad_norm             | 3491.1116 |
| qfs_loss                | 69.28047  |
| qs_abs_difference       | 13.4      |
| qs_difference           | 12.9      |
| qs_mean                 | 290.3871  |
| time_elapsed            | 13658     |
| total timesteps         | 175171    |
| train_time              | 3470      |
| update_time             | 9615      |
---------------------------------------
---------------------------------------
| act_time                | 131       |
| current_lr              | 0.0003    |
| discount_q              | 5.53e-05  |
| env_time                | 286       |
| ep_rewmean              | 807       |
| episodes                | 1908      |
| eplenmean               | 252       |
| fps                     | 12        |
| mean 100 episode reward | 807       |
| n_updates               | 304400    |
| q_grad_norm             | 2481.956  |
| qfs_loss                | 48.98274  |
| qs_abs_difference       | 17.8      |
| qs_difference           | 17.7      |
| qs_mean                 | 291.54907 |
| time_elapsed            | 13800     |
| total timesteps         | 177141    |
| train_time              | 3516      |
| update_time             | 9705      |
---------------------------------------
---------------------------------------
| act_time                | 132       |
| current_lr              | 0.0003    |
| discount_q              | 0.014     |
| env_time                | 288       |
| ep_rewmean              | 819       |
| episodes                | 1912      |
| eplenmean               | 255       |
| fps                     | 12        |
| mean 100 episode reward | 819       |
| n_updates               | 306200    |
| q_grad_norm             | 2885.163  |
| qfs_loss                | 62.698067 |
| qs_abs_difference       | 236       |
| qs_difference           | 236       |
| qs_mean                 | 299.30185 |
| time_elapsed            | 13864     |
| total timesteps         | 178097    |
| train_time              | 3537      |
| update_time             | 9746      |
---------------------------------------
---------------------------------------
| act_time                | 133       |
| current_lr              | 0.0003    |
| discount_q              | 0.000286  |
| env_time                | 290       |
| ep_rewmean              | 844       |
| episodes                | 1916      |
| eplenmean               | 263       |
| fps                     | 12        |
| mean 100 episode reward | 844       |
| n_updates               | 309600    |
| q_grad_norm             | 2952.3772 |
| qfs_loss                | 59.220394 |
| qs_abs_difference       | 17.6      |
| qs_difference           | 17.3      |
| qs_mean                 | 266.84683 |
| time_elapsed            | 13984     |
| total timesteps         | 179752    |
| train_time              | 3577      |
| update_time             | 9822      |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 836      |
| eval_abs_qs_difference  | 8.309019 |
| eval_discount_q         | 260      |
| eval_ep_rewmean         | 1.26e+03 |
| eval_eplenmean          | 366      |
| eval_qs                 | 275.0912 |
| eval_qs_difference      | 2.29     |
| eval_time_elapsed       | 9        |
| total timesteps         | 180001   |
--------------------------------------
---------------------------------------
| act_time                | 134       |
| current_lr              | 0.0003    |
| discount_q              | 0.428     |
| env_time                | 291       |
| ep_rewmean              | 827       |
| episodes                | 1920      |
| eplenmean               | 258       |
| fps                     | 12        |
| mean 100 episode reward | 827       |
| n_updates               | 310600    |
| q_grad_norm             | 2742.7932 |
| qfs_loss                | 54.949062 |
| qs_abs_difference       | 254       |
| qs_difference           | 254       |
| qs_mean                 | 285.80054 |
| time_elapsed            | 14028     |
| total timesteps         | 180268    |
| train_time              | 3588      |
| update_time             | 9845      |
---------------------------------------
---------------------------------------
| act_time                | 135       |
| current_lr              | 0.0003    |
| discount_q              | 0.0924    |
| env_time                | 293       |
| ep_rewmean              | 846       |
| episodes                | 1924      |
| eplenmean               | 262       |
| fps                     | 12        |
| mean 100 episode reward | 846       |
| n_updates               | 312800    |
| q_grad_norm             | 2027.5103 |
| qfs_loss                | 35.498146 |
| qs_abs_difference       | 7.2       |
| qs_difference           | 5.06      |
| qs_mean                 | 274.15152 |
| time_elapsed            | 14106     |
| total timesteps         | 181399    |
| train_time              | 3614      |
| update_time             | 9893      |
---------------------------------------
---------------------------------------
| act_time                | 136       |
| current_lr              | 0.0003    |
| discount_q              | 0.106     |
| env_time                | 295       |
| ep_rewmean              | 856       |
| episodes                | 1928      |
| eplenmean               | 265       |
| fps                     | 12        |
| mean 100 episode reward | 856       |
| n_updates               | 315400    |
| q_grad_norm             | 2520.0974 |
| qfs_loss                | 63.331875 |
| qs_abs_difference       | 8.45      |
| qs_difference           | 6.16      |
| qs_mean                 | 286.00223 |
| time_elapsed            | 14197     |
| total timesteps         | 182601    |
| train_time              | 3644      |
| update_time             | 9952      |
---------------------------------------
---------------------------------------
| act_time                | 138       |
| current_lr              | 0.0003    |
| discount_q              | 3.83e-05  |
| env_time                | 298       |
| ep_rewmean              | 905       |
| episodes                | 1932      |
| eplenmean               | 280       |
| fps                     | 12        |
| mean 100 episode reward | 905       |
| n_updates               | 319600    |
| q_grad_norm             | 2200.3374 |
| qfs_loss                | 54.200096 |
| qs_abs_difference       | 13.5      |
| qs_difference           | 13.2      |
| qs_mean                 | 301.0752  |
| time_elapsed            | 14346     |
| total timesteps         | 184766    |
| train_time              | 3692      |
| update_time             | 10046     |
---------------------------------------
---------------------------------------
| act_time                | 139       |
| current_lr              | 0.0003    |
| discount_q              | 0.0136    |
| env_time                | 301       |
| ep_rewmean              | 929       |
| episodes                | 1936      |
| eplenmean               | 286       |
| fps                     | 12        |
| mean 100 episode reward | 929       |
| n_updates               | 322400    |
| q_grad_norm             | 2708.22   |
| qfs_loss                | 58.850445 |
| qs_abs_difference       | 18        |
| qs_difference           | 17.7      |
| qs_mean                 | 287.70135 |
| time_elapsed            | 14445     |
| total timesteps         | 186149    |
| train_time              | 3725      |
| update_time             | 10108     |
---------------------------------------
---------------------------------------
| act_time                | 140       |
| current_lr              | 0.0003    |
| discount_q              | 0.0107    |
| env_time                | 303       |
| ep_rewmean              | 930       |
| episodes                | 1940      |
| eplenmean               | 287       |
| fps                     | 12        |
| mean 100 episode reward | 930       |
| n_updates               | 325000    |
| q_grad_norm             | 2853.064  |
| qfs_loss                | 52.179604 |
| qs_abs_difference       | 9.69      |
| qs_difference           | 7.29      |
| qs_mean                 | 259.23843 |
| time_elapsed            | 14537     |
| total timesteps         | 187432    |
| train_time              | 3755      |
| update_time             | 10167     |
---------------------------------------
---------------------------------------
| act_time                | 141       |
| current_lr              | 0.0003    |
| discount_q              | 0.00356   |
| env_time                | 305       |
| ep_rewmean              | 971       |
| episodes                | 1944      |
| eplenmean               | 298       |
| fps                     | 12        |
| mean 100 episode reward | 971       |
| n_updates               | 328200    |
| q_grad_norm             | 2876.8071 |
| qfs_loss                | 53.503403 |
| qs_abs_difference       | 8.3       |
| qs_difference           | 8.01      |
| qs_mean                 | 301.0721  |
| time_elapsed            | 14650     |
| total timesteps         | 189092    |
| train_time              | 3792      |
| update_time             | 10238     |
---------------------------------------
---------------------------------------
| act_time                | 142       |
| current_lr              | 0.0003    |
| discount_q              | 0.00287   |
| env_time                | 307       |
| ep_rewmean              | 974       |
| episodes                | 1948      |
| eplenmean               | 299       |
| fps                     | 12        |
| mean 100 episode reward | 974       |
| n_updates               | 330000    |
| q_grad_norm             | 2383.3232 |
| qfs_loss                | 50.410343 |
| qs_abs_difference       | 265       |
| qs_difference           | 265       |
| qs_mean                 | 273.99042 |
| time_elapsed            | 14714     |
| total timesteps         | 189954    |
| train_time              | 3813      |
| update_time             | 10279     |
---------------------------------------
----------------------------------------
| eval mean 100 episod... | 907        |
| eval_abs_qs_difference  | 12.5293455 |
| eval_discount_q         | 263        |
| eval_ep_rewmean         | 2.11e+03   |
| eval_eplenmean          | 614        |
| eval_qs                 | 293.27994  |
| eval_qs_difference      | -4.74      |
| eval_time_elapsed       | 16         |
| total timesteps         | 190001     |
----------------------------------------
---------------------------------------
| act_time                | 142       |
| current_lr              | 0.0003    |
| discount_q              | 10.1      |
| env_time                | 307       |
| ep_rewmean              | 940       |
| episodes                | 1952      |
| eplenmean               | 289       |
| fps                     | 12        |
| mean 100 episode reward | 940       |
| n_updates               | 330200    |
| q_grad_norm             | 3131.3992 |
| qfs_loss                | 53.89987  |
| qs_abs_difference       | 265       |
| qs_difference           | 265       |
| qs_mean                 | 274.66895 |
| time_elapsed            | 14737     |
| total timesteps         | 190006    |
| train_time              | 3815      |
| update_time             | 10283     |
---------------------------------------
---------------------------------------
| act_time                | 143       |
| current_lr              | 0.0003    |
| discount_q              | 0.0153    |
| env_time                | 310       |
| ep_rewmean              | 950       |
| episodes                | 1956      |
| eplenmean               | 292       |
| fps                     | 12        |
| mean 100 episode reward | 950       |
| n_updates               | 333200    |
| q_grad_norm             | 1695.4801 |
| qfs_loss                | 42.73227  |
| qs_abs_difference       | 9.84      |
| qs_difference           | 8.01      |
| qs_mean                 | 299.2266  |
| time_elapsed            | 14844     |
| total timesteps         | 191566    |
| train_time              | 3850      |
| update_time             | 10350     |
---------------------------------------
---------------------------------------
| act_time                | 145       |
| current_lr              | 0.0003    |
| discount_q              | 0.000521  |
| env_time                | 313       |
| ep_rewmean              | 984       |
| episodes                | 1960      |
| eplenmean               | 303       |
| fps                     | 12        |
| mean 100 episode reward | 984       |
| n_updates               | 337800    |
| q_grad_norm             | 1695.158  |
| qfs_loss                | 35.34448  |
| qs_abs_difference       | 37        |
| qs_difference           | 37        |
| qs_mean                 | 328.63812 |
| time_elapsed            | 15007     |
| total timesteps         | 193870    |
| train_time              | 3903      |
| update_time             | 10454     |
---------------------------------------
---------------------------------------
| act_time                | 147       |
| current_lr              | 0.0003    |
| discount_q              | 0.0202    |
| env_time                | 316       |
| ep_rewmean              | 994       |
| episodes                | 1964      |
| eplenmean               | 308       |
| fps                     | 12        |
| mean 100 episode reward | 994       |
| n_updates               | 341200    |
| q_grad_norm             | 2783.3782 |
| qfs_loss                | 61.99477  |
| qs_abs_difference       | 31.4      |
| qs_difference           | 31.3      |
| qs_mean                 | 301.16833 |
| time_elapsed            | 15126     |
| total timesteps         | 195512    |
| train_time              | 3942      |
| update_time             | 10530     |
---------------------------------------
---------------------------------------
| act_time                | 148       |
| current_lr              | 0.0003    |
| discount_q              | 4.42e-05  |
| env_time                | 319       |
| ep_rewmean              | 1.02e+03  |
| episodes                | 1968      |
| eplenmean               | 317       |
| fps                     | 12        |
| mean 100 episode reward | 1.02e+03  |
| n_updates               | 345000    |
| q_grad_norm             | 1702.6831 |
| qfs_loss                | 48.924667 |
| qs_abs_difference       | 22.4      |
| qs_difference           | 22.4      |
| qs_mean                 | 281.28378 |
| time_elapsed            | 15261     |
| total timesteps         | 197435    |
| train_time              | 3986      |
| update_time             | 10615     |
---------------------------------------
---------------------------------------
| act_time                | 149       |
| current_lr              | 0.0003    |
| discount_q              | 0.000848  |
| env_time                | 321       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 1972      |
| eplenmean               | 321       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 347600    |
| q_grad_norm             | 2050.9412 |
| qfs_loss                | 51.290184 |
| qs_abs_difference       | 207       |
| qs_difference           | 207       |
| qs_mean                 | 314.32648 |
| time_elapsed            | 15353     |
| total timesteps         | 198740    |
| train_time              | 4016      |
| update_time             | 10673     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 916       |
| eval_abs_qs_difference  | 12.382449 |
| eval_discount_q         | 256       |
| eval_ep_rewmean         | 1.25e+03  |
| eval_eplenmean          | 372       |
| eval_qs                 | 278.26035 |
| eval_qs_difference      | 9.52      |
| eval_time_elapsed       | 9         |
| total timesteps         | 200001    |
---------------------------------------
---------------------------------------
| act_time                | 151       |
| current_lr              | 0.0003    |
| discount_q              | 0.0084    |
| env_time                | 324       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1976      |
| eplenmean               | 325       |
| fps                     | 12        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 351000    |
| q_grad_norm             | 1992.7404 |
| qfs_loss                | 38.338997 |
| qs_abs_difference       | 7.94      |
| qs_difference           | 6.31      |
| qs_mean                 | 300.83713 |
| time_elapsed            | 15483     |
| total timesteps         | 200407    |
| train_time              | 4056      |
| update_time             | 10749     |
---------------------------------------
---------------------------------------
| act_time                | 152       |
| current_lr              | 0.0003    |
| discount_q              | 0.198     |
| env_time                | 326       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 1980      |
| eplenmean               | 323       |
| fps                     | 12        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 353400    |
| q_grad_norm             | 1186.8904 |
| qfs_loss                | 27.904524 |
| qs_abs_difference       | 14.7      |
| qs_difference           | 13.5      |
| qs_mean                 | 291.62207 |
| time_elapsed            | 15568     |
| total timesteps         | 201627    |
| train_time              | 4083      |
| update_time             | 10803     |
---------------------------------------
---------------------------------------
| act_time                | 154       |
| current_lr              | 0.0003    |
| discount_q              | 4.7e-05   |
| env_time                | 329       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 1984      |
| eplenmean               | 338       |
| fps                     | 12        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 357400    |
| q_grad_norm             | 1978.4332 |
| qfs_loss                | 35.02477  |
| qs_abs_difference       | 11.6      |
| qs_difference           | 11.4      |
| qs_mean                 | 294.02612 |
| time_elapsed            | 15710     |
| total timesteps         | 203695    |
| train_time              | 4130      |
| update_time             | 10893     |
---------------------------------------
---------------------------------------
| act_time                | 155       |
| current_lr              | 0.0003    |
| discount_q              | 0.00162   |
| env_time                | 332       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 1988      |
| eplenmean               | 348       |
| fps                     | 12        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 360600    |
| q_grad_norm             | 1992.5966 |
| qfs_loss                | 33.82473  |
| qs_abs_difference       | 8.21      |
| qs_difference           | 7.19      |
| qs_mean                 | 279.59637 |
| time_elapsed            | 15823     |
| total timesteps         | 205278    |
| train_time              | 4166      |
| update_time             | 10965     |
---------------------------------------
---------------------------------------
| act_time                | 156       |
| current_lr              | 0.0003    |
| discount_q              | 0.00311   |
| env_time                | 334       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 1992      |
| eplenmean               | 348       |
| fps                     | 12        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 363400    |
| q_grad_norm             | 1767.3636 |
| qfs_loss                | 38.583736 |
| qs_abs_difference       | 16.8      |
| qs_difference           | 12.7      |
| qs_mean                 | 260.67648 |
| time_elapsed            | 15922     |
| total timesteps         | 206679    |
| train_time              | 4199      |
| update_time             | 11027     |
---------------------------------------
---------------------------------------
| act_time                | 157       |
| current_lr              | 0.0003    |
| discount_q              | 0.000126  |
| env_time                | 336       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 1996      |
| eplenmean               | 349       |
| fps                     | 12        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 365800    |
| q_grad_norm             | 2542.4424 |
| qfs_loss                | 43.378906 |
| qs_abs_difference       | 266       |
| qs_difference           | 266       |
| qs_mean                 | 272.9106  |
| time_elapsed            | 16006     |
| total timesteps         | 207816    |
| train_time              | 4227      |
| update_time             | 11081     |
---------------------------------------
--------------------------------------
| act_time                | 157      |
| current_lr              | 0.0003   |
| discount_q              | 7.22     |
| env_time                | 336      |
| ep_rewmean              | 1.11e+03 |
| episodes                | 2000     |
| eplenmean               | 342      |
| fps                     | 12       |
| mean 100 episode reward | 1.11e+03 |
| n_updates               | 365800   |
| qs_abs_difference       | 265      |
| qs_difference           | 265      |
| qs_mean                 | 271.3941 |
| time_elapsed            | 16006    |
| total timesteps         | 207860   |
| train_time              | 4227     |
| update_time             | 11081    |
--------------------------------------
---------------------------------------
| act_time                | 157       |
| current_lr              | 0.0003    |
| discount_q              | 6.49      |
| env_time                | 336       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2004      |
| eplenmean               | 327       |
| fps                     | 12        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 365800    |
| qs_abs_difference       | 266       |
| qs_difference           | 266       |
| qs_mean                 | 271.28317 |
| time_elapsed            | 16007     |
| total timesteps         | 207898    |
| train_time              | 4227      |
| update_time             | 11081     |
---------------------------------------
---------------------------------------
| act_time                | 158       |
| current_lr              | 0.0003    |
| discount_q              | 0.371     |
| env_time                | 338       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2008      |
| eplenmean               | 318       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 368000    |
| q_grad_norm             | 2370.8977 |
| qfs_loss                | 49.512764 |
| qs_abs_difference       | 14.4      |
| qs_difference           | 14.4      |
| qs_mean                 | 283.90585 |
| time_elapsed            | 16085     |
| total timesteps         | 208935    |
| train_time              | 4252      |
| update_time             | 11131     |
---------------------------------------
---------------------------------------
| act_time                | 159       |
| current_lr              | 0.0003    |
| discount_q              | 2.13      |
| env_time                | 340       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2012      |
| eplenmean               | 318       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 370000    |
| q_grad_norm             | 1908.0007 |
| qfs_loss                | 38.96235  |
| qs_abs_difference       | 9.09      |
| qs_difference           | 8.07      |
| qs_mean                 | 292.62402 |
| time_elapsed            | 16156     |
| total timesteps         | 209919    |
| train_time              | 4275      |
| update_time             | 11176     |
---------------------------------------
--------------------------------------
| eval mean 100 episod... | 1.14e+03 |
| eval_abs_qs_difference  | 28.37343 |
| eval_discount_q         | 251      |
| eval_ep_rewmean         | 2.62e+03 |
| eval_eplenmean          | 820      |
| eval_qs                 | 313.6768 |
| eval_qs_difference      | 26.6     |
| eval_time_elapsed       | 21       |
| total timesteps         | 210001   |
--------------------------------------
---------------------------------------
| act_time                | 160       |
| current_lr              | 0.0003    |
| discount_q              | 0.000758  |
| env_time                | 342       |
| ep_rewmean              | 1.03e+03  |
| episodes                | 2016      |
| eplenmean               | 319       |
| fps                     | 12        |
| mean 100 episode reward | 1.03e+03  |
| n_updates               | 373400    |
| q_grad_norm             | 2591.5215 |
| qfs_loss                | 47.453312 |
| qs_abs_difference       | 20.6      |
| qs_difference           | 20        |
| qs_mean                 | 284.06155 |
| time_elapsed            | 16298     |
| total timesteps         | 211620    |
| train_time              | 4315      |
| update_time             | 11252     |
---------------------------------------
---------------------------------------
| act_time                | 161       |
| current_lr              | 0.0003    |
| discount_q              | 0.127     |
| env_time                | 344       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2020      |
| eplenmean               | 324       |
| fps                     | 12        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 375400    |
| q_grad_norm             | 1928.0809 |
| qfs_loss                | 31.036238 |
| qs_abs_difference       | 12.4      |
| qs_difference           | 12.4      |
| qs_mean                 | 274.37827 |
| time_elapsed            | 16369     |
| total timesteps         | 212697    |
| train_time              | 4338      |
| update_time             | 11298     |
---------------------------------------
---------------------------------------
| act_time                | 163       |
| current_lr              | 0.0003    |
| discount_q              | 0.00567   |
| env_time                | 347       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2024      |
| eplenmean               | 329       |
| fps                     | 12        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 378600    |
| q_grad_norm             | 1947.8185 |
| qfs_loss                | 43.911434 |
| qs_abs_difference       | 10.1      |
| qs_difference           | 9.22      |
| qs_mean                 | 292.4097  |
| time_elapsed            | 16483     |
| total timesteps         | 214278    |
| train_time              | 4375      |
| update_time             | 11370     |
---------------------------------------
---------------------------------------
| act_time                | 163       |
| current_lr              | 0.0003    |
| discount_q              | 0.656     |
| env_time                | 348       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2028      |
| eplenmean               | 325       |
| fps                     | 13        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 380200    |
| q_grad_norm             | 2236.2646 |
| qfs_loss                | 39.345078 |
| qs_abs_difference       | 23.3      |
| qs_difference           | 23.2      |
| qs_mean                 | 234.26614 |
| time_elapsed            | 16539     |
| total timesteps         | 215066    |
| train_time              | 4393      |
| update_time             | 11406     |
---------------------------------------
---------------------------------------
| act_time                | 165       |
| current_lr              | 0.0003    |
| discount_q              | 2.84e-06  |
| env_time                | 352       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2032      |
| eplenmean               | 327       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 385000    |
| q_grad_norm             | 2716.0413 |
| qfs_loss                | 41.188667 |
| qs_abs_difference       | 12        |
| qs_difference           | 11.2      |
| qs_mean                 | 295.90433 |
| time_elapsed            | 16710     |
| total timesteps         | 217438    |
| train_time              | 4449      |
| update_time             | 11514     |
---------------------------------------
---------------------------------------
| act_time                | 167       |
| current_lr              | 0.0003    |
| discount_q              | 0.00882   |
| env_time                | 355       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2036      |
| eplenmean               | 330       |
| fps                     | 13        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 388400    |
| q_grad_norm             | 2376.242  |
| qfs_loss                | 38.003204 |
| qs_abs_difference       | 19.4      |
| qs_difference           | 18.9      |
| qs_mean                 | 308.2673  |
| time_elapsed            | 16831     |
| total timesteps         | 219130    |
| train_time              | 4488      |
| update_time             | 11590     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.24e+03  |
| eval_abs_qs_difference  | 11.179918 |
| eval_discount_q         | 243       |
| eval_ep_rewmean         | 1.39e+03  |
| eval_eplenmean          | 417       |
| eval_qs                 | 278.07285 |
| eval_qs_difference      | 5.47      |
| eval_time_elapsed       | 10        |
| total timesteps         | 220001    |
---------------------------------------
---------------------------------------
| act_time                | 168       |
| current_lr              | 0.0003    |
| discount_q              | 0.0314    |
| env_time                | 357       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2040      |
| eplenmean               | 330       |
| fps                     | 13        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 391000    |
| q_grad_norm             | 2368.0315 |
| qfs_loss                | 36.13158  |
| qs_abs_difference       | 19.4      |
| qs_difference           | 19.4      |
| qs_mean                 | 287.17096 |
| time_elapsed            | 16933     |
| total timesteps         | 220451    |
| train_time              | 4518      |
| update_time             | 11648     |
---------------------------------------
---------------------------------------
| act_time                | 169       |
| current_lr              | 0.0003    |
| discount_q              | 0.000105  |
| env_time                | 360       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2044      |
| eplenmean               | 332       |
| fps                     | 13        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 394600    |
| q_grad_norm             | 1723.1127 |
| qfs_loss                | 35.920006 |
| qs_abs_difference       | 16        |
| qs_difference           | 15.6      |
| qs_mean                 | 281.75854 |
| time_elapsed            | 17061     |
| total timesteps         | 222293    |
| train_time              | 4560      |
| update_time             | 11729     |
---------------------------------------
---------------------------------------
| act_time                | 170       |
| current_lr              | 0.0003    |
| discount_q              | 0.0159    |
| env_time                | 362       |
| ep_rewmean              | 1.08e+03  |
| episodes                | 2048      |
| eplenmean               | 335       |
| fps                     | 13        |
| mean 100 episode reward | 1.08e+03  |
| n_updates               | 397000    |
| q_grad_norm             | 1868.6592 |
| qfs_loss                | 41.953506 |
| qs_abs_difference       | 21.2      |
| qs_difference           | 21        |
| qs_mean                 | 244.02832 |
| time_elapsed            | 17145     |
| total timesteps         | 223471    |
| train_time              | 4588      |
| update_time             | 11783     |
---------------------------------------
---------------------------------------
| act_time                | 171       |
| current_lr              | 0.0003    |
| discount_q              | 0.168     |
| env_time                | 363       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2052      |
| eplenmean               | 344       |
| fps                     | 13        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 399000    |
| q_grad_norm             | 1754.8384 |
| qfs_loss                | 31.875948 |
| qs_abs_difference       | 16.6      |
| qs_difference           | 15.2      |
| qs_mean                 | 250.98271 |
| time_elapsed            | 17216     |
| total timesteps         | 224444    |
| train_time              | 4611      |
| update_time             | 11827     |
---------------------------------------
---------------------------------------
| act_time                | 172       |
| current_lr              | 0.0003    |
| discount_q              | 0.00239   |
| env_time                | 366       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2056      |
| eplenmean               | 344       |
| fps                     | 13        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 402000    |
| q_grad_norm             | 2086.3008 |
| qfs_loss                | 36.383217 |
| qs_abs_difference       | 8.97      |
| qs_difference           | 8.31      |
| qs_mean                 | 274.42993 |
| time_elapsed            | 17322     |
| total timesteps         | 225953    |
| train_time              | 4646      |
| update_time             | 11894     |
---------------------------------------
---------------------------------------
| act_time                | 173       |
| current_lr              | 0.0003    |
| discount_q              | 0.0191    |
| env_time                | 367       |
| ep_rewmean              | 1.06e+03  |
| episodes                | 2060      |
| eplenmean               | 329       |
| fps                     | 13        |
| mean 100 episode reward | 1.06e+03  |
| n_updates               | 403600    |
| q_grad_norm             | 1531.544  |
| qfs_loss                | 31.670427 |
| qs_abs_difference       | 254       |
| qs_difference           | 254       |
| qs_mean                 | 276.936   |
| time_elapsed            | 17379     |
| total timesteps         | 226726    |
| train_time              | 4665      |
| update_time             | 11930     |
---------------------------------------
---------------------------------------
| act_time                | 175       |
| current_lr              | 0.0003    |
| discount_q              | 1.36e-05  |
| env_time                | 370       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2064      |
| eplenmean               | 331       |
| fps                     | 13        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 407200    |
| q_grad_norm             | 1833.6722 |
| qfs_loss                | 35.117844 |
| qs_abs_difference       | 21.4      |
| qs_difference           | 20.8      |
| qs_mean                 | 236.3525  |
| time_elapsed            | 17505     |
| total timesteps         | 228594    |
| train_time              | 4706      |
| update_time             | 12011     |
---------------------------------------
---------------------------------------
| act_time                | 175       |
| current_lr              | 0.0003    |
| discount_q              | 0.0013    |
| env_time                | 372       |
| ep_rewmean              | 1.05e+03  |
| episodes                | 2068      |
| eplenmean               | 322       |
| fps                     | 13        |
| mean 100 episode reward | 1.05e+03  |
| n_updates               | 409400    |
| q_grad_norm             | 1534.0348 |
| qfs_loss                | 30.241917 |
| qs_abs_difference       | 249       |
| qs_difference           | 249       |
| qs_mean                 | 274.3276  |
| time_elapsed            | 17583     |
| total timesteps         | 229651    |
| train_time              | 4731      |
| update_time             | 12060     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.39e+03  |
| eval_abs_qs_difference  | 25.113567 |
| eval_discount_q         | 260       |
| eval_ep_rewmean         | 2.45e+03  |
| eval_eplenmean          | 734       |
| eval_qs                 | 304.75964 |
| eval_qs_difference      | 18.9      |
| eval_time_elapsed       | 19        |
| total timesteps         | 230001    |
---------------------------------------
---------------------------------------
| act_time                | 176       |
| current_lr              | 0.0003    |
| discount_q              | 0.0195    |
| env_time                | 373       |
| ep_rewmean              | 1.04e+03  |
| episodes                | 2072      |
| eplenmean               | 317       |
| fps                     | 13        |
| mean 100 episode reward | 1.04e+03  |
| n_updates               | 411000    |
| q_grad_norm             | 1814.179  |
| qfs_loss                | 36.773075 |
| qs_abs_difference       | 250       |
| qs_difference           | 250       |
| qs_mean                 | 272.61984 |
| time_elapsed            | 17658     |
| total timesteps         | 230425    |
| train_time              | 4750      |
| update_time             | 12095     |
---------------------------------------
---------------------------------------
| act_time                | 176       |
| current_lr              | 0.0003    |
| discount_q              | 17.3      |
| env_time                | 373       |
| ep_rewmean              | 983       |
| episodes                | 2076      |
| eplenmean               | 301       |
| fps                     | 13        |
| mean 100 episode reward | 983       |
| n_updates               | 411200    |
| q_grad_norm             | 1350.0718 |
| qfs_loss                | 25.423529 |
| qs_abs_difference       | 247       |
| qs_difference           | 247       |
| qs_mean                 | 270.5153  |
| time_elapsed            | 17665     |
| total timesteps         | 230528    |
| train_time              | 4752      |
| update_time             | 12100     |
---------------------------------------
---------------------------------------
| act_time                | 177       |
| current_lr              | 0.0003    |
| discount_q              | 0.00299   |
| env_time                | 375       |
| ep_rewmean              | 994       |
| episodes                | 2080      |
| eplenmean               | 304       |
| fps                     | 13        |
| mean 100 episode reward | 994       |
| n_updates               | 414200    |
| q_grad_norm             | 2371.247  |
| qfs_loss                | 53.055817 |
| qs_abs_difference       | 14.8      |
| qs_difference           | 13.9      |
| qs_mean                 | 276.48837 |
| time_elapsed            | 17771     |
| total timesteps         | 232009    |
| train_time              | 4787      |
| update_time             | 12167     |
---------------------------------------
---------------------------------------
| act_time                | 179       |
| current_lr              | 0.0003    |
| discount_q              | 0.000562  |
| env_time                | 378       |
| ep_rewmean              | 979       |
| episodes                | 2084      |
| eplenmean               | 299       |
| fps                     | 13        |
| mean 100 episode reward | 979       |
| n_updates               | 417400    |
| q_grad_norm             | 1293.8799 |
| qfs_loss                | 27.771461 |
| qs_abs_difference       | 10.9      |
| qs_difference           | -1.53     |
| qs_mean                 | 258.77255 |
| time_elapsed            | 17884     |
| total timesteps         | 233601    |
| train_time              | 4824      |
| update_time             | 12238     |
---------------------------------------
---------------------------------------
| act_time                | 180       |
| current_lr              | 0.0003    |
| discount_q              | 0.000177  |
| env_time                | 381       |
| ep_rewmean              | 977       |
| episodes                | 2088      |
| eplenmean               | 299       |
| fps                     | 13        |
| mean 100 episode reward | 977       |
| n_updates               | 420600    |
| q_grad_norm             | 1775.278  |
| qfs_loss                | 34.781666 |
| qs_abs_difference       | 39.1      |
| qs_difference           | 39.1      |
| qs_mean                 | 241.69133 |
| time_elapsed            | 17996     |
| total timesteps         | 235202    |
| train_time              | 4861      |
| update_time             | 12309     |
---------------------------------------
---------------------------------------
| act_time                | 181       |
| current_lr              | 0.0003    |
| discount_q              | 0.0114    |
| env_time                | 383       |
| ep_rewmean              | 976       |
| episodes                | 2092      |
| eplenmean               | 300       |
| fps                     | 13        |
| mean 100 episode reward | 976       |
| n_updates               | 423400    |
| q_grad_norm             | 1419.8447 |
| qfs_loss                | 27.23938  |
| qs_abs_difference       | 8.5       |
| qs_difference           | 7.69      |
| qs_mean                 | 286.76007 |
| time_elapsed            | 18095     |
| total timesteps         | 236643    |
| train_time              | 4894      |
| update_time             | 12371     |
---------------------------------------
---------------------------------------
| act_time                | 183       |
| current_lr              | 0.0003    |
| discount_q              | 0.00442   |
| env_time                | 386       |
| ep_rewmean              | 989       |
| episodes                | 2096      |
| eplenmean               | 304       |
| fps                     | 13        |
| mean 100 episode reward | 989       |
| n_updates               | 426400    |
| q_grad_norm             | 1728.5181 |
| qfs_loss                | 31.93279  |
| qs_abs_difference       | 73.3      |
| qs_difference           | 73.3      |
| qs_mean                 | 329.252   |
| time_elapsed            | 18201     |
| total timesteps         | 238166    |
| train_time              | 4928      |
| update_time             | 12437     |
---------------------------------------
---------------------------------------
| act_time                | 183       |
| current_lr              | 0.0003    |
| discount_q              | 0.888     |
| env_time                | 387       |
| ep_rewmean              | 1.01e+03  |
| episodes                | 2100      |
| eplenmean               | 310       |
| fps                     | 13        |
| mean 100 episode reward | 1.01e+03  |
| n_updates               | 427800    |
| q_grad_norm             | 2294.4868 |
| qfs_loss                | 49.387383 |
| qs_abs_difference       | 160       |
| qs_difference           | 160       |
| qs_mean                 | 314.29907 |
| time_elapsed            | 18249     |
| total timesteps         | 238855    |
| train_time              | 4945      |
| update_time             | 12468     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.65e+03  |
| eval_abs_qs_difference  | 33.055496 |
| eval_discount_q         | 264       |
| eval_ep_rewmean         | 3.11e+03  |
| eval_eplenmean          | 944       |
| eval_qs                 | 327.8585  |
| eval_qs_difference      | 26.6      |
| eval_time_elapsed       | 24        |
| total timesteps         | 240001    |
---------------------------------------
---------------------------------------
| act_time                | 185       |
| current_lr              | 0.0003    |
| discount_q              | 8.25e-05  |
| env_time                | 391       |
| ep_rewmean              | 1.09e+03  |
| episodes                | 2104      |
| eplenmean               | 334       |
| fps                     | 13        |
| mean 100 episode reward | 1.09e+03  |
| n_updates               | 432800    |
| q_grad_norm             | 1430.2867 |
| qfs_loss                | 41.950195 |
| qs_abs_difference       | 23.1      |
| qs_difference           | 22.8      |
| qs_mean                 | 326.79874 |
| time_elapsed            | 18449     |
| total timesteps         | 241344    |
| train_time              | 5002      |
| update_time             | 12578     |
---------------------------------------
---------------------------------------
| act_time                | 187       |
| current_lr              | 0.0003    |
| discount_q              | 0.00828   |
| env_time                | 394       |
| ep_rewmean              | 1.13e+03  |
| episodes                | 2108      |
| eplenmean               | 344       |
| fps                     | 13        |
| mean 100 episode reward | 1.13e+03  |
| n_updates               | 436800    |
| q_grad_norm             | 2590.2637 |
| qfs_loss                | 51.970184 |
| qs_abs_difference       | 18.5      |
| qs_difference           | 15.7      |
| qs_mean                 | 324.9666  |
| time_elapsed            | 18589     |
| total timesteps         | 243376    |
| train_time              | 5049      |
| update_time             | 12667     |
---------------------------------------
---------------------------------------
| act_time                | 188       |
| current_lr              | 0.0003    |
| discount_q              | 0.000964  |
| env_time                | 397       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2112      |
| eplenmean               | 350       |
| fps                     | 13        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 440000    |
| q_grad_norm             | 1524.3125 |
| qfs_loss                | 28.50315  |
| qs_abs_difference       | 4.98      |
| qs_difference           | 2.85      |
| qs_mean                 | 272.81207 |
| time_elapsed            | 18700     |
| total timesteps         | 244951    |
| train_time              | 5086      |
| update_time             | 12737     |
---------------------------------------
---------------------------------------
| act_time                | 190       |
| current_lr              | 0.0003    |
| discount_q              | 3.66e-05  |
| env_time                | 399       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2116      |
| eplenmean               | 350       |
| fps                     | 13        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 443400    |
| q_grad_norm             | 1446.1445 |
| qfs_loss                | 24.023987 |
| qs_abs_difference       | 155       |
| qs_difference           | 155       |
| qs_mean                 | 318.00287 |
| time_elapsed            | 18819     |
| total timesteps         | 246663    |
| train_time              | 5125      |
| update_time             | 12812     |
---------------------------------------
--------------------------------------
| act_time                | 191      |
| current_lr              | 0.0003   |
| discount_q              | 0.0288   |
| env_time                | 401      |
| ep_rewmean              | 1.15e+03 |
| episodes                | 2120     |
| eplenmean               | 352      |
| fps                     | 13       |
| mean 100 episode reward | 1.15e+03 |
| n_updates               | 445800   |
| q_grad_norm             | 1534.652 |
| qfs_loss                | 32.70093 |
| qs_abs_difference       | 113      |
| qs_difference           | 113      |
| qs_mean                 | 324.8917 |
| time_elapsed            | 18903    |
| total timesteps         | 247855   |
| train_time              | 5153     |
| update_time             | 12864    |
--------------------------------------
---------------------------------------
| act_time                | 192       |
| current_lr              | 0.0003    |
| discount_q              | 0.0215    |
| env_time                | 403       |
| ep_rewmean              | 1.14e+03  |
| episodes                | 2124      |
| eplenmean               | 348       |
| fps                     | 13        |
| mean 100 episode reward | 1.14e+03  |
| n_updates               | 448200    |
| q_grad_norm             | 1154.802  |
| qfs_loss                | 20.673418 |
| qs_abs_difference       | 6.54      |
| qs_difference           | 2.27      |
| qs_mean                 | 265.2599  |
| time_elapsed            | 18987     |
| total timesteps         | 249084    |
| train_time              | 5180      |
| update_time             | 12917     |
---------------------------------------
---------------------------------------
| act_time                | 193       |
| current_lr              | 0.0003    |
| discount_q              | 0.254     |
| env_time                | 405       |
| ep_rewmean              | 1.15e+03  |
| episodes                | 2128      |
| eplenmean               | 349       |
| fps                     | 13        |
| mean 100 episode reward | 1.15e+03  |
| n_updates               | 450000    |
| q_grad_norm             | 1196.8868 |
| qfs_loss                | 20.689095 |
| qs_abs_difference       | 147       |
| qs_difference           | 147       |
| qs_mean                 | 323.63483 |
| time_elapsed            | 19050     |
| total timesteps         | 249946    |
| train_time              | 5201      |
| update_time             | 12957     |
---------------------------------------
---------------------------------------
| eval mean 100 episod... | 1.69e+03  |
| eval_abs_qs_difference  | 20.162428 |
| eval_discount_q         | 254       |
| eval_ep_rewmean         | 967       |
| eval_eplenmean          | 278       |
| eval_qs                 | 258.75882 |
| eval_qs_difference      | 5.74      |
| eval_time_elapsed       | 7         |
| total timesteps         | 250001    |
---------------------------------------
---------------------------------------
| act_time                | 194       |
| current_lr              | 0.0003    |
| discount_q              | 0.00104   |
| env_time                | 407       |
| ep_rewmean              | 1.12e+03  |
| episodes                | 2132      |
| eplenmean               | 339       |
| fps                     | 13        |
| mean 100 episode reward | 1.12e+03  |
| n_updates               | 452800    |
| q_grad_norm             | 1718.7076 |
| qfs_loss                | 29.057297 |
| qs_abs_difference       | 43.6      |
| qs_difference           | 43.6      |
| qs_mean                 | 251.16624 |
| time_elapsed            | 19154     |
| total timesteps         | 251387    |
| train_time              | 5234      |
| update_time             | 13018     |
---------------------------------------
---------------------------------------
| act_time                | 195       |
| current_lr              | 0.0003    |
| discount_q              | 0.0417    |
| env_time                | 409       |
| ep_rewmean              | 1.1e+03   |
| episodes                | 2136      |
| eplenmean               | 335       |
| fps                     | 13        |
| mean 100 episode reward | 1.10e+03  |
| n_updates               | 455400    |
| q_grad_norm             | 1552.8864 |
| qfs_loss                | 45.40172  |
| qs_abs_difference       | 10.1      |
| qs_difference           | 7.27      |
| qs_mean                 | 280.51733 |
| time_elapsed            | 19245     |
| total timesteps         | 252638    |
| train_time              | 5264      |
| update_time             | 13075     |
---------------------------------------
---------------------------------------
| act_time                | 196       |
| current_lr              | 0.0003    |
| discount_q              | 0.00423   |
| env_time                | 411       |
| ep_rewmean              | 1.11e+03  |
| episodes                | 2140      |
| eplenmean               | 335       |
| fps                     | 13        |
| mean 100 episode reward | 1.11e+03  |
| n_updates               | 458000    |
| q_grad_norm             | 2590.282  |
| qfs_loss                | 50.701847 |
| qs_abs_difference       | 27        |
| qs_difference           | 26.3      |
| qs_mean                 | 250.92851 |
| time_elapsed            | 19335     |
| total timesteps         | 253948    |
| train_time              | 5294      |
| update_time             | 13131     |
---------------------------------------
---------------------------------------
| act_time                | 197       |
| current_lr              | 0.0003    |
| discount_q              | 10.6      |
| env_time                | 412       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2144      |
| eplenmean               | 324       |
| fps                     | 13        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 459400    |
| q_grad_norm             | 1740.1433 |
| qfs_loss                | 35.078762 |
| qs_abs_difference       | 6.32      |
| qs_difference           | 4         |
| qs_mean                 | 284.6382  |
| time_elapsed            | 19384     |
| total timesteps         | 254678    |
| train_time              | 5309      |
| update_time             | 13163     |
---------------------------------------
---------------------------------------
| act_time                | 197       |
| current_lr              | 0.0003    |
| discount_q              | 0.196     |
| env_time                | 414       |
| ep_rewmean              | 1.07e+03  |
| episodes                | 2148      |
| eplenmean               | 322       |
| fps                     | 13        |
| mean 100 episode reward | 1.07e+03  |
| n_updates               | 461600    |
| q_grad_norm             | 2284.0076 |
| qfs_loss                | 41.21765  |
| qs_abs_difference       | 7.23      |
| qs_difference           | 3.16      |
| qs_mean                 | 269.9771  |
| time_elapsed            | 19459     |
| total timesteps         | 255700    |
| train_time              | 5333      |
| update_time             | 13211     |
---------------------------------------
Terminated
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

{'env_type': 'mujoco', 'env_id': 'Hopper-v3', 'agent': 'GEM', 'layer_norm': False, 'evaluation': True, 'seed': 4, 'comment': 'hopper_gem+tbp_4', 'gamma': 0.99, 'num_timesteps': 400001, 'max_steps': 1000, 'delay_step': 0}
Logging to ./log_gem/mujoco/gem+tbp/hopper_gem+tbp_4
max_step:  1000
Box(-inf, inf, (11,), float64) Box(-1.0, 1.0, (3,), float32)
max_step:  1000
seed=4, logdir=./log_gem/mujoco/gem+tbp/hopper_gem+tbp_4
/home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.
  warnings.warn(message, FutureWarning)
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/run/train.py:30: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2022-05-05 22:30:42.000483: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-05-05 22:30:42.024493: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz
2022-05-05 22:30:42.025002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560d617fc960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-05-05 22:30:42.025039: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:98: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/policies.py:283: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.Dense instead.
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:138: The name tf.random_normal is deprecated. Please use tf.random.normal instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:203: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/common/tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:226: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.

WARNING:tensorflow:From /home/lizhuo/miniconda/envs/gem/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:251: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:261: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /home/lizhuo/workspace/GEM/gem_mujoco/stable_baselines/td3/td3_mem_gem.py:264: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

GEM Agent Here
TD3 Update Memory Many Agent here
here (?, 1)
model building finished
--------------------------------------
| eval mean 100 episod... | 4.9      |
| eval_abs_qs_difference  | 3.340407 |
| eval_discount_q         | 4.79     |
| eval_ep_rewmean         | 4.93     |
| eval_eplenmean          | 8        |
| eval_qs                 | -1.04297 |
| eval_qs_difference      | -3.34    |
| eval_time_elapsed       | 0        |
| total timesteps         | 1        |
--------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.42       |
| env_time                | 0          |
| ep_rewmean              | 12         |
| episodes                | 4          |
| eplenmean               | 18.5       |
| fps                     | 78         |
| mean 100 episode reward | 12         |
| n_updates               | 0          |
| qs_abs_difference       | 5.42       |
| qs_difference           | -5.42      |
| qs_mean                 | -0.3848826 |
| time_elapsed            | 0          |
| total timesteps         | 74         |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 8.49        |
| env_time                | 0           |
| ep_rewmean              | 13.5        |
| episodes                | 8           |
| eplenmean               | 17.5        |
| fps                     | 99          |
| mean 100 episode reward | 13.5        |
| n_updates               | 0           |
| qs_abs_difference       | 6.4         |
| qs_difference           | -6.4        |
| qs_mean                 | -0.36110753 |
| time_elapsed            | 1           |
| total timesteps         | 140         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.06        |
| env_time                | 0           |
| ep_rewmean              | 16.8        |
| episodes                | 12          |
| eplenmean               | 19.6        |
| fps                     | 143         |
| mean 100 episode reward | 16.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.06        |
| qs_difference           | -5.06       |
| qs_mean                 | -0.27423665 |
| time_elapsed            | 1           |
| total timesteps         | 235         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 9.43        |
| env_time                | 0           |
| ep_rewmean              | 17.2        |
| episodes                | 16          |
| eplenmean               | 19.4        |
| fps                     | 164         |
| mean 100 episode reward | 17.2        |
| n_updates               | 0           |
| qs_abs_difference       | 9.57        |
| qs_difference           | -9.57       |
| qs_mean                 | -0.52026737 |
| time_elapsed            | 1           |
| total timesteps         | 311         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 6.34       |
| env_time                | 0          |
| ep_rewmean              | 16         |
| episodes                | 20         |
| eplenmean               | 19.1       |
| fps                     | 183        |
| mean 100 episode reward | 16         |
| n_updates               | 0          |
| qs_abs_difference       | 5.61       |
| qs_difference           | -5.61      |
| qs_mean                 | -0.3790978 |
| time_elapsed            | 2          |
| total timesteps         | 383        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.39        |
| env_time                | 1           |
| ep_rewmean              | 16.1        |
| episodes                | 24          |
| eplenmean               | 20.2        |
| fps                     | 203         |
| mean 100 episode reward | 16.1        |
| n_updates               | 0           |
| qs_abs_difference       | 10.3        |
| qs_difference           | -10.3       |
| qs_mean                 | -0.68808156 |
| time_elapsed            | 2           |
| total timesteps         | 485         |
| train_time              | 0           |
| update_time             | 0           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.32       |
| env_time                | 1          |
| ep_rewmean              | 15.6       |
| episodes                | 28         |
| eplenmean               | 19.5       |
| fps                     | 208        |
| mean 100 episode reward | 15.6       |
| n_updates               | 0          |
| qs_abs_difference       | 4.91       |
| qs_difference           | -4.91      |
| qs_mean                 | -0.4453959 |
| time_elapsed            | 2          |
| total timesteps         | 547        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 18.5       |
| env_time                | 1          |
| ep_rewmean              | 15.7       |
| episodes                | 32         |
| eplenmean               | 19.7       |
| fps                     | 216        |
| mean 100 episode reward | 15.7       |
| n_updates               | 0          |
| qs_abs_difference       | 21         |
| qs_difference           | -21        |
| qs_mean                 | -0.8172516 |
| time_elapsed            | 2          |
| total timesteps         | 630        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.34       |
| env_time                | 1          |
| ep_rewmean              | 15.7       |
| episodes                | 36         |
| eplenmean               | 19.5       |
| fps                     | 221        |
| mean 100 episode reward | 15.7       |
| n_updates               | 0          |
| qs_abs_difference       | 8.66       |
| qs_difference           | -8.66      |
| qs_mean                 | -0.7644925 |
| time_elapsed            | 3          |
| total timesteps         | 702        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.6        |
| env_time                | 1          |
| ep_rewmean              | 15.3       |
| episodes                | 40         |
| eplenmean               | 19.2       |
| fps                     | 233        |
| mean 100 episode reward | 15.3       |
| n_updates               | 0          |
| qs_abs_difference       | 8.73       |
| qs_difference           | -8.73      |
| qs_mean                 | -0.6351421 |
| time_elapsed            | 3          |
| total timesteps         | 768        |
| train_time              | 0          |
| update_time             | 0          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 11.4      |
| env_time                | 1         |
| ep_rewmean              | 15.5      |
| episodes                | 44        |
| eplenmean               | 19.5      |
| fps                     | 237       |
| mean 100 episode reward | 15.5      |
| n_updates               | 0         |
| qs_abs_difference       | 11        |
| qs_difference           | -11       |
| qs_mean                 | -0.532496 |
| time_elapsed            | 3         |
| total timesteps         | 859       |
| train_time              | 0         |
| update_time             | 0         |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 10          |
| env_time                | 1           |
| ep_rewmean              | 15.6        |
| episodes                | 48          |
| eplenmean               | 19.3        |
| fps                     | 238         |
| mean 100 episode reward | 15.6        |
| n_updates               | 0           |
| qs_abs_difference       | 9.63        |
| qs_difference           | -9.63       |
| qs_mean                 | -0.91890466 |
| time_elapsed            | 3           |
| total timesteps         | 928         |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.43        |
| env_time                | 1           |
| ep_rewmean              | 15.3        |
| episodes                | 52          |
| eplenmean               | 19.5        |
| fps                     | 238         |
| mean 100 episode reward | 15.3        |
| n_updates               | 0           |
| qs_abs_difference       | 4.34        |
| qs_difference           | -4.34       |
| qs_mean                 | -0.72594327 |
| time_elapsed            | 4           |
| total timesteps         | 1015        |
| train_time              | 0           |
| update_time             | 1           |
-----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 13        |
| env_time                | 1         |
| ep_rewmean              | 16        |
| episodes                | 56        |
| eplenmean               | 19.8      |
| fps                     | 236       |
| mean 100 episode reward | 16        |
| n_updates               | 0         |
| qs_abs_difference       | 16        |
| qs_difference           | -16       |
| qs_mean                 | -0.696199 |
| time_elapsed            | 4         |
| total timesteps         | 1110      |
| train_time              | 0         |
| update_time             | 1         |
---------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 3.91      |
| env_time                | 2         |
| ep_rewmean              | 17.5      |
| episodes                | 60        |
| eplenmean               | 20.4      |
| fps                     | 237       |
| mean 100 episode reward | 17.5      |
| n_updates               | 0         |
| qs_abs_difference       | 5.51      |
| qs_difference           | -5.51     |
| qs_mean                 | -0.260863 |
| time_elapsed            | 5         |
| total timesteps         | 1223      |
| train_time              | 0         |
| update_time             | 1         |
---------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 24.6       |
| env_time                | 2          |
| ep_rewmean              | 18.2       |
| episodes                | 64         |
| eplenmean               | 20.7       |
| fps                     | 235        |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 32         |
| qs_difference           | -32        |
| qs_mean                 | -0.8969805 |
| time_elapsed            | 5          |
| total timesteps         | 1327       |
| train_time              | 0          |
| update_time             | 1          |
----------------------------------------
---------------------------------------
| act_time                | 0         |
| current_lr              | 0.0003    |
| discount_q              | 4.21      |
| env_time                | 2         |
| ep_rewmean              | 18.3      |
| episodes                | 68        |
| eplenmean               | 21.1      |
| fps                     | 232       |
| mean 100 episode reward | 18.3      |
| n_updates               | 0         |
| qs_abs_difference       | 2.78      |
| qs_difference           | -2.78     |
| qs_mean                 | -0.590343 |
| time_elapsed            | 6         |
| total timesteps         | 1433      |
| train_time              | 0         |
| update_time             | 2         |
---------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 7.16        |
| env_time                | 2           |
| ep_rewmean              | 17.8        |
| episodes                | 72          |
| eplenmean               | 20.7        |
| fps                     | 238         |
| mean 100 episode reward | 17.8        |
| n_updates               | 0           |
| qs_abs_difference       | 5.81        |
| qs_difference           | -5.81       |
| qs_mean                 | -0.37437433 |
| time_elapsed            | 6           |
| total timesteps         | 1490        |
| train_time              | 0           |
| update_time             | 2           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 4.71        |
| env_time                | 2           |
| ep_rewmean              | 18.4        |
| episodes                | 76          |
| eplenmean               | 21          |
| fps                     | 238         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 6.13        |
| qs_difference           | -6.13       |
| qs_mean                 | -0.39103475 |
| time_elapsed            | 6           |
| total timesteps         | 1599        |
| train_time              | 0           |
| update_time             | 2           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 11.8       |
| env_time                | 2          |
| ep_rewmean              | 18.1       |
| episodes                | 80         |
| eplenmean               | 20.9       |
| fps                     | 235        |
| mean 100 episode reward | 18.1       |
| n_updates               | 0          |
| qs_abs_difference       | 10.2       |
| qs_difference           | -10.2      |
| qs_mean                 | -0.4167471 |
| time_elapsed            | 7          |
| total timesteps         | 1671       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.96       |
| env_time                | 3          |
| ep_rewmean              | 17.9       |
| episodes                | 84         |
| eplenmean               | 21         |
| fps                     | 232        |
| mean 100 episode reward | 17.9       |
| n_updates               | 0          |
| qs_abs_difference       | 6.73       |
| qs_difference           | -6.73      |
| qs_mean                 | -0.6758159 |
| time_elapsed            | 7          |
| total timesteps         | 1767       |
| train_time              | 0          |
| update_time             | 2          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.55        |
| env_time                | 3           |
| ep_rewmean              | 17.6        |
| episodes                | 88          |
| eplenmean               | 20.9        |
| fps                     | 229         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 3.94        |
| qs_difference           | -3.94       |
| qs_mean                 | -0.69670206 |
| time_elapsed            | 8           |
| total timesteps         | 1843        |
| train_time              | 0           |
| update_time             | 3           |
-----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.65        |
| env_time                | 3           |
| ep_rewmean              | 17.6        |
| episodes                | 92          |
| eplenmean               | 21.2        |
| fps                     | 229         |
| mean 100 episode reward | 17.6        |
| n_updates               | 0           |
| qs_abs_difference       | 6.06        |
| qs_difference           | -6.06       |
| qs_mean                 | -0.80524707 |
| time_elapsed            | 8           |
| total timesteps         | 1953        |
| train_time              | 0           |
| update_time             | 3           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.91       |
| env_time                | 3          |
| ep_rewmean              | 17.4       |
| episodes                | 96         |
| eplenmean               | 21.1       |
| fps                     | 225        |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 3.77       |
| qs_difference           | -3.77      |
| qs_mean                 | -0.5649665 |
| time_elapsed            | 8          |
| total timesteps         | 2025       |
| train_time              | 0          |
| update_time             | 3          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 18.4       |
| env_time                | 3          |
| ep_rewmean              | 17.4       |
| episodes                | 100        |
| eplenmean               | 21.2       |
| fps                     | 222        |
| mean 100 episode reward | 17.4       |
| n_updates               | 0          |
| qs_abs_difference       | 18.6       |
| qs_difference           | -18.6      |
| qs_mean                 | -0.7253627 |
| time_elapsed            | 9          |
| total timesteps         | 2125       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.28        |
| env_time                | 3           |
| ep_rewmean              | 17.3        |
| episodes                | 104         |
| eplenmean               | 21          |
| fps                     | 225         |
| mean 100 episode reward | 17.3        |
| n_updates               | 0           |
| qs_abs_difference       | 4.33        |
| qs_difference           | -4.33       |
| qs_mean                 | -0.38982967 |
| time_elapsed            | 9           |
| total timesteps         | 2175        |
| train_time              | 0           |
| update_time             | 4           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.65       |
| env_time                | 3          |
| ep_rewmean              | 17.3       |
| episodes                | 108        |
| eplenmean               | 21.2       |
| fps                     | 221        |
| mean 100 episode reward | 17.3       |
| n_updates               | 0          |
| qs_abs_difference       | 5.51       |
| qs_difference           | -5.51      |
| qs_mean                 | -0.5691765 |
| time_elapsed            | 10         |
| total timesteps         | 2265       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.36       |
| env_time                | 3          |
| ep_rewmean              | 17.1       |
| episodes                | 112        |
| eplenmean               | 21.4       |
| fps                     | 219        |
| mean 100 episode reward | 17.1       |
| n_updates               | 0          |
| qs_abs_difference       | 3.84       |
| qs_difference           | -3.84      |
| qs_mean                 | -0.9424502 |
| time_elapsed            | 10         |
| total timesteps         | 2371       |
| train_time              | 0          |
| update_time             | 4          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 8.13       |
| env_time                | 4          |
| ep_rewmean              | 17         |
| episodes                | 116        |
| eplenmean               | 21.5       |
| fps                     | 217        |
| mean 100 episode reward | 17         |
| n_updates               | 0          |
| qs_abs_difference       | 8.24       |
| qs_difference           | -8.24      |
| qs_mean                 | -0.5325761 |
| time_elapsed            | 11         |
| total timesteps         | 2460       |
| train_time              | 0          |
| update_time             | 5          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 5.85        |
| env_time                | 4           |
| ep_rewmean              | 17.1        |
| episodes                | 120         |
| eplenmean               | 21.7        |
| fps                     | 214         |
| mean 100 episode reward | 17.1        |
| n_updates               | 0           |
| qs_abs_difference       | 6.36        |
| qs_difference           | -6.36       |
| qs_mean                 | -0.75633615 |
| time_elapsed            | 11          |
| total timesteps         | 2551        |
| train_time              | 0           |
| update_time             | 5           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 3.28       |
| env_time                | 4          |
| ep_rewmean              | 16.9       |
| episodes                | 124        |
| eplenmean               | 21.4       |
| fps                     | 210        |
| mean 100 episode reward | 16.9       |
| n_updates               | 0          |
| qs_abs_difference       | 3.93       |
| qs_difference           | -3.93      |
| qs_mean                 | -0.7929263 |
| time_elapsed            | 12         |
| total timesteps         | 2629       |
| train_time              | 0          |
| update_time             | 6          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 5.37       |
| env_time                | 4          |
| ep_rewmean              | 16.8       |
| episodes                | 128        |
| eplenmean               | 21.7       |
| fps                     | 207        |
| mean 100 episode reward | 16.8       |
| n_updates               | 0          |
| qs_abs_difference       | 4.45       |
| qs_difference           | -4.44      |
| qs_mean                 | -0.5697715 |
| time_elapsed            | 13         |
| total timesteps         | 2715       |
| train_time              | 0          |
| update_time             | 6          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.92        |
| env_time                | 4           |
| ep_rewmean              | 17.5        |
| episodes                | 132         |
| eplenmean               | 21.9        |
| fps                     | 205         |
| mean 100 episode reward | 17.5        |
| n_updates               | 0           |
| qs_abs_difference       | 4.45        |
| qs_difference           | -4.45       |
| qs_mean                 | -0.47693938 |
| time_elapsed            | 13          |
| total timesteps         | 2822        |
| train_time              | 0           |
| update_time             | 6           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.71       |
| env_time                | 4          |
| ep_rewmean              | 17.6       |
| episodes                | 136        |
| eplenmean               | 22.1       |
| fps                     | 203        |
| mean 100 episode reward | 17.6       |
| n_updates               | 0          |
| qs_abs_difference       | 3.01       |
| qs_difference           | -3.01      |
| qs_mean                 | -0.5006492 |
| time_elapsed            | 14         |
| total timesteps         | 2916       |
| train_time              | 0          |
| update_time             | 7          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 30.9        |
| env_time                | 4           |
| ep_rewmean              | 18.4        |
| episodes                | 140         |
| eplenmean               | 22.6        |
| fps                     | 201         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 37.5        |
| qs_difference           | -37.5       |
| qs_mean                 | -0.83565927 |
| time_elapsed            | 15          |
| total timesteps         | 3029        |
| train_time              | 0           |
| update_time             | 7           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 7.61       |
| env_time                | 4          |
| ep_rewmean              | 18.2       |
| episodes                | 144        |
| eplenmean               | 22.4       |
| fps                     | 197        |
| mean 100 episode reward | 18.2       |
| n_updates               | 0          |
| qs_abs_difference       | 8.3        |
| qs_difference           | -8.3       |
| qs_mean                 | -0.7199851 |
| time_elapsed            | 15         |
| total timesteps         | 3102       |
| train_time              | 0          |
| update_time             | 8          |
----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 26         |
| env_time                | 5          |
| ep_rewmean              | 19.1       |
| episodes                | 148        |
| eplenmean               | 23.2       |
| fps                     | 196        |
| mean 100 episode reward | 19.1       |
| n_updates               | 0          |
| qs_abs_difference       | 42.8       |
| qs_difference           | -42.8      |
| qs_mean                 | -0.5345302 |
| time_elapsed            | 16         |
| total timesteps         | 3251       |
| train_time              | 0          |
| update_time             | 8          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 3.42        |
| env_time                | 5           |
| ep_rewmean              | 19.4        |
| episodes                | 152         |
| eplenmean               | 23.2        |
| fps                     | 192         |
| mean 100 episode reward | 19.4        |
| n_updates               | 0           |
| qs_abs_difference       | 3.39        |
| qs_difference           | -3.39       |
| qs_mean                 | -0.85648227 |
| time_elapsed            | 17          |
| total timesteps         | 3332        |
| train_time              | 0           |
| update_time             | 9           |
-----------------------------------------
----------------------------------------
| act_time                | 0          |
| current_lr              | 0.0003     |
| discount_q              | 4.22       |
| env_time                | 5          |
| ep_rewmean              | 19.3       |
| episodes                | 156        |
| eplenmean               | 23.5       |
| fps                     | 191        |
| mean 100 episode reward | 19.3       |
| n_updates               | 0          |
| qs_abs_difference       | 5.17       |
| qs_difference           | -5.17      |
| qs_mean                 | -0.6443573 |
| time_elapsed            | 18         |
| total timesteps         | 3456       |
| train_time              | 0          |
| update_time             | 9          |
----------------------------------------
-----------------------------------------
| act_time                | 0           |
| current_lr              | 0.0003      |
| discount_q              | 6.75        |
| env_time                | 5           |
| ep_rewmean              | 18.4        |
| episodes                | 160         |
| eplenmean               | 23.2        |
| fps                     | 187         |
| mean 100 episode reward | 18.4        |
| n_updates               | 0           |
| qs_abs_difference       | 4.89        |
| qs_difference           | -4.89       |
| qs_mean                 | -0.36995542 |
| time_elapsed            | 18          |
| total timesteps         | 3539        |
| train_time              | 0           |
| update_time             | 10          |
-----------------------------------------
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
Terminated
